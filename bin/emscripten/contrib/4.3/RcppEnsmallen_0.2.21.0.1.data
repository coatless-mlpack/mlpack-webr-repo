Ensmallen is written by a team of talented developers listed in the COPYRIGHTS.txt
file:

  ensmallen: a flexible C++ library for efficient function optimization.
  Copyright 2008-2018, Ryan Curtin <ryan@ratml.org>
  Copyright 2008-2012, Dongryeol Lee <dongryel@cc.gatech.edu>
  Copyright 2010-2012, James Cline <james.cline@gatech.edu>
  Copyright 2013-2018, Marcus Edel <marcus.edel@fu-berlin.de>
  Copyright 2013-2018, Sumedh Ghaisas <sumedhghaisas@gmail.com>
  Copyright 2013, Mudit Raj Gupta <mudit.raaj.gupta@gmail.com>
  Copyright 2014, Ryan Birmingham <birm@gatech.edu>
  Copyright 2014, Siddharth Agrawal <siddharth.950@gmail.com>
  Copyright 2014-2015, Stephen Tu <tu.stephenl@gmail.com>
  Copyright 2015&2017, Shangtong Zhang <zhangshangtong.cpp@gmail.com>
  Copyright 2016, Shikhar Bhardwaj <shikharbhardwaj68@gmail.com>
  Copyright 2016, Mike Izbicki <mike@izbicki.me>
  Copyright 2016, Ranjan Mondal <ranjan.rev@gmail.com>
  Copyright 2017, Vivek Pal <vivekpal.dtu@gmail.com>
  Copyright 2017-2018, Sourabh Varshney <sourabhvarshney111@gmail.com>
  Copyright 2017, Chenzhe Diao <williamdiao@gmail.com>
  Copyright 2017, Abhinav Moudgil <abhinavmoudgil95@gmail.com>
  Copyright 2017, Konstantin Sidorov <partobs.mdp@gmail.com>
  Copyright 2017, Kirill Mishchenko <ki.mishchenko@gmail.com>
  Copyright 2017&2019, N Rajiv Vaidyanathan <rajivvaidyanathan4@gmail.com>
  Copyright 2017, Kartik Nighania <kartiknighania@gmail.com>
  Copyright 2017-2018, Manish Kumar <manish887kr@gmail.com>
  Copyright 2017-2018, Haritha Sreedharan Nair <haritha1313@gmail.com>
  Copyright 2018, B Kartheek Reddy <bkartheekreddy@gmail.com>
  Copyright 2018, Moksh Jain <mokshjn00@gmail.com>
  Copyright 2018, Shikhar Jaiswal <jaiswalshikhar87@gmail.com>
  Copyright 2018, Conrad Sanderson
  Copyright 2018, Dan Timson
  Copyright 2019, Rahul Ganesh Prabhu
  Copyright 2019, Roberto Hueso <robertohueso96@gmail.com>
  Copyright 2019, Sayan Goswami <sayan.goswami.106@gmail.com>
  Copyright 2020, Joe Dinius <josephwdinius@gmail.com>

The RcppEnsmallen package provides an integration of Ensmallen and its dependences
into R. RcppEnsmallen accomplishes this by linking into RcppArmadillo,
establishing plugins, examples, and more. The R implementation was done by James
Joseph Balamuta and Dirk Eddelbuettel with additional contributions by
contributors listed in the ChangeLog.
citHeader("To cite the 'RcppEnsmallen' R package and 'Ensmallen' libray in publications, please use:")

bibentry(bibtype = "Manual",
         title        = "{RcppEnsmallen: Header-Only C++ Mathematical Optimization Library for 'Armadillo'}",
         author       = c(as.person("James Joseph Balamuta"),
                          as.person("Dirk Eddelbuettel")
                          ),
         year         = 2018,
         textVersion  = paste("Balamuta, J.J. and Eddelbuettel, D. (2018)",
                              "RcppEnsmallen: Header-Only C++ Mathematical Optimization Library for 'Armadillo'.",
                              "URL https://cran.r-project.org/package=RcppEnsmallen.")
)

bibentry(bibtype = "Article",
         title        = "{ensmallen: a flexible C++ library for efficient function optimization}",
         author       = c(as.person("Shikhar Bhardwaj"),
                          as.person("Ryan R. Curtin"),
                          as.person("Marcus Edel"),
                          as.person("Yannis Mentekidis"),
                          as.person("Conrad Sanderson")),
           journal = "Workshop on Systems for ML and Open Source Software at NIPS",
           year = "2018",
           month = "dec",
         textVersion  = paste("S. Bhardwaj, R. Curtin, M. Edel, Y. Mentekidis, and C. Sanderson (2018).",
                              "ensmallen: a flexible C++ library for efficient function optimization.",
                              "Workshop on Systems for ML and Open Source Software at NIPS 2018.",
                              "URL http://www.ensmallen.org/files/ensmallen_2018.pdf.")
)
Overall license:
================

   The underlying ensmallen library is released under the
   BSD-3-Clause, July 1999 (https://opensource.org/licenses/BSD-3-Clause)

   The aggregation, integration and packaging work is released under the
   GNU GPL (>= 2).

Details:
========

Files: *
Copyright: 2018 - 2019 James Joseph Balamuta and Dirk Eddelbuettel
License: GPL (>= 2)

Files: inst/include/ensmallen.h:
       inst/include/ensmallen_bits/*:
Copyright:
  Copyright 2008-2018, Ryan Curtin <ryan@ratml.org>
  Copyright 2008-2012, Dongryeol Lee <dongryel@cc.gatech.edu>
  Copyright 2010-2012, James Cline <james.cline@gatech.edu>
  Copyright 2013-2018, Marcus Edel <marcus.edel@fu-berlin.de>
  Copyright 2013-2018, Sumedh Ghaisas <sumedhghaisas@gmail.com>
  Copyright 2013, Mudit Raj Gupta <mudit.raaj.gupta@gmail.com>
  Copyright 2014, Ryan Birmingham <birm@gatech.edu>
  Copyright 2014, Siddharth Agrawal <siddharth.950@gmail.com>
  Copyright 2014-2015, Stephen Tu <tu.stephenl@gmail.com>
  Copyright 2015&2017, Shangtong Zhang <zhangshangtong.cpp@gmail.com>
  Copyright 2016, Shikhar Bhardwaj <shikharbhardwaj68@gmail.com>
  Copyright 2016, Mike Izbicki <mike@izbicki.me>
  Copyright 2016, Ranjan Mondal <ranjan.rev@gmail.com>
  Copyright 2017, Vivek Pal <vivekpal.dtu@gmail.com>
  Copyright 2017-2018, Sourabh Varshney <sourabhvarshney111@gmail.com>
  Copyright 2017, Chenzhe Diao <williamdiao@gmail.com>
  Copyright 2017, Abhinav Moudgil <abhinavmoudgil95@gmail.com>
  Copyright 2017, Konstantin Sidorov <partobs.mdp@gmail.com>
  Copyright 2017, Kirill Mishchenko <ki.mishchenko@gmail.com>
  Copyright 2017&2019, N Rajiv Vaidyanathan <rajivvaidyanathan4@gmail.com>
  Copyright 2017, Kartik Nighania <kartiknighania@gmail.com>
  Copyright 2017-2018, Manish Kumar <manish887kr@gmail.com>
  Copyright 2017-2018, Haritha Sreedharan Nair <haritha1313@gmail.com>
  Copyright 2018, B Kartheek Reddy <bkartheekreddy@gmail.com>
  Copyright 2018, Moksh Jain <mokshjn00@gmail.com>
  Copyright 2018, Shikhar Jaiswal <jaiswalshikhar87@gmail.com>
  Copyright 2018, Conrad Sanderson
  Copyright 2018, Dan Timson
  Copyright 2019, Rahul Ganesh Prabhu
  Copyright 2019, Roberto Hueso <robertohueso96@gmail.com>
  Copyright 2019, Sayan Goswami <sayan.goswami.106@gmail.com>
  Copyright 2020, Joe Dinius <josephwdinius@gmail.com>

License: BSD-3-clause
  All rights reserved.
  .
  Redistribution and use of mlpack in source and binary forms, with or without
  modification, are permitted provided that the following conditions are met:
  .
  1. Redistributions of source code must retain the above copyright notice, this
  list of conditions and the following disclaimer.
  .
  2. Redistributions in binary form must reproduce the above copyright notice,
  this list of conditions and the following disclaimer in the documentation and/or
  other materials provided with the distribution.
  .
  3. Neither the name of the copyright holder nor the names of its contributors
  may be used to endorse or promote products derived from this software without
  specific prior written permission.
  .
  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
  WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR
  ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
  (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
  LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
  ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
  SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
Package: RcppEnsmallen
Title: Header-Only C++ Mathematical Optimization Library for
        'Armadillo'
Version: 0.2.21.0.1
Authors@R: c(
    person("James Joseph", "Balamuta", email = "balamut2@illinois.edu", 
           role = c("aut", "cre", "cph"), 
           comment = c(ORCID = "0000-0003-2826-8458")),
    person("Dirk", "Eddelbuettel", email = "edd@debian.org", 
           role = c("aut", "cph"),
           comment = c(ORCID = "0000-0001-6419-907X"))
    )
Description: 'Ensmallen' is a templated C++ mathematical optimization library 
 (by the 'MLPACK' team) that provides a simple set of abstractions for writing an
 objective function to optimize. Provided within are various standard and
 cutting-edge optimizers that include full-batch gradient descent techniques, 
 small-batch techniques, gradient-free optimizers, and constrained optimization.
 The 'RcppEnsmallen' package includes the header files from the 'Ensmallen' library
 and pairs the appropriate header files from 'armadillo' through the 
 'RcppArmadillo' package. Therefore, users do not need to install 'Ensmallen' nor
 'Armadillo' to use 'RcppEnsmallen'. Note that 'Ensmallen' is licensed under 
 3-Clause BSD, 'Armadillo' starting from 7.800.0 is licensed under Apache License 2,
 'RcppArmadillo' (the 'Rcpp' bindings/bridge to 'Armadillo') is licensed under 
 the GNU GPL version 2 or later. Thus, 'RcppEnsmallen' is also licensed under
 similar terms. Note that 'Ensmallen' requires a compiler that supports 
 'C++11' and 'Armadillo' 9.800 or later.
Depends: R (>= 4.0.0)
License: GPL (>= 2)
URL: https://github.com/coatless-rpkg/rcppensmallen,
        https://r-pkg.thecoatlessprofessor.com/rcppensmallen/,
        https://github.com/mlpack/ensmallen, https://ensmallen.org/
BugReports: https://github.com/coatless-rpkg/rcppensmallen/issues
Encoding: UTF-8
LinkingTo: Rcpp, RcppArmadillo (>= 0.9.800.0.0)
Imports: Rcpp
RoxygenNote: 7.2.3
Suggests: knitr, rmarkdown
VignetteBuilder: knitr
NeedsCompilation: yes
Packaged: 2023-11-27 20:38:47 UTC; ronin
Author: James Joseph Balamuta [aut, cre, cph]
    (<https://orcid.org/0000-0003-2826-8458>),
  Dirk Eddelbuettel [aut, cph] (<https://orcid.org/0000-0001-6419-907X>)
Maintainer: James Joseph Balamuta <balamut2@illinois.edu>
Repository: RSPM
Date/Publication: 2023-11-27 21:20:03 UTC
Built: R 4.3.2; wasm32-unknown-emscripten; 2024-01-16 09:11:04 UTC; unix
RcppEnsmallen-package   RcppEnsmallen: Header-Only C++ Mathematical
                        Optimization Library for 'Armadillo'
lin_reg_lbfgs           Linear Regression with L-BFGS
ã      }QAk¬0Õle*8Ï2»ÕÉ¥06∆∂õ›∆úı‡M>€X√“§§ÈN˚Â∫tk§)sá‰˚Úﬁ˜Ø_ÑêÖl´Ç¨™j—Yo<{Y.Æ›ÁÍ˛ˆNëmÖ÷‘i©SA6™´z1ı¢h¿„#‹â¿˚ÄÄ∏S?Á[åÚ•$¡í≠÷Aú·¶˛¸O}N6qIyjŒ¢˝n?‡g>ëŒÑ≥˜ª]¸…ÜÑêPûD	Èßz	éGt%A¶x-$ÓÙd>eLtrﬂÀÂ$ûí@í8Œ[öl»y>ÕJ!P!\˚7˘¶Úˇï¸*Oé≠¶hè
ınW
fU!—˚≠Â†=§L/◊´›œ”H˜’9MCµ˜ÑOy†PèQàïoN˜˜HîﬁØ$›
È«Â0ÉXá—`√á‹µÃbò„u)∂ÆŒﬂÃ>ˆK]˚˝~ß Ó?NÖ÷  ã      ã‡b```f`afb`f2¯˝Ç=„#åıLt-Õ,òÑÅ¢å@, ¶Y8Å¥äQZJöY≤°ÖÆô•y¢ÆIR¢πníEjöÆ°a≤Aä•Qö°±ë9í÷ºƒ‹‘b4É∏3ÛJRãÚsä=]Ä‹ zÓjê   ã      µRﬂO¬0.€»ƒDCb|4Èd&®1ËÚCâ`¬)[ç]ªtK˛Òbù∏A|·“ªØw˜ıæÎ‰ †C◊Ä^î.8oÙF›È‰ˆ˙Œ™=‹◊%r!Õ @+«∑“+…ÛlËAõÖ>¢≥<dŒB-qnîsô*≥‰| '=)aSÅΩ)ùÕΩPÅÉT≈#|¡»≈¬Í3∫ÇÕjæ°hÅ}Qÿ"‚ìOqm2H¨‡úXiπÑR^Q}Øl¬0pà=Å√0.XíhmÎ©Û< ˝–3ãÔ„éUO¿–‚Ÿ®ªƒè´•i ÃL âLa»«°⁄D|˜%≠º…›ÊòÉîf¶úr %P°÷m)œË…F…{∆$¢ªÄƒI€Ã·.aﬁñi≥˜Rﬁ_‡ÓÏ˝Ü„V‹»VXˇíSﬂZåkÎÚÈ…ÙJP∏ß÷è™;¿p$ã˘äWK.‹ÁirÊ‡  Â˘˚;g˜  ã      ã‡b```f`afb`f2¯˝Ç=„#åıLt-Õ,ò *8Å¥±ûû>%∏ÊÁ&Ê‰§ÊÈgî‰Ê†
È$&g'¶ßÍÅ§(◊™çSkNf^|Qjz|NRZz1DP#T+k^bnj1êÅÏ^ì†Ç¢Xù”ÅbP‡ ∂%ªß9  ã      uQ—jÉ0ç∆"V⁄9¸éF«ÿGŸ`ïb_˙&Q3àQLÌœoKLtj7!‹‹sœΩ˜úx\  p†‡B^¡˙9:º%«ÕÌ˝Õ›”√# v(Q_-myÇ.wÄ'£gu=√<^µMÜ∑Ö%,ipë–ÙΩ‡¶Ã‰q˛éˆdò⁄¸¬xâ(≈L*±G≈C%Ó7Ù†˙æå/ÈÜ› ∞4˛¨ŸF{Ë˙’Î€‘°¡ØZéc\.$H≈ÏÛsôV4ÍîhË∫—^…IIúÍŒ(‚s›A$˘ü8ÆZAﬁ°Z˚òh˘ÔU:√¡Ø¯ÅsR*æ˘ß⁄ÂÂ\ﬂ–]R÷U#z#.>ç”µN˜H‹∞]Èû≠≤Ñg‡ãè*@›?cjp GÃŸ:7?3J“AøZèzáMiJ≥?≥™i~  ã      ’Vmo€6vúdI‹u-P`≈Äa ÇNPK∂Â4omÉÊm]∫º¡Iä√P–csëHï§ízˇe_ˆC∑)—ñTgi˜i3`H"èœ=˜‹ë«∑µJ•2]ôôÆV¶g·µÚ’ˆÒŸ¡ª∑w≈io¨Æ√‰#ùØT™·˘ue¶≤ œ˚]?é˜ôåpñnˇHp@Ñs¬¬!⁄}Úa5 V‘«!:âçËo≈:§=Å≈]rQ´oã4y=™µ\œı⁄nÀmß#Sá˛R¡/&Br∂¥¯GD¢◊\íx∞ÿ@ã;8ƒQ¢0ºÉC¢h±óéy/ö2N•KÇPˆ<$`Î/-‚Di _Û ÿÂ¢©œ£à0e¨O∫ª{⁄G~¸;é∑Ó≠:Î+O◊óóÆ{T\iÃ˝  a/!Jë0œì¡ÀÄÙ(f.˝;	füL¨Ì¨Æ¥7úç÷⁄[ fñ-ßöŒ|[%∞é®D)≈!V$0ŸãÚŸ„˘ÏÖYˆjh©7D`ÖÍGáß€ª?’GÀ0Ñäø¶—¿í0Aí(ƒ/ÓI%∞Ø°§Æ t#®¢¨è0´!ﬁ˚ï¿‘5Aó	36HqÎû∏Ë4E–U ]cAy"ëTòX ‘êü(çÍê†OF B¶‰(Û√$–N¬–ÈaÂP_@j!Å≥Øüä¯Fﬂ'DÍú©2”¸å]Ê\
í˜”–, 9LK0ŒkË÷–π÷≠∞èÍ(∆˛∫=iƒòmÖ.ióÇG©‰πeYBj∆eå©H‚r
)ù R«£}÷Ç'˝ÅYUKYçw•eÂj Ç@∆H%Rkpƒ∏Bå@xê&
¡•7[Âˆ∏∂É≈Â–]tÃÅ¶IN©0C
Èê‡!a:ÑÍ8ª!÷;g{ç6∏¶îLÑkÓz´Â∂&`lCHÍa:äº∆«A/)õü:ÍQ ™lˆ’’!‰º.O$©óø:æ@ØN—5h•+ŸCPÌzá	≠e5R. ΩC…Kp5ΩÉhàTûà‰mZ	Ú>°¬Ï88bHµHçd«\(©s[ª›ÆõJ…+∑°µ”ÀN‚/ªhiÎZÅ£∏µlOgëıÏ»•bπŸlˆaO&=ú7}éîötD|’o
àíX¢çöµL∫†îµÜzΩÑ£∞™9^ñsÖ∫8õcldçFC˙TmfLü~”&ï6y∂xˆ‚¸g=˚¯^'ÆÅ
EcTiπiŸçõ—Vdz['˚xx≈® ‚*‡7∂ìŒöÒÏcz8bù◊Ú:NªÌxk»kmv÷7W÷–≈˘Ó3Ëå⁄’øÁª#≤≠˝§Å|Ωy°â¸bz¡“s+>åTz⁄ñÈ8∫ë°|≥êÄˆèHπ&¥e5q&ì|>±koçÑ<;= ﬁÁµhoÇ≠é÷¬^F∫Pµ◊{Ün∞å:ûì∞+
;$íæ†±"ÏhË≠8@ØΩäZõÌˆfk%ï3aÙ∏´–îÕ	”Ñu“r˜†π”Ùh¥6ÁJ…ŒΩIw}ˆπ∞ù®Úe7∏∑GR&cõπ=≈ÿtœeÁì-ÑãÓ°›É;IøKÃûŒFÊ˜ôœı!e›RvüÁ‹ÇDy˚{]˛aÿ'Lü$‚,È˜âô<xC˚L'z'°!úB∂hè·¥óªÊÄ¡9ÚÛôAˆ˝E∞e|MPÈF8—H™∏Z‰=8{ößINø<Ú¨&†‡ÂO∏ÜÍÎËLv-ù“WQsÅ5cÊY-ÁÕ±¥yõ∂û∫Ô‰P¬}Á›u!I≤VWfIDıG√ÜäA¥næπµÃJÜèo)∫íŸÃ∏ß˛ Êf≤π©ÓHr» Ù„».“Z˘OŒ‘0&9’¶K. ¶8P›zqã∞ŸO≥©Z6’£Y!õçΩµ,nO π¢ÿ≠ˇ$&ÇJ	†íõ´fœ©RPYW(.ú*xÉî/å{Ãù Ö˘j—˚«hyó]ßÌÔÛºñ÷ﬁ©Õ'˙òX=˜M¸ŒJöÕ“≥”Ë?QQÛïøt|ay—¸®'ÌüÌvNœNéãáov‡tÉBáZ∞ﬂﬁ‰Vn)•&îkRE˝¨˙è2˝r≠“”Ùˇ]`ße∑  ã      uPªN√0uì¥–JH@Ö`Ù –L|BÈ¢ï	F+1¡¬è»và`‚Àõﬁ$6"U|_ÁücøÃBJ‚E1îÒ¬Œi?GS»g%Õ>h¡ïÖòô{‡≤≤\ìï%SVR!òÍ‡!ˇ˙π]√÷n√Ê
øÍ ‡u≠0¡õ^¡nµ¯l)˜\1j0aÖa÷r≠pßà*…œ∫t\ÚoÍ ⁄=ö~wRx‰ÍêÎﬁÄ|æ8¯J Ê›rOBÚ?Û§ùç¸•cE%≥ú¯a≤‚"¸¡¯âªﬂ&ﬁ,Wæ_-¯…≠oèÔÿW≠ÙC°©—uƒNZg?ö¶ŸÓ; µ¡QŒrÍh˙fÄ›vYñá/  # Generated by roxygen2: do not edit by hand

export(lin_reg_lbfgs)
importFrom(Rcpp,sourceCpp)
useDynLib(RcppEnsmallen, .registration=TRUE)
# RcppEnsmallen 0.2.21.0.1

- Upgraded to ensmallen 2.21.0: "Stripped Bolt Head" (2023-11-27)
  - Clarify return values for different callback types
    ([#383](https://github.com/mlpack/ensmallen/pull/383)).
  - Fix return types of callbacks
    ([#382](https://github.com/mlpack/ensmallen/pull/382)).
  - Minor cleanup for printing optimization reports via `Report()`
    ([#385](https://github.com/mlpack/ensmallen/pull/385)).
- Updated vignettes to account for R 4.0.0 change. ([#61](https://github.com/coatless-rpkg/rcppensmallen/pull/61))
- Added pkgdown website URL to DESCRIPTION. 

# RcppEnsmallen 0.2.20.0.1

- Upgraded to ensmallen 2.20.0: "Eight Ball Deluxe" (2023-10-05)
  - Implementation of Active CMAES
    ([#367](https://github.com/mlpack/ensmallen/pull/367)).
  - LBFGS: avoid generation of NaNs, and add checks for finite values
    ([#368](https://github.com/mlpack/ensmallen/pull/368)).
  - Fix CNE test tolerances
    ([#360](https://github.com/mlpack/ensmallen/pull/360)).
  - Rename `SCD` optimizer, to `CD`
    ([#379](https://github.com/mlpack/ensmallen/pull/379)).
- Updated GitHub Action runners `update-ensmallen-refresh` and `pkgdown` to address deprecation notices.
    ([#53](https://github.com/coatless-rpkg/rcppensmallen/pull/53), [#54](https://github.com/coatless-rpkg/rcppensmallen/pull/54), [#55](https://github.com/coatless-rpkg/rcppensmallen/pull/55)).
- Removed explicit C++11 requirement from `DESCRIPTION` and `Makevars{.win}`.
- Increased the R version required to R 4.0 to ensure a compiler with
  C++11 is available.

# RcppEnsmallen 0.2.19.1.1

- Upgraded to ensmallen 2.19.1: "Eight Ball Deluxe" (2023-02-08)
 - Avoid deprecation warnings in Armadillo 11.2+
    ([#347](https://github.com/mlpack/ensmallen/pull/347)).
- Updated GitHub Action's runner to the latest versions 
    ([#51](https://github.com/coatless-rpkg/rcppensmallen/pull/51)).

# RcppEnsmallen 0.2.19.0.1

- Upgraded to ensmallen 2.19.0: "Eight Ball Deluxe" (2022-04-11)
 - Added DemonSGD and DemonAdam optimizers
    ([#211](https://github.com/mlpack/ensmallen/pull/211)).
  - Fix bug with Adam-like optimizers not resetting when `resetPolicy` is `true`.
    ([#340](https://github.com/mlpack/ensmallen/pull/340)).
  - Add Yogi optimizer
    ([#232](https://github.com/mlpack/ensmallen/pull/232)).
  - Add AdaBelief optimizer
    ([#233](https://github.com/mlpack/ensmallen/pull/233)).
  - Add AdaSqrt optimizer
    ([#234](https://github.com/mlpack/ensmallen/pull/234)).
    
  - Bump check for minimum supported version of Armadillo
    ([#342](https://github.com/mlpack/ensmallen/pull/342)).

# RcppEnsmallen 0.2.18.2.1

- Upgraded to ensmallen 2.18.2: "Fairmount Bagel" (2022-02-14)
  - Update Catch2 to 2.13.8
   ([#336](https://github.com/mlpack/ensmallen/pull/336)).
  - Fix epoch timing output
   ([#337](https://github.com/mlpack/ensmallen/pull/337)).
- Update _R_ package URLs.

# RcppEnsmallen 0.2.18.1.1

- Upgraded to ensmallen 2.18.1: "Fairmount Bagel" (2021-11-20)
  - Accelerate SGD test time
    ([#330](https://github.com/mlpack/ensmallen/pull/300)).
  - Fix potential infinite loop in CMAES
    ([#331](https://github.com/mlpack/ensmallen/pull/331)).
  - Fix SCD partial gradient test
    ([#332](https://github.com/mlpack/ensmallen/pull/332)).

# RcppEnsmallen 0.2.18.0.1

- Upgraded to ensmallen 2.18.0: "Fairmount Bagel" (2021-10-21)
  - Add gradient value clipping and gradient norm scaling callback
    ([#315](https://github.com/mlpack/ensmallen/pull/315)).
  - Remove superfluous CMake option to build the tests
    ([#313](https://github.com/mlpack/ensmallen/pull/313)).
  - Bump minimum Armadillo version to 9.800
    ([#318](https://github.com/mlpack/ensmallen/pull/318)).
  - Update Catch2 to 2.13.7
    ([#322](https://github.com/mlpack/ensmallen/pull/322)).
  - Remove redundant template argument for C++20 compatibility
    ([#324](https://github.com/mlpack/ensmallen/pull/324)).
  - Fix MOEAD test stability
    ([#327](https://github.com/mlpack/ensmallen/pull/327)).
- Update GitHub Actions to the standard `r-lib/actions` configuration.
  ([#45](https://github.com/coatless-rpkg/rcppensmallen/pull/45))

# RcppEnsmallen 0.2.17.0.1

- Upgraded to ensmallen 2.17.0: "Pachis Din Me Pesa Double" (2021-07-06)
  - CheckArbitraryFunctionTypeAPI extended for MOO support
    ([#283](https://github.com/mlpack/ensmallen/pull/283)).
  - Refactor NSGA2
    ([#263](https://github.com/mlpack/ensmallen/pull/263),
    [#304](https://github.com/mlpack/ensmallen/pull/304)).
  - Add Indicators for Multiobjective optimizers
    ([#285](https://github.com/mlpack/ensmallen/pull/285)).
  - Make Callback flexible for MultiObjective Optimizers
    ([#289](https://github.com/mlpack/ensmallen/pull/289)).
  - Add ZDT Test Suite
    ([#273](https://github.com/mlpack/ensmallen/pull/273)).
  - Add MOEA-D/DE Optimizer
    ([#269](https://github.com/mlpack/ensmallen/pull/269)).
  - Introduce Policy Methods for MOEA/D-DE
    ([#293](https://github.com/mlpack/ensmallen/pull/293)).
  - Add Das-Dennis weight initialization method
    ([#295](https://github.com/mlpack/ensmallen/pull/295)).
  - Add Dirichlet Weight Initialization
    ([#296](https://github.com/mlpack/ensmallen/pull/296)).
  - Improved installation and compilation instructions
    ([#300](https://github.com/mlpack/ensmallen/pull/300)).
  - Disable building the tests by default for faster installation
    ([#303](https://github.com/mlpack/ensmallen/pull/303)).
  - Modify matrix initialisation to take into account
    default element zeroing in Armadillo 10.5
    ([#305](https://github.com/mlpack/ensmallen/pull/305)).

# RcppEnsmallen 0.2.16.2.1 (GitHub-only Release)

- Upgraded to ensmallen 2.16.2: "Severely Dented Can Of Polyurethane" (2021-03-25)
  - Fix CNE test trials
    ([#267](https://github.com/mlpack/ensmallen/pull/267)).
  - Update Catch2 to 2.13.4
    ([#268](https://github.com/mlpack/ensmallen/pull/268)).
  - Fix typos in documentation
    ([#270](https://github.com/mlpack/ensmallen/pull/270),
     [#271](https://github.com/mlpack/ensmallen/pull/271)).
  - Add clarifying comments in problems/ implementations
    ([#276](https://github.com/mlpack/ensmallen/pull/276)).
  - Remove `AdamSchafferFunctionN2Test` test from Adam test suite to prevent
    spurious issue on some aarch64 ([#259](https://github.com/mlpack/ensmallen/pull/259)).

# RcppEnsmallen 0.2.16.1.1

- Upgraded to ensmallen 2.16.1: "Severely Dented Can Of Polyurethane" (2021-03-04)
  - Fix test compilation issue when `ENS_USE_OPENMP` is set
    ([#255](https://github.com/mlpack/ensmallen/pull/255)).
  - Fix CNE initial population generation to use normal distribution
    ([#258](https://github.com/mlpack/ensmallen/pull/258)).
  - Fix compilation warnings
    ([#259](https://github.com/mlpack/ensmallen/pull/259)).

# RcppEnsmallen 0.2.16.0.1 (GitHub-Only Release)

- Upgraded to ensmallen 2.16.0: "Severely Dented Can Of Polyurethane" (2021-02-19)
  - Expand README with example installation and add simple example program
    showing usage of the L-BFGS optimizer
    ([#248](https://github.com/mlpack/ensmallen/pull/248)).
  - Refactor tests to increase stability and reduce random errors
    ([#249](https://github.com/mlpack/ensmallen/pull/249)).
  

# RcppEnsmallen 0.2.15.1.1

- Upgraded to ensmallen 2.15.1: "Why Can't I Manage To Grow Any Plants?" (2020-11-05)
  - Fix include order to ensure traits is loaded before reports
    ([#239](https://github.com/mlpack/ensmallen/pull/239)).

# RcppEnsmallen 0.2.15.0.1

- Upgraded to ensmallen 2.15.0: "No Direction Home" (2020-11-03)
  - Make a few tests more robust
    ([#228](https://github.com/mlpack/ensmallen/pull/228)).
  - Add release date to version information. ([#226](https://github.com/mlpack/ensmallen/pull/226))
  - Fix typo in release script
    ([#236](https://github.com/mlpack/ensmallen/pull/236)).
  - Add optimizer summary report callback 
    ([#213](https://github.com/mlpack/ensmallen/pull/213)).

# RcppEnsmallen 0.2.14.2.1

- Upgraded to ensmallen 2.14.2: "No Direction Home" (2020-09-05)
  - Fix implementation of fonesca fleming problem function f1 and f2 
    type usage and negative signs. ([#223](https://github.com/mlpack/ensmallen/pull/223))

# RcppEnsmallen 0.2.14.1.1

- Upgraded to ensmallen 2.14.1: "No Direction Home" (2020-08-21)
  - Fix release script (remove hardcoded information, trim leading
    whitespaces introduced by `wc -l` in MacOS)
    ([#216](https://github.com/mlpack/ensmallen/pull/216), [#220](https://github.com/mlpack/ensmallen/pull/220)).
  - Adjust tolerance for AugLagrangian convergence based on element type ([#217](https://github.com/mlpack/ensmallen/pull/217)). 
  - Add NSGA2 optimizer for multi-objective functions ([#149](https://github.com/mlpack/ensmallen/pull/149)). 
  - Update automatic website update release script ([#207](https://github.com/mlpack/ensmallen/pull/207)). 
  - Clarify and fix documentation for constrained optimizers ([#201](https://github.com/mlpack/ensmallen/pull/201)). 
  - Fix L-BFGS convergence when starting from a minimum ([#201](https://github.com/mlpack/ensmallen/pull/201)).
- Switch GitHub Actions to use reference tags to always be up-to-date with 
  CRAN's check grid (`oldrel`, `release`, `devel`). ([#29](https://github.com/coatless-rpkg/rcppensmallen/pull/29), 
  [#32](https://github.com/coatless-rpkg/rcppensmallen/pull/32))
- Added a GitHub Action to automatically create a PR with the new version of
  Ensmallen when a new release is detected. ([#30](https://github.com/coatless-rpkg/rcppensmallen/pull/30), [#33](https://github.com/coatless-rpkg/rcppensmallen/pull/33))

# RcppEnsmallen 0.2.13.0.1

- Upgraded to ensmallen 2.13.0: "Automatically Automated Automation" (2020-07-15)
  - Fix CMake package export
    ([#198](https://github.com/mlpack/ensmallen/pull/198)).
  - Allow early stop callback to accept a lambda function
    ([#165](https://github.com/mlpack/ensmallen/pull/165)).

# RcppEnsmallen 0.2.12.1.1

- Upgraded to ensmallen 2.12.1: "Stir Crazy" (2020-04-20)
 - Fix total number of epochs and time estimation for ProgressBar callback
 ([#181](https://github.com/mlpack/ensmallen/pull/181)).
 - Handle SpSubview_col and SpSubview_row in Armadillo 9.870
 ([#194](https://github.com/mlpack/ensmallen/pull/194)).
 - Minor documentation fixes
 ([#197](https://github.com/mlpack/ensmallen/pull/197)).
 - Correction in the formulation of sigma in CMA-ES
 ([#183](https://github.com/mlpack/ensmallen/pull/183)).
 - Remove deprecated methods from PrimalDualSolver implementation
 ([#185](https://github.com/mlpack/ensmallen/pull/185)).
 ([#186](https://github.com/mlpack/ensmallen/pull/186)).

# RcppEnsmallen 0.2.11.3.1

- Upgraded to ensmallen 2.11.3: "The Poster Session Is Full" (2020-02-19)
  - Prevent spurious compiler warnings
 ([#161](https://github.com/mlpack/ensmallen/pull/161)).
  - Fix minor memory leaks
 ([#167](https://github.com/mlpack/ensmallen/pull/167)).
  - Revamp CMake configuration
 ([#152](https://github.com/mlpack/ensmallen/pull/152)).
  - Allow callback instantiation for SGD based optimizer 
 ([#155](https://github.com/mlpack/ensmallen/pull/155)).
  - Minor test stability fixes on i386
 ([#156](https://github.com/mlpack/ensmallen/pull/156)).
  - Fix Lookahead MaxIterations() check.
 ([#159](https://github.com/mlpack/ensmallen/pull/159)).

# RcppEnsmallen 0.2.11.1.1

- Upgraded to ensmallen 2.11.1: "The Poster Session Is Full" (2019-12-28)
  - Fix Lookahead Synchronization period type
 ([#153](https://github.com/mlpack/ensmallen/pull/153)).
  - Add Lookahead
 ([#138](https://github.com/mlpack/ensmallen/pull/138)).
  - Add AdaBound and AMSBound
 ([#137](https://github.com/mlpack/ensmallen/pull/137)).
  - SGD callback test 32-bit safety (big number)
 ([#143](https://github.com/mlpack/ensmallen/pull/143)).
  - Use "arbitrary" and "separable" terms in static function type checks
 ([#145](https://github.com/mlpack/ensmallen/pull/145)).
  - Remove 'using namespace std' from `problems/` files
 ([#147](https://github.com/mlpack/ensmallen/pull/147)).
  - Add optional tests building.
 ([#141](https://github.com/mlpack/ensmallen/pull/141)).
  - Make code samples collapsible in the documentation.
 ([#140](https://github.com/mlpack/ensmallen/pull/140)).
- Switched deployment from TravisCI to GitHub Actions. ([#17](https://github.com/coatless-rpkg/rcppensmallen/pull/17), [#22](https://github.com/coatless-rpkg/rcppensmallen/pull/22))
- Removed check on header file inclusion ([#21](https://github.com/coatless-rpkg/rcppensmallen/pull/21))

# RcppEnsmallen 0.2.10.3.1

- Upgraded to ensmallen 2.10.3: "Fried Chicken" (2019-09-26)
  - Add release script to rel/ for maintainers
 ([#128](https://github.com/mlpack/ensmallen/pull/128)).
  - Fix Armadillo version check
 ([#133](https://github.com/mlpack/ensmallen/pull/133)).
  - Documentation fix for callbacks
 ([#129](https://github.com/mlpack/ensmallen/pull/129)).
  - Compatibility fixes for ensmallen 1.x
 ([#131](https://github.com/mlpack/ensmallen/pull/131)).
  - Fix ParallelSGD runtime bug.
 ([#135](https://github.com/mlpack/ensmallen/pull/135)).
  - Add additional L-BFGS convergence check
 ([#136](https://github.com/mlpack/ensmallen/pull/136)).
- Added vignette with worked example for linear regression and for package 
  inclusion.

# RcppEnsmallen 0.2.10.0.1

- Upgraded to ensmallen 2.10.0: "Fried Chicken" (2019-09-07)
  - All `Optimize()` functions now take any matrix type; so, e.g., `arma::fmat`
    or `arma::sp_mat` can be used for optimization.  See the documentation for
 ([#113](https://github.com/mlpack/ensmallen/pull/113)).
 ([#119](https://github.com/mlpack/ensmallen/pull/119)).
  - Introduce callback support.  Callbacks can be appended as the last arguments
    of an `Optimize()` call, and can perform custom behavior at different points
    during the optimization.  See the documentation for more details
 ([#119](https://github.com/mlpack/ensmallen/pull/119)).
  - Slight speedups for `FrankWolfe` optimizer
 ([#127](https://github.com/mlpack/ensmallen/pull/127)).

# RcppEnsmallen 0.1.16.0.1

- Upgraded to ensmallen release 1.16.0 "Loud Alarm Clock" (2019-08-09)
  - Add option to avoid computing exact objective at the end of the optimization
 ([#109](https://github.com/mlpack/ensmallen/pull/109)).
 ([#118](https://github.com/mlpack/ensmallen/pull/118)).
 ([#118](https://github.com/mlpack/ensmallen/pull/118)).
  - Introduce local-best particle swarm optimization, `LBestPSO`, for
 ([#86](https://github.com/mlpack/ensmallen/pull/86)).
- ([#123](https://github.com/mlpack/ensmallen/pull/123)).

# RcppEnsmallen 0.1.15.0.1

- Upgraded to ensmallen release 1.15.0 "Wrong Side Of The Road" (2019-05-14)
 ([#81](https://github.com/mlpack/ensmallen/pull/81)).
- ([#115](https://github.com/mlpack/ensmallen/pull/115)).
- ([#115](https://github.com/mlpack/ensmallen/pull/115)).

# RcppEnsmallen 0.1.14.4.1

- Upgraded to ensmallen release 1.14.4 "Difficult Crimp" (2019-05-12)
 ([#91](https://github.com/mlpack/ensmallen/pull/91)).
 ([#100](https://github.com/mlpack/ensmallen/pull/100)).
 ([#97](https://github.com/mlpack/ensmallen/pull/97)).
 ([#98](https://github.com/mlpack/ensmallen/pull/98)).
 ([#92](https://github.com/mlpack/ensmallen/pull/92)).

# RcppEnsmallen 0.1.14.1.1

- Upgraded to ensmallen release 1.14.1 "Difficult Crimp" (2019-03-09)
 ([#87](https://github.com/mlpack/ensmallen/pull/87)).
 ([#90](https://github.com/mlpack/ensmallen/pull/90)).
     in CNE to be a normal distribution about the given starting point, 
     which should accelerate convergence.
 ([#77](https://github.com/mlpack/ensmallen/pull/77)).
 ([#83](https://github.com/mlpack/ensmallen/pull/83)).

# RcppEnsmallen 0.1.13.0.1

- Upgraded to ensmallen release 1.13.0 "Coronavirus Invasion" (2019-01-14)
 ([#66](https://github.com/mlpack/ensmallen/pull/66)).
 ([#69](https://github.com/mlpack/ensmallen/pull/69)).
   - Fix list of contributors.
   - Make sure all files end with newlines.
- Reordered SPSA parameters to quiet initialization error surfaced with `-Wreorder`.

# RcppEnsmallen 0.1.12.0.1

- Upgraded to ensmallen release 1.12.0 "New Year's Party" (2018-12-30)
   - Add link to ensmallen PDF to README.md.
   - Minor documentation fixes.  Remove too-verbose documentation from source for
 ([#61](https://github.com/mlpack/ensmallen/pull/61)).
 ([#48](https://github.com/mlpack/ensmallen/pull/48)).
 ([#42](https://github.com/mlpack/ensmallen/pull/42)).
 ([#46](https://github.com/mlpack/ensmallen/pull/46)).
 ([#45](https://github.com/mlpack/ensmallen/pull/45)).
 ([#60](https://github.com/mlpack/ensmallen/pull/60)).
- Updated citation information

# RcppEnsmallen 0.1.11.1.1

- Upgraded to ensmallen release 1.11.1 "Jet Lag" (2018-11-28)
    - Minor documentation fixes.
    - Add WNGrad optimizer.
    - Fix header name in documentation samples.
- Added citation information

# RcppEnsmallen 0.1.10.0.1

## New

- Support for compiling via _R_ the mathematical optimizers in the _C++_
  [ensmallen](https://ensmallen.org/docs.html) library.
- Includes ensmallen release 1.10.0 "Corporate Catabolism" (2018-10-19)

## Special Thanks

- The crux of this package has largely been developed by 
  Ensmallen development team that consists of Conrad Sanderson, Ryan Curtin, 
  and the MLPACK developers
#  File share/R/nspackloader.R
#  Part of the R package, https://www.R-project.org
#
#  Copyright (C) 1995-2012 The R Core Team
#
#  This program is free software; you can redistribute it and/or modify
#  it under the terms of the GNU General Public License as published by
#  the Free Software Foundation; either version 2 of the License, or
#  (at your option) any later version.
#
#  This program is distributed in the hope that it will be useful,
#  but WITHOUT ANY WARRANTY; without even the implied warranty of
#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#  GNU General Public License for more details.
#
#  A copy of the GNU General Public License is available at
#  https://www.r-project.org/Licenses/

local({
    info <- loadingNamespaceInfo()
    pkg <- info$pkgname
    ns <- .getNamespace(as.name(pkg))
    if (is.null(ns))
        stop("cannot find namespace environment for ", pkg, domain = NA);
    dbbase <- file.path(info$libname, pkg, "R", pkg)
    lazyLoad(dbbase, ns, filter = function(n) n != ".__NAMESPACE__.")
})
   œxúã‡b```f`afb`f2¯˝Ç=„#åıLt-Õ,òÑÅ¢¨PXòÄ#'H</17µ»ÄH2¸‚èPö¨êÿ ˇCı∞B‚H ÃK…ÃK/ÜÚŸRÛísÚa<Æƒíí¢Ã§“íTòKfq∞	LmN~rvj
»V J{⁄  xúã‡b```f`afb`f2¯˝Ç=„#åıLt-Õ,òÑÅ¢¨PXòÄ#'H</17µ»ÄH2¸‚èP≈åPqòb±úƒ™ îƒíD´†‰Ç◊º‚‹ƒúú‘<àëåˇ—T≥ÄåÜö»5çïç¢è™è#)3/%3/Ω gKÕKŒ…áÒ∏KJä2ìJKRa",ô≈¡&0µ9˘…Ÿ©) [„¶%µ  ≥xúuQKO√0}0ViâüÅh◊Æ∞±B∏Ä¥ÿ•i∆"“¥j≤âÒØ9qí6—Jé_ü˝ŸÓ<@π»s‰˙⁄D«◊˜Ÿ›”|¶ÁÒ’Â!ÁTG}´{Zü†ˆÛ˝ ıMáÇïZ¥8»Êµ|Z˘∞1ÄR±ûN€‘Tm∂ïñ ê}Y≠BoÍzè—∏§R]hCl*‹/r,»À±§`œ`;ÜÌQúE™¨£ô~.Êc˙-ßq:&ãIöê»Ùª≤ƒúSaw‚¡nÚ'√$L‚p∆]ÛöM≠›[”F≤J¸≥^nêçJ™ñU!°¶ÿŒÚ≠K_Î™Q[óï›#éﬂ6V»k¨ñ`Àö{¨w´·ø°]{g2zÁLL<Àﬂ^Å`•ñØÖà«dññW‰ÖÜı!4c¶   :xúã‡b```f`afb`f2¯˝Ç=„#åıLt-Õ,Ä"ﬂ ÄëÅÖÅH≥•ÊïYY ≤˙   œxúã‡b```f`afb`f2¯˝Ç=„#åıLt-Õ,òÑÅ¢¨PXòÄ#'H</17µ»ÄH2¸‚èPö¨êÿ ˇCı∞B‚H ÃK…ÃK/ÜÚŸRÛísÚa<Æƒíí¢Ã§“íTòKfq∞	LmN~rvj
»V J{⁄   :xúã‡b```f`afb`f2¯˝Ç=„#åıLt-Õ,Ä"ﬂ ÄëÅÖÅH≥•ÊïYYô  ≤"˝   =xúã‡b```f`afb`f2¯˝Ç=„#åıLt-Õ,Ä"@Ã»¿¬¿	§yÉí
\ÛässrRÛ ∆o	`  xúçSﬂKÎ0ék77Ω ›É|Ï√|X¥^Íú:¨ﬁr{ÖÅ%÷lÜµiY¶2¸ÀEÿÃ⁄Œµ1!È˜ù_Œ9i-  †*9†‰˘,7v”i˝Åª5˝`opä£o ˛r@%æ/˝s√∞Aôè<”\ÿÜ;pGá€PÁn9éÃ%å!‰€;_Cæ
)jÓ5
õsGµù E¬πìYÀ–ª;	Z¥⁄)c˛wäügFëèø°g®˜Bh¬ß	‘ë x11ıCßÌ°éLi«h~$I$XE´⁄ófÛ‘˘k5nÆ-ß~nˆÊ§BÔ©âû®»(9<Ï’qs¨<∆`˙®ã{q“Lõó	uΩßÔq;Ëa·k	Ω~îô¯x"ƒQ=rœô˘±>éUïd5”¥™iXF˝ ·E≤7◊µÍ©iÿü?Á—A"∫d⁄%¥Û?'”ïdâﬂË˘ËÅx^ 1HÔã„Ù≈|’1"∑ã:b’d~3ª]d∏ﬂÁ˜IΩî≈—øÃïµ)XIVƒ
¶œ©X¯óuu·‘-+ÀlÆ≤¨_ÂZ¬-BY+ôãTsgà≠HŒç´#â∞“≠›pÍ≠ñÆ˘£VòM©(÷∫#§Ö   Ûxúã‡b```f`afb`f2¯˝Ç=„#åıLt-Õ,ÄR@—ü¿ƒ¿¬¿	§yÉí
\ÛässrRÛ†Ç\zFzFÜzzÜ@mL@F®cê¯ç.X	d¯ƒl»’`õPYıúÅvA%`Ç2Ò(Óàœ…Ãã/JMèœIJK/Ü®e˙°ôˇCm˙ ≥9!¯ã      ã‡b```f`afb`f2¯˝Ç=„#åıLt-Õ,òÑ¡* 4H	/3Q3ê∂Cô}—¯›@⁄âéÅÅÒ	Çœ∫	Hœ```≤X8AÊÁ%Ê¶`À Ç¸zÒÒ~éæÆ¡éŒÆÒÒzPa†p∞±ojIF~JqHbRN*BéGØ 19;1=’hÃòÃºúÃºTÁääÄú“ÙÃ<®0/P0æ(5=>')-dı?®_Yne¥bzê¯ ˆz§∞9˘çÒ?‘;,PŸRÛ ¨¨QxF(<cû	ƒM\‡pcsô°™9Àã2A¡P‡*JMK-JÕKFà$ÁÁ•ß¶Ä ≥Z˝  <!DOCTYPE html>
<html>
<head><title>R: Vignettes and other documentation</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link rel="stylesheet" type="text/css" href="/doc/html/R.css" />
</head><body><div class="container">
<h1> Vignettes and other documentation
<img class="toplogo" src="/doc/html/Rlogo.svg" alt="[R logo]" />
</h1>
<hr/>
<div style="text-align: center;">
<a href="/doc/html/index.html"><img class="arrow" src="/doc/html/up.jpg" alt="[Top]" /></a>
</div>
<h2>Vignettes from package 'RcppEnsmallen'</h2>
<table style="width: 100%;">
<col style="width: 22%;" />
<col style="width:  2%;" />
<col style="width: 50%;" />
<col style="width:  8%;" />
<col style="width:  8%;" />
<col style="width:  8%;" />
<tr><td style="text-align: right; vertical-align: top;"><a href="../../../library/RcppEnsmallen/doc/package-usage.html">RcppEnsmallen::package-usage</a></td>
<td></td><td style="vertical-align: top;">Using RcppEnsmallen in Your Own R Package</td>
<td style="vertical-align: top;"><a href="../../../library/RcppEnsmallen/doc/package-usage.html">HTML</a></td>
<td style="vertical-align: top;"><a href="../../../library/RcppEnsmallen/doc/package-usage.Rmd">source</a></td>
<td style="vertical-align: top; white-space: nowrap"></td></tr>
<tr><td style="text-align: right; vertical-align: top;"><a href="../../../library/RcppEnsmallen/doc/using-rcppensmallen.html">RcppEnsmallen::using-rcppensmallen</a></td>
<td></td><td style="vertical-align: top;">Solving Linear Regression using Numeric Optimization</td>
<td style="vertical-align: top;"><a href="../../../library/RcppEnsmallen/doc/using-rcppensmallen.html">HTML</a></td>
<td style="vertical-align: top;"><a href="../../../library/RcppEnsmallen/doc/using-rcppensmallen.Rmd">source</a></td>
<td style="vertical-align: top; white-space: nowrap"><a href="../../../library/RcppEnsmallen/doc/using-rcppensmallen.R">R code</a></td></tr>
</table>
</div></body></html>
---
title: "Using RcppEnsmallen in Your Own R Package"
author: James Joseph Balamuta
abstract: |
  This vignette describes the best practices for using RcppEnsmallen in your
  own R package.
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Using RcppEnsmallen in Your Own R Package}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

# Overview

RcppEnsmallen is best used within an _R_ package. 
The setup for `RcppEnsmallen`'s use mirrors that of other `Rcpp`-based projects.
In particular, the `DESCRIPTION` file requires the `LinkingTo` field and
two files inside the `src/` to establish the necessary compilation options.
In the next two sections, we show the modifications. 

## DESCRIPTION file

Open your R package's `DESCRIPTION` file. Ensure that the `LinkingTo` directive
is present and contains:

```bash
LinkingTo: Rcpp, RcppArmadillo (>= 0.9.800.0.0), RcppEnsmallen (>= 0.2.20.0.1)
```

## Makevars inside the src/ Directory 

Next, the `src/` directory must contain both a `Makevars` and `Makevars.win` 
file. Each file must have the same contents of:

```bash
PKG_CXXFLAGS = $(SHLIB_OPENMP_CXXFLAGS)
PKG_LIBS = $(SHLIB_OPENMP_CXXFLAGS) $(LAPACK_LIBS) $(BLAS_LIBS) $(FLIBS)
```

The `Makevars.win` file provides the appropriate configuration for Windows
while `Makevars` acts on Unix-alike systems like macOS, Linux, and Solaris.
<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="James Joseph Balamuta" />


<title>Using RcppEnsmallen in Your Own R Package</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>

<style type="text/css">
p.abstract{
text-align: center;
font-weight: bold;
}
div.abstract{
margin: auto;
width: 90%;
}
</style>



<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Using RcppEnsmallen in Your Own R
Package</h1>
<h4 class="author">James Joseph Balamuta</h4>
<div class="abstract">
<p class="abstract">Abstract</p>
<p>This vignette describes the best practices for using RcppEnsmallen in
your own R package.</p>
</div>



<div id="overview" class="section level1">
<h1>Overview</h1>
<p>RcppEnsmallen is best used within an <em>R</em> package. The setup
for <code>RcppEnsmallen</code>‚Äôs use mirrors that of other
<code>Rcpp</code>-based projects. In particular, the
<code>DESCRIPTION</code> file requires the <code>LinkingTo</code> field
and two files inside the <code>src/</code> to establish the necessary
compilation options. In the next two sections, we show the
modifications.</p>
<div id="description-file" class="section level2">
<h2>DESCRIPTION file</h2>
<p>Open your R package‚Äôs <code>DESCRIPTION</code> file. Ensure that the
<code>LinkingTo</code> directive is present and contains:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="ex">LinkingTo:</span> Rcpp, RcppArmadillo <span class="er">(</span><span class="op">&gt;</span>= <span class="ex">0.9.800.0.0</span><span class="kw">)</span><span class="ex">,</span> RcppEnsmallen <span class="er">(</span><span class="op">&gt;</span>= <span class="ex">0.2.20.0.1</span><span class="kw">)</span></span></code></pre></div>
</div>
<div id="makevars-inside-the-src-directory" class="section level2">
<h2>Makevars inside the src/ Directory</h2>
<p>Next, the <code>src/</code> directory must contain both a
<code>Makevars</code> and <code>Makevars.win</code> file. Each file must
have the same contents of:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="ex">PKG_CXXFLAGS</span> = <span class="va">$(</span><span class="ex">SHLIB_OPENMP_CXXFLAGS</span><span class="va">)</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="ex">PKG_LIBS</span> = <span class="va">$(</span><span class="ex">SHLIB_OPENMP_CXXFLAGS</span><span class="va">)</span> <span class="va">$(</span><span class="ex">LAPACK_LIBS</span><span class="va">)</span> <span class="va">$(</span><span class="ex">BLAS_LIBS</span><span class="va">)</span> <span class="va">$(</span><span class="ex">FLIBS</span><span class="va">)</span></span></code></pre></div>
<p>The <code>Makevars.win</code> file provides the appropriate
configuration for Windows while <code>Makevars</code> acts on Unix-alike
systems like macOS, Linux, and Solaris.</p>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
## ----include = FALSE----------------------------------------------------------
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)

## ----data-generation----------------------------------------------------------
n <- 1e6
beta <- c(-2, 1.5, 3, 8.2, 6.6)
p <- length(beta)
X <- cbind(1, matrix(rnorm(n), ncol = p - 1))
y <- X %*% beta + rnorm(n / (p - 1))

## ----data-estimation, eval = FALSE--------------------------------------------
#  coefs_lbfgs <- lin_reg_lbfgs(X, y)
#  coefs_lm <- lm.fit(X, y)$coefficients

## ----echo = FALSE-------------------------------------------------------------
coefs_lbfgs <- RcppEnsmallen::lin_reg_lbfgs(X, y)
coefs_lm <- lm.fit(X, y)$coefficients
compare_coefs = cbind(coefs_lbfgs, coefs_lm)
colnames(compare_coefs) = c("LBFGS", "LM")
rownames(compare_coefs) = paste0("Beta", seq_len(nrow(compare_coefs)))
knitr::kable(compare_coefs, longtable = FALSE, caption = "Comparison of Estimated Coefficients")

---
title: "Solving Linear Regression using Numeric Optimization"
author: James Joseph Balamuta and Dirk Eddelbuettel
abstract: |
  In this vignette, we describe how to use RcppEnsmallen in a standalone 
  C++ file. 
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Solving Linear Regression using Numeric Optimization}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Overview

`RcppEnsmallen` package provides an embedded copy of the
[`ensmallen`](https://www.ensmallen.org/docs.html) 
C++ library of optimization functions. Optimizers contained within are state
of the art and possess a high level of code quality. Each optimizer must be 
accessed through _C++_ by implementing the appropriate objective functions and,
then, surfaced into _R_ through
[`RcppArmadillo`](https://cran.r-project.org/package=RcppArmadillo). 
Alternatively, work has been done by Dirk Schumacher in 
[`armacmp`](https://github.com/dirkschumacher/armacmp) to automatically create
the underlying _C++_ code from _R_.  

**Note:** Optimizers in `RcppEnsmallen` only work with [`armadillo`](https://arma.sourceforge.net/docs.html)
data structures. Thus, if using [`Eigen`](https://eigen.tuxfamily.org/index.php?title=Main_Page) through 
[`RcppEigen`](https://cran.r-project.org/package=RcppEigen), please consider the 
[`RcppNumerical`](https://cran.r-project.org/package=RcppNumerical)
package.

## Linear Regression 

Consider the **Residual Sum of Squares**, also known as **RSS**, defined as:

$$RSS\left( \beta \right) = \left( { \mathbf{y} - \mathbf{X} \beta } \right)^{\top} \left( \mathbf{y} - \mathbf{X} \beta \right)$$

The objective function we wish to minimize would be defined as:

$$f(\beta) = \rVert \mathbf{y} - \mathbf{X}\beta\lVert_2$$

The gradient is defined as:

$$\frac{\partial RSS}{\partial \beta} = -2 \mathbf{X}^{\top} \left(\mathbf{y} - \mathbf{X} \beta \right)$$

### Two-Step Implementation

When using `ensmallen` to solve this problem, we must create a _C++_ class that 
computes both the objective function value and its gradient value either
together or separately under member functions named as:

- `Evaluate()`: Value of the objective function under the parameters.
- `Gradient()`: Convergence to the correct value under the given parameters. 
- `EvaluateWithGradient()`: Perform both steps at the same time. (Optional)

In the Linear Regression scenario, we will define each step separately to
emphasize the calculation occurring. Generally, the one step `EvaluateWithGradient()` 
function will be faster than the two step variant. More details on design can be
found on [`ensmallen` documentation page for differentiable functions](https://www.ensmallen.org/docs.html#differentiable-functions).

Before writing the class, `RcppEnsmallen` requires accessing the
library in a standalone C++ file with the follow include and Rcpp Attribute
declarations:

```{Rcpp header, eval = FALSE}
#include <RcppEnsmallen.h>
// [[Rcpp::depends(RcppEnsmallen)]]
```

The overaching Linear regression class should be constructed as follows: 

```{Rcpp classdef, eval = FALSE}
#include <RcppEnsmallen.h>
// [[Rcpp::depends(RcppEnsmallen)]]

// Define a differentiable objective function by implementing both Evaluate()
// and Gradient() separately.
class LinearRegressionFunction
{
public:
  // Construct the object with the given the design 
  // matrix and responses.
  LinearRegressionFunction(const arma::mat& X,
                           const arma::vec& y) :
  X(X), y(y) { }

  // Return the objective function for model parameters beta.
  double Evaluate(const arma::mat& beta)
  {
      return std::pow(arma::norm(y - X * beta), 2.0);
  }

  // Compute the gradient for model parameters beta
  void Gradient(const arma::mat& beta, arma::mat& g)
  {
      g = -2 * X.t() * (y - X * beta);
  }

private:
  // The design matrix.
  const arma::mat& X;
  // The responses to each data point.
  const arma::vec& y;
};
```

From there:

1. Construct a _C++_ function that exports into _R_.
2. Within the function, determine an appropriate optimizer for the problem. 
3. Combine the optimizer with the linear regression class to compute 
   the solution to the problem.

**Note:** Make sure to have the definition of the Linear Regression class in 
the same _C++_ file as the exported _C++_ function into _R_. 

```{Rcpp linreg, eval = FALSE}
// [[Rcpp::export]]
arma::mat lin_reg_lbfgs(const arma::mat& X, const arma::vec& y) {

  // Construct the first objective function.
  LinearRegressionFunction lrf(X, y);

  // Create the L_BFGS optimizer with default parameters.
  // The ens::L_BFGS type can be replaced with any ensmallen optimizer that can
  // handle differentiable functions.
  ens::L_BFGS lbfgs;

  lbfgs.MaxIterations() = 10;

  // Create a starting point for our optimization randomly.
  // The model has p parameters, so the shape is p x 1.
  arma::mat beta(X.n_cols, 1, arma::fill::randn);

  // Run the optimization
  lbfgs.Optimize(lrf, beta);

  return beta;
}
```

### Verifying Results

Prior to using the new optimizer in mission critical work, compare the results
to methods already implemented in _R_. The best way to achieve this is to create
an oracle model by specifying the parameters known to generate data and, then,
try to recover them. Moreover, if a method is already implemented in _R_ feel
free to try to check the result equality within an appropriate tolerance threshold.  

Following with this methodology, data must be generated. 

```{r data-generation}
n <- 1e6
beta <- c(-2, 1.5, 3, 8.2, 6.6)
p <- length(beta)
X <- cbind(1, matrix(rnorm(n), ncol = p - 1))
y <- X %*% beta + rnorm(n / (p - 1))
```

Next, the optimization procedure is used to estimate the parameters of interest.
Under this example, the results of the estimation can be compared to `lm()`. 
That said, `lm()` may have more precise results when compared against the 
optimizer as it is implemented with a closed-form solution to linear regression
plus the computational is performed more rigorously.  

```{r data-estimation, eval = FALSE}
coefs_lbfgs <- lin_reg_lbfgs(X, y)
coefs_lm <- lm.fit(X, y)$coefficients
```

```{r echo = FALSE}
coefs_lbfgs <- RcppEnsmallen::lin_reg_lbfgs(X, y)
coefs_lm <- lm.fit(X, y)$coefficients
compare_coefs = cbind(coefs_lbfgs, coefs_lm)
colnames(compare_coefs) = c("LBFGS", "LM")
rownames(compare_coefs) = paste0("Beta", seq_len(nrow(compare_coefs)))
knitr::kable(compare_coefs, longtable = FALSE, caption = "Comparison of Estimated Coefficients")
```

<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="James Joseph Balamuta and Dirk Eddelbuettel" />


<title>Solving Linear Regression using Numeric Optimization</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>

<style type="text/css">
p.abstract{
text-align: center;
font-weight: bold;
}
div.abstract{
margin: auto;
width: 90%;
}
</style>



<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Solving Linear Regression using Numeric
Optimization</h1>
<h4 class="author">James Joseph Balamuta and Dirk Eddelbuettel</h4>
<div class="abstract">
<p class="abstract">Abstract</p>
<p>In this vignette, we describe how to use RcppEnsmallen in a
standalone C++ file.</p>
</div>



<div id="overview" class="section level1">
<h1>Overview</h1>
<p><code>RcppEnsmallen</code> package provides an embedded copy of the
<a href="https://www.ensmallen.org/docs.html"><code>ensmallen</code></a>
C++ library of optimization functions. Optimizers contained within are
state of the art and possess a high level of code quality. Each
optimizer must be accessed through <em>C++</em> by implementing the
appropriate objective functions and, then, surfaced into <em>R</em>
through <a href="https://cran.r-project.org/package=RcppArmadillo"><code>RcppArmadillo</code></a>.
Alternatively, work has been done by Dirk Schumacher in <a href="https://github.com/dirkschumacher/armacmp"><code>armacmp</code></a>
to automatically create the underlying <em>C++</em> code from
<em>R</em>.</p>
<p><strong>Note:</strong> Optimizers in <code>RcppEnsmallen</code> only
work with <a href="https://arma.sourceforge.net/docs.html"><code>armadillo</code></a>
data structures. Thus, if using <a href="https://eigen.tuxfamily.org/index.php?title=Main_Page"><code>Eigen</code></a>
through <a href="https://cran.r-project.org/package=RcppEigen"><code>RcppEigen</code></a>,
please consider the <a href="https://cran.r-project.org/package=RcppNumerical"><code>RcppNumerical</code></a>
package.</p>
<div id="linear-regression" class="section level2">
<h2>Linear Regression</h2>
<p>Consider the <strong>Residual Sum of Squares</strong>, also known as
<strong>RSS</strong>, defined as:</p>
<p><span class="math display">\[RSS\left( \beta \right) = \left( {
\mathbf{y} - \mathbf{X} \beta } \right)^{\top} \left( \mathbf{y} -
\mathbf{X} \beta \right)\]</span></p>
<p>The objective function we wish to minimize would be defined as:</p>
<p><span class="math display">\[f(\beta) = \rVert \mathbf{y} -
\mathbf{X}\beta\lVert_2\]</span></p>
<p>The gradient is defined as:</p>
<p><span class="math display">\[\frac{\partial RSS}{\partial \beta} = -2
\mathbf{X}^{\top} \left(\mathbf{y} - \mathbf{X} \beta
\right)\]</span></p>
<div id="two-step-implementation" class="section level3">
<h3>Two-Step Implementation</h3>
<p>When using <code>ensmallen</code> to solve this problem, we must
create a <em>C++</em> class that computes both the objective function
value and its gradient value either together or separately under member
functions named as:</p>
<ul>
<li><code>Evaluate()</code>: Value of the objective function under the
parameters.</li>
<li><code>Gradient()</code>: Convergence to the correct value under the
given parameters.</li>
<li><code>EvaluateWithGradient()</code>: Perform both steps at the same
time. (Optional)</li>
</ul>
<p>In the Linear Regression scenario, we will define each step
separately to emphasize the calculation occurring. Generally, the one
step <code>EvaluateWithGradient()</code> function will be faster than
the two step variant. More details on design can be found on <a href="https://www.ensmallen.org/docs.html#differentiable-functions"><code>ensmallen</code>
documentation page for differentiable functions</a>.</p>
<p>Before writing the class, <code>RcppEnsmallen</code> requires
accessing the library in a standalone C++ file with the follow include
and Rcpp Attribute declarations:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode cpp"><code class="sourceCode cpp"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;RcppEnsmallen.h&gt;</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="co">// [[Rcpp::depends(RcppEnsmallen)]]</span></span></code></pre></div>
<p>The overaching Linear regression class should be constructed as
follows:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode cpp"><code class="sourceCode cpp"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;RcppEnsmallen.h&gt;</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="co">// [[Rcpp::depends(RcppEnsmallen)]]</span></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a><span class="co">// Define a differentiable objective function by implementing both Evaluate()</span></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a><span class="co">// and Gradient() separately.</span></span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a><span class="kw">class</span> LinearRegressionFunction</span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a><span class="op">{</span></span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a><span class="kw">public</span><span class="op">:</span></span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a>  <span class="co">// Construct the object with the given the design </span></span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a>  <span class="co">// matrix and responses.</span></span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a>  LinearRegressionFunction<span class="op">(</span><span class="at">const</span> arma<span class="op">::</span>mat<span class="op">&amp;</span> X<span class="op">,</span></span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a>                           <span class="at">const</span> arma<span class="op">::</span>vec<span class="op">&amp;</span> y<span class="op">)</span> <span class="op">:</span></span>
<span id="cb2-13"><a href="#cb2-13" tabindex="-1"></a>  X<span class="op">(</span>X<span class="op">),</span> y<span class="op">(</span>y<span class="op">)</span> <span class="op">{</span> <span class="op">}</span></span>
<span id="cb2-14"><a href="#cb2-14" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" tabindex="-1"></a>  <span class="co">// Return the objective function for model parameters beta.</span></span>
<span id="cb2-16"><a href="#cb2-16" tabindex="-1"></a>  <span class="dt">double</span> Evaluate<span class="op">(</span><span class="at">const</span> arma<span class="op">::</span>mat<span class="op">&amp;</span> beta<span class="op">)</span></span>
<span id="cb2-17"><a href="#cb2-17" tabindex="-1"></a>  <span class="op">{</span></span>
<span id="cb2-18"><a href="#cb2-18" tabindex="-1"></a>      <span class="cf">return</span> <span class="bu">std::</span>pow<span class="op">(</span>arma<span class="op">::</span>norm<span class="op">(</span>y <span class="op">-</span> X <span class="op">*</span> beta<span class="op">),</span> <span class="fl">2.0</span><span class="op">);</span></span>
<span id="cb2-19"><a href="#cb2-19" tabindex="-1"></a>  <span class="op">}</span></span>
<span id="cb2-20"><a href="#cb2-20" tabindex="-1"></a></span>
<span id="cb2-21"><a href="#cb2-21" tabindex="-1"></a>  <span class="co">// Compute the gradient for model parameters beta</span></span>
<span id="cb2-22"><a href="#cb2-22" tabindex="-1"></a>  <span class="dt">void</span> Gradient<span class="op">(</span><span class="at">const</span> arma<span class="op">::</span>mat<span class="op">&amp;</span> beta<span class="op">,</span> arma<span class="op">::</span>mat<span class="op">&amp;</span> g<span class="op">)</span></span>
<span id="cb2-23"><a href="#cb2-23" tabindex="-1"></a>  <span class="op">{</span></span>
<span id="cb2-24"><a href="#cb2-24" tabindex="-1"></a>      g <span class="op">=</span> <span class="op">-</span><span class="dv">2</span> <span class="op">*</span> X<span class="op">.</span>t<span class="op">()</span> <span class="op">*</span> <span class="op">(</span>y <span class="op">-</span> X <span class="op">*</span> beta<span class="op">);</span></span>
<span id="cb2-25"><a href="#cb2-25" tabindex="-1"></a>  <span class="op">}</span></span>
<span id="cb2-26"><a href="#cb2-26" tabindex="-1"></a></span>
<span id="cb2-27"><a href="#cb2-27" tabindex="-1"></a><span class="kw">private</span><span class="op">:</span></span>
<span id="cb2-28"><a href="#cb2-28" tabindex="-1"></a>  <span class="co">// The design matrix.</span></span>
<span id="cb2-29"><a href="#cb2-29" tabindex="-1"></a>  <span class="at">const</span> arma<span class="op">::</span>mat<span class="op">&amp;</span> X<span class="op">;</span></span>
<span id="cb2-30"><a href="#cb2-30" tabindex="-1"></a>  <span class="co">// The responses to each data point.</span></span>
<span id="cb2-31"><a href="#cb2-31" tabindex="-1"></a>  <span class="at">const</span> arma<span class="op">::</span>vec<span class="op">&amp;</span> y<span class="op">;</span></span>
<span id="cb2-32"><a href="#cb2-32" tabindex="-1"></a><span class="op">};</span></span></code></pre></div>
<p>From there:</p>
<ol style="list-style-type: decimal">
<li>Construct a <em>C++</em> function that exports into <em>R</em>.</li>
<li>Within the function, determine an appropriate optimizer for the
problem.</li>
<li>Combine the optimizer with the linear regression class to compute
the solution to the problem.</li>
</ol>
<p><strong>Note:</strong> Make sure to have the definition of the Linear
Regression class in the same <em>C++</em> file as the exported
<em>C++</em> function into <em>R</em>.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode cpp"><code class="sourceCode cpp"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="co">// [[Rcpp::export]]</span></span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>arma<span class="op">::</span>mat lin_reg_lbfgs<span class="op">(</span><span class="at">const</span> arma<span class="op">::</span>mat<span class="op">&amp;</span> X<span class="op">,</span> <span class="at">const</span> arma<span class="op">::</span>vec<span class="op">&amp;</span> y<span class="op">)</span> <span class="op">{</span></span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a>  <span class="co">// Construct the first objective function.</span></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a>  LinearRegressionFunction lrf<span class="op">(</span>X<span class="op">,</span> y<span class="op">);</span></span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a>  <span class="co">// Create the L_BFGS optimizer with default parameters.</span></span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a>  <span class="co">// The ens::L_BFGS type can be replaced with any ensmallen optimizer that can</span></span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a>  <span class="co">// handle differentiable functions.</span></span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a>  ens<span class="op">::</span>L_BFGS lbfgs<span class="op">;</span></span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a>  lbfgs<span class="op">.</span>MaxIterations<span class="op">()</span> <span class="op">=</span> <span class="dv">10</span><span class="op">;</span></span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a>  <span class="co">// Create a starting point for our optimization randomly.</span></span>
<span id="cb3-15"><a href="#cb3-15" tabindex="-1"></a>  <span class="co">// The model has p parameters, so the shape is p x 1.</span></span>
<span id="cb3-16"><a href="#cb3-16" tabindex="-1"></a>  arma<span class="op">::</span>mat beta<span class="op">(</span>X<span class="op">.</span>n_cols<span class="op">,</span> <span class="dv">1</span><span class="op">,</span> arma<span class="op">::</span>fill<span class="op">::</span>randn<span class="op">);</span></span>
<span id="cb3-17"><a href="#cb3-17" tabindex="-1"></a></span>
<span id="cb3-18"><a href="#cb3-18" tabindex="-1"></a>  <span class="co">// Run the optimization</span></span>
<span id="cb3-19"><a href="#cb3-19" tabindex="-1"></a>  lbfgs<span class="op">.</span>Optimize<span class="op">(</span>lrf<span class="op">,</span> beta<span class="op">);</span></span>
<span id="cb3-20"><a href="#cb3-20" tabindex="-1"></a></span>
<span id="cb3-21"><a href="#cb3-21" tabindex="-1"></a>  <span class="cf">return</span> beta<span class="op">;</span></span>
<span id="cb3-22"><a href="#cb3-22" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
</div>
<div id="verifying-results" class="section level3">
<h3>Verifying Results</h3>
<p>Prior to using the new optimizer in mission critical work, compare
the results to methods already implemented in <em>R</em>. The best way
to achieve this is to create an oracle model by specifying the
parameters known to generate data and, then, try to recover them.
Moreover, if a method is already implemented in <em>R</em> feel free to
try to check the result equality within an appropriate tolerance
threshold.</p>
<p>Following with this methodology, data must be generated.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fl">1e6</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>beta <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">2</span>, <span class="fl">1.5</span>, <span class="dv">3</span>, <span class="fl">8.2</span>, <span class="fl">6.6</span>)</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fu">length</span>(beta)</span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, <span class="fu">matrix</span>(<span class="fu">rnorm</span>(n), <span class="at">ncol =</span> p <span class="sc">-</span> <span class="dv">1</span>))</span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a>y <span class="ot">&lt;-</span> X <span class="sc">%*%</span> beta <span class="sc">+</span> <span class="fu">rnorm</span>(n <span class="sc">/</span> (p <span class="sc">-</span> <span class="dv">1</span>))</span></code></pre></div>
<p>Next, the optimization procedure is used to estimate the parameters
of interest. Under this example, the results of the estimation can be
compared to <code>lm()</code>. That said, <code>lm()</code> may have
more precise results when compared against the optimizer as it is
implemented with a closed-form solution to linear regression plus the
computational is performed more rigorously.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a>coefs_lbfgs <span class="ot">&lt;-</span> <span class="fu">lin_reg_lbfgs</span>(X, y)</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>coefs_lm <span class="ot">&lt;-</span> <span class="fu">lm.fit</span>(X, y)<span class="sc">$</span>coefficients</span></code></pre></div>
<table>
<caption>Comparison of Estimated Coefficients</caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">LBFGS</th>
<th align="right">LM</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Beta1</td>
<td align="right">-2.000360</td>
<td align="right">-2.000360</td>
</tr>
<tr class="even">
<td align="left">Beta2</td>
<td align="right">1.500481</td>
<td align="right">1.500481</td>
</tr>
<tr class="odd">
<td align="left">Beta3</td>
<td align="right">2.999367</td>
<td align="right">2.999367</td>
</tr>
<tr class="even">
<td align="left">Beta4</td>
<td align="right">8.197844</td>
<td align="right">8.197844</td>
</tr>
<tr class="odd">
<td align="left">Beta5</td>
<td align="right">6.598912</td>
<td align="right">6.598912</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
RcppEnsmallen-package	RcppEnsmallen-package
lin_reg_lbfgs	lin_reg_lbfgs
RcppEnsmallen	RcppEnsmallen-package
  PxúmPÀN√0‹ºHõCÖƒÖ@i(Ñ GEÍÖ¢Dn»qLe’q¢⁄à#ˇ¬"> ∞ã-h»!ŒŒx=3ªe ¯û^†Jò\›ã«Útö∆≥ÀÏ¿=Pl˚á}ı9‡√X„˚ªÎX7ëæ˚ó‰®!¢˜|4Á∏≠)_©˙≥wwò„Æõs— ∆è;Ñ◊hE¶y≠ÚNtﬂÎªŒæıç0C¬πÜoó≈¢ƒ“¿Ω-îÆGâl∫$W«Ú¨<'…edñWivíe…N¶cÁÀHF¬SCŸ˘àùœ`≠¶aXRµâöŒÓKmB}òç;ΩÄ°ÿ`≠“3ˇ7Ω÷àÃ{ÿ≠Sè* uRaW§¢≥÷¢Iπ°’≥$ñÒ©(R€ÀZº&€‰ﬂΩW  66xú’[ksGK≤ëp≤b¬¶k	%(,…íç±ΩIUlCÒO¡U1ï¥fZRáy•ª«â©dD˛læÖÌ;sG	)Y	ç=´™ˆπ÷Ù„ÙÈæ}Øf§˝√0ÚF!ü3Ú≥⁄4w=ª˜˝˛ZeΩ\€⁄ÿ‘?÷Ôû2å‡å∆èB,Ûü4LﬂøÌJá⁄6s∑…]F-& è]˚àÏ]øNR’aU‹§6yÏ+Ó7˙?œ%xSPqDZû •·Pã€∂W2åB.—ˇ\√˙^—∂∂í£ûﬂﬁ>XS
S∞ñÊ{˛ã8EƒóhøhuJ∑jqõiÛ#zu;dÓ·ˆvm†¡¨iS)¯t«6˛å
4ôy;XÎ@qC¡’‹€¶3à˚hÔGıÚoˇé⁄Ï;„≤∫rK}+Wˆ©˘ö∂ŸÍÖoo7vá/ i¿ãh_úÒ°\f\ÍS±Ä ~Üˆg)´x¶O≈1’õ≈M	xÌs)´7w@mNÂ63àKh/˝?l¬9în◊Ω8›uS∆9î⁄ó¶,cn@∆ôÖQíı >í —b±Lçd‚ja°‘]‡·íP¢ò„€T1+N2Dx…acà∏⁄<"∫)=|dgÔõíÓÄ:◊Ù[T_xá‹b–≠‰∫[F$Sƒk⁄îJP:íaê˘Yp≈›6°.Òö?2}ÂêëV‡ÜUàÚ‚±YÖ<â:µ»œ\u∏K®`‰ê
ÓíHE]ã
K˜c3P–gôYm÷m/dDçª¶X0ÜmóõTô“:Ã1WÕÿTÃÏ∏¸ßÄ…äÑìÔ«ç -¡í£¨DÙ¸ÙDπ´È&’´êÁ YüÉïzXÃMÜ∫v¬†M j©ÑÁDj'ö≈+˙îã®ıµ˙æ‡z)áÙQ¢›†Æk/hw¢~ÅR/‡«îBæzyÇ≠ê@ÇäñG\OóÈ©Èı·z¢öO1∑?{Äj∫Ì‡¥+‰ëß9Ü´2∞mÆ◊AÍ¯Øï˜l
=Ï>ªµ“◊≥[Ñ˚'ú‹Õ ÊÍjeuH;z>zñ¢wI}Âù	_Ì™P"MÓZ∫SYm
{HÛOzmHˇ–¯Œ£‰Œì‰P´õ∑N¥‡QT‰ ;Î~gKo∞3Ì2‹¶∫S&9J%¡~
∏]ÃÙ_Ø∞à*…¿˜=°$)i?Æ’J·ˆHj∂*ı∏ç{JÕ„Òû"ë]XH˘`?} Æ)∏>4‚‰N»'.S=ﬁOøÔÒ˛	ä#ñTC˘¬C})8áƒòlœ#C¿≥hüMyôOËC”s€#ËÃ ‚D”àç∆Ömr_'≥í‹˜$Û;dó⁄‘	%HxÒ:⁄◊”Œ›öŸ˙◊⁄ŸπÎqYaV0Ò5ƒ;hﬂI=w”È∑G∞YAºãˆ›îñ>GÆN†’=ƒ˚hﬂü~fi[Ï+•|π]≠z¬‰V≈ÌÍ™~ïuY+◊7ÎÂÕıõc&Ó0ëßà⁄¡Ù&4t"≥è{˜nM†¸/àø¢˝kÍs;a•°dæA¸ÌﬂR⁄§K◊»w¶Á	ﬁÓ(“Òlù4º7—ˇ ˛éˆÔ);T^àˆHßœìWÁw’ÒÑ‹ó‰ßH0ôM”ÛãÔ´‰≤eE1bIÈ$c≤ªà≤Ê–ŒMYBc§+s˝ëw©º—ªuñè0…>&∑∏xMn[≥õSäŸìhXD\F{9Â,cëY÷◊krÍB‘ôÄÒø´hWO,Ω∏ò(´=ÃHzljàu¥Î'ü^‘ Îµ≠Ú÷ÍÕ˝1”ò»‚+¥_e1Ω Ç? Zh['ï^ â5DÜ6ÀrzD[ào–~ì≤z≈DÁoÜ=ÜXé∂E˜Dö≈ÿAHÂà%‰∑À”Pnƒç &e#Ó¢ Ö¶¥êp~ÃæØfQ¶cöY◊‚…ZÅMÙß˝◊„'±ßQB¿E¥ß˘Ã‰\~_9œ†Ñ1f+âM»ñù$»‰”Nbg&Q,˘∞K™)k%Nf⁄\uÇf≈Ùú™ÈQe3)À¬›Æ
”˜ŸÑçèÎå˜0’C≤pàa	-å=è¯%⁄_f%ö ©Øà%#Æ¸a¥qBÃå+ô<bÊ\HxÆ|#veQ÷~[Q;≤/ºñOÑÓ›Á–’1=˙C‹§ÄªhÔûêGáyƒ=¥˜≤‚—@ÍV±dƒ££:f∆£°R1suä	<èæ<$8;6|°:iDÜ:ãà´hOÒ∂ŒX˛uÊkh◊≤‚øPßû@,ÒﬂDª%ƒÃ¯/ê…#fŒÅT1Å«·øüƒ˛€ı÷n·ò.å/£}˘Ñ\8Ã#~ÅˆYqY u%ÅX2‚≤g£bf\»‰”vŸèHÉ¡W∞H3hKB’$œ£}˛∏rÍˇÌ„qïK09¶É√Ñ.!>E˚È	98p∏Äÿ@ªëRœà%U°˛ÍÓ˘ôh«tøyï©ªÁ…GXπ^…πs®Vå«q˜ºx É/ñ·ÛrXJèOÔj√¬_Ò$€‹≠*«Ø6Ùü«7ˆo≤óU®S[_mÆo‘76™}_ë≠:‘≠˝5B•aç‡îãØÙ÷∆aäˆŒΩ˛'}ønË≈¯5À‡äNYû˘¸»gΩ©ˆIø>«aåÈI€«≠ËÊS¡‡°dÏòŒ˛¸/ûeÀ”  HxúmPKN√0|˘ë6ã™«@m(Ñ KEÍÜ¢DvQ‚∏ëÖ„D±KÓ¬	 ÏbYÿ~3∂gÊΩ,  \««ì%ÃÆn“Mûù.£≈Í2æ ∞%Î˝ú0óÀ¶
ﬂﬂ]/‘£1“µì¨h0|ü¨j+¬jYÓÊî∞º«uNÀ]ÕóI%sŒ‘˝Àõ Èø-∏1∞5Èﬂn”MÜÑÜ{(F‹éB—ta"∑ÌYvé¬°xóQ|«aÇ∫nÕxSPäŸ∑±ı©%<-·»fL_ÿÙ•±RS–x*àÜ(öNˆs•CΩÎI[ÉÄ>ÔëRòˇÎ^i˙?¸≠GSOJ¬TRnF$£”÷††¢'Âì¿Üq	O#Ûñ∂ËÔìæëT/  :≤xúÕ[[SIûêpT@/–¢s!—UŸZ/(n±`%îÊ!%5ôÈÑﬁùÃƒô	ö•x∞j_uˇàÓﬂ€7›Ó…ô§'ÓNí∆X’~gn‰Î”Á÷==ôIíÇR(ÿ'˚©(ç?ÿM?;»‹ä≠G?&Ô–ãìÙÏ∞$ı1P<Á`àùìÆÓÀ&J·Çâ-ã:zCÏC¥}¯‰iZíB}‹Õ)ı¿ñT‚ˇDh+≥ﬂ|ße*&Œ”cG¥1nCÄ◊@æ÷Ù‘ }*O4L≈§Íø⁄ƒ˙—›ªkMÙ+ölYM|jø-}Æ6ˆH‡KÛ]YõÿÏßÿ’æ/MLÄK /UÔ~˘/j˝_˝N3œa”à~`‚¬ÅñÀ¨îC/∂R=ôÍ 'AûÏaO.˝Y].zi/c8ÚT/k/∆¬C›%‹¬¯dç»V6¿ _Ë≤˙ÇMÍå¥RY›≥HûßmúCh]#…_›N⁄∂ê}à—W±ÍÜE,¢ñe•ÀEd‰Q˙uY¶WQŸ"z°˙î ¸ˆqîœp‰mA}5J6)í?∞ÛK‹¡¡QêG[Ôô¨ä-≈$î¥°∑0p{°u’Ü˚˛Ø˜ßÌ=ﬁÚ`…⁄á–ÑTCÄ
g"®≤Ïõ ®rPY[™≤%º‚¸ 08»ù*«Z9Ñ÷mKîºíR „ìÏå≠ã–∫EVÚ
˝}P,›6ZG°˘}†(€&yÎ◊aµ	¿iêßÖ◊Eä°z˘Àò√êgÖõ$Õ{≤çH5k>¶≤†£_¢ºa:gÕz¡_2çúÜã±6,ap‰]·Í%6.∂  ‹yOêz}á!FÍ9á–zÉW5àÃ÷ﬁ1≤‚ì,ÛöA{3F∫~~F:Ω<¬äﬂ …¯M NÅ,∫¢h π¸ÏÃ| Ö8	Bä°€2—›9Ö%C∑0:íµ2∂¸ÜB∆ı"‡»ﬂ+û©ZáÉIêìΩm©€B™©ë¨l E¨€^3ÓaP—ò$.˛çw™6Ê#B2¶cè®'WÎüD/Ç/r˙¶[¨¥A›më:
5Õ¡¨eõÜ^hAg0
rT–êüã Y≥Ùªnº—ëlµ3Í1¿Mê7E'ºT:›Õ'Ä€ wqMßù˛	»œçx©8Ot¨“·ΩÎ7¸0Üø æ˘Â)’à«tú≥Œ€aîÕa[FYìÌe¥â‡Ù1 “	‚a.\9A—⁄AÊ8qyuº‚>ÙÌG‡ÅVjj±îÃ&ôÉÄÔ@~◊ÂÍ¥Y=ÀT=a∆ô)$\°ù…¨8áØˆ—J√â6:Û'‡Gê?
ØiT¸⁄kIq∫⁄s?Å¸©WjFÍo°	!w}üÊd#˜VlrÑQæ¨+lñÕı;ÔP)√Î _?%ˇûÕá≥çˆ[=|µÊ”`g¡„ŒÉ</ÿ˚.Âõ|è˙\˚Ï ÔÅ|Ô{π€,ÿ √˚ ﬂÔwc§69Ñ&Ñ‹ÊnSV	ù=tËdó@ëØÄ|ÂîúL…ÊMY9Œñd”&¥P¶I„§~‰8‹	µ·Ëó
πl)"Y^eH@&Ç›uA•è´kß∑ö%∑ç^hÄÔA~ˇΩ‹ˆ2X√ Ë∑e§˛‚öPMQMŸ2—ºÊ˝Ó€u◊EÃ˚Cù*çM˙Ü8˘írú≈:lŸÑ˙7çp>ôûû∂©ª{æ›˙ù8‰”s—)¿êª¯B∆ìh®MûóÁ@ûÏ7°¨wÄ9Àµ˘:
1«(¢ÈI.bõ∞*[{w•U˜Å‘_a˘ﬁ6¡à#¿êw+u Ît£Öójwã	E3oò∏*Uﬂf∏M»‡O.¢›r1Gáﬁ»£Á—mÀ7ﬂ9–$Cnõåæ√:≠'´´´æYŒ3Ü√ üvŒn…#ªmô¡Eî∆ùÿ:ÖX›˚˝è¸¿î!7ï¬zäI%]ã†Dl#ÇnE–ù=H∆í˛w˘, ﬂÖF€Ë{XF.ä¥áhC0±J€0-&∫¢ïUˆÍé∆l*∏d˚◊Û5`œ0
≤®ÂıÛ%j ÷ˆauπ¿7[nrm{›˘û±
n…H∏U$—S¨cì÷®®T7äºiëåt√,“	≠J,€$π2[Û›õ–Ü	êÇz≥î9 ‘6™˚õ¬&£÷ó#HWçû/—ôi¬øµÑÅuX≥ÉΩ3kYF.ä¥ZG<PU$ÎıP·õÔ
pd(∫éò»∞Tí#∫ND5ˇÉ(2‰61˜»‡GÄëã"äòC¯&ÃÂ!ﬂ34,OUËËgñVñúö‚&ÇxÄ‚(\ç˛≠!îr)ØG¨!å\isã(U÷lµóÌ⁄ßNŒûlﬂ‘WÅ.Cn¶!Ñ:õÙ⁄Ú€”πâ∫±ïúKk|âﬂ#V±å\iããË6Iæ¬Õ7–l≤-aäqD’7ˇ[¿ô!W0·©&Y±Ÿ˛óMgÍ·VÒ6Î∂„ﬂL÷Å<C.p]%Œ‚∑r±§aØ5€´@bCåe∞ªÍWS*|ã»?Ûs‹.ñ‚)˙ﬂﬁFÊ6~g˜$÷WsÎ…µd2ûRJ•-›¢5(-˜„EYè7∏k,•∂‡“Á^©ù	ùµBwÔãs∑‘tO?˚Ø˘˚«A’Pˆ+%\ÔSÉ›Ó÷@©{:l‡6D´sÍSòˆ´∂å}¯˘_Ù≤Eã      ã‡b```f`afb`f2¯˝Ç=„#åıLt-Õ,òÑ¡* 4ÛBhFuˆ√>óêˇÖÅÅ§ÜëÅÖÅH≥Ê%Ê¶`EA—†‰Ç◊º‚‹ƒúú‘<›Çƒ‰ÏƒÙT®$oNf^|Qjz|NRZ:HÁ?L´A d=åœÒ
»◊ÄXÕ¯Õ6∂‘º2++Cûƒ\.∞S¡E/3T5gYbQfbR–Æ¢‘¥‘¢‘ºdÑHr~nAQjqqj
»P ìM¬∑P  ã      ã‡b```f`afb`f2¯˝Ç=„#åıLt-Õ,ò *8Å¥hPrAÅk^qnbNNjûnAbrvbz*Tí7'3/æ(5=>')-Ωø&†$#Tk^bnj1êAô]º(:Äˇ üªùyﬂ   ã      ïåΩÇ0EØM4æT´n:òË¢	≤5!ñ¶ûﬂ¯iXÓOŒp≤	 æ«‡t1;\ngô≠¢$åwb∞9Qc⁄Ô«S™Î:€Ë;/k£„dë'b)OÁé∂kî1⁄ÚFŸ_:U<U•£Ù1¯ˆˇ˙Lme´+iÚ≤Í>¯å<£¡îu€ıt¶_ƒî◊0®ËÂ   <!DOCTYPE html>
<html>
<head><title>R: Header-Only C++ Mathematical Optimization Library for
'Armadillo'</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link rel="stylesheet" type="text/css" href="R.css" />
</head><body><div class="container">
<h1> Header-Only C++ Mathematical Optimization Library for
'Armadillo'
<img class="toplogo" src="../../../doc/html/Rlogo.svg" alt="[R logo]" />
</h1>
<hr/>
<div style="text-align: center;">
<a href="../../../doc/html/packages.html"><img class="arrow" src="../../../doc/html/left.jpg" alt="[Up]" /></a>
<a href="../../../doc/html/index.html"><img class="arrow" src="../../../doc/html/up.jpg" alt="[Top]" /></a>
</div><h2>Documentation for package &lsquo;RcppEnsmallen&rsquo; version 0.2.21.0.1</h2>

<ul><li><a href="../DESCRIPTION">DESCRIPTION file</a>.</li>
<li><a href="../doc/index.html">User guides, package vignettes and other documentation.</a></li>
<li><a href="../NEWS">Package NEWS</a>.</li>
</ul>

<h2>Help Pages</h2>


<table style="width: 100%;">
<tr><td style="width: 25%;"><a href="RcppEnsmallen-package.html">RcppEnsmallen-package</a></td>
<td>RcppEnsmallen: Header-Only C++ Mathematical Optimization Library for 'Armadillo'</td></tr>
<tr><td style="width: 25%;"><a href="lin_reg_lbfgs.html">lin_reg_lbfgs</a></td>
<td>Linear Regression with L-BFGS</td></tr>
<tr><td style="width: 25%;"><a href="RcppEnsmallen-package.html">RcppEnsmallen</a></td>
<td>RcppEnsmallen: Header-Only C++ Mathematical Optimization Library for 'Armadillo'</td></tr>
</table>
</div></body></html>
@media screen {
    .container {
	padding-right: 10px;
	padding-left: 10px;
	margin-right: auto;
	margin-left: auto;
	max-width: 900px;
    }
}

.rimage img { /* from knitr - for examples and demos */
    width: 96%;
    margin-left: 2%;
} 	

.katex { font-size: 1.1em; }

code {
    color: inherit;
    background: inherit;
}

body {
    line-height: 1.4;
    background: white;
    color: black;
}

a:link {
    background: white;
    color: blue;
}

a:visited {
    background: white;
    color: rgb(50%, 0%, 50%);
}

h1 {
    background: white;
    color: rgb(55%, 55%, 55%);
    font-family: monospace;
    font-size: 1.4em; /* x-large; */
    text-align: center;
}

h2 {
    background: white;
    color: rgb(40%, 40%, 40%);
    font-family: monospace;
    font-size: 1.2em; /* large; */
    text-align: center;
}

h3 {
    background: white;
    color: rgb(40%, 40%, 40%);
    font-family: monospace;
    font-size: 1.2em; /* large; */
}

h4 {
    background: white;
    color: rgb(40%, 40%, 40%);
    font-family: monospace;
    font-style: italic;
    font-size: 1.2em; /* large; */
}

h5 {
    background: white;
    color: rgb(40%, 40%, 40%);
    font-family: monospace;
}

h6 {
    background: white;
    color: rgb(40%, 40%, 40%);
    font-family: monospace;
    font-style: italic;
}

img.toplogo {
    width: 4em;
    vertical-align: middle;
}

img.arrow {
    width: 30px;
    height: 30px;
    border: 0;
}

span.acronym {
    font-size: small;
}

span.env {
    font-family: monospace;
}

span.file {
    font-family: monospace;
}

span.option{
    font-family: monospace;
}

span.pkg {
    font-weight: bold;
}

span.samp{
    font-family: monospace;
}

div.vignettes a:hover {
    background: rgb(85%, 85%, 85%);
}

tr {
    vertical-align: top;
}

span.rlang {
    font-family: Courier New, Courier;
    color: #666666;
}

Procedure for updating the ensmallen library:

- Download ensmallen from upstream
- Copy and replace the ensmallen.hpp and ensmallen_bits found in this directory
// Copyright (C) 2018 - Present James Balamuta and Dirk Eddelbuettel
//
// This file is part of RcppEnsmallen.
//
// RcppEnsmallen is free software: you can redistribute it and/or modify it
// under the terms of the GNU General Public License as published by
// the Free Software Foundation, either version 2 of the License, or
// (at your option) any later version.
//
// RcppEnsmallen is distributed in the hope that it will be useful, but
// WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU General Public License for more details.
//
// You should have received a copy of the GNU General Public License
// along with RcppEnsmallen.  If not, see <http://www.gnu.org/licenses/>.

#ifndef RcppEnsmallen__RcppEnsmallen__h
#define RcppEnsmallen__RcppEnsmallen__h

// Enable RcppArmadillo and Rcpp
#include <RcppArmadillo.h>

// Load the ensmallen library
#include "ensmallen.hpp"

#endif
/**
 * @file ensmallen.hpp
 *
 * This is the main header to include if you want to use the ensmallen library.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */

// NOTE: When using the ensmallen library in your code, only include the ensmallen.hpp header.
// NOTE: Do not include any of the files in the ensmallen_bits folder.

#ifndef ENSMALLEN_HPP
#define ENSMALLEN_HPP

// certain compilers are way behind the curve
#if (defined(_MSVC_LANG) && (_MSVC_LANG >= 201402L))
  #undef  ARMA_USE_CXX11
  #define ARMA_USE_CXX11
#endif

#include <armadillo>

#if !defined(ARMA_USE_CXX11)
  // armadillo automatically enables ARMA_USE_CXX11
  // when a C++11/C++14/C++17/etc compiler is detected
  #error "please enable C++11/C++14 mode in your compiler"
#endif

#if ((ARMA_VERSION_MAJOR < 9) || ((ARMA_VERSION_MAJOR == 9) && (ARMA_VERSION_MINOR < 800)))
  #error "need Armadillo version 9.800 or later"
#endif

#include <cctype>
#include <cfloat>
#include <climits>
#include <cmath>
#include <cstdint>
#include <cstdio>
#include <cstdlib>
#include <cstring>
#include <iostream>
#include <map>
#include <set>
#include <limits>
#include <sstream>
#include <stdexcept>
#include <string>
#include <tuple>
#include <utility>
#include <vector>

// On Visual Studio, disable C4519 (default arguments for function templates)
// since it's by default an error, which doesn't even make any sense because
// it's part of the C++11 standard.
#ifdef _MSC_VER
  #pragma warning(disable : 4519)
#endif

#include "ensmallen_bits/config.hpp"
#include "ensmallen_bits/ens_version.hpp"
#include "ensmallen_bits/log.hpp" // TODO: should move to another place

#include "ensmallen_bits/utility/any.hpp"
#include "ensmallen_bits/utility/arma_traits.hpp"
#include "ensmallen_bits/utility/indicators/epsilon.hpp"
#include "ensmallen_bits/utility/indicators/igd_plus.hpp"

// Contains traits, must be placed before report callback.
#include "ensmallen_bits/function.hpp" // TODO: should move to function/

// Callbacks.
#include "ensmallen_bits/callbacks/callbacks.hpp"
#include "ensmallen_bits/callbacks/early_stop_at_min_loss.hpp"
#include "ensmallen_bits/callbacks/grad_clip_by_norm.hpp"
#include "ensmallen_bits/callbacks/grad_clip_by_value.hpp"
#include "ensmallen_bits/callbacks/print_loss.hpp"
#include "ensmallen_bits/callbacks/progress_bar.hpp"
#include "ensmallen_bits/callbacks/query_front.hpp"
#include "ensmallen_bits/callbacks/report.hpp"
#include "ensmallen_bits/callbacks/store_best_coordinates.hpp"
#include "ensmallen_bits/callbacks/timer_stop.hpp"

#include "ensmallen_bits/problems/problems.hpp" // TODO: should move to another place

#include "ensmallen_bits/ada_belief/ada_belief.hpp"
#include "ensmallen_bits/ada_bound/ada_bound.hpp"
#include "ensmallen_bits/ada_delta/ada_delta.hpp"
#include "ensmallen_bits/ada_grad/ada_grad.hpp"
#include "ensmallen_bits/ada_sqrt/ada_sqrt.hpp"
#include "ensmallen_bits/adam/adam.hpp"
#include "ensmallen_bits/demon_adam/demon_adam.hpp"
#include "ensmallen_bits/demon_sgd/demon_sgd.hpp"
#include "ensmallen_bits/qhadam/qhadam.hpp"
#include "ensmallen_bits/aug_lagrangian/aug_lagrangian.hpp"
#include "ensmallen_bits/bigbatch_sgd/bigbatch_sgd.hpp"
#include "ensmallen_bits/cmaes/cmaes.hpp"
#include "ensmallen_bits/cmaes/active_cmaes.hpp"
#include "ensmallen_bits/cd/cd.hpp"
#include "ensmallen_bits/cne/cne.hpp"
#include "ensmallen_bits/de/de.hpp"
#include "ensmallen_bits/eve/eve.hpp"
#include "ensmallen_bits/ftml/ftml.hpp"

#include "ensmallen_bits/fw/frank_wolfe.hpp"
#include "ensmallen_bits/gradient_descent/gradient_descent.hpp"
#include "ensmallen_bits/grid_search/grid_search.hpp"
#include "ensmallen_bits/iqn/iqn.hpp"
#include "ensmallen_bits/katyusha/katyusha.hpp"
#include "ensmallen_bits/lbfgs/lbfgs.hpp"
#include "ensmallen_bits/lookahead/lookahead.hpp"
#include "ensmallen_bits/moead/moead.hpp"
#include "ensmallen_bits/nsga2/nsga2.hpp"
#include "ensmallen_bits/padam/padam.hpp"
#include "ensmallen_bits/parallel_sgd/parallel_sgd.hpp"
#include "ensmallen_bits/pso/pso.hpp"
#include "ensmallen_bits/rmsprop/rmsprop.hpp"

#include "ensmallen_bits/sa/sa.hpp"
#include "ensmallen_bits/sarah/sarah.hpp"
#include "ensmallen_bits/sdp/sdp.hpp"
#include "ensmallen_bits/sdp/lrsdp.hpp"
#include "ensmallen_bits/sdp/primal_dual.hpp"

#include "ensmallen_bits/sgd/sgd.hpp"
// TODO: this should probably be included in sgd.hpp
#include "ensmallen_bits/sgd/update_policies/gradient_clipping.hpp"
#include "ensmallen_bits/sgdr/sgdr.hpp"
#include "ensmallen_bits/sgdr/snapshot_ensembles.hpp"
#include "ensmallen_bits/sgdr/snapshot_sgdr.hpp"
#include "ensmallen_bits/smorms3/smorms3.hpp"
#include "ensmallen_bits/spalera_sgd/spalera_sgd.hpp"
#include "ensmallen_bits/spsa/spsa.hpp"
#include "ensmallen_bits/svrg/svrg.hpp"
#include "ensmallen_bits/swats/swats.hpp"
#include "ensmallen_bits/wn_grad/wn_grad.hpp"
#include "ensmallen_bits/yogi/yogi.hpp"

#endif
/**
 * @file ada_belief.hpp
 * @author Marcus Edel
 *
 * Class wrapper for the AdaBelief update Policy. The intuition for AdaBelief is
 * to adapt the stepsize according to the "belief" in the current gradient
 * direction.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_ADA_BELIEF_HPP
#define ENSMALLEN_ADA_BELIEF_HPP

#include <ensmallen_bits/sgd/sgd.hpp>
#include "ada_belief_update.hpp"

namespace ens {

/**
 * The intuition for AdaBelief is to adapt the stepsize according to the
 * "belief" in the current gradient direction. For more information, see the
 * following.
 *
 * @code
 * @misc{zhuang2020adabelief,
 *   title         = {AdaBelief Optimizer: Adapting Stepsizes by the Belief in
 *                    Observed Gradients},
 *   author        = {Juntang Zhuang and Tommy Tang and Sekhar Tatikonda and
 *                    Nicha Dvornek and Yifan Ding and Xenophon Papademetris
 *                    and James S. Duncan},
 *   year          = {2020},
 *   eprint        = {2010.07468},
 *   archivePrefix = {arXiv},
 * }
 * @endcode
 *
 * AdaBelief can optimize differentiable separable functions. For more details,
 * see the documentation on function types included with this distribution or
 * on the ensmallen website.
 */
class AdaBelief
{
 public:
  /**
   * Construct the AdaBelief optimizer with the given function and parameters.
   * AdaBelief is sensitive to its parameters and hence a good hyperparameter
   * selection is necessary as its default may not fit every case.
   *
   * The maximum number of iterations refers to the maximum number of
   * points that are processed (i.e., one iteration equals one point; one
   * iteration does not equal one pass over the dataset).
   *
   * @param stepSize Step size for each iteration.
   * @param batchSize Number of points to process in a single step.
   * @param beta1 The exponential decay rate for the 1st moment estimates.
   * @param beta2 The exponential decay rate for the 2nd moment estimates.
   * @param epsilon A small constant for numerical stability.
   * @param maxIterations Maximum number of iterations allowed (0 means no
   *     limit).
   * @param tolerance Maximum absolute tolerance to terminate algorithm.
   * @param shuffle If true, the function order is shuffled; otherwise, each
   *     function is visited in linear order.
   * @param resetPolicy If true, parameters are reset before every Optimize
   *     call; otherwise, their values are retained.
   * @param exactObjective Calculate the exact objective (Default: estimate the
   *        final objective obtained on the last pass over the data).
   */
  AdaBelief(const double stepSize = 0.001,
            const size_t batchSize = 32,
            const double beta1 = 0.9,
            const double beta2 = 0.999,
            const double epsilon = 1e-12,
            const size_t maxIterations = 100000,
            const double tolerance = 1e-5,
            const bool shuffle = true,
            const bool resetPolicy = true,
            const bool exactObjective = false);

  /**
   * Optimize the given function using AdaBelief. The given starting point will
   * be modified to store the finishing point of the algorithm, and the final
   * objective value is returned.
   *
   * @tparam SeparableFunctionType Type of the function to optimize.
   * @tparam MatType Type of matrix to optimize with.
   * @tparam GradType Type of matrix to use to represent function gradients.
   * @tparam CallbackTypes Types of callback functions.
   * @param function Function to optimize.
   * @param iterate Starting point (will be modified).
   * @param callbacks Callback functions.
   * @return Objective value of the final point.
   */
  template<typename SeparableFunctionType,
           typename MatType,
           typename GradType,
           typename... CallbackTypes>
  typename std::enable_if<IsArmaType<GradType>::value,
      typename MatType::elem_type>::type
  Optimize(SeparableFunctionType& function,
           MatType& iterate,
           CallbackTypes&&... callbacks)
  {
    return optimizer.Optimize<SeparableFunctionType, MatType, GradType,
        CallbackTypes...>(function, iterate,
        std::forward<CallbackTypes>(callbacks)...);
  }

  //! Forward the MatType as GradType.
  template<typename SeparableFunctionType,
           typename MatType,
           typename... CallbackTypes>
  typename MatType::elem_type Optimize(SeparableFunctionType& function,
                                       MatType& iterate,
                                       CallbackTypes&&... callbacks)
  {
    return Optimize<SeparableFunctionType, MatType, MatType,
        CallbackTypes...>(function, iterate,
        std::forward<CallbackTypes>(callbacks)...);
  }

  //! Get the step size.
  double StepSize() const { return optimizer.StepSize(); }
  //! Modify the step size.
  double& StepSize() { return optimizer.StepSize(); }

  //! Get the batch size.
  size_t BatchSize() const { return optimizer.BatchSize(); }
  //! Modify the batch size.
  size_t& BatchSize() { return optimizer.BatchSize(); }

  //! Get the exponential decay rate for the 1st moment estimates.
  double Beta1() const { return optimizer.UpdatePolicy().Beta1(); }
  //! Modify the exponential decay rate for the 1st moment estimates.
  double& Beta1() { return optimizer.UpdatePolicy().Beta1(); }

  //! Get the exponential decay rate for the 2nd moment estimates.
  double Beta2() const { return optimizer.UpdatePolicy().Beta2(); }
  //! Get the second moment coefficient.
  double& Beta2() { return optimizer.UpdatePolicy().Beta2(); }

  //! Get the value for numerical stability.
  double Epsilon() const { return optimizer.UpdatePolicy().Epsilon(); }
  //! Modify the value used for numerical stability.
  double& Epsilon() { return optimizer.UpdatePolicy().Epsilon(); }

  //! Get the maximum number of iterations (0 indicates no limit).
  size_t MaxIterations() const { return optimizer.MaxIterations(); }
  //! Modify the maximum number of iterations (0 indicates no limit).
  size_t& MaxIterations() { return optimizer.MaxIterations(); }

  //! Get the tolerance for termination.
  double Tolerance() const { return optimizer.Tolerance(); }
  //! Modify the tolerance for termination.
  double& Tolerance() { return optimizer.Tolerance(); }

  //! Get whether or not the individual functions are shuffled.
  bool Shuffle() const { return optimizer.Shuffle(); }
  //! Modify whether or not the individual functions are shuffled.
  bool& Shuffle() { return optimizer.Shuffle(); }

  //! Get whether or not the actual objective is calculated.
  bool ExactObjective() const { return optimizer.ExactObjective(); }
  //! Modify whether or not the actual objective is calculated.
  bool& ExactObjective() { return optimizer.ExactObjective(); }

  //! Get whether or not the update policy parameters are reset before
  //! Optimize call.
  bool ResetPolicy() const { return optimizer.ResetPolicy(); }
  //! Modify whether or not the update policy parameters
  //! are reset before Optimize call.
  bool& ResetPolicy() { return optimizer.ResetPolicy(); }

  private:
  //! The Stochastic Gradient Descent object with AdaBelief policy.
  SGD<AdaBeliefUpdate> optimizer;
};

} // namespace ens

// Include implementation.
#include "ada_belief_impl.hpp"

#endif
/**
 * @file ada_belief_impl.hpp
 * @author Marcus Edel
 *
 * Implementation of AdaBelief class wrapper.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_ADA_BELIEF_ADA_BELIEF_IMPL_HPP
#define ENSMALLEN_ADA_BELIEF_ADA_BELIEF_IMPL_HPP

// In case it hasn't been included yet.
#include "ada_belief.hpp"

namespace ens {

inline AdaBelief::AdaBelief(
    const double stepSize,
    const size_t batchSize,
    const double beta1,
    const double beta2,
    const double epsilon,
    const size_t maxIterations,
    const double tolerance,
    const bool shuffle,
    const bool resetPolicy,
    const bool exactObjective) :
    optimizer(stepSize,
              batchSize,
              maxIterations,
              tolerance,
              shuffle,
              AdaBeliefUpdate(epsilon, beta1, beta2),
              NoDecay(),
              resetPolicy,
              exactObjective)
{ /* Nothing to do. */ }

} // namespace ens

 #endif
/**
 * @file ada_belief_update.hpp
 * @author Marcus Edel
 *
 * AdaBelief optimizer update policy. The intuition for AdaBelief is to adapt
 * the stepsize according to the "belief" in the current gradient direction.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_ADA_BELIEF_ADA_BELIEF_UPDATE_HPP
#define ENSMALLEN_ADA_BELIEF_ADA_BELIEF_UPDATE_HPP

namespace ens {

/**
 * The intuition for AdaBelief is to adapt the stepsize according to the
 * "belief" in the current gradient direction.
 *
 * For more information, see the following.
 *
 * @code
 * @misc{zhuang2020adabelief,
 *   title         = {AdaBelief Optimizer: Adapting Stepsizes by the Belief in
 *                    Observed Gradients},
 *   author        = {Juntang Zhuang and Tommy Tang and Sekhar Tatikonda and
 *                    Nicha Dvornek and Yifan Ding and Xenophon Papademetris
 *                    and James S. Duncan},
 *   year          = {2020},
 *   eprint        = {2010.07468},
 *   archivePrefix = {arXiv},
 * }
 * @endcode
 */
class AdaBeliefUpdate
{
 public:
  /**
   * Construct the AdaBelief update policy with the given parameters.
   *
   * @param epsilon A small constant for numerical stability.
   * @param beta1 The exponential decay rate for the 1st moment estimates.
   * @param beta2 The exponential decay rate for the 2nd moment estimates.
   */
  AdaBeliefUpdate(const double epsilon = 1e-8,
                  const double beta1 = 0.9,
                  const double beta2 = 0.999) :
    epsilon(epsilon),
    beta1(beta1),
    beta2(beta2)
  {
    // Nothing to do.
  }

  //! Get the value for numerical stability.
  double Epsilon() const { return epsilon; }
  //! Modify the value used for numerical stability.
  double& Epsilon() { return epsilon; }

  //! Get the exponential decay rate for the 1st moment estimates.
  double Beta1() const { return beta1; }
  //! Modify the exponential decay rate for the 1st moment estimates.
  double& Beta1() { return beta1; }

  //! Get the exponential decay rate for the 2nd moment estimates.
  double Beta2() const { return beta2; }
  //! Modify the exponential decay rate for the 2nd moment estimates.
  double& Beta2() { return beta2; }

  /**
   * The UpdatePolicyType policy classes must contain an internal 'Policy'
   * template class with two template arguments: MatType and GradType.  This is
   * instantiated at the start of the optimization, and holds parameters
   * specific to an individual optimization.
   */
  template<typename MatType, typename GradType>
  class Policy
  {
   public:
    /**
     * This constructor is called by the SGD Optimize() method before the start
     * of the iteration update process.
     *
     * @param parent AdaBeliefUpdate object.
     * @param rows Number of rows in the gradient matrix.
     * @param cols Number of columns in the gradient matrix.
     */
    Policy(AdaBeliefUpdate& parent, const size_t rows, const size_t cols) :
        parent(parent),
        iteration(0)
    {
      m.zeros(rows, cols);
      s.zeros(rows, cols);
    }

    /**
     * Update step for AdaBelief.
     *
     * @param iterate Parameters that minimize the function.
     * @param stepSize Step size to be used for the given iteration.
     * @param gradient The gradient matrix.
     */
    void Update(MatType& iterate,
                const double stepSize,
                const GradType& gradient)
    {
      // Increment the iteration counter variable.
      ++iteration;

      m *= parent.beta1;
      m += (1 - parent.beta1) * gradient;

      s *= parent.beta2;
      s += (1 - parent.beta2) * arma::pow(gradient - m, 2.0) + parent.epsilon;

      const double biasCorrection1 = 1.0 - std::pow(parent.beta1, iteration);
      const double biasCorrection2 = 1.0 - std::pow(parent.beta2, iteration);

      // And update the iterate.
      iterate -= ((m / biasCorrection1) * stepSize) / (arma::sqrt(s /
          biasCorrection2) + parent.epsilon);
    }

   private:
    //! Instantiated parent object.
    AdaBeliefUpdate& parent;

    //! The exponential moving average of gradient values.
    GradType m;

    // The exponential moving average of squared gradient values.
    GradType s;

    // The number of iterations.
    size_t iteration;
  };

 private:
  // The epsilon value used to initialise the squared gradient parameter.
  double epsilon;

  // The xponential decay rate for the 1st moment estimates.
  double beta1;

  // The exponential decay rate for the 2nd moment estimates.
  double beta2;
};

} // namespace ens

#endif
/**
 * @file ada_bound.hpp
 * @author Marcus Edel
 *
 * Class wrapper for the AdaBound and AMSBound update Policy.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_ADA_BOUND_HPP
#define ENSMALLEN_ADA_BOUND_HPP

#include <ensmallen_bits/sgd/sgd.hpp>
#include "ada_bound_update.hpp"
#include "ams_bound_update.hpp"

namespace ens {

/**
 * AdaBound and AMSBound, employ dynamic bounds on learning rates to achieve a
 * gradual and smooth transition from adaptive methods to SGD.
 *
 * For more information, see the following.
 *
 * @code
 * @inproceedings{Luo2019AdaBound,
 *   author    = {Luo, Liangchen and Xiong, Yuanhao and Liu, Yan and Sun, Xu},
 *   title     = {Adaptive Gradient Methods with Dynamic Bound of Learning
 *                Rate},
 *   booktitle = {Proceedings of the 7th International Conference on Learning
 *                Representations},
 *   month     = {May},
 *   year      = {2019},
 *   address   = {New Orleans, Louisiana}
 * }
 * @endcode
 *
 * AdaBound and AMSBound can optimize differentiable separable functions.
 * For more details, see the documentation on function types included with this
 * distribution or on the ensmallen website.
 */
template<typename UpdatePolicyType = AdaBoundUpdate,
         typename DecayPolicyType = NoDecay>
class AdaBoundType
{
 public:
  /**
   * Construct the AdaBoundType optimizer with the given function and
   * parameters. AdaBoundType is sensitive to its parameters and hence a good
   * hyper paramater selection is necessary as its default may not fit every
   * case.
   *
   * The maximum number of iterations refers to the maximum number of
   * points that are processed (i.e., one iteration equals one point; one
   * iteration does not equal one pass over the dataset).
   *
   * @param stepSize Step size for each iteration.
   * @param batchSize Number of points to process in a single step.
   * @param finalLr The final (SGD) learning rate.
   * @param gamma The convergence speed of the bound functions.
   * @param beta1 Exponential decay rate for the first moment estimates.
   * @param beta2 Exponential decay rate for the weighted infinity norm
   *     estimates.
   * @param epsilon Value used to initialise the mean squared gradient
   *     parameter.
   * @param maxIterations Maximum number of iterations allowed (0 means no
   *     limit).
   * @param tolerance Maximum absolute tolerance to terminate algorithm.
   * @param shuffle If true, the function order is shuffled; otherwise, each
   *     function is visited in linear order.
   * @param resetPolicy If true, parameters are reset before every Optimize
   *     call; otherwise, their values are retained.
   * @param exactObjective Calculate the exact objective (Default: estimate the
   *        final objective obtained on the last pass over the data).
   */
  AdaBoundType(const double stepSize = 0.001,
               const size_t batchSize = 32,
               const double finalLr = 0.1,
               const double gamma = 1e-3,
               const double beta1 = 0.9,
               const double beta2 = 0.999,
               const double epsilon = 1e-8,
               const size_t maxIterations = 100000,
               const double tolerance = 1e-5,
               const bool shuffle = true,
               const bool resetPolicy = true,
               const bool exactObjective = false);

  /**
   * Optimize the given function using AdaBoundType. The given starting point
   * will be modified to store the finishing point of the algorithm, and the
   * final objective value is returned. The DecomposableFunctionType is checked
   * for API consistency at compile time.
   *
   * @tparam DecomposableFunctionType Type of the function to be optimized.
   * @tparam MatType Type of matrix to optimize with.
   * @tparam GradType Type of matrix to use to represent function gradients.
   * @tparam CallbackTypes Types of callback functions.
   * @param function Function to optimize.
   * @param iterate Starting point (will be modified).
   * @param callbacks Callback functions.
   * @return Objective value of the final point.
   */
  template<typename DecomposableFunctionType,
           typename MatType,
           typename GradType,
           typename... CallbackTypes>
  typename std::enable_if<IsArmaType<GradType>::value,
      typename MatType::elem_type>::type
  Optimize(DecomposableFunctionType& function,
           MatType& iterate,
           CallbackTypes&&... callbacks)
  {
    return optimizer.template Optimize<DecomposableFunctionType, MatType,
        GradType, CallbackTypes...>(function, iterate,
        std::forward<CallbackTypes>(callbacks)...);
  }

  //! Forward the MatType as GradType.
  template<typename DecomposableFunctionType,
           typename MatType,
           typename... CallbackTypes>
  typename MatType::elem_type Optimize(DecomposableFunctionType& function,
                                       MatType& iterate,
                                       CallbackTypes&&... callbacks)
  {
    return Optimize<DecomposableFunctionType, MatType, MatType,
        CallbackTypes...>(function, iterate,
        std::forward<CallbackTypes>(callbacks)...);
  }

  //! Get the final (SGD) learning rate.
  double FinalLr() const { return optimizer.UpdatePolicy().FinalLr(); }
  //! Modify the final (SGD) learning rate.
  double& FinalLr() { return optimizer.UpdatePolicy().FinalLr(); }

  //! Get the convergence speed of the bound functions.
  double Gamma() const { return optimizer.UpdatePolicy().Gamma(); }
  //! Modify the convergence speed of the bound functions.
  double& Gamma() { return optimizer.UpdatePolicy().Gamma(); }

  //! Get the step size.
  double StepSize() const { return optimizer.StepSize(); }
  //! Modify the step size.
  double& StepSize() { return optimizer.StepSize(); }

  //! Get the batch size.
  size_t BatchSize() const { return optimizer.BatchSize(); }
  //! Modify the batch size.
  size_t& BatchSize() { return optimizer.BatchSize(); }

  //! Get the smoothing parameter.
  double Beta1() const { return optimizer.UpdatePolicy().Beta1(); }
  //! Modify the smoothing parameter.
  double& Beta1() { return optimizer.UpdatePolicy().Beta1(); }

  //! Get the second moment coefficient.
  double Beta2() const { return optimizer.UpdatePolicy().Beta2(); }
  //! Modify the second moment coefficient.
  double& Beta2() { return optimizer.UpdatePolicy().Beta2(); }

  //! Get the value used to initialise the mean squared gradient parameter.
  double Epsilon() const { return optimizer.UpdatePolicy().Epsilon(); }
  //! Modify the value used to initialise the mean squared gradient parameter.
  double& Epsilon() { return optimizer.UpdatePolicy().Epsilon(); }

  //! Get the maximum number of iterations (0 indicates no limit).
  size_t MaxIterations() const { return optimizer.MaxIterations(); }
  //! Modify the maximum number of iterations (0 indicates no limit).
  size_t& MaxIterations() { return optimizer.MaxIterations(); }

  //! Get the tolerance for termination.
  double Tolerance() const { return optimizer.Tolerance(); }
  //! Modify the tolerance for termination.
  double& Tolerance() { return optimizer.Tolerance(); }

  //! Get whether or not the individual functions are shuffled.
  bool Shuffle() const { return optimizer.Shuffle(); }
  //! Modify whether or not the individual functions are shuffled.
  bool& Shuffle() { return optimizer.Shuffle(); }

  //! Get whether or not the actual objective is calculated.
  bool ExactObjective() const { return optimizer.ExactObjective(); }
  //! Modify whether or not the actual objective is calculated.
  bool& ExactObjective() { return optimizer.ExactObjective(); }

  //! Get whether or not the update policy parameters are reset before
  //! Optimize call.
  bool ResetPolicy() const { return optimizer.ResetPolicy(); }
  //! Modify whether or not the update policy parameters
  //! are reset before Optimize call.
  bool& ResetPolicy() { return optimizer.ResetPolicy(); }

 private:
  //! The Stochastic Gradient Descent object with QHAdam policy.
  SGD<UpdatePolicyType, DecayPolicyType> optimizer;
};

using AdaBound = AdaBoundType<AdaBoundUpdate>;
using AMSBound = AdaBoundType<AMSBoundUpdate>;

} // namespace ens

// Include implementation.
#include "ada_bound_impl.hpp"

#endif
/**
 * @file qhadam_impl.hpp
 * @author Niteya Shah
 *
 * Implementation of QHAdam class wrapper.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_ADA_BOUND_IMPL_HPP
#define ENSMALLEN_ADA_BOUND_IMPL_HPP

// In case it hasn't been included yet.
#include "ada_bound.hpp"

namespace ens {

template<typename UpdatePolicyType, typename DecayPolicyType>
AdaBoundType<UpdatePolicyType, DecayPolicyType>::AdaBoundType(
    const double stepSize,
    const size_t batchSize,
    const double finalLr,
    const double gamma,
    const double beta1,
    const double beta2,
    const double epsilon,
    const size_t maxIterations,
    const double tolerance,
    const bool shuffle,
    const bool resetPolicy,
    const bool exactObjective) :
    optimizer(stepSize,
              batchSize,
              maxIterations,
              tolerance,
              shuffle,
              UpdatePolicyType(finalLr, gamma, epsilon, beta1, beta2),
              NoDecay(),
              resetPolicy,
              exactObjective)
{ /* Nothing to do. */ }

} // namespace ens

 #endif
/**
 * @file ada_bound_update.hpp
 * @author Marcus Edel
 *
 * Implments the AdaBound Optimizer. AdaBound is a variant of Adam which
 * employs dynamic bounds on learning rates.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_ADA_BOUND_UPDATE_HPP
#define ENSMALLEN_ADA_BOUND_UPDATE_HPP

namespace ens {

/**
 * AdaBound employs dynamic bounds on learning rates to achieve a gradual and
 * smooth transition from adaptive methods to SGD.
 *
 * For more information, see the following.
 *
 * @code
 * @inproceedings{Luo2019AdaBound,
 *   author    = {Luo, Liangchen and Xiong, Yuanhao and Liu, Yan and Sun, Xu},
 *   title     = {Adaptive Gradient Methods with Dynamic Bound of Learning
 *                Rate},
 *   booktitle = {Proceedings of the 7th International Conference on Learning
 *                Representations},
 *   month     = {May},
 *   year      = {2019},
 *   address   = {New Orleans, Louisiana}
 * }
 * @endcode
 */
class AdaBoundUpdate
{
 public:
  /**
   * Construct the AdaBound update policy with the given parameters.
   *
   * @param finalLr The final (SGD) learning rate.
   * @param gamma The convergence speed of the bound functions.
   * @param epsilon The epsilon value used to initialise the squared gradient
   *        parameter.
   * @param beta1 The smoothing parameter.
   * @param beta2 The second moment coefficient.
   */
  AdaBoundUpdate(const double finalLr = 0.1,
                 const double gamma = 1e-3,
                 const double epsilon = 1e-8,
                 const double beta1 = 0.9,
                 const double beta2 = 0.999) :
    finalLr(finalLr),
    gamma(gamma),
    epsilon(epsilon),
    beta1(beta1),
    beta2(beta2)
  {
    // Nothing to do.
  }

  //! Get the final (SGD) learning rate.
  double FinalLr() const { return finalLr; }
  //! Modify the final (SGD) learning rate.
  double& FinalLr() { return finalLr; }

  //! Get the convergence speed of the bound functions.
  double Gamma() const { return finalLr; }
  //! Modify the convergence speed of the bound functions.
  double& Gamma() { return finalLr; }

  //! Get the value used to initialise the squared gradient parameter.
  double Epsilon() const { return epsilon; }
  //! Modify the value used to initialise the squared gradient parameter.
  double& Epsilon() { return epsilon; }

  //! Get the smoothing parameter.
  double Beta1() const { return beta1; }
  //! Modify the smoothing parameter.
  double& Beta1() { return beta1; }

  //! Get the second moment coefficient.
  double Beta2() const { return beta2; }
  //! Modify the second moment coefficient.
  double& Beta2() { return beta2; }

  /**
   * The UpdatePolicyType policy classes must contain an internal 'Policy'
   * template class with two template arguments: MatType and GradType.  This is
   * instantiated at the start of the optimization, and holds parameters
   * specific to an individual optimization.
   */
  template<typename MatType, typename GradType>
  class Policy
  {
   public:
    /**
     * This constructor is called by the SGD Optimize() method before the start
     * of the iteration update process.
     *
     * @param parent AdaBoundUpdate object.
     * @param rows Number of rows in the gradient matrix.
     * @param cols Number of columns in the gradient matrix.
     */
    Policy(AdaBoundUpdate& parent, const size_t rows, const size_t cols) :
        parent(parent), first(true), initialStepSize(0), iteration(0)
    {
      m.zeros(rows, cols);
      v.zeros(rows, cols);
    }

    /**
     * Update step for AdaBound.
     *
     * @param iterate Parameters that minimize the function.
     * @param stepSize Step size to be used for the given iteration.
     * @param gradient The gradient matrix.
     */
    void Update(MatType& iterate,
                const double stepSize,
                const GradType& gradient)
    {
      // Convenience typedefs.
      typedef typename MatType::elem_type ElemType;

      // Save the initial step size.
      if (first)
      {
        first = false;
        initialStepSize = stepSize;
      }

      // Increment the iteration counter variable.
      ++iteration;

      // Decay the first and second moment running average coefficient.
      m *= parent.beta1;
      m += (1 - parent.beta1) * gradient;

      v *= parent.beta2;
      v += (1 - parent.beta2) * (gradient % gradient);

      const ElemType biasCorrection1 = 1.0 - std::pow(parent.beta1, iteration);
      const ElemType biasCorrection2 = 1.0 - std::pow(parent.beta2, iteration);

      const ElemType fl = parent.finalLr * stepSize / initialStepSize;
      const ElemType lower = fl * (1.0 - 1.0 / (parent.gamma * iteration + 1));
      const ElemType upper = fl * (1.0 + 1.0 / (parent.gamma * iteration));

       // Applies bounds on actual learning rate.
      iterate -= arma::clamp((stepSize *
          std::sqrt(biasCorrection2) / biasCorrection1) / (arma::sqrt(v) +
          parent.epsilon), lower, upper) % m;
    }

   private:
    // Instantiated parent object.
    AdaBoundUpdate& parent;

    // The exponential moving average of gradient values.
    GradType m;

    // The exponential moving average of squared gradient values.
    GradType v;

    // Whether this is the first call of the Update method.
    bool first;

    // The initial (Adam) learning rate.
    double initialStepSize;

    // The number of iterations.
    size_t iteration;
  };

 private:
  // The final (SGD) learning rate.
  double finalLr;

  // The convergence speed of the bound functions.
  double gamma;

  // The epsilon value used to initialise the squared gradient parameter.
  double epsilon;

  // The smoothing parameter.
  double beta1;

  // The second moment coefficient.
  double beta2;
};

} // namespace ens

#endif
/**
 * @file ams_bound_update.hpp
 * @author Marcus Edel
 *
 * Implments the AMSBound Optimizer. AMSBound is a variant of Adam which
 * employs dynamic bounds on learning rates.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_AMS_BOUND_UPDATE_HPP
#define ENSMALLEN_AMS_BOUND_UPDATE_HPP

namespace ens {

/**
 * AMSBound employs dynamic bounds on learning rates to achieve a gradual and
 * smooth transition from adaptive methods to SGD.
 *
 * For more information, see the following.
 *
 * @code
 * @inproceedings{Luo2019AdaBound,
 *   author    = {Luo, Liangchen and Xiong, Yuanhao and Liu, Yan and Sun, Xu},
 *   title     = {Adaptive Gradient Methods with Dynamic Bound of Learning
 *                Rate},
 *   booktitle = {Proceedings of the 7th International Conference on Learning
 *                Representations},
 *   month     = {May},
 *   year      = {2019},
 *   address   = {New Orleans, Louisiana}
 * }
 * @endcode
 */
class AMSBoundUpdate
{
 public:
  /**
   * Construct the AMSBound update policy with the given parameters.
   *
   * @param finalLr The final (SGD) learning rate.
   * @param gamma The convergence speed of the bound functions.
   * @param epsilon The epsilon value used to initialise the squared gradient
   *        parameter.
   * @param beta1 The smoothing parameter.
   * @param beta2 The second moment coefficient.
   */
  AMSBoundUpdate(const double finalLr = 0.1,
                 const double gamma = 1e-3,
                 const double epsilon = 1e-8,
                 const double beta1 = 0.9,
                 const double beta2 = 0.999) :
      finalLr(finalLr),
      gamma(gamma),
      epsilon(epsilon),
      beta1(beta1),
      beta2(beta2)
  {
    // Nothing to do.
  }

  //! Get the final (SGD) learning rate.
  double FinalLr() const { return finalLr; }
  //! Modify the final (SGD) learning rate.
  double& FinalLr() { return finalLr; }

  //! Get the convergence speed of the bound functions.
  double Gamma() const { return finalLr; }
  //! Modify the convergence speed of the bound functions.
  double& Gamma() { return finalLr; }

  //! Get the value used to initialise the squared gradient parameter.
  double Epsilon() const { return epsilon; }
  //! Modify the value used to initialise the squared gradient parameter.
  double& Epsilon() { return epsilon; }

  //! Get the smoothing parameter.
  double Beta1() const { return beta1; }
  //! Modify the smoothing parameter.
  double& Beta1() { return beta1; }

  //! Get the second moment coefficient.
  double Beta2() const { return beta2; }
  //! Modify the second moment coefficient.
  double& Beta2() { return beta2; }

  /**
   * The UpdatePolicyType policy classes must contain an internal 'Policy'
   * template class with two template arguments: MatType and GradType.  This is
   * instantiated at the start of the optimization, and holds parameters
   * specific to an individual optimization.
   */
  template<typename MatType, typename GradType>
  class Policy
  {
   public:
    /**
     * This constructor is called by the SGD Optimize() method before the start
     * of the iteration update process.
     *
     * @param parent AMSBoundUpdate object.
     * @param rows Number of rows in the gradient matrix.
     * @param cols Number of columns in the gradient matrix.
     */
    Policy(AMSBoundUpdate& parent, const size_t rows, const size_t cols) :
        parent(parent), first(true), initialStepSize(0), iteration(0)
    {
      m.zeros(rows, cols);
      v.zeros(rows, cols);
      vImproved.zeros(rows, cols);
    }

    /**
     * Update step for AMSBound.
     *
     * @param iterate Parameters that minimize the function.
     * @param stepSize Step size to be used for the given iteration.
     * @param gradient The gradient matrix.
     */
    void Update(MatType& iterate,
                const double stepSize,
                const GradType& gradient)
    {
      // Convenience typedefs.
      typedef typename MatType::elem_type ElemType;

      // Save the initial step size.
      if (first)
      {
        first = false;
        initialStepSize = stepSize;
      }

      // Increment the iteration counter variable.
      ++iteration;

      // Decay the first and second moment running average coefficient.
      m *= parent.beta1;
      m += (1 - parent.beta1) * gradient;

      v *= parent.beta2;
      v += (1 - parent.beta2) * (gradient % gradient);

      const ElemType biasCorrection1 = 1.0 - std::pow(parent.beta1, iteration);
      const ElemType biasCorrection2 = 1.0 - std::pow(parent.beta2, iteration);

      const ElemType fl = parent.finalLr * stepSize / initialStepSize;
      const ElemType lower = fl * (1.0 - 1.0 / (parent.gamma * iteration + 1));
      const ElemType upper = fl * (1.0 + 1.0 / (parent.gamma * iteration));

      // Element wise maximum of past and present squared gradients.
      vImproved = arma::max(vImproved, v);

      // Applies bounds on actual learning rate.
      iterate -= arma::clamp((stepSize *
          std::sqrt(biasCorrection2) / biasCorrection1) /
          (arma::sqrt(vImproved) + parent.epsilon),  lower, upper) % m;
    }

   private:
    // Instantiated parent object.
    AMSBoundUpdate& parent;

    // The exponential moving average of gradient values.
    GradType m;

    // The exponential moving average of squared gradient values.
    GradType v;

    // Whether this is the first call of the Update method.
    bool first;

    // The initial (Adam) learning rate.
    double initialStepSize;

    // The optimal squared gradient value.
    GradType vImproved;

    // The number of iterations.
    size_t iteration;
  };

 private:
  // The final (SGD) learning rate.
  double finalLr;

  // The convergence speed of the bound functions.
  double gamma;

  // The epsilon value used to initialise the squared gradient parameter.
  double epsilon;

  // The smoothing parameter.
  double beta1;

  // The second moment coefficient.
  double beta2;
};

} // namespace ens

#endif
/**
 * @file ada_delta.hpp
 * @author Ryan Curtin
 * @author Vasanth Kalingeri
 * @author Abhinav Moudgil
 *
 * Implementation of the AdaDelta optimizer. AdaDelta is an optimizer that
 * dynamically adapts over time using only first order information.
 * Additionally, AdaDelta requires no manual tuning of a learning rate.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_ADA_DELTA_ADA_DELTA_HPP
#define ENSMALLEN_ADA_DELTA_ADA_DELTA_HPP

#include <ensmallen_bits/sgd/sgd.hpp>
#include "ada_delta_update.hpp"

namespace ens {

/**
 * AdaDelta is an optimizer that uses two ideas to improve upon the two main
 * drawbacks of the Adagrad method:
 *
 *  - Accumulate Over Window
 *  - Correct Units with Hessian Approximation
 *
 * For more information, see the following.
 *
 * @code
 * @article{Zeiler2012,
 *   author  = {Matthew D. Zeiler},
 *   title   = {{ADADELTA:} An Adaptive Learning Rate Method},
 *   journal = {CoRR},
 *   year    = {2012}
 * }
 * @endcode
 *
 * AdaDelta can optimize differentiable separable functions.  For more details,
 * see the documentation on function types included with this distribution or on
 * the ensmallen website.
 */
class AdaDelta
{
 public:
  /**
   * Construct the AdaDelta optimizer with the given function and parameters.
   * The defaults here are not necessarily good for the given problem, so it is
   * suggested that the values used be tailored to the task at hand. The
   * maximum number of iterations refers to the maximum number of points that
   * are processed (i.e., one iteration equals one point; one iteration does not
   * equal one pass over the dataset).
   *
   * @param stepSize Step size for each iteration.
   * @param batchSize Number of points to process in one step.
   * @param rho Smoothing constant.
   * @param epsilon Value used to initialise the mean squared gradient
   *        parameter.
   * @param maxIterations Maximum number of iterations allowed (0 means no
   *        limit).
   * @param tolerance Maximum absolute tolerance to terminate algorithm.
   * @param shuffle If true, the function order is shuffled; otherwise, each
   *        function is visited in linear order.
   * @param resetPolicy If true, parameters are reset before every Optimize
   *        call; otherwise, their values are retained.
   * @param exactObjective Calculate the exact objective (Default: estimate the
   *        final objective obtained on the last pass over the data).
   */
  AdaDelta(const double stepSize = 1.0,
           const size_t batchSize = 32,
           const double rho = 0.95,
           const double epsilon = 1e-6,
           const size_t maxIterations = 100000,
           const double tolerance = 1e-5,
           const bool shuffle = true,
           const bool resetPolicy = true,
           const bool exactObjective = false);

  /**
   * Optimize the given function using AdaDelta. The given starting point will
   * be modified to store the finishing point of the algorithm, and the final
   * objective value is returned. The SeparableFunctionType is checked for
   * API consistency at compile time.
   *
   * @tparam SeparableFunctionType Type of the function to be optimized.
   * @tparam MatType Type of matrix to optimize with.
   * @tparam GradType Type of matrix to use to represent function gradients.
   * @tparam CallbackTypes Types of callback functions.
   * @param function Function to optimize.
   * @param iterate Starting point (will be modified).
   * @param callbacks Callback functions.
   * @return Objective value of the final point.
   */
  template<typename SeparableFunctionType,
           typename MatType,
           typename GradType,
           typename... CallbackTypes>
  typename std::enable_if<IsArmaType<GradType>::value,
      typename MatType::elem_type>::type
  Optimize(SeparableFunctionType& function,
           MatType& iterate,
           CallbackTypes&&... callbacks)
  {
    return optimizer.Optimize<SeparableFunctionType, MatType, GradType,
        CallbackTypes...>(function, iterate,
        std::forward<CallbackTypes>(callbacks)...);
  }

  //! Forward the MatType as GradType.
  template<typename SeparableFunctionType,
           typename MatType,
           typename... CallbackTypes>
  typename MatType::elem_type Optimize(SeparableFunctionType& function,
                                       MatType& iterate,
                                       CallbackTypes&&... callbacks)
  {
    return Optimize<SeparableFunctionType, MatType, MatType,
        CallbackTypes...>(function, iterate,
        std::forward<CallbackTypes>(callbacks)...);
  }

  //! Get the step size.
  double StepSize() const { return optimizer.StepSize(); }
  //! Modify the step size.
  double& StepSize() { return optimizer.StepSize(); }

  //! Get the batch size.
  size_t BatchSize() const { return optimizer.BatchSize(); }
  //! Modify the batch size.
  size_t& BatchSize() { return optimizer.BatchSize(); }

  //! Get the smoothing parameter.
  double Rho() const { return optimizer.UpdatePolicy().Rho(); }
  //! Modify the smoothing parameter.
  double& Rho() { return optimizer.UpdatePolicy().Rho(); }

  //! Get the value used to initialise the mean squared gradient parameter.
  double Epsilon() const { return optimizer.UpdatePolicy().Epsilon(); }
  //! Modify the value used to initialise the mean squared gradient parameter.
  double& Epsilon() { return optimizer.UpdatePolicy().Epsilon(); }

  //! Get the maximum number of iterations (0 indicates no limit).
  size_t MaxIterations() const { return optimizer.MaxIterations(); }
  //! Modify the maximum number of iterations (0 indicates no limit).
  size_t& MaxIterations() { return optimizer.MaxIterations(); }

  //! Get the tolerance for termination.
  double Tolerance() const { return optimizer.Tolerance(); }
  //! Modify the tolerance for termination.
  double& Tolerance() { return optimizer.Tolerance(); }

  //! Get whether or not the individual functions are shuffled.
  bool Shuffle() const { return optimizer.Shuffle(); }
  //! Modify whether or not the individual functions are shuffled.
  bool& Shuffle() { return optimizer.Shuffle(); }

  //! Get whether or not the actual objective is calculated.
  bool ExactObjective() const { return optimizer.ExactObjective(); }
  //! Modify whether or not the actual objective is calculated.
  bool& ExactObjective() { return optimizer.ExactObjective(); }

  //! Get whether or not the update policy parameters
  //! are reset before Optimize call.
  bool ResetPolicy() const { return optimizer.ResetPolicy(); }
  //! Modify whether or not the update policy parameters
  //! are reset before Optimize call.
  bool& ResetPolicy() { return optimizer.ResetPolicy(); }

 private:
  //! The Stochastic Gradient Descent object with AdaDelta policy.
  SGD<AdaDeltaUpdate> optimizer;
};

} // namespace ens

// Include implementation.
#include "ada_delta_impl.hpp"

#endif
/**
 * @file ada_delta_impl.hpp
 * @author Ryan Curtin
 * @author Vasanth Kalingeri
 * @author Abhinav Moudgil
 *
 * Implementation of the AdaDelta optimizer.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_ADA_DELTA_ADA_DELTA_IMPL_HPP
#define ENSMALLEN_ADA_DELTA_ADA_DELTA_IMPL_HPP

// In case it hasn't been included yet.
#include "ada_delta.hpp"

namespace ens {

inline AdaDelta::AdaDelta(const double stepSize,
                          const size_t batchSize,
                          const double rho,
                          const double epsilon,
                          const size_t maxIterations,
                          const double tolerance,
                          const bool shuffle,
                          const bool resetPolicy,
                          const bool exactObjective) :
    optimizer(stepSize,
              batchSize,
              maxIterations,
              tolerance,
              shuffle,
              AdaDeltaUpdate(rho, epsilon),
              NoDecay(),
              resetPolicy,
              exactObjective)
{ /* Nothing to do. */ }

} // namespace ens

#endif
/**
 * @file ada_delta_update.hpp
 * @author Vasanth Kalingeri
 * @author Abhinav Moudgil
 *
 * AdaDelta update for Stochastic Gradient Descent.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_ADA_DELTA_ADA_DELTA_UPDATE_HPP
#define ENSMALLEN_ADA_DELTA_ADA_DELTA_UPDATE_HPP

namespace ens {

/**
 * Implementation of the AdaDelta update policy. AdaDelta is an optimizer that
 * uses two ideas to improve upon the two main drawbacks of the AdaGrad method:
 *
 * - Accumulate Over Window
 * - Correct Units with Hessian Approximation
 *
 * For more information, see the following.
 *
 * @code
 * @article{Zeiler2012,
 *   author  = {Matthew D. Zeiler},
 *   title   = {{ADADELTA:} An Adaptive Learning Rate Method},
 *   journal = {CoRR},
 *   year    = {2012}
 * }
 * @endcode
 *
 */
class AdaDeltaUpdate
{
 public:
  /**
   * Construct the AdaDelta update policy with given rho and epsilon parameters.
   *
   * @param rho The smoothing parameter.
   * @param epsilon The epsilon value used to initialise the squared gradient
   *    parameter.
   */
  AdaDeltaUpdate(const double rho = 0.95, const double epsilon = 1e-6) :
      rho(rho),
      epsilon(epsilon)
  {
    // Nothing to do.
  }

  //! Get the smoothing parameter.
  double Rho() const { return rho; }
  //! Modify the smoothing parameter.
  double& Rho() { return rho; }

  //! Get the value used to initialise the mean squared gradient parameter.
  double Epsilon() const { return epsilon; }
  //! Modify the value used to initialise the mean squared gradient parameter.
  double& Epsilon() { return epsilon; }

  /**
   * The UpdatePolicyType policy classes must contain an internal 'Policy'
   * template class with two template arguments: MatType and GradType.  This is
   * instantiated at the start of the optimization, and holds parameters
   * specific to an individual optimization.
   */
  template<typename MatType, typename GradType>
  class Policy
  {
   public:
    /**
     * This constructor is called by the SGD optimizer method before the start
     * of the iteration update process. In AdaDelta update policy, the mean
     * squared and the delta mean squared gradient matrices are initialized to
     * the zeros matrix with the same size as gradient matrix (see ens::SGD<>).
     *
     * @param parent AdaDeltaUpdate object.
     * @param rows Number of rows in the gradient matrix.
     * @param cols Number of columns in the gradient matrix.
     */
    Policy(AdaDeltaUpdate& parent, const size_t rows, const size_t cols) :
        parent(parent)
    {
      meanSquaredGradient.zeros(rows, cols);
      meanSquaredGradientDx.zeros(rows, cols);
    }

    /**
     * Update step for SGD. The AdaDelta update dynamically adapts over time
     * using only first order information. Additionally, AdaDelta requires no
     * manual tuning of a learning rate.
     *
     * @param iterate Parameters that minimize the function.
     * @param stepSize Step size to be used for the given iteration.
     * @param gradient The gradient matrix.
     */
    void Update(MatType& iterate,
                const double stepSize,
                const GradType& gradient)
    {
      // Accumulate gradient.
      meanSquaredGradient *= parent.rho;
      meanSquaredGradient += (1 - parent.rho) * (gradient % gradient);
      GradType dx = arma::sqrt((meanSquaredGradientDx + parent.epsilon) /
          (meanSquaredGradient + parent.epsilon)) % gradient;

      // Accumulate updates.
      meanSquaredGradientDx *= parent.rho;
      meanSquaredGradientDx += (1 - parent.rho) * (dx % dx);

      // Apply update.
      iterate -= (stepSize * dx);
    }

   private:
    // The instantiated parent class.
    AdaDeltaUpdate& parent;

    // The mean squared gradient matrix.
    GradType meanSquaredGradient;

    // The delta mean squared gradient matrix.
    GradType meanSquaredGradientDx;
  };

 private:
  // The smoothing parameter.
  double rho;

  // The epsilon value used to initialise the mean squared gradient parameter.
  double epsilon;
};

} // namespace ens

#endif
/**
 * @file ada_grad.hpp
 * @author Abhinav Moudgil
 *
 * Implementation of the AdaGrad optimizer. AdaGrad is an optimizer that
 * chooses learning rate dynamically by adapting to the data. Hence AdaGrad
 * eliminates the need to manually tune the learning rate.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * terms of the 3-clause BSD license. You should have received a copy of the
 * 3-clause BSD license along with ensmallen. If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_ADA_GRAD_ADA_GRAD_HPP
#define ENSMALLEN_ADA_GRAD_ADA_GRAD_HPP

#include <ensmallen_bits/sgd/sgd.hpp>
#include "ada_grad_update.hpp"

namespace ens {

/**
 * AdaGrad is a modified version of stochastic gradient descent which performs
 * larger updates for more sparse parameters and smaller updates for less sparse
 * parameters.
 *
 * For more information, see the following.
 *
 * @code
 * @article{duchi2011adaptive,
 *   author  = {Duchi, John and Hazan, Elad and Singer, Yoram},
 *   title   = {Adaptive subgradient methods for online learning and stochastic
 *              optimization},
 *   journal = {Journal of Machine Learning Research},
 *   volume  = {12},
 *   number  = {Jul},
 *   pages   = {2121--2159},
 *   year    = {2011}
 * }
 * @endcode
 *
 * AdaGrad can optimize differentiable separable functions.  For more details,
 * see the documentation on function types included with this distribution or on
 * the ensmallen website.
 */
class AdaGrad
{
 public:
  /**
   * Construct the AdaGrad optimizer with the given function and parameters.
   * The defaults here are not necessarily good for the given problem, so it is
   * suggested that the values used be tailored to the task at hand. The
   * maximum number of iterations refers to the maximum number of points that
   * are processed (i.e., one iteration equals one point; one iteration does not
   * equal one pass over the dataset).
   *
   * @param stepSize Step size for each iteration.
   * @param batchSize Number of points to process in one step.
   * @param epsilon Value used to initialise the squared gradient parameter.
   * @param maxIterations Maximum number of iterations allowed (0 means no
   *        limit).
   * @param tolerance Maximum absolute tolerance to terminate algorithm.
   * @param shuffle If true, the function order is shuffled; otherwise, each
   *        function is visited in linear order.
   * @param resetPolicy If true, parameters are reset before every Optimize
   *        call; otherwise, their values are retained.
   * @param exactObjective Calculate the exact objective (Default: estimate the
   *        final objective obtained on the last pass over the data).
   */
  AdaGrad(const double stepSize = 0.01,
          const size_t batchSize = 32,
          const double epsilon = 1e-8,
          const size_t maxIterations = 100000,
          const double tolerance = 1e-5,
          const bool shuffle = true,
          const bool resetPolicy = true,
          const bool exactObjective = false);

  /**
   * Optimize the given function using AdaGrad. The given starting point will
   * be modified to store the finishing point of the algorithm, and the final
   * objective value is returned.
   *
   * @tparam SeparableFunctionType Type of the function to be optimized.
   * @tparam MatType Type of matrix to optimize with.
   * @tparam GradType Type of matrix to use to represent function gradients.
   * @tparam CallbackTypes Types of callback functions.
   * @param function Function to optimize.
   * @param iterate Starting point (will be modified).
   * @param callbacks Callback functions.
   * @return Objective value of the final point.
   */
  template<typename SeparableFunctionType,
           typename MatType,
           typename GradType,
           typename... CallbackTypes>
  typename std::enable_if<IsArmaType<GradType>::value,
      typename MatType::elem_type>::type
  Optimize(SeparableFunctionType& function,
           MatType& iterate,
           CallbackTypes&&... callbacks)
  {
    return optimizer.Optimize<SeparableFunctionType, MatType, GradType,
        CallbackTypes...>(function, iterate,
        std::forward<CallbackTypes>(callbacks)...);
  }

  //! Forward the MatType as GradType.
  template<typename SeparableFunctionType,
           typename MatType,
           typename... CallbackTypes>
  typename MatType::elem_type Optimize(SeparableFunctionType& function,
                                       MatType& iterate,
                                       CallbackTypes&&... callbacks)
  {
    return Optimize<SeparableFunctionType, MatType, MatType,
        CallbackTypes...>(function, iterate,
        std::forward<CallbackTypes>(callbacks)...);
  }

  //! Get the step size.
  double StepSize() const { return optimizer.StepSize(); }
  //! Modify the step size.
  double& StepSize() { return optimizer.StepSize(); }

  //! Get the batch size.
  size_t BatchSize() const { return optimizer.BatchSize(); }
  //! Modify the batch size.
  size_t& BatchSize() { return optimizer.BatchSize(); }

  //! Get the value used to initialise the squared gradient parameter.
  double Epsilon() const { return optimizer.UpdatePolicy().Epsilon(); }
  //! Modify the value used to initialise the squared gradient parameter.
  double& Epsilon() { return optimizer.UpdatePolicy().Epsilon(); }

  //! Get the maximum number of iterations (0 indicates no limit).
  size_t MaxIterations() const { return optimizer.MaxIterations(); }
  //! Modify the maximum number of iterations (0 indicates no limit).
  size_t& MaxIterations() { return optimizer.MaxIterations(); }

  //! Get the tolerance for termination.
  double Tolerance() const { return optimizer.Tolerance(); }
  //! Modify the tolerance for termination.
  double& Tolerance() { return optimizer.Tolerance(); }

  //! Get whether or not the individual functions are shuffled.
  bool Shuffle() const { return optimizer.Shuffle(); }
  //! Modify whether or not the individual functions are shuffled.
  bool& Shuffle() { return optimizer.Shuffle(); }

  //! Get whether or not the actual objective is calculated.
  bool ExactObjective() const { return optimizer.ExactObjective(); }
  //! Modify whether or not the actual objective is calculated.
  bool& ExactObjective() { return optimizer.ExactObjective(); }

  //! Get whether or not the update policy parameters
  //! are reset before Optimize call.
  bool ResetPolicy() const { return optimizer.ResetPolicy(); }
  //! Modify whether or not the update policy parameters
  //! are reset before Optimize call.
  bool& ResetPolicy() { return optimizer.ResetPolicy(); }

 private:
  //! The Stochastic Gradient Descent object with AdaGrad policy.
  SGD<AdaGradUpdate> optimizer;
};

} // namespace ens

// Include implementation.
#include "ada_grad_impl.hpp"

#endif
/**
 * @file ada_grad_impl.hpp
 * @author Abhinav Moudgil
 *
 * Implementation of AdaGrad optimizer.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_ADA_GRAD_ADA_GRAD_IMPL_HPP
#define ENSMALLEN_ADA_GRAD_ADA_GRAD_IMPL_HPP

// In case it hasn't been included yet.
#include "ada_grad.hpp"

namespace ens {

inline AdaGrad::AdaGrad(const double stepSize,
                        const size_t batchSize,
                        const double epsilon,
                        const size_t maxIterations,
                        const double tolerance,
                        const bool shuffle,
                        const bool resetPolicy,
                        const bool exactObjective) :
    optimizer(stepSize,
              batchSize,
              maxIterations,
              tolerance,
              shuffle,
              AdaGradUpdate(epsilon),
              NoDecay(),
              resetPolicy,
              exactObjective)
{ /* Nothing to do. */ }

} // namespace ens

#endif
/**
 * @file ada_grad_update.hpp
 * @author Abhinav Moudgil
 *
 * AdaGrad update for Stochastic Gradient Descent.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_ADA_GRAD_ADA_GRAD_UPDATE_HPP
#define ENSMALLEN_ADA_GRAD_ADA_GRAD_UPDATE_HPP

namespace ens {

/**
 * Implementation of the AdaGrad update policy. AdaGrad update policy chooses
 * learning rate dynamically by adapting to the data. Hence AdaGrad eliminates
 * the need to manually tune the learning rate.
 *
 * For more information, see the following.
 *
 * @code
 * @article{duchi2011adaptive,
 *   author  = {Duchi, John and Hazan, Elad and Singer, Yoram},
 *   title   = {Adaptive subgradient methods for online learning and
 *              stochastic optimization},
 *   journal = {Journal of Machine Learning Research},
 *   volume  = {12},
 *   number  = {Jul},
 *   pages   = {2121--2159},
 *   year    = {2011}
 * }
 * @endcode
 *
 */
class AdaGradUpdate
{
 public:
  /**
   * Construct the AdaGrad update policy with given epsilon parameter.
   *
   * @param epsilon The epsilon value used to initialise the squared gradient
   *        parameter.
   */
  AdaGradUpdate(const double epsilon = 1e-8) : epsilon(epsilon)
  {
    // Nothing to do.
  }

  //! Get the value used to initialise the squared gradient parameter.
  double Epsilon() const { return epsilon; }
  //! Modify the value used to initialise the squared gradient parameter.
  double& Epsilon() { return epsilon; }

  /**
   * The UpdatePolicyType policy classes must contain an internal 'Policy'
   * template class with two template arguments: MatType and GradType.  This is
   * instantiated at the start of the optimization, and holds parameters
   * specific to an individual optimization.
   */
  template<typename MatType, typename GradType>
  class Policy
  {
   public:
    /**
     * This constructor is called by the SGD optimizer before the start of the
     * iteration update process. In AdaGrad update policy, squared gradient
     * matrix is initialized to the zeros matrix with the same size as gradient
     * matrix (see ens::SGD<>).
     *
     * @param parent Instantiated parent class.
     * @param rows Number of rows in the gradient matrix.
     * @param cols Number of columns in the gradient matrix.
     */
    Policy(AdaGradUpdate& parent, const size_t rows, const size_t cols) :
        parent(parent),
        squaredGradient(rows, cols)
    {
      // Initialize an empty matrix for sum of squares of parameter gradient.
      squaredGradient.zeros();
    }

    /**
     * Update step for SGD. The AdaGrad update adapts the learning rate by
     * performing larger updates for more sparse parameters and smaller updates
     * for less sparse parameters.
     *
     * @param iterate Parameters that minimize the function.
     * @param stepSize Step size to be used for the given iteration.
     * @param gradient The gradient matrix.
     */
    void Update(MatType& iterate,
                const double stepSize,
                const GradType& gradient)
    {
      squaredGradient += (gradient % gradient);
      iterate -= (stepSize * gradient) / (arma::sqrt(squaredGradient) +
          parent.epsilon);
    }

   private:
    // Instantiated parent class.
    AdaGradUpdate& parent;
    // The squared gradient matrix.
    GradType squaredGradient;
  };

 private:
  // The epsilon value used to initialise the squared gradient parameter.
  double epsilon;
};

} // namespace ens

#endif
/**
 * @file ada_sqrt.hpp
 * @author Marcus Edel
 *
 * Implementation of the AdaSqrt optimizer. AdaSqrt is an optimizer that
 * chooses learning rate dynamically by adapting to the data and iteration.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * terms of the 3-clause BSD license. You should have received a copy of the
 * 3-clause BSD license along with ensmallen. If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_ADA_SQRT_ADA_SQRT_HPP
#define ENSMALLEN_ADA_SQRT_ADA_SQRT_HPP

#include "../sgd/sgd.hpp"
#include "ada_sqrt_update.hpp"

namespace ens {

/**
 * AdaSqrt is a modified version of stochastic gradient descent which performs
 * larger updates for more sparse parameters and smaller updates for less sparse
 * parameters.
 *
 * For more information, see the following.
 *
 * @code
 * @misc{hu2019secondorder,
 *   title  = {Second-order Information in First-order Optimization Methods},
 *   author = {Yuzheng Hu and Licong Lin and Shange Tang},
 *   year   = {2019},
 *   eprint = {1912.09926},
 * }
 * @endcode
 *
 * AdaSqrt can optimize differentiable separable functions.  For more details,
 * see the documentation on function types included with this distribution or on
 * the ensmallen website.
 */
class AdaSqrt
{
 public:
  /**
   * Construct the AdaSqrt optimizer with the given function and parameters.
   * The defaults here are not necessarily good for the given problem, so it is
   * suggested that the values used be tailored to the task at hand. The
   * maximum number of iterations refers to the maximum number of points that
   * are processed (i.e., one iteration equals one point; one iteration does not
   * equal one pass over the dataset).
   *
   * @param stepSize Step size for each iteration.
   * @param batchSize Number of points to process in one step.
   * @param epsilon Value used to initialise the squared gradient parameter.
   * @param maxIterations Maximum number of iterations allowed (0 means no
   *        limit).
   * @param tolerance Maximum absolute tolerance to terminate algorithm.
   * @param shuffle If true, the function order is shuffled; otherwise, each
   *        function is visited in linear order.
   * @param resetPolicy If true, parameters are reset before every Optimize
   *        call; otherwise, their values are retained.
   * @param exactObjective Calculate the exact objective (Default: estimate the
   *        final objective obtained on the last pass over the data).
   */
  AdaSqrt(const double stepSize = 0.01,
          const size_t batchSize = 32,
          const double epsilon = 1e-8,
          const size_t maxIterations = 100000,
          const double tolerance = 1e-5,
          const bool shuffle = true,
          const bool resetPolicy = true,
          const bool exactObjective = false);

  /**
   * Optimize the given function using AdaSqrt. The given starting point will
   * be modified to store the finishing point of the algorithm, and the final
   * objective value is returned.
   *
   * @tparam SeparableFunctionType Type of the function to be optimized.
   * @tparam MatType Type of matrix to optimize with.
   * @tparam GradType Type of matrix to use to represent function gradients.
   * @tparam CallbackTypes Types of callback functions.
   * @param function Function to optimize.
   * @param iterate Starting point (will be modified).
   * @param callbacks Callback functions.
   * @return Objective value of the final point.
   */
  template<typename SeparableFunctionType,
           typename MatType,
           typename GradType,
           typename... CallbackTypes>
  typename std::enable_if<IsArmaType<GradType>::value,
      typename MatType::elem_type>::type
  Optimize(SeparableFunctionType& function,
           MatType& iterate,
           CallbackTypes&&... callbacks)
  {
    return optimizer.Optimize<SeparableFunctionType, MatType, GradType,
        CallbackTypes...>(function, iterate,
        std::forward<CallbackTypes>(callbacks)...);
  }

  //! Forward the MatType as GradType.
  template<typename SeparableFunctionType,
           typename MatType,
           typename... CallbackTypes>
  typename MatType::elem_type Optimize(SeparableFunctionType& function,
                                       MatType& iterate,
                                       CallbackTypes&&... callbacks)
  {
    return Optimize<SeparableFunctionType, MatType, MatType,
        CallbackTypes...>(function, iterate,
        std::forward<CallbackTypes>(callbacks)...);
  }

  //! Get the step size.
  double StepSize() const { return optimizer.StepSize(); }
  //! Modify the step size.
  double& StepSize() { return optimizer.StepSize(); }

  //! Get the batch size.
  size_t BatchSize() const { return optimizer.BatchSize(); }
  //! Modify the batch size.
  size_t& BatchSize() { return optimizer.BatchSize(); }

  //! Get the value used to initialise the squared gradient parameter.
  double Epsilon() const { return optimizer.UpdatePolicy().Epsilon(); }
  //! Modify the value used to initialise the squared gradient parameter.
  double& Epsilon() { return optimizer.UpdatePolicy().Epsilon(); }

  //! Get the maximum number of iterations (0 indicates no limit).
  size_t MaxIterations() const { return optimizer.MaxIterations(); }
  //! Modify the maximum number of iterations (0 indicates no limit).
  size_t& MaxIterations() { return optimizer.MaxIterations(); }

  //! Get the tolerance for termination.
  double Tolerance() const { return optimizer.Tolerance(); }
  //! Modify the tolerance for termination.
  double& Tolerance() { return optimizer.Tolerance(); }

  //! Get whether or not the individual functions are shuffled.
  bool Shuffle() const { return optimizer.Shuffle(); }
  //! Modify whether or not the individual functions are shuffled.
  bool& Shuffle() { return optimizer.Shuffle(); }

  //! Get whether or not the actual objective is calculated.
  bool ExactObjective() const { return optimizer.ExactObjective(); }
  //! Modify whether or not the actual objective is calculated.
  bool& ExactObjective() { return optimizer.ExactObjective(); }

  //! Get whether or not the update policy parameters
  //! are reset before Optimize call.
  bool ResetPolicy() const { return optimizer.ResetPolicy(); }
  //! Modify whether or not the update policy parameters
  //! are reset before Optimize call.
  bool& ResetPolicy() { return optimizer.ResetPolicy(); }

 private:
  //! The Stochastic Gradient Descent object with AdaSqrt policy.
  SGD<AdaSqrtUpdate> optimizer;
};

} // namespace ens

// Include implementation.
#include "ada_sqrt_impl.hpp"

#endif
/**
 * @file ada_sqrt_impl.hpp
 * @author Marcus Edel
 *
 * Implementation of AdaSqrt optimizer.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_ADA_SQRT_ADA_SQRT_IMPL_HPP
#define ENSMALLEN_ADA_SQRT_ADA_SQRT_IMPL_HPP

namespace ens {

inline AdaSqrt::AdaSqrt(const double stepSize,
                        const size_t batchSize,
                        const double epsilon,
                        const size_t maxIterations,
                        const double tolerance,
                        const bool shuffle,
                        const bool resetPolicy,
                        const bool exactObjective) :
    optimizer(stepSize,
              batchSize,
              maxIterations,
              tolerance,
              shuffle,
              AdaSqrtUpdate(epsilon),
              NoDecay(),
              resetPolicy,
              exactObjective)
{ /* Nothing to do. */ }

} // namespace ens

#endif
/**
 * @file ada_sqrt_update.hpp
 * @author Marcus Edel
 *
 * AdaSqrt update for Stochastic Gradient Descent.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_ADA_SQRT_ADA_SQRT_UPDATE_HPP
#define ENSMALLEN_ADA_SQRT_ADA_SQRT_UPDATE_HPP

namespace ens {

/**
 * Implementation of the AdaSqrt update policy. AdaSqrt update policy chooses
 * learning rate dynamically by adapting to the data and iteration.
 *
 * For more information, see the following.
 *
 * @code
 * @misc{hu2019secondorder,
 *   title  = {Second-order Information in First-order Optimization Methods},
 *   author = {Yuzheng Hu and Licong Lin and Shange Tang},
 *   year   = {2019},
 *   eprint = {1912.09926},
 * }
 * @endcode
 *
 */
class AdaSqrtUpdate
{
 public:
  /**
   * Construct the AdaSqrt update policy with given epsilon parameter.
   *
   * @param epsilon The epsilon value used to initialise the squared gradient
   *        parameter.
   */
  AdaSqrtUpdate(const double epsilon = 1e-8) : epsilon(epsilon)
  {
    // Nothing to do.
  }

  //! Get the value used to initialise the squared gradient parameter.
  double Epsilon() const { return epsilon; }
  //! Modify the value used to initialise the squared gradient parameter.
  double& Epsilon() { return epsilon; }

  /**
   * The UpdatePolicyType policy classes must contain an internal 'Policy'
   * template class with two template arguments: MatType and GradType.  This is
   * instantiated at the start of the optimization, and holds parameters
   * specific to an individual optimization.
   */
  template<typename MatType, typename GradType>
  class Policy
  {
   public:
    /**
     * This constructor is called by the SGD optimizer before the start of the
     * iteration update process. In AdaSqrt update policy, squared gradient
     * matrix is initialized to the zeros matrix with the same size as gradient
     * matrix (see ens::SGD<>).
     *
     * @param parent Instantiated parent class.
     * @param rows Number of rows in the gradient matrix.
     * @param cols Number of columns in the gradient matrix.
     */
    Policy(AdaSqrtUpdate& parent, const size_t rows, const size_t cols) :
        parent(parent),
        squaredGradient(rows, cols),
        iteration(0)
    {
      // Initialize an empty matrix for sum of squares of parameter gradient.
      squaredGradient.zeros();
    }

    /**
     * Update step for SGD. The AdaSqrt update adapts the learning rate by
     * performing larger updates for more sparse parameters and smaller updates
     * for less sparse parameters.
     *
     * @param iterate Parameters that minimize the function.
     * @param stepSize Step size to be used for the given iteration.
     * @param gradient The gradient matrix.
     */
    void Update(MatType& iterate,
                const double stepSize,
                const GradType& gradient)
    {
      ++iteration;

      squaredGradient += arma::square(gradient);

      iterate -= stepSize * std::sqrt(iteration) * gradient /
          (squaredGradient + parent.epsilon);
    }

   private:
    // Instantiated parent class.
    AdaSqrtUpdate& parent;
    // The squared gradient matrix.
    GradType squaredGradient;
    // The number of iterations.
    size_t iteration;
  };

 private:
  // The epsilon value used to initialise the squared gradient parameter.
  double epsilon;
};

} // namespace ens

#endif
/**
 * @file adam.hpp
 * @author Ryan Curtin
 * @author Vasanth Kalingeri
 * @author Marcus Edel
 * @author Vivek Pal
 * @author Sourabh Varshney
 * @author Haritha Nair
 *
 * Adam, AdaMax, AMSGrad, Nadam and Nadamax optimizers. Adam is an an algorithm
 * for first-order gradient-based optimization of stochastic objective
 * functions, based on adaptive estimates of lower-order moments. AdaMax is
 * simply a variant of Adam based on the infinity norm. AMSGrad is another
 * variant of Adam with guaranteed convergence. Nadam is another variant of
 * Adam based on NAG. NadaMax is a variant for Nadam based on Infinity form.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_ADAM_ADAM_HPP
#define ENSMALLEN_ADAM_ADAM_HPP

#include <ensmallen_bits/sgd/sgd.hpp>
#include "adam_update.hpp"
#include "adamax_update.hpp"
#include "amsgrad_update.hpp"
#include "nadam_update.hpp"
#include "nadamax_update.hpp"
#include "optimisticadam_update.hpp"

namespace ens {

/**
 * Adam is an optimizer that computes individual adaptive learning rates for
 * different parameters from estimates of first and second moments of the
 * gradients. AdaMax is a variant of Adam based on the infinity norm as given
 * in the section 7 of the following paper. Nadam is an optimizer that
 * combines the Adam and NAG. NadaMax is an variant of Nadam based on Infinity
 * form.
 *
 * For more information, see the following.
 *
 * @code
 * @article{Kingma2014,
 *   author  = {Diederik P. Kingma and Jimmy Ba},
 *   title   = {Adam: {A} Method for Stochastic Optimization},
 *   journal = {CoRR},
 *   year    = {2014},
 *   url     = {http://arxiv.org/abs/1412.6980}
 * }
 * @article{
 *   title   = {On the convergence of Adam and beyond},
 *   url     = {https://openreview.net/pdf?id=ryQu7f-RZ}
 *   year    = {2018}
 * }
 * @endcode
 *
 * Adam, AdaMax, AMSGrad, Nadam, and NadaMax can optimize differentiable
 * separable functions.  For more details, see the documentation on function
 * types included with this distribution or on the ensmallen website.
 *
 * @tparam UpdateRule Adam optimizer update rule to be used.
 */
template<typename UpdateRule = AdamUpdate>
class AdamType
{
 public:
  /**
   * Construct the Adam optimizer with the given function and parameters. The
   * defaults here are not necessarily good for the given problem, so it is
   * suggested that the values used be tailored to the task at hand.  The
   * maximum number of iterations refers to the maximum number of points that
   * are processed (i.e., one iteration equals one point; one iteration does not
   * equal one pass over the dataset).
   *
   * @param stepSize Step size for each iteration.
   * @param batchSize Number of points to process in a single step.
   * @param beta1 Exponential decay rate for the first moment estimates.
   * @param beta2 Exponential decay rate for the weighted infinity norm
            estimates.
   * @param eps Value used to initialise the mean squared gradient parameter.
   * @param maxIterations Maximum number of iterations allowed (0 means no
   *        limit).
   * @param tolerance Maximum absolute tolerance to terminate algorithm.
   * @param shuffle If true, the function order is shuffled; otherwise, each
   *        function is visited in linear order.
   * @param resetPolicy If true, parameters are reset before every Optimize
   *        call; otherwise, their values are retained.
   * @param exactObjective Calculate the exact objective (Default: estimate the
   *        final objective obtained on the last pass over the data).
   */
  AdamType(const double stepSize = 0.001,
           const size_t batchSize = 32,
           const double beta1 = 0.9,
           const double beta2 = 0.999,
           const double eps = 1e-8,
           const size_t maxIterations = 100000,
           const double tolerance = 1e-5,
           const bool shuffle = true,
           const bool resetPolicy = true,
           const bool exactObjective = false);

  /**
   * Optimize the given function using Adam. The given starting point will be
   * modified to store the finishing point of the algorithm, and the final
   * objective value is returned.
   *
   * @tparam SeparableFunctionType Type of the function to be optimized.
   * @tparam MatType Type of matrix to optimize with.
   * @tparam GradType Type of matrix to use to represent function gradients.
   * @tparam CallbackTypes Types of callback functions.
   * @param function Function to optimize.
   * @param iterate Starting point (will be modified).
   * @param callbacks Callback functions.
   * @return Objective value of the final point.
   */
  template<typename SeparableFunctionType,
           typename MatType,
           typename GradType,
           typename... CallbackTypes>
  typename std::enable_if<IsArmaType<GradType>::value,
      typename MatType::elem_type>::type
  Optimize(SeparableFunctionType& function,
           MatType& iterate,
           CallbackTypes&&... callbacks)
  {
    return optimizer.template Optimize<
        SeparableFunctionType, MatType, GradType, CallbackTypes...>(
        function, iterate, std::forward<CallbackTypes>(callbacks)...);
  }

  //! Forward the MatType as GradType.
  template<typename SeparableFunctionType,
           typename MatType,
           typename... CallbackTypes>
  typename MatType::elem_type Optimize(SeparableFunctionType& function,
                                       MatType& iterate,
                                       CallbackTypes&&... callbacks)
  {
    return Optimize<SeparableFunctionType, MatType, MatType,
        CallbackTypes...>(function, iterate,
        std::forward<CallbackTypes>(callbacks)...);
  }

  //! Get the step size.
  double StepSize() const { return optimizer.StepSize(); }
  //! Modify the step size.
  double& StepSize() { return optimizer.StepSize(); }

  //! Get the batch size.
  size_t BatchSize() const { return optimizer.BatchSize(); }
  //! Modify the batch size.
  size_t& BatchSize() { return optimizer.BatchSize(); }

  //! Get the smoothing parameter.
  double Beta1() const { return optimizer.UpdatePolicy().Beta1(); }
  //! Modify the smoothing parameter.
  double& Beta1() { return optimizer.UpdatePolicy().Beta1(); }

  //! Get the second moment coefficient.
  double Beta2() const { return optimizer.UpdatePolicy().Beta2(); }
  //! Modify the second moment coefficient.
  double& Beta2() { return optimizer.UpdatePolicy().Beta2(); }

  //! Get the value used to initialise the mean squared gradient parameter.
  double Epsilon() const { return optimizer.UpdatePolicy().Epsilon(); }
  //! Modify the value used to initialise the mean squared gradient parameter.
  double& Epsilon() { return optimizer.UpdatePolicy().Epsilon(); }

  //! Get the maximum number of iterations (0 indicates no limit).
  size_t MaxIterations() const { return optimizer.MaxIterations(); }
  //! Modify the maximum number of iterations (0 indicates no limit).
  size_t& MaxIterations() { return optimizer.MaxIterations(); }

  //! Get the tolerance for termination.
  double Tolerance() const { return optimizer.Tolerance(); }
  //! Modify the tolerance for termination.
  double& Tolerance() { return optimizer.Tolerance(); }

  //! Get whether or not the individual functions are shuffled.
  bool Shuffle() const { return optimizer.Shuffle(); }
  //! Modify whether or not the individual functions are shuffled.
  bool& Shuffle() { return optimizer.Shuffle(); }

  //! Get whether or not the actual objective is calculated.
  bool ExactObjective() const { return optimizer.ExactObjective(); }
  //! Modify whether or not the actual objective is calculated.
  bool& ExactObjective() { return optimizer.ExactObjective(); }

  //! Get whether or not the update policy parameters
  //! are reset before Optimize call.
  bool ResetPolicy() const { return optimizer.ResetPolicy(); }
  //! Modify whether or not the update policy parameters
  //! are reset before Optimize call.
  bool& ResetPolicy() { return optimizer.ResetPolicy(); }

 private:
  //! The Stochastic Gradient Descent object with Adam policy.
  SGD<UpdateRule> optimizer;
};

using Adam = AdamType<AdamUpdate>;

using AdaMax = AdamType<AdaMaxUpdate>;

using AMSGrad = AdamType<AMSGradUpdate>;

using Nadam = AdamType<NadamUpdate>;

using NadaMax = AdamType<NadaMaxUpdate>;

using OptimisticAdam = AdamType<OptimisticAdamUpdate>;

} // namespace ens

// Include implementation.
#include "adam_impl.hpp"

#endif
/**
 * @file adam_impl.hpp
 * @author Ryan Curtin
 * @author Vasanth Kalingeri
 * @author Marcus Edel
 * @author Vivek Pal
 *
 * Implementation of the Adam, AdaMax, AMSGrad, Nadam and NadaMax optimizer.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_ADAM_ADAM_IMPL_HPP
#define ENSMALLEN_ADAM_ADAM_IMPL_HPP

// In case it hasn't been included yet.
#include "adam.hpp"

namespace ens {

template<typename UpdateRule>
AdamType<UpdateRule>::AdamType(
    const double stepSize,
    const size_t batchSize,
    const double beta1,
    const double beta2,
    const double epsilon,
    const size_t maxIterations,
    const double tolerance,
    const bool shuffle,
    const bool resetPolicy,
    const bool exactObjective) :
    optimizer(stepSize,
              batchSize,
              maxIterations,
              tolerance,
              shuffle,
              UpdateRule(epsilon, beta1, beta2),
              NoDecay(),
              resetPolicy,
              exactObjective)
{ /* Nothing to do. */ }

} // namespace ens

#endif
/**
 * @file adam_update.hpp
 * @author Ryan Curtin
 * @author Vasanth Kalingeri
 * @author Marcus Edel
 * @author Vivek Pal
 *
 * Adam optimizer. Adam is an an algorithm for first-order gradient-based
 * optimization of stochastic objective functions, based on adaptive estimates
 * of lower-order moments.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_ADAM_ADAM_UPDATE_HPP
#define ENSMALLEN_ADAM_ADAM_UPDATE_HPP

namespace ens {

/**
 * Adam is an optimizer that computes individual adaptive learning rates for
 * different parameters from estimates of first and second moments of the
 * gradients as given in the section 7 of the following paper.
 *
 * For more information, see the following.
 *
 * @code
 * @article{Kingma2014,
 *   author  = {Diederik P. Kingma and Jimmy Ba},
 *   title   = {Adam: {A} Method for Stochastic Optimization},
 *   journal = {CoRR},
 *   year    = {2014},
 *   url     = {http://arxiv.org/abs/1412.6980}
 * }
 * @endcode
 */
class AdamUpdate
{
 public:
  /**
   * Construct the Adam update policy with the given parameters.
   *
   * @param epsilon The epsilon value used to initialise the squared gradient
   *        parameter.
   * @param beta1 The smoothing parameter.
   * @param beta2 The second moment coefficient.
   */
  AdamUpdate(const double epsilon = 1e-8,
             const double beta1 = 0.9,
             const double beta2 = 0.999) :
    epsilon(epsilon),
    beta1(beta1),
    beta2(beta2)
  {
    // Nothing to do.
  }

  //! Get the value used to initialise the squared gradient parameter.
  double Epsilon() const { return epsilon; }
  //! Modify the value used to initialise the squared gradient parameter.
  double& Epsilon() { return epsilon; }

  //! Get the smoothing parameter.
  double Beta1() const { return beta1; }
  //! Modify the smoothing parameter.
  double& Beta1() { return beta1; }

  //! Get the second moment coefficient.
  double Beta2() const { return beta2; }
  //! Modify the second moment coefficient.
  double& Beta2() { return beta2; }

  /**
   * The UpdatePolicyType policy classes must contain an internal 'Policy'
   * template class with two template arguments: MatType and GradType.  This is
   * instantiated at the start of the optimization, and holds parameters
   * specific to an individual optimization.
   */
  template<typename MatType, typename GradType>
  class Policy
  {
   public:
    /**
     * This constructor is called by the SGD Optimize() method before the start
     * of the iteration update process.
     *
     * @param parent AdamUpdate object.
     * @param rows Number of rows in the gradient matrix.
     * @param cols Number of columns in the gradient matrix.
     */
    Policy(AdamUpdate& parent, const size_t rows, const size_t cols) :
        parent(parent),
        iteration(0)
    {
      m.zeros(rows, cols);
      v.zeros(rows, cols);
    }

    /**
     * Update step for Adam.
     *
     * @param iterate Parameters that minimize the function.
     * @param stepSize Step size to be used for the given iteration.
     * @param gradient The gradient matrix.
     */
    void Update(MatType& iterate,
                const double stepSize,
                const GradType& gradient)
    {
      // Increment the iteration counter variable.
      ++iteration;

      // And update the iterate.
      m *= parent.beta1;
      m += (1 - parent.beta1) * gradient;

      v *= parent.beta2;
      v += (1 - parent.beta2) * (gradient % gradient);

      const double biasCorrection1 = 1.0 - std::pow(parent.beta1, iteration);
      const double biasCorrection2 = 1.0 - std::pow(parent.beta2, iteration);

      /**
       * It should be noted that the term, m / (arma::sqrt(v) + eps), in the
       * following expression is an approximation of the following actual term;
       * m / (arma::sqrt(v) + (arma::sqrt(biasCorrection2) * eps).
       */
      iterate -= (stepSize * std::sqrt(biasCorrection2) / biasCorrection1) *
          m / (arma::sqrt(v) + parent.epsilon);
    }

   private:
    // Instantiated parent object.
    AdamUpdate& parent;

    // The exponential moving average of gradient values.
    GradType m;

    // The exponential moving average of squared gradient values.
    GradType v;

    // The number of iterations.
    size_t iteration;
  };

 private:
  // The epsilon value used to initialise the squared gradient parameter.
  double epsilon;

  // The smoothing parameter.
  double beta1;

  // The second moment coefficient.
  double beta2;
};

} // namespace ens

#endif
/**
 * @file adamax_update.hpp
 * @author Ryan Curtin
 * @author Vasanth Kalingeri
 * @author Marcus Edel
 * @author Vivek Pal
 *
 * AdaMax update rule. Adam is an an algorithm for first-order gradient-
 * -based optimization of stochastic objective functions, based on adaptive
 * estimates of lower-order moments. AdaMax is simply a variant of Adam based
 * on the infinity norm.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_ADAM_ADAMAX_UPDATE_HPP
#define ENSMALLEN_ADAM_ADAMAX_UPDATE_HPP

namespace ens {

/**
 * AdaMax is a variant of Adam, an optimizer that computes individual adaptive
 * learning rates for different parameters from estimates of first and second
 * moments of the gradients.based on the infinity norm as given in the section
 * 7 of the following paper.
 *
 * For more information, see the following.
 *
 * @code
 * @article{Kingma2014,
 *   author    = {Diederik P. Kingma and Jimmy Ba},
 *   title     = {Adam: {A} Method for Stochastic Optimization},
 *   journal   = {CoRR},
 *   year      = {2014},
 *   url       = {http://arxiv.org/abs/1412.6980}
 * }
 * @endcode
 */
class AdaMaxUpdate
{
 public:
  /**
   * Construct the AdaMax update policy with the given parameters.
   *
   * @param epsilon The epsilon value used to initialise the squared gradient
   *        parameter.
   * @param beta1 The smoothing parameter.
   * @param beta2 The second moment coefficient.
   */
  AdaMaxUpdate(const double epsilon = 1e-8,
               const double beta1 = 0.9,
               const double beta2 = 0.999) :
    epsilon(epsilon),
    beta1(beta1),
    beta2(beta2)
  {
    // Nothing to do.
  }

  //! Get the value used to initialise the squared gradient parameter.
  double Epsilon() const { return epsilon; }
  //! Modify the value used to initialise the squared gradient parameter.
  double& Epsilon() { return epsilon; }

  //! Get the smoothing parameter.
  double Beta1() const { return beta1; }
  //! Modify the smoothing parameter.
  double& Beta1() { return beta1; }

  //! Get the second moment coefficient.
  double Beta2() const { return beta2; }
  //! Modify the second moment coefficient.
  double& Beta2() { return beta2; }

  /**
   * The UpdatePolicyType policy classes must contain an internal 'Policy'
   * template class with two template arguments: MatType and GradType.  This is
   * instantiated at the start of the optimization, and holds parameters
   * specific to an individual optimization.
   */
  template<typename MatType, typename GradType>
  class Policy
  {
   public:
    /**
     * This constructor is called by the SGD Optimize() method before the start
     * of the iteration update process.
     *
     * @param parent AdaMaxUpdate object.
     * @param rows Number of rows in the gradient matrix.
     * @param cols Number of columns in the gradient matrix.
     */
    Policy(AdaMaxUpdate& parent, const size_t rows, const size_t cols) :
        parent(parent),
        iteration(0)
    {
      m.zeros(rows, cols);
      u.zeros(rows, cols);
    }

    /**
     * Update step for AdaMax.
     *
     * @param iterate Parameters that minimize the function.
     * @param stepSize Step size to be used for the given iteration.
     * @param gradient The gradient matrix.
     */
    void Update(MatType& iterate,
                const double stepSize,
                const GradType& gradient)
    {
      // Increment the iteration counter variable.
      ++iteration;

      // And update the iterate.
      m *= parent.beta1;
      m += (1 - parent.beta1) * gradient;

      // Update the exponentially weighted infinity norm.
      u *= parent.beta2;
      u = arma::max(u, arma::abs(gradient));

      const double biasCorrection1 = 1.0 - std::pow(parent.beta1, iteration);

      if (biasCorrection1 != 0)
        iterate -= (stepSize / biasCorrection1 * m / (u + parent.epsilon));
    }

   private:
    // Instantiated parent object.
    AdaMaxUpdate& parent;
    // The exponential moving average of gradient values.
    GradType m;
    // The exponentially weighted infinity norm.
    GradType u;
    // The number of iterations.
    size_t iteration;
  };

 private:
  // The epsilon value used to initialise the squared gradient parameter.
  double epsilon;

  // The smoothing parameter.
  double beta1;

  // The second moment coefficient.
  double beta2;
};

} // namespace ens

#endif
/**
 * @file amsgrad_update.hpp
 * @author Haritha Nair
 *
 * Implementation of AMSGrad optimizer. AMSGrad is an exponential moving average 
 * optimizer that dynamically adapts over time with guaranteed convergence.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_AMS_GRAD_AMS_GRAD_UPDATE_HPP
#define ENSMALLEN_AMS_GRAD_AMS_GRAD_UPDATE_HPP

namespace ens {

/**
 * AMSGrad is an exponential moving average variant which along with having
 * benefits of optimizers like Adam and RMSProp, also guarantees convergence.
 * Unlike Adam, it uses maximum of past squared gradients rather than their
 * exponential average for updation.
 *
 * For more information, see the following.
 *
 * @code
 * @article{
 *   title   = {On the convergence of Adam and beyond},
 *   url     = {https://openreview.net/pdf?id=ryQu7f-RZ}
 *   year    = {2018}
 * }
 * @endcode
 */
class AMSGradUpdate
{
 public:
  /**
   * Construct the AMSGrad update policy with the given parameters.
   *
   * @param epsilon The epsilon value used to initialise the squared gradient
   *        parameter.
   * @param beta1 The smoothing parameter.
   * @param beta2 The second moment coefficient.
   */
  AMSGradUpdate(const double epsilon = 1e-8,
                const double beta1 = 0.9,
                const double beta2 = 0.999) :
    epsilon(epsilon),
    beta1(beta1),
    beta2(beta2)
  {
    // Nothing to do.
  }

  //! Get the value used to initialise the squared gradient parameter.
  double Epsilon() const { return epsilon; }
  //! Modify the value used to initialise the squared gradient parameter.
  double& Epsilon() { return epsilon; }

  //! Get the smoothing parameter.
  double Beta1() const { return beta1; }
  //! Modify the smoothing parameter.
  double& Beta1() { return beta1; }

  //! Get the second moment coefficient.
  double Beta2() const { return beta2; }
  //! Modify the second moment coefficient.
  double& Beta2() { return beta2; }

  /**
   * The UpdatePolicyType policy classes must contain an internal 'Policy'
   * template class with two template arguments: MatType and GradType.  This is
   * instantiated at the start of the optimization, and holds parameters
   * specific to an individual optimization.
   */
  template<typename MatType, typename GradType>
  class Policy
  {
   public:
    /**
     * This constructor is called by the SGD Optimize() method before the start
     * of the iteration update process.
     *
     * @param parent Instantiated AMSGradUpdate parent object.
     * @param rows Number of rows in the gradient matrix.
     * @param cols Number of columns in the gradient matrix.
     */
    Policy(AMSGradUpdate& parent, const size_t rows, const size_t cols) :
        parent(parent),
        iteration(0)
    {
      m.zeros(rows, cols);
      v.zeros(rows, cols);
      vImproved.zeros(rows, cols);
    }

    /**
     * Update step for AMSGrad.
     *
     * @param iterate Parameters that minimize the function.
     * @param stepSize Step size to be used for the given iteration.
     * @param gradient The gradient matrix.
     */
    void Update(MatType& iterate,
                const double stepSize,
                const GradType& gradient)
    {
      // Increment the iteration counter variable.
      ++iteration;

      // And update the iterate.
      m *= parent.beta1;
      m += (1 - parent.beta1) * gradient;

      v *= parent.beta2;
      v += (1 - parent.beta2) * (gradient % gradient);

      const double biasCorrection1 = 1.0 - std::pow(parent.beta1, iteration);
      const double biasCorrection2 = 1.0 - std::pow(parent.beta2, iteration);

      // Element wise maximum of past and present squared gradients.
      vImproved = arma::max(vImproved, v);

      iterate -= (stepSize * std::sqrt(biasCorrection2) / biasCorrection1) *
                  m / (arma::sqrt(vImproved) + parent.epsilon);
    }

   private:
    // Instantiated parent AMSGradUpdate object.
    AMSGradUpdate& parent;

    // The exponential moving average of gradient values.
    GradType m;

    // The exponential moving average of squared gradient values.
    GradType v;

    // The optimal squared gradient value.
    GradType vImproved;

    // The number of iterations.
    size_t iteration;
  };

 private:
  // The epsilon value used to initialise the squared gradient parameter.
  double epsilon;

  // The smoothing parameter.
  double beta1;

  // The second moment coefficient.
  double beta2;
};

} // namespace ens

#endif
/**
 * @file nadam_update.hpp
 * @author Sourabh Varshney
 *
 * Nadam update rule. Nadam is an optimizer that combines the effect of Adam
 * and NAG to the gradient descent to improve its Performance.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_ADAM_NADAM_UPDATE_HPP
#define ENSMALLEN_ADAM_NADAM_UPDATE_HPP

namespace ens {

/**
 * Nadam is an optimizer that combines the Adam and NAG optimization strategies.
 *
 * For more information, see the following.
 *
 * @code
 * @techreport{Dozat2015,
 *   title       = {Incorporating Nesterov momentum into Adam},
 *   author      = {Timothy Dozat},
 *   institution = {Stanford University},
 *   address     = {Stanford},
 *   year        = {2015},
 *   url         = {https://openreview.net/pdf?id=OM0jvwB8jIp57ZJjtNEZ}
 * }
 * @endcode
 */
class NadamUpdate
{
 public:
  /**
   * Construct the Nadam update policy with the given parameters.
   *
   * @param epsilon The epsilon value used to initialise the squared gradient
   *        parameter.
   * @param beta1 The smoothing parameter.
   * @param beta2 The second moment coefficient
   * @param scheduleDecay The decay parameter for decay coefficients
   */
  NadamUpdate(const double epsilon = 1e-8,
              const double beta1 = 0.9,
              const double beta2 = 0.99,
              const double scheduleDecay = 4e-3) :
      epsilon(epsilon),
      beta1(beta1),
      beta2(beta2),
      scheduleDecay(scheduleDecay)
  {
    // Nothing to do.
  }

  //! Get the value used to initialise the squared gradient parameter.
  double Epsilon() const { return epsilon; }
  //! Modify the value used to initialise the squared gradient parameter.
  double& Epsilon() { return epsilon; }

  //! Get the smoothing parameter.
  double Beta1() const { return beta1; }
  //! Modify the smoothing parameter.
  double& Beta1() { return beta1; }

  //! Get the second moment coefficient.
  double Beta2() const { return beta2; }
  //! Modify the second moment coefficient.
  double& Beta2() { return beta2; }

  //! Get the decay parameter for decay coefficients
  double ScheduleDecay() const { return scheduleDecay; }
  //! Modify the decay parameter for decay coefficients
  double& ScheduleDecay() { return scheduleDecay; }

  /**
   * The UpdatePolicyType policy classes must contain an internal 'Policy'
   * template class with two template arguments: MatType and GradType.  This is
   * instantiated at the start of the optimization, and holds parameters
   * specific to an individual optimization.
   */
  template<typename MatType, typename GradType>
  class Policy
  {
   public:
    /**
     * This constructor is called by the optimizer before the start of the
     * iteration update process.
     *
     * @param parent Instantiated NadamUpdate parent object.
     * @param rows Number of rows in the gradient matrix.
     * @param cols Number of columns in the gradient matrix.
     */
    Policy(NadamUpdate& parent, const size_t rows, const size_t cols) :
        parent(parent),
        cumBeta1(1),
        iteration(0)
    {
      m.zeros(rows, cols);
      v.zeros(rows, cols);
    }

    /**
     * Update step for Nadam.
     *
     * @param iterate Parameters that minimize the function.
     * @param stepSize Step size to be used for the given iteration.
     * @param gradient The gradient matrix.
     */
    void Update(MatType& iterate,
                const double stepSize,
                const GradType& gradient)
    {
      // Increment the iteration counter variable.
      ++iteration;

      // And update the iterate.
      m *= parent.beta1;
      m += (1 - parent.beta1) * gradient;

      v *= parent.beta2;
      v += (1 - parent.beta2) * gradient % gradient;

      double beta1T = parent.beta1 * (1 - (0.5 *
          std::pow(0.96, iteration * parent.scheduleDecay)));

      double beta1T1 = parent.beta1 * (1 - (0.5 *
          std::pow(0.96, (iteration + 1) * parent.scheduleDecay)));

      cumBeta1 *= beta1T;

      const double biasCorrection1 = 1.0 - cumBeta1;
      const double biasCorrection2 = 1.0 - std::pow(parent.beta2, iteration);
      const double biasCorrection3 = 1.0 - (cumBeta1 * beta1T1);

      /* Note :- arma::sqrt(v) + epsilon * sqrt(biasCorrection2) is approximated
       * as arma::sqrt(v) + epsilon
       */
      iterate -= (stepSize * (((1 - beta1T) / biasCorrection1) * gradient
          + (beta1T1 / biasCorrection3) * m) * sqrt(biasCorrection2))
          / (arma::sqrt(v) + parent.epsilon);
    }

   private:
    // Instantiated parent object.
    NadamUpdate& parent;

    // The exponential moving average of gradient values.
    GradType m;

    // The exponential moving average of squared gradient values.
    GradType v;

    // The cumulative product of decay coefficients.
    double cumBeta1;

    // The number of iterations.
    size_t iteration;
  };

 private:
  // The epsilon value used to initialise the squared gradient parameter.
  double epsilon;

  // The smoothing parameter.
  double beta1;

  // The second moment coefficient.
  double beta2;

  // The decay parameter for decay coefficients.
  double scheduleDecay;
};

} // namespace ens

#endif
/**
 * @file nadamax_update.hpp
 * @author Sourabh Varshney
 *
 * NadaMax update rule. NadaMax is an optimizer that combines the effect of
 * Adamax and NAG to the gradient descent to improve its Performance.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_ADAM_NADAMAX_UPDATE_HPP
#define ENSMALLEN_ADAM_NADAMAX_UPDATE_HPP

namespace ens {

/**
 * NadaMax is an optimizer that combines the AdaMax and NAG.
 *
 * For more information, see the following.
 *
 * @code
 * @techreport{Dozat2015,
 *   title       = {Incorporating Nesterov momentum into Adam},
 *   author      = {Timothy Dozat},
 *   institution = {Stanford University},
 *   address     = {Stanford},
 *   year        = {2015},
 *   url         = {https://openreview.net/pdf?id=OM0jvwB8jIp57ZJjtNEZ}
 * }
 * @endcode
 */
class NadaMaxUpdate
{
 public:
  /**
   * Construct the NadaMax update policy with the given parameters.
   *
   * @param epsilon The epsilon value used to initialise the squared gradient
   *        parameter.
   * @param beta1 The smoothing parameter.
   * @param beta2 The second moment coefficient
   * @param scheduleDecay The decay parameter for decay coefficients
   */
  NadaMaxUpdate(const double epsilon = 1e-8,
                const double beta1 = 0.9,
                const double beta2 = 0.99,
                const double scheduleDecay = 4e-3) :
      epsilon(epsilon),
      beta1(beta1),
      beta2(beta2),
      scheduleDecay(scheduleDecay)
  {
    // Nothing to do.
  }

  //! Get the value used to initialise the squared gradient parameter.
  double Epsilon() const { return epsilon; }
  //! Modify the value used to initialise the squared gradient parameter.
  double& Epsilon() { return epsilon; }

  //! Get the smoothing parameter.
  double Beta1() const { return beta1; }
  //! Modify the smoothing parameter.
  double& Beta1() { return beta1; }

  //! Get the second moment coefficient.
  double Beta2() const { return beta2; }
  //! Modify the second moment coefficient.
  double& Beta2() { return beta2; }

  //! Get the decay parameter for decay coefficients
  double ScheduleDecay() const { return scheduleDecay; }
  //! Modify the decay parameter for decay coefficients
  double& ScheduleDecay() { return scheduleDecay; }

  /**
   * The UpdatePolicyType policy classes must contain an internal 'Policy'
   * template class with two template arguments: MatType and GradType.  This is
   * instantiated at the start of the optimization, and holds parameters
   * specific to an individual optimization.
   */
  template<typename MatType, typename GradType>
  class Policy
  {
   public:
    /**
     * This constructor method is called by the optimizer before the start of
     * the iteration update process.
     *
     * @param parent Instantiated NadaMaxUpdate parent object.
     * @param rows Number of rows in the gradient matrix.
     * @param cols Number of columns in the gradient matrix.
     */
    Policy(NadaMaxUpdate& parent, const size_t rows, const size_t cols) :
        parent(parent),
        cumBeta1(1),
        iteration(0)
    {
      m.zeros(rows, cols);
      u.zeros(rows, cols);
    }

    /**
     * Update step for NadaMax.
     *
     * @param iterate Parameters that minimize the function.
     * @param stepSize Step size to be used for the given iteration.
     * @param gradient The gradient matrix.
     */
    void Update(MatType& iterate,
                const double stepSize,
                const GradType& gradient)
    {
      // Increment the iteration counter variable.
      ++iteration;

      // And update the iterate.
      m *= parent.beta1;
      m += (1 - parent.beta1) * gradient;

      u = arma::max(u * parent.beta2, arma::abs(gradient));

      double beta1T = parent.beta1 * (1 - (0.5 *
          std::pow(0.96, iteration * parent.scheduleDecay)));

      double beta1T1 = parent.beta1 * (1 - (0.5 *
          std::pow(0.96, (iteration + 1) * parent.scheduleDecay)));

      cumBeta1 *= beta1T;

      const double biasCorrection1 = 1.0 - cumBeta1;

      const double biasCorrection2 = 1.0 - (cumBeta1 * beta1T1);

      if ((biasCorrection1 != 0) && (biasCorrection2 != 0))
      {
         iterate -= (stepSize * (((1 - beta1T) / biasCorrection1) * gradient
             + (beta1T1 / biasCorrection2) * m)) / (u + parent.epsilon);
      }
    }

   private:
    // Instantiated parent object.
    NadaMaxUpdate& parent;

    // The exponential moving average of gradient values.
    GradType m;

    // The exponentially weighted infinity norm.
    GradType u;

    // The cumulative product of decay coefficients.
    double cumBeta1;

    // The number of iterations.
    size_t iteration;
  };

 private:
  // The epsilon value used to initialise the squared gradient parameter.
  double epsilon;

  // The smoothing parameter.
  double beta1;

  // The second moment coefficient.
  double beta2;

  // The decay parameter for decay coefficients.
  double scheduleDecay;
};

} // namespace ens

#endif
/**
 * @file optimisticadam_update.hpp
 * @author Moksh Jain
 *
 * OptmisticAdam optimizer. Implements Optimistic Adam, an algorithm which
 * uses Optimistic Mirror Descent with the Adam optimizer.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_ADAM_OPTIMISTICADAM_UPDATE_HPP
#define ENSMALLEN_ADAM_OPTIMISTICADAM_UPDATE_HPP

namespace ens {

/**
 * OptimisticAdam is an optimizer which implements the Optimistic Adam
 * algorithm which uses Optmistic Mirror Descent with the Adam Optimizer.
 * It addresses the problem of limit cycling while training GANs. It uses
 * OMD to achieve faster regret rates in solving the zero sum game of
 * training a GAN. It consistently achieves a smaller KL divergnce with
 * respect to the true underlying data distribution.
 *
 * For more information, see the following.
 *
 * @code
 * @article{
 *   author  = {Constantinos Daskalakis, Andrew Ilyas, Vasilis Syrgkanis,
 *              Haoyang Zeng},
 *   title   = {Training GANs with Optimism},
 *   year    = {2017},
 *   url     = {https://arxiv.org/abs/1711.00141}
 * }
 * @endcode
 */
class OptimisticAdamUpdate
{
 public:
  /**
   * Construct the OptimisticAdam update policy with the given parameters.
   *
   * @param epsilon The epsilon value used to initialize the squared gradient
   *        parameter.
   * @param beta1 The smoothing parameter.
   * @param beta2 The second moment coefficient.
   */
  OptimisticAdamUpdate(const double epsilon = 1e-8,
                       const double beta1 = 0.9,
                       const double beta2 = 0.999) :
    epsilon(epsilon),
    beta1(beta1),
    beta2(beta2)
  {
    // Nothing to do.
  }

  //! Get the value used to initialize the squared gradient parameter.
  double Epsilon() const { return epsilon; }
  //! Modify the value used to initialize the squared gradient parameter.
  double& Epsilon() { return epsilon; }

  //! Get the smoothing parameter.
  double Beta1() const { return beta1; }
  //! Modify the smoothing parameter.
  double& Beta1() { return beta1; }

  //! Get the second moment coefficient.
  double Beta2() const { return beta2; }
  //! Modify the second moment coefficient.
  double& Beta2() { return beta2; }

  /**
   * The UpdatePolicyType policy classes must contain an internal 'Policy'
   * template class with two template arguments: MatType and GradType.  This is
   * instantiated at the start of the optimization, and holds parameters
   * specific to an individual optimization.
   */
  template<typename MatType, typename GradType>
  class Policy
  {
   public:
    /**
     * This constructor is called by the SGD Optimize() method before the start
     * of the iteration update process.
     *
     * @param parent Instantiated OptimisticAdamUpdate parent object.
     * @param rows Number of rows in the gradient matrix.
     * @param cols Number of columns in the gradient matrix.
     */
    Policy(OptimisticAdamUpdate& parent, const size_t rows, const size_t cols) :
        parent(parent),
        iteration(0)
    {
      m.zeros(rows, cols);
      v.zeros(rows, cols);
      g.zeros(rows, cols);
    }

    /**
     * Update step for OptimisticAdam.
     *
     * @param iterate Parameters that minimize the function.
     * @param stepSize Step size to be used for the given iteration.
     * @param gradient The gradient matrix.
     */
    void Update(MatType& iterate,
                const double stepSize,
                const GradType& gradient)
    {
      // Increment the iteration counter variable.
      ++iteration;

      // And update the iterate.
      m *= parent.beta1;
      m += (1 - parent.beta1) * gradient;

      v *= parent.beta2;
      v += (1 - parent.beta2) * arma::square(gradient);

      GradType mCorrected = m / (1.0 - std::pow(parent.beta1, iteration));
      GradType vCorrected = v / (1.0 - std::pow(parent.beta2, iteration));

      GradType update = mCorrected / (arma::sqrt(vCorrected) + parent.epsilon);

      iterate -= (2 * stepSize * update - stepSize * g);

      g = std::move(update);
    }

   private:
    // Instantiated parent object.
    OptimisticAdamUpdate& parent;

    // The exponential moving average of gradient values.
    GradType m;

    // The exponential moving average of squared gradient values.
    GradType v;

    // The previous update.
    GradType g;

    // The number of iterations.
    size_t iteration;
  };

 private:
  // The epsilon value used to initialize the squared gradient parameter.
  double epsilon;

  // The smoothing parameter.
  double beta1;

  // The second moment coefficient.
  double beta2;
};

} // namespace ens

#endif
/**
 * @file aug_lagrangian.hpp
 * @author Ryan Curtin
 *
 * Definition of AugLagrangian class, which implements the Augmented Lagrangian
 * optimization method (also called the 'method of multipliers'.  This class
 * uses the L-BFGS optimizer.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */

#ifndef ENSMALLEN_AUG_LAGRANGIAN_AUG_LAGRANGIAN_HPP
#define ENSMALLEN_AUG_LAGRANGIAN_AUG_LAGRANGIAN_HPP

#include <ensmallen_bits/lbfgs/lbfgs.hpp>

#include "aug_lagrangian_function.hpp"

namespace ens {

/**
 * The AugLagrangian class implements the Augmented Lagrangian method of
 * optimization.  In this scheme, a penalty term is added to the Lagrangian.
 * This method is also called the "method of multipliers".
 *
 * AugLagrangian can optimize constrained functions.  For more details, see the
 * documentation on function types included with this distribution or on the
 * ensmallen website.
 */
class AugLagrangian
{
 public:
  /**
   * Initialize the Augmented Lagrangian with the default L-BFGS optimizer.
   * @param penaltyThresholdFactor When the penalty threshold is updated set
   *    the penalty threshold to the penalty multplied by this factor. The
   *    default value of 0.25 is is taken from Burer and Monteiro (2002).
   * @param sigmaUpdateFactor When sigma is updated  multiply sigma by this
   *    value. The default value of 10 is taken from Burer and Monteiro (2002).
   * @param maxIterations Maximum number of iterations of the Augmented
   *     Lagrangian algorithm.  0 indicates no maximum.
   */
  AugLagrangian(const size_t maxIterations = 1000,
                const double penaltyThresholdFactor = 0.25,
                const double sigmaUpdateFactor = 10.0,
                const L_BFGS& lbfgs = L_BFGS());

  /**
   * Optimize the function.  The value '1' is used for the initial value of each
   * Lagrange multiplier.  To set the Lagrange multipliers yourself, use the
   * other overload of Optimize().
   *
   * @tparam LagrangianFunctionType Function which can be optimized by this
   *     class.
   * @tparam MatType Type of matrix to optimize with.
   * @tparam GradType Type of matrix to use to represent function gradients.
   * @tparam CallbackTypes Types of callback functions.
   * @param function The function to optimize.
   * @param coordinates Output matrix to store the optimized coordinates in.
   * @param callbacks Callback functions.
   */
  template<typename LagrangianFunctionType,
           typename MatType,
           typename GradType,
           typename... CallbackTypes>
  typename std::enable_if<IsArmaType<GradType>::value, bool>::type
  Optimize(LagrangianFunctionType& function,
           MatType& coordinates,
           CallbackTypes&&... callbacks);

  //! Forward the MatType as GradType.
  template<typename LagrangianFunctionType,
           typename MatType,
           typename... CallbackTypes>
  bool Optimize(LagrangianFunctionType& function,
                MatType& coordinates,
                CallbackTypes&&... callbacks)
  {
    return Optimize<LagrangianFunctionType, MatType, MatType,
        CallbackTypes...>(function, coordinates,
        std::forward<CallbackTypes>(callbacks)...);
  }

  /**
   * Optimize the function, giving initial estimates for the Lagrange
   * multipliers.  The vector of Lagrange multipliers will be modified to
   * contain the Lagrange multipliers of the final solution (if one is found).
   *
   * @tparam LagrangianFunctionType Function which can be optimized by this
   *      class.
   * @tparam MatType Type of matrix to optimize with.
   * @tparam GradType Type of matrix to use to represent function gradients.
   * @tparam CallbackTypes Types of callback functions.
   * @param function The function to optimize.
   * @param coordinates Output matrix to store the optimized coordinates in.
   * @param initLambda Vector of initial Lagrange multipliers.  Should have
   *     length equal to the number of constraints.
   * @param initSigma Initial penalty parameter.
   * @param callbacks Callback functions.
   */
  template<typename LagrangianFunctionType,
           typename MatType,
           typename GradType,
           typename... CallbackTypes>
  typename std::enable_if<IsArmaType<GradType>::value, bool>::type
  Optimize(LagrangianFunctionType& function,
           MatType& coordinates,
           const arma::vec& initLambda,
           const double initSigma,
           CallbackTypes&&... callbacks);

  //! Forward the MatType as GradType.
  template<typename LagrangianFunctionType,
           typename MatType,
           typename... CallbackTypes>
  bool Optimize(LagrangianFunctionType& function,
                MatType& coordinates,
                const arma::vec& initLambda,
                const double initSigma,
                CallbackTypes&&... callbacks)
  {
    return Optimize<LagrangianFunctionType, MatType, MatType,
        CallbackTypes...>(function, coordinates, initLambda, initSigma,
        std::forward<CallbackTypes>(callbacks)...);
  }

  //! Get the L-BFGS object used for the actual optimization.
  const L_BFGS& LBFGS() const { return lbfgs; }
  //! Modify the L-BFGS object used for the actual optimization.
  L_BFGS& LBFGS() { return lbfgs; }

  //! Get the Lagrange multipliers.
  const arma::vec& Lambda() const { return lambda; }
  //! Modify the Lagrange multipliers (i.e. set them before optimization).
  arma::vec& Lambda() { return lambda; }

  //! Get the penalty parameter.
  double Sigma() const { return sigma; }
  //! Modify the penalty parameter.
  double& Sigma() { return sigma; }

  //! Get the maximum iterations
  size_t MaxIterations() const { return maxIterations; }
  //! Modify the maximum iterations
  size_t& MaxIterations() { return maxIterations; }

  //! Get the penalty threshold updating parameter
  double PenaltyThresholdFactor() const { return penaltyThresholdFactor; }
  //! Modify the penalty threshold updating parameter
  double& PenaltyThresholdFactor() { return penaltyThresholdFactor; }

  //! Get the sigma update factor
  double SigmaUpdateFactor() const { return sigmaUpdateFactor; }
  //! Modify the sigma update factor
  double& SigmaUpdateFactor() { return sigmaUpdateFactor; }

 private:
  //! Maximum number of iterations.
  size_t maxIterations;

  //! Parameter for updating the penalty threshold
  double penaltyThresholdFactor;

  //! Parameter for updating sigma
  double sigmaUpdateFactor;

  //! The L-BFGS optimizer that we will use.
  L_BFGS lbfgs;

  //! Controls early termination of the optimization process.
  bool terminate;

  //! Lagrange multipliers.
  arma::vec lambda;

  //! Penalty parameter.
  double sigma;

  /**
   * Internal optimization function: given an initialized AugLagrangianFunction,
   * perform the optimization itself.
   */
  template<typename LagrangianFunctionType,
           typename MatType,
           typename GradType,
           typename... CallbackTypes>
  typename std::enable_if<IsArmaType<GradType>::value, bool>::type
  Optimize(AugLagrangianFunction<LagrangianFunctionType>& augfunc,
           MatType& coordinates,
           CallbackTypes&&... callbacks);

  //! Forward the MatType as GradType.
  template<typename LagrangianFunctionType,
           typename MatType,
           typename... CallbackTypes>
  bool Optimize(AugLagrangianFunction<LagrangianFunctionType>& function,
                MatType& coordinates,
                CallbackTypes&&... callbacks)
  {
    return Optimize<LagrangianFunctionType, MatType, MatType,
        CallbackTypes...>(function, coordinates,
        std::forward<CallbackTypes>(callbacks)...);
  }
};

} // namespace ens

#include "aug_lagrangian_impl.hpp"

#endif // ENSMALLEN_AUG_LAGRANGIAN_AUG_LAGRANGIAN_HPP

/**
 * @file aug_lagrangian_function.hpp
 * @author Ryan Curtin
 *
 * Contains a utility class for AugLagrangian.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_AUG_LAGRANGIAN_AUG_LAGRANGIAN_FUNCTION_HPP
#define ENSMALLEN_AUG_LAGRANGIAN_AUG_LAGRANGIAN_FUNCTION_HPP

namespace ens {

/**
 * This is a utility class used by AugLagrangian, meant to wrap a
 * LagrangianFunction into a function usable by a simple optimizer like L-BFGS.
 * Given a LagrangianFunction which follows the format outlined in the
 * documentation for AugLagrangian, this class provides Evaluate(), Gradient(),
 * and GetInitialPoint() functions which allow this class to be used with a
 * simple optimizer like L-BFGS.
 *
 * This class can be specialized for your particular implementation -- commonly,
 * a faster method for computing the overall objective and gradient of the
 * augmented Lagrangian function can be implemented than the naive, default
 * implementation given.  Use class template specialization and re-implement all
 * of the methods (unfortunately, C++ specialization rules mean you have to
 * re-implement everything).
 *
 * @tparam LagrangianFunction Lagrangian function to be used.
 */
template<typename LagrangianFunction>
class AugLagrangianFunction
{
 public:
  /**
   * Initialize the AugLagrangianFunction, but don't set the Lagrange
   * multipliers or penalty parameters yet.  Make sure you set the Lagrange
   * multipliers before you use this...
   *
   * @param function Lagrangian function.
   */
  AugLagrangianFunction(LagrangianFunction& function);

  /**
   * Initialize the AugLagrangianFunction with the given LagrangianFunction,
   * Lagrange multipliers, and initial penalty parameter.
   *
   * @param function Lagrangian function.
   * @param lambda Initial Lagrange multipliers.
   * @param sigma Initial penalty parameter.
   */
  AugLagrangianFunction(LagrangianFunction& function,
                        const arma::vec& lambda,
                        const double sigma);
  /**
   * Evaluate the objective function of the Augmented Lagrangian function, which
   * is the standard Lagrangian function evaluation plus a penalty term, which
   * penalizes unsatisfied constraints.
   *
   * @param coordinates Coordinates to evaluate function at.
   * @return Objective function.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates) const;

  /**
   * Evaluate the gradient of the Augmented Lagrangian function.
   *
   * @param coordinates Coordinates to evaluate gradient at.
   * @param gradient Matrix to store gradient into.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates, GradType& gradient) const;

  /**
   * Get the initial point of the optimization (supplied by the
   * LagrangianFunction).
   *
   * @return Initial point.
   */
  template<typename MatType = arma::mat>
  const MatType& GetInitialPoint() const;

  //! Get the Lagrange multipliers.
  const arma::vec& Lambda() const { return lambda; }
  //! Modify the Lagrange multipliers.
  arma::vec& Lambda() { return lambda; }

  //! Get sigma (the penalty parameter).
  double Sigma() const { return sigma; }
  //! Modify sigma (the penalty parameter).
  double& Sigma() { return sigma; }

  //! Get the Lagrangian function.
  const LagrangianFunction& Function() const { return function; }
  //! Modify the Lagrangian function.
  LagrangianFunction& Function() { return function; }

 private:
  //! Instantiation of the function to be optimized.
  LagrangianFunction& function;

  //! The Lagrange multipliers.
  arma::vec lambda;
  //! The penalty parameter.
  double sigma;
};

} // namespace ens

// Include basic implementation.
#include "aug_lagrangian_function_impl.hpp"

#endif // ENSMALLEN_AUG_LAGRANGIAN_AUG_LAGRANGIAN_FUNCTION_HPP

/**
 * @file aug_lagrangian_function_impl.hpp
 * @author Ryan Curtin
 *
 * Simple, naive implementation of AugLagrangianFunction.  Better
 * specializations can probably be given in many cases, but this is the most
 * general case.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_AUG_LAGRANGIAN_AUG_LAGRANGIAN_FUNCTION_IMPL_HPP
#define ENSMALLEN_AUG_LAGRANGIAN_AUG_LAGRANGIAN_FUNCTION_IMPL_HPP

// In case it hasn't been included.
#include "aug_lagrangian_function.hpp"

namespace ens {

// Initialize the AugLagrangianFunction.
template<typename LagrangianFunction>
AugLagrangianFunction<LagrangianFunction>::AugLagrangianFunction(
    LagrangianFunction& function) :
    function(function),
    lambda(function.NumConstraints()),
    sigma(10)
{
  // Initialize lambda vector to all zeroes.
  lambda.zeros();
}

// Initialize the AugLagrangianFunction.
template<typename LagrangianFunction>
AugLagrangianFunction<LagrangianFunction>::AugLagrangianFunction(
    LagrangianFunction& function,
    const arma::vec& lambda,
    const double sigma) :
    function(function),
    lambda(lambda),
    sigma(sigma)
{
  // Nothing else to do.
}

// Evaluate the AugLagrangianFunction at the given coordinates.
template<typename LagrangianFunction>
template<typename MatType>
typename MatType::elem_type AugLagrangianFunction<LagrangianFunction>::Evaluate(
    const MatType& coordinates) const
{
  // The augmented Lagrangian is evaluated as
  //    f(x) + {-lambda_i * c_i(x) + (sigma / 2) c_i(x)^2} for all constraints

  typedef typename MatType::elem_type ElemType;

  // First get the function's objective value.
  ElemType objective = function.Evaluate(coordinates);

  // Now loop for each constraint.
  for (size_t i = 0; i < function.NumConstraints(); ++i)
  {
    ElemType constraint = function.EvaluateConstraint(i, coordinates);

    objective += (-lambda[i] * constraint) +
        sigma * std::pow(constraint, 2) / 2;
  }

  return objective;
}

// Evaluate the gradient of the AugLagrangianFunction at the given coordinates.
template<typename LagrangianFunction>
template<typename MatType, typename GradType>
void AugLagrangianFunction<LagrangianFunction>::Gradient(
    const MatType& coordinates,
    GradType& gradient) const
{
  // The augmented Lagrangian's gradient is evaluted as
  // f'(x) + {(-lambda_i + sigma * c_i(x)) * c'_i(x)} for all constraints
  gradient.zeros();
  function.Gradient(coordinates, gradient);

  GradType constraintGradient; // Temporary for constraint gradients.
  for (size_t i = 0; i < function.NumConstraints(); i++)
  {
    function.GradientConstraint(i, coordinates, constraintGradient);

    // Now calculate scaling factor and add to existing gradient.
    GradType tmpGradient;
    tmpGradient = (-lambda[i] + sigma *
        function.EvaluateConstraint(i, coordinates)) * constraintGradient;
    gradient += tmpGradient;
  }
}

// Get the initial point.
template<typename LagrangianFunction>
template<typename MatType>
const MatType& AugLagrangianFunction<LagrangianFunction>::GetInitialPoint()
    const
{
  return function.template GetInitialPoint<MatType>();
}

} // namespace ens

#endif

/**
 * @file aug_lagrangian_impl.hpp
 * @author Ryan Curtin
 *
 * Implementation of AugLagrangian class (Augmented Lagrangian optimization
 * method).
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_AUG_LAGRANGIAN_AUG_LAGRANGIAN_IMPL_HPP
#define ENSMALLEN_AUG_LAGRANGIAN_AUG_LAGRANGIAN_IMPL_HPP

#include <ensmallen_bits/lbfgs/lbfgs.hpp>
#include <ensmallen_bits/function.hpp>
#include "aug_lagrangian_function.hpp"

namespace ens {

inline AugLagrangian::AugLagrangian(const size_t maxIterations,
                                    const double penaltyThresholdFactor,
                                    const double sigmaUpdateFactor,
                                    const L_BFGS& lbfgs) :
    maxIterations(maxIterations),
    penaltyThresholdFactor(penaltyThresholdFactor),
    sigmaUpdateFactor(sigmaUpdateFactor),
    lbfgs(lbfgs),
    terminate(false),
    sigma(0.0)
{
}

template<typename LagrangianFunctionType,
         typename MatType,
         typename GradType,
         typename... CallbackTypes>
typename std::enable_if<IsArmaType<GradType>::value, bool>::type
AugLagrangian::Optimize(LagrangianFunctionType& function,
                        MatType& coordinates,
                        const arma::vec& initLambda,
                        const double initSigma,
                        CallbackTypes&&... callbacks)
{
  lambda = initLambda;
  sigma = initSigma;

  AugLagrangianFunction<LagrangianFunctionType> augfunc(function,
      lambda, sigma);

  return Optimize(augfunc, coordinates, callbacks...);
}

template<typename LagrangianFunctionType,
         typename MatType,
         typename GradType,
         typename... CallbackTypes>
typename std::enable_if<IsArmaType<GradType>::value, bool>::type
AugLagrangian::Optimize(LagrangianFunctionType& function,
                        MatType& coordinates,
                        CallbackTypes&&... callbacks)
{
  // If the user did not specify the right size for sigma and lambda, we will
  // use defaults.
  if (!lambda.is_empty())
  {
    AugLagrangianFunction<LagrangianFunctionType> augfunc(function, lambda,
        sigma);
    return Optimize(augfunc, coordinates, callbacks...);
  }
  else
  {
    AugLagrangianFunction<LagrangianFunctionType> augfunc(function);
    return Optimize(augfunc, coordinates, callbacks...);
  }
}

template<typename LagrangianFunctionType,
         typename MatType,
         typename GradType,
         typename... CallbackTypes>
typename std::enable_if<IsArmaType<GradType>::value, bool>::type
AugLagrangian::Optimize(
    AugLagrangianFunction<LagrangianFunctionType>& augfunc,
    MatType& coordinatesIn,
    CallbackTypes&&... callbacks)
{
  // Convenience typedefs.
  typedef typename MatType::elem_type ElemType;
  typedef typename MatTypeTraits<MatType>::BaseMatType BaseMatType;
  typedef typename MatTypeTraits<GradType>::BaseMatType BaseGradType;

  BaseMatType& coordinates = (BaseMatType&) coordinatesIn;

  // Check that the types satisfy our needs.
  traits::CheckConstrainedFunctionTypeAPI<LagrangianFunctionType, BaseMatType,
      BaseGradType>();
  RequireFloatingPointType<BaseMatType>();
  RequireFloatingPointType<BaseGradType>();
  RequireSameInternalTypes<BaseMatType, BaseGradType>();

  LagrangianFunctionType& function = augfunc.Function();

  // Ensure that we update lambda immediately.
  ElemType penaltyThreshold = std::numeric_limits<ElemType>::max();

  // Track the last objective to compare for convergence.
  ElemType lastObjective = function.Evaluate(coordinates);

  // Convergence tolerance---depends on the epsilon of the type we are using for
  // optimization.
  ElemType tolerance = 1e3 * std::numeric_limits<ElemType>::epsilon();

  // Then, calculate the current penalty.
  ElemType penalty = 0;
  for (size_t i = 0; i < function.NumConstraints(); i++)
  {
    const ElemType p = std::pow(function.EvaluateConstraint(i, coordinates), 2);
    terminate |= Callback::EvaluateConstraint(*this, function, coordinates, i,
        p, callbacks...);

    penalty += p;
  }

  Info << "Penalty is " << penalty << " (threshold " << penaltyThreshold
      << ")." << std::endl;

  // The odd comparison allows user to pass maxIterations = 0 (i.e. no limit on
  // number of iterations).
  size_t it;
  Callback::BeginOptimization(*this, function, coordinates, callbacks...);
  for (it = 0; it != (maxIterations - 1) && !terminate; it++)
  {
    Info << "AugLagrangian on iteration " << it
        << ", starting with objective "  << lastObjective << "." << std::endl;

    if (!lbfgs.Optimize(augfunc, coordinates, callbacks...))
      Info << "L-BFGS reported an error during optimization."
          << std::endl;
    Info << "Done with L-BFGS: " << coordinates << "\n";

    const ElemType objective = function.Evaluate(coordinates);

    terminate |= Callback::Evaluate(*this, function, coordinates, objective,
        callbacks...);

    // Check if we are done with the entire optimization (the threshold we are
    // comparing with is arbitrary).
    if (std::abs(lastObjective - objective) < tolerance &&
        augfunc.Sigma() > 500000)
    {
      lambda = std::move(augfunc.Lambda());
      sigma = augfunc.Sigma();

      Callback::EndOptimization(*this, function, coordinates, callbacks...);
      return true;
    }

    lastObjective = objective;

    // Assuming that the optimization has converged to a new set of coordinates,
    // we now update either lambda or sigma.  We update sigma if the penalty
    // term is too high, and we update lambda otherwise.

    // First, calculate the current penalty.
    ElemType penalty = 0;
    for (size_t i = 0; i < function.NumConstraints(); i++)
    {
      const ElemType p = std::pow(function.EvaluateConstraint(i, coordinates),
          2);
      terminate |= Callback::EvaluateConstraint(*this, function, coordinates, i,
          p, callbacks...);

      penalty += p;
    }

    Info << "Penalty is " << penalty << " (threshold " << penaltyThreshold
        << ")." << std::endl;

    if (terminate)
      break;

    if (penalty < penaltyThreshold) // We update lambda.
    {
      // We use the update: lambda_{k + 1} = lambda_k - sigma * c(coordinates),
      // but we have to write a loop to do this for each constraint.
      for (size_t i = 0; i < function.NumConstraints(); i++)
      {
        const ElemType p = function.EvaluateConstraint(i, coordinates);
        terminate |= Callback::EvaluateConstraint(*this, function, coordinates,
            i, p, callbacks...);

        augfunc.Lambda()[i] -= augfunc.Sigma() * p;
      }

      // We also update the penalty threshold to be a factor of the current
      // penalty.
      penaltyThreshold = penaltyThresholdFactor * penalty;
      Info << "Lagrange multiplier estimates updated." << std::endl;
    }
    else
    {
      // We multiply sigma by a constant value.
      augfunc.Sigma() *= sigmaUpdateFactor;
      Info << "Updated sigma to " << augfunc.Sigma() << "." << std::endl;
      if (augfunc.Sigma() >= std::numeric_limits<ElemType>::max() / 2.0)
      {
        Warn << "AugLagrangian::Optimize(): sigma too large for element type; "
            << "terminating." << std::endl;
        Callback::EndOptimization(*this, function, coordinates, callbacks...);
        return false;
      }
    }

    terminate |= Callback::StepTaken(*this, function, coordinates,
        callbacks...);
  }

  Callback::EndOptimization(*this, function, coordinates, callbacks...);
  return false;
}

} // namespace ens

#endif // ENSMALLEN_AUG_LAGRANGIAN_AUG_LAGRANGIAN_IMPL_HPP

/**
 * @file adaptive_stepsize.hpp
 * @author Marcus Edel
 *
 * Definition of the adaptive stepsize technique as described in:
 * "Big Batch SGD: Automated Inference using Adaptive Batch Sizes" by
 * S. De et al.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_BIGBATCH_SGD_ADAPTIVE_STEPSIZE_HPP
#define ENSMALLEN_BIGBATCH_SGD_ADAPTIVE_STEPSIZE_HPP

namespace ens {

/**
 * Definition of the adaptive stepize technique, a non-monotonic stepsize scheme
 * that uses curvature estimates to propose new stepsize choices.
 * direction.
 *
 * For more information, please refer to:
 *
 * @code
 * @article{De2017,
 *   title   = {Big Batch {SGD:} Automated Inference using Adaptive Batch
 *              Sizes},
 *   author  = {Soham De and Abhay Kumar Yadav and David W. Jacobs and
                Tom Goldstein},
 *   journal = {CoRR},
 *   year    = {2017},
 *   url     = {http://arxiv.org/abs/1610.05792},
 * }
 * @endcode
 */
class AdaptiveStepsize
{
 public:
  /**
   * Construct the AdaptiveStepsize object with the given function and
   * parameters. The defaults here are not necessarily good for the given
   * problem, so it is suggested that the values used be tailored to the task at
   * hand.
   *
   * @param backtrackStepSize The backtracking step size for each iteration.
   * @param searchParameter The backtracking search parameter for each
   *        iteration.
   */
  AdaptiveStepsize(const double backtrackStepSize = 0.5,
                   const double searchParameter = 0.1) :
      backtrackStepSize(backtrackStepSize),
      searchParameter(searchParameter)
  { /* Nothing to do here. */ }

  //! Get the backtracking step size.
  double BacktrackStepSize() const { return backtrackStepSize; }
  //! Modify the backtracking step size.
  double& BacktrackStepSize() { return backtrackStepSize; }

  //! Get the search parameter.
  double SearchParameter() const { return searchParameter; }
  //! Modify the search parameter.
  double& SearchParameter() { return searchParameter; }


  template<typename MatType>
  class Policy
  {
   public:
    // Create the instantiated object.
    Policy(AdaptiveStepsize& parent) : parent(parent) { }

    /**
     * This function is called in each iteration.
     *
     * @tparam SeparableFunctionType Type of the function to be optimized.
     * @param function Function to be optimized (minimized).
     * @param stepSize Step size to be used for the given iteration.
     * @param iterate Parameters that minimize the function.
     * @param gradient The gradient matrix.
     * @param gradientNorm The gradient norm to be used for the given iteration.
     * @param offset The batch offset to be used for the given iteration.
     * @param batchSize Batch size to be used for the given iteration.
     * @param backtrackingBatchSize Backtracking batch size to be used for the
     *        given iteration.
     * @param reset Reset the step size decay parameter.
     */
    template<typename SeparableFunctionType,
             typename GradType>
    void Update(SeparableFunctionType& function,
                double& stepSize,
                MatType& iterate,
                GradType& gradient,
                double& gradientNorm,
                double& sampleVariance,
                const size_t offset,
                const size_t batchSize,
                const size_t backtrackingBatchSize,
                const bool /* reset */)
    {
      Backtracking(function, stepSize, iterate, gradient, gradientNorm, offset,
          backtrackingBatchSize);

      // Update the iterate.
      iterate -= stepSize * gradient;

      // Update Gradient & calculate curvature of quadratic approximation.
      GradType functionGradient(iterate.n_rows, iterate.n_cols);
      GradType gradPrevIterate(iterate.n_rows, iterate.n_cols);
      GradType functionGradientPrev(iterate.n_rows, iterate.n_cols);

      double vB = 0;
      GradType delta0, delta1;

      // Initialize previous iterate, if not already initialized.
      if (iteratePrev.is_empty())
      {
        iteratePrev.zeros(iterate.n_rows, iterate.n_cols);
      }

      // Compute the stochastic gradient estimation.
      function.Gradient(iterate, offset, gradient, 1);
      function.Gradient(iteratePrev, offset, gradPrevIterate, 1);

      delta1 = gradient;

      for (size_t j = 1, k = 1; j < backtrackingBatchSize; ++j, ++k)
      {
        function.Gradient(iterate, offset + j, functionGradient, 1);
        delta0 = delta1 + (functionGradient - delta1) / k;

        // Compute sample variance.
        vB += arma::norm(functionGradient - delta1, 2.0) *
            arma::norm(functionGradient - delta0, 2.0);

        delta1 = delta0;
        gradient += functionGradient;

        // Used for curvature calculation.
        function.Gradient(iteratePrev, offset + j, functionGradientPrev, 1);
        gradPrevIterate += functionGradientPrev;
      }

      // Update sample variance & norm of the gradient.
      sampleVariance = vB;
      gradientNorm = std::pow(arma::norm(gradient / backtrackingBatchSize, 2),
          2.0);

      // Compute curvature.
      double v = arma::trace(arma::trans(iterate - iteratePrev) *
          (gradient - gradPrevIterate)) /
          std::pow(arma::norm(iterate - iteratePrev, 2), 2.0);

      // Update previous iterate.
      iteratePrev = iterate;

      // TODO: Develop an absolute strategy to deal with stepSizeDecay updates
      // in case we arrive at local minima. See #1469 for more details.
      double stepSizeDecay = 0;
      if (gradientNorm && sampleVariance && batchSize)
      {
        if (batchSize < function.NumFunctions())
        {
          stepSizeDecay = (1 - (1 / ((double) batchSize - 1) * sampleVariance) /
              (batchSize * gradientNorm)) / v;
        }
        else
        {
          stepSizeDecay = 1 / v;
        }
      }

      // Stepsize smoothing.
      stepSize *= (1 - ((double) batchSize / function.NumFunctions()));
      stepSize += stepSizeDecay * ((double) batchSize /
          function.NumFunctions());

      Backtracking(function, stepSize, iterate, gradient, gradientNorm, offset,
          backtrackingBatchSize);
    }

    /**
     * Definition of the backtracking line search algorithm based on the
     * Armijo‚ÄìGoldstein condition to determine the maximum amount to move along
     * the given search direction.
     *
     * @tparam SeparableFunctionType Type of the function to be optimized.
     * @param function Function to be optimized (minimized).
     * @param stepSize Step size to be used for the given iteration.
     * @param iterate Parameters that minimize the function.
     * @param gradient The gradient matrix.
     * @param gradientNorm The gradient norm to be used for the given iteration.
     * @param offset The batch offset to be used for the given iteration.
     * @param backtrackingBatchSize The backtracking batch size.
     */
    template<typename SeparableFunctionType,
             typename GradType>
    void Backtracking(SeparableFunctionType& function,
                      double& stepSize,
                      const MatType& iterate,
                      const GradType& gradient,
                      const double gradientNorm,
                      const size_t offset,
                      const size_t backtrackingBatchSize)
    {
      typedef typename MatType::elem_type ElemType;

      ElemType overallObjective = function.Evaluate(iterate,
          offset, backtrackingBatchSize);

      MatType iterateUpdate = iterate - (stepSize * gradient);
      ElemType overallObjectiveUpdate = function.Evaluate(iterateUpdate, offset,
          backtrackingBatchSize);

      while (overallObjectiveUpdate >
          (overallObjective - parent.searchParameter * stepSize *
           gradientNorm))
      {
        stepSize *= parent.backtrackStepSize;

        iterateUpdate = iterate - (stepSize * gradient);
        overallObjectiveUpdate = function.Evaluate(iterateUpdate, offset,
            backtrackingBatchSize);
      }
    }

   private:
    //! Reference to parent.
    AdaptiveStepsize& parent;

    //! Last function parameters value.
    MatType iteratePrev;
  };

 private:
  //! The backtracking step size for each iteration.
  double backtrackStepSize;

  //! The search parameter for each iteration.
  double searchParameter;
};

} // namespace ens

#endif // ENSMALLEN_BIGBATCH_SGD_ADAPTIVE_STEPSIZE_HPP
/**
 * @file backtracking_line_search.hpp
 * @author Marcus Edel
 *
 * Definition of the backtracking line search technique as described in:
 * "Big Batch SGD: Automated Inference using Adaptive Batch Sizes" by
 * S. De et al.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */

#ifndef ENSMALLEN_BIGBATCH_SGD_BACKTRACKING_LINE_SEARCH_HPP
#define ENSMALLEN_BIGBATCH_SGD_BACKTRACKING_LINE_SEARCH_HPP

namespace ens {

/**
 * Definition of the backtracking line search algorithm based on the
 * Armijo‚ÄìGoldstein condition to determine the maximum amount to move along the
 * given search direction.
 *
 * For more information, please refer to:
 *
 * @code
 * @article{De2017,
 *   title   = {Big Batch {SGD:} Automated Inference using Adaptive Batch
 *              Sizes},
 *   author  = {Soham De and Abhay Kumar Yadav and David W. Jacobs and
                Tom Goldstein},
 *   journal = {CoRR},
 *   year    = {2017},
 *   url     = {http://arxiv.org/abs/1610.05792},
 * }
 * @endcode
 */
class BacktrackingLineSearch
{
 public:
  /**
   * Construct the BacktrackingLineSearch object with the given function and
   * parameters. The defaults here are not necessarily good for the given
   * problem, so it is suggested that the values used be tailored to the task at
   * hand.
   *
   * @param function Function to be optimized (minimized).
   */
  BacktrackingLineSearch(const double searchParameter = 0.1) :
      searchParameter(searchParameter)
  { /* Nothing to do here. */ }

  //! Get the search parameter.
  double SearchParameter() const { return searchParameter; }
  //! Modify the search parameter.
  double& SearchParameter() { return searchParameter; }

  template<typename MatType>
  class Policy
  {
   public:
    // Instantiate the policy with the given parent.
    Policy(BacktrackingLineSearch& parent) : parent(parent) { }

    /**
     * This function is called in each iteration.
     *
     * @tparam SeparableFunctionType Type of the function to be optimized.
     * @param function Function to be optimized (minimized).
     * @param stepSize Step size to be used for the given iteration.
     * @param iterate Parameters that minimize the function.
     * @param gradient The gradient matrix.
     * @param gradientNorm The gradient norm to be used for the given iteration.
     * @param offset The batch offset to be used for the given iteration.
     * @param batchSize Batch size to be used for the given iteration.
     * @param backtrackingBatchSize Backtracking batch size to be used for the
     *        given iteration.
     * @param reset Reset the step size decay parameter.
     */
    template<typename SeparableFunctionType,
             typename GradType>
    void Update(SeparableFunctionType& function,
                double& stepSize,
                MatType& iterate,
                GradType& gradient,
                double& gradientNorm,
                double& /* sampleVariance */,
                const size_t offset,
                const size_t /* batchSize */,
                const size_t backtrackingBatchSize,
                const bool reset)
    {
      if (reset)
        stepSize *= 2;

      typedef typename MatType::elem_type ElemType;

      ElemType overallObjective = function.Evaluate(iterate, offset,
          backtrackingBatchSize);

      MatType iterateUpdate = iterate - (stepSize * gradient);
      ElemType overallObjectiveUpdate = function.Evaluate(iterateUpdate, offset,
          backtrackingBatchSize);

      while (overallObjectiveUpdate >
          (overallObjective - parent.searchParameter * stepSize *
           gradientNorm))
      {
        stepSize /= 2;

        iterateUpdate = iterate - (stepSize * gradient);
        overallObjectiveUpdate = function.Evaluate(iterateUpdate,
          offset, backtrackingBatchSize);
      }
    }

   private:
    //! Reference to instantiated parent object.
    BacktrackingLineSearch& parent;
  };

 private:
  //! The search parameter for each iteration.
  double searchParameter;
};

} // namespace ens

#endif // ENSMALLEN_BIGBATCH_SGD_BACKTRACKING_LINE_SEARCH_HPP
/**
 * @file bigbatch_sgd.hpp
 * @author Marcus Edel
 *
 * Definition of Big-batch Stochastic Gradient Descent (BBSGD) as described in:
 * "Big Batch SGD: Automated Inference using Adaptive Batch Sizes"
 * by Soham De et al.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_BIGBATCH_SGD_BIGBATCH_SGD_HPP
#define ENSMALLEN_BIGBATCH_SGD_BIGBATCH_SGD_HPP

#include "adaptive_stepsize.hpp"
#include "backtracking_line_search.hpp"

namespace ens {

/**
 * Big-batch Stochastic Gradient Descent is a technique for minimizing a
 * function which can be expressed as a sum of other functions.  That is,
 * suppose we have
 *
 * \f[
 * f(A) = \sum_{i = 0}^{n} f_i(A)
 * \f]
 *
 * and our task is to minimize \f$ A \f$.  Big-batch SGD iterates over batches
 * of functions \f$ \{ f_{i0}(A), f_{i1}(A), \ldots, f_{i(m - 1)}(A) \f$ for
 * some batch size \f$ m \f$, producing the following update scheme:
 *
 * \f[
 * A_{j + 1} = A_j + \alpha \left(\sum_{k = 0}^{m - 1} \nabla f_{ik}(A) \right)
 * \f]
 *
 * where \f$ \alpha \f$ is a parameter which specifies the step size.  Each
 * big-batch is passed through either sequentially or randomly.  The algorithm
 * continues until \f$ j \f$ reaches the maximum number of iterations---or when
 * a full sequence of updates through each of the big-batches produces an
 * improvement within a certain tolerance \f$ \epsilon \f$.
 *
 * The parameter \f$ \epsilon \f$ is specified by the tolerance parameter tot he
 * constructor, as is the maximum number of iterations specified by the
 * maxIterations parameter.
 *
 * This class is useful for data-dependent functions whose objective function
 * can be expressed as a sum of objective functions operating on an individual
 * point.  Then, big-batch SGD considers the gradient of the objective function
 * operation on an individual big-batch of points in its update of \f$ A \f$.
 *
 * For more information, please refer to:
 *
 * @code
 * @article{De2017,
 *   title   = {Big Batch {SGD:} Automated Inference using Adaptive Batch
 *              Sizes},
 *   author  = {Soham De and Abhay Kumar Yadav and David W. Jacobs and
 *              Tom Goldstein},
 *   journal = {CoRR},
 *   year    = {2017},
 *   url     = {http://arxiv.org/abs/1610.05792},
 * }
 * @endcode
 *
 * Big-batch SGD can optimize differentiable separable functions.  For more
 * details, see the documentation on function types included with this
 * distribution or on the ensmallen website.
 *
 * @tparam UpdatePolicyType Update policy used during the iterative update
 *     process. By default the AdaptiveStepsize update policy is used.
 */
template<typename UpdatePolicyType = AdaptiveStepsize>
class BigBatchSGD
{
 public:
  /**
   * Construct the BigBatchSGD optimizer with the given function and
   * parameters.  The defaults here are not necessarily good for the given
   * problem, so it is suggested that the values used be tailored for the task
   * at hand.  The maximum number of iterations refers to the maximum number of
   * batches that are processed.
   *
   * @param batchSize Initial batch size.
   * @param stepSize Step size for each iteration.
   * @param batchDelta Factor for the batch update step.
   * @param maxIterations Maximum number of iterations allowed (0 means no
   *        limit).
   * @param tolerance Maximum absolute tolerance to terminate algorithm.
   * @param shuffle If true, the batch order is shuffled; otherwise, each
   *        batch is visited in linear order.
   * @param exactObjective Calculate the exact objective (Default: estimate the
   *        final objective obtained on the last pass over the data).
   */
  BigBatchSGD(const size_t batchSize = 1000,
              const double stepSize = 0.01,
              const double batchDelta = 0.1,
              const size_t maxIterations = 100000,
              const double tolerance = 1e-5,
              const bool shuffle = true,
              const bool exactObjective = false);

  /**
   * Clean any memory associated with the BigBatchSGD object.
   */
  ~BigBatchSGD();

  /**
   * Optimize the given function using big-batch SGD.  The given starting point
   * will be modified to store the finishing point of the algorithm, and the
   * final objective value is returned.
   *
   * @tparam SeparableFunctionType Type of the function to be optimized.
   * @tparam MatType Type of matrix to optimize with.
   * @tparam GradType Type of matrix to use to represent function gradients.
   * @tparam CallbackTypes Types of callback functions.
   * @param function Function to optimize.
   * @param iterate Starting point (will be modified).
   * @param callbacks Callback functions.
   * @return Objective value of the final point.
   */
  template<typename SeparableFunctionType,
           typename MatType,
           typename GradType,
           typename... CallbackTypes>
  typename std::enable_if<IsArmaType<GradType>::value,
      typename MatType::elem_type>::type
  Optimize(SeparableFunctionType& function,
           MatType& iterate,
           CallbackTypes&&... callbacks);

  //! Forward the MatType as GradType.
  template<typename SeparableFunctionType,
           typename MatType,
           typename... CallbackTypes>
  typename MatType::elem_type Optimize(SeparableFunctionType& function,
                                       MatType& iterate,
                                       CallbackTypes&&... callbacks)
  {
    return Optimize<SeparableFunctionType, MatType, MatType,
        CallbackTypes...>(function, iterate,
        std::forward<CallbackTypes>(callbacks)...);
  }

  //! Get the batch size.
  size_t BatchSize() const { return batchSize; }
  //! Modify the batch size.
  size_t& BatchSize() { return batchSize; }

  //! Get the step size.
  double StepSize() const { return stepSize; }
  //! Modify the step size.
  double& StepSize() { return stepSize; }

  //! Get the batch delta.
  double BatchDelta() const { return batchDelta; }
  //! Modify the batch delta.
  double& BatchDelta() { return batchDelta; }

  //! Get the maximum number of iterations (0 indicates no limit).
  size_t MaxIterations() const { return maxIterations; }
  //! Modify the maximum number of iterations (0 indicates no limit).
  size_t& MaxIterations() { return maxIterations; }

  //! Get the tolerance for termination.
  double Tolerance() const { return tolerance; }
  //! Modify the tolerance for termination.
  double& Tolerance() { return tolerance; }

  //! Get whether or not the individual functions are shuffled.
  bool Shuffle() const { return shuffle; }
  //! Modify whether or not the individual functions are shuffled.
  bool& Shuffle() { return shuffle; }

  //! Get the update policy.
  UpdatePolicyType UpdatePolicy() const { return updatePolicy; }
  //! Modify the update policy.
  UpdatePolicyType& UpdatePolicy() { return updatePolicy; }

  //! Get whether or not the actual objective is calculated.
  bool ExactObjective() const { return exactObjective; }
  //! Modify whether or not the actual objective is calculated.
  bool& ExactObjective() { return exactObjective; }

 private:
  //! The size of the current batch.
  size_t batchSize;

  //! The step size for each example.
  double stepSize;

  //! The factor for the batch update step.
  double batchDelta;

  //! The maximum number of allowed iterations.
  size_t maxIterations;

  //! The tolerance for termination.
  double tolerance;

  //! Controls whether or not the individual functions are shuffled when
  //! iterating.
  bool shuffle;

  //! Controls whether or not the actual Objective value is calculated.
  bool exactObjective;

  //! The update policy used to update the parameters in each iteration.
  UpdatePolicyType updatePolicy;

  //! Instantiated update policy.
  Any instUpdatePolicy;
};

using BBS_Armijo = BigBatchSGD<BacktrackingLineSearch>;
using BBS_BB = BigBatchSGD<AdaptiveStepsize>;

} // namespace ens

// Include implementation.
#include "bigbatch_sgd_impl.hpp"

#endif
/**
 * @file bigbatch_sgd_impl.hpp
 * @author Marcus Edel
 *
 * Implementation of big-batch SGD.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_BIGBATCH_SGD_BIGBATCH_SGD_IMPL_HPP
#define ENSMALLEN_BIGBATCH_SGD_BIGBATCH_SGD_IMPL_HPP

// In case it hasn't been included yet.
#include "bigbatch_sgd.hpp"

#include <ensmallen_bits/function.hpp>

namespace ens {

template<typename UpdatePolicyType>
BigBatchSGD<UpdatePolicyType>::BigBatchSGD(
    const size_t batchSize,
    const double stepSize,
    const double batchDelta,
    const size_t maxIterations,
    const double tolerance,
    const bool shuffle,
    const bool exactObjective) :
    batchSize(batchSize),
    stepSize(stepSize),
    batchDelta(batchDelta),
    maxIterations(maxIterations),
    tolerance(tolerance),
    shuffle(shuffle),
    exactObjective(exactObjective),
    updatePolicy(UpdatePolicyType())
{ /* Nothing to do. */ }

template<typename UpdatePolicyType>
BigBatchSGD<UpdatePolicyType>::~BigBatchSGD()
{
  instUpdatePolicy.Clean();
}

//! Optimize the function (minimize).
template<typename UpdatePolicyType>
template<typename SeparableFunctionType,
         typename MatType,
         typename GradType,
         typename... CallbackTypes>
typename std::enable_if<IsArmaType<GradType>::value,
typename MatType::elem_type>::type
BigBatchSGD<UpdatePolicyType>::Optimize(
    SeparableFunctionType& function,
    MatType& iterateIn,
    CallbackTypes&&... callbacks)
{
  // Convenience typedefs.
  typedef typename MatType::elem_type ElemType;
  typedef typename MatTypeTraits<MatType>::BaseMatType BaseMatType;
  typedef typename MatTypeTraits<GradType>::BaseMatType BaseGradType;

  typedef Function<SeparableFunctionType, BaseMatType, BaseGradType>
      FullFunctionType;
  FullFunctionType& f(static_cast<FullFunctionType&>(function));

  // Make sure we have all the methods that we need.
  traits::CheckSeparableFunctionTypeAPI<FullFunctionType, BaseMatType,
      BaseGradType>();
  RequireFloatingPointType<BaseMatType>();
  RequireFloatingPointType<BaseGradType>();
  RequireSameInternalTypes<BaseMatType, BaseGradType>();

  BaseMatType& iterate = (BaseMatType&) iterateIn;

  typedef typename UpdatePolicyType::template Policy<BaseMatType>
      InstUpdatePolicyType;

  if (!instUpdatePolicy.Has<InstUpdatePolicyType>())
  {
    instUpdatePolicy.Clean();
    instUpdatePolicy.Set<InstUpdatePolicyType>(
        new InstUpdatePolicyType(updatePolicy));
  }

  // Find the number of functions to use.
  const size_t numFunctions = f.NumFunctions();

  // To keep track of where we are and how things are going.
  size_t currentFunction = 0;
  size_t epoch = 1;
  ElemType overallObjective = 0;
  ElemType lastObjective = DBL_MAX;
  bool reset = false;
  BaseGradType delta0, delta1;

  // Controls early termination of the optimization process.
  bool terminate = false;

  // Now iterate!
  BaseGradType gradient(iterate.n_rows, iterate.n_cols);
  BaseGradType functionGradient(iterate.n_rows, iterate.n_cols);
  const size_t actualMaxIterations = (maxIterations == 0) ?
      std::numeric_limits<size_t>::max() : maxIterations;
  Callback::BeginOptimization(*this, f, iterate, callbacks...);
  for (size_t i = 0; i < actualMaxIterations && !terminate;
      /* incrementing done manually */)
  {
    // Find the effective batch size; we have to take the minimum of three
    // things:
    // - the batch size can't be larger than the user-specified batch size;
    // - the batch size can't be larger than the number of iterations left
    //       before actualMaxIterations is hit;
    // - the batch size can't be larger than the number of functions left.
    size_t effectiveBatchSize = std::min(
        std::min(batchSize, actualMaxIterations - i),
        numFunctions - currentFunction);

    size_t k = 1;
    double vB = 0;

    // Compute the stochastic gradient estimation.
    f.Gradient(iterate, currentFunction, gradient, 1);

    terminate |= Callback::Gradient(*this, f, iterate, gradient, callbacks...);

    delta1 = gradient;
    for (size_t j = 1; j < effectiveBatchSize; ++j, ++k)
    {
      f.Gradient(iterate, currentFunction + j, functionGradient, 1);

      terminate |= Callback::Gradient(*this, f, iterate, functionGradient,
          callbacks...);

      delta0 = delta1 + (functionGradient - delta1) / k;

      // Compute sample variance.
      vB += arma::norm(functionGradient - delta1, 2.0) *
          arma::norm(functionGradient - delta0, 2.0);

      delta1 = delta0;
      gradient += functionGradient;
    }
    double gB = std::pow(arma::norm(gradient / effectiveBatchSize, 2), 2.0);

    // Reset the batch size update process counter.
    reset = false;

    // Increase batchSize only if there are more samples left.
    if (effectiveBatchSize == batchSize)
    {
      // Update batch size.
      while (gB <= ((1 / ((double) batchSize - 1) * vB) / batchSize))
      {
        // Increase batch size at least by one.
        size_t batchOffset = batchDelta * batchSize;
        if (batchOffset <= 0)
          batchOffset = 1;

        if ((currentFunction + batchSize + batchOffset) >= numFunctions)
          break;

        // Update the stochastic gradient estimation.
        const size_t batchStart = (currentFunction + batchSize + batchOffset
            - 1) < numFunctions ? currentFunction + batchSize - 1 : 0;
        for (size_t j = 0; j < batchOffset; ++j, ++k)
        {
          f.Gradient(iterate, batchStart + j, functionGradient, 1);
          terminate |= Callback::Gradient(*this, f, iterate,
              functionGradient, callbacks...);

          delta0 = delta1 + (functionGradient - delta1) / (k + 1);

          // Compute sample variance.
          vB += arma::norm(functionGradient - delta1, 2.0) *
              arma::norm(functionGradient - delta0, 2.0);

          delta1 = delta0;
          gradient += functionGradient;
        }
        gB = std::pow(arma::norm(gradient / (batchSize + batchOffset), 2), 2.0);

        // Update the batchSize.
        batchSize += batchOffset;
        effectiveBatchSize += batchOffset;

        // Batch size updated.
        reset = true;
      }
    }

    if (terminate)
      break;

    instUpdatePolicy.As<InstUpdatePolicyType>().Update(f, stepSize, iterate,
        gradient, gB, vB, currentFunction, batchSize, effectiveBatchSize,
        reset);

    // Update the iterate.
    iterate -= stepSize * gradient;
    terminate |= Callback::StepTaken(*this, f, iterate, callbacks...);

    const ElemType objective = f.Evaluate(iterate, currentFunction,
        effectiveBatchSize);
    overallObjective += objective;

    terminate |= Callback::Evaluate(*this, f, iterate, objective,
        callbacks...);

    i += effectiveBatchSize;
    currentFunction += effectiveBatchSize;

    // Is this iteration the start of a sequence?
    if ((currentFunction % numFunctions) == 0)
    {
      terminate |= Callback::EndEpoch(*this, f, iterate, epoch++,
          overallObjective / (ElemType) numFunctions, callbacks...);

      // Output current objective function.
      Info << "Big-batch SGD: iteration " << i << ", objective "
          << overallObjective << "." << std::endl;

      if (std::isnan(overallObjective) || std::isinf(overallObjective))
      {
        Warn << "Big-batch SGD: converged to " << overallObjective
            << "; terminating with failure.  Try a smaller step size?"
            << std::endl;

        Callback::EndOptimization(*this, f, iterate, callbacks...);
        return overallObjective;
      }

      if (std::abs(lastObjective - overallObjective) < tolerance)
      {
        Info << "Big-batch SGD: minimized within tolerance " << tolerance
            << "; terminating optimization." << std::endl;

        Callback::EndOptimization(*this, f, iterate, callbacks...);
        return overallObjective;
      }

      terminate |= Callback::BeginEpoch(*this, f, iterate, epoch,
          overallObjective, callbacks...);

      // Reset the counter variables.
      lastObjective = overallObjective;
      overallObjective = 0;
      currentFunction = 0;

      if (shuffle) // Determine order of visitation.
        f.Shuffle();
    }
  }

  if (!terminate)
  {
    Info << "Big-batch SGD: maximum iterations (" << maxIterations << ") "
        << "reached; terminating optimization." << std::endl;
  }

  // Calculate final objective if exactObjective is set to true.
  if (exactObjective)
  {
    overallObjective = 0;
    for (size_t i = 0; i < numFunctions; i += batchSize)
    {
      const size_t effectiveBatchSize = std::min(batchSize, numFunctions - i);
      const ElemType objective = f.Evaluate(iterate, i, effectiveBatchSize);
      overallObjective += objective;

      // The optimization is finished, so we don't need to care what the
      // callback returns.
      (void) Callback::Evaluate(*this, f, iterate, objective, callbacks...);
    }
  }

  Callback::EndOptimization(*this, f, iterate, callbacks...);
  return overallObjective;
}

} // namespace ens

#endif
/**
 * @file callbacks.hpp
 * @author Marcus Edel
 *
 * The Callback class will invoke the specified callbacks.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_CALLBACKS_CALLBACKS_HPP
#define ENSMALLEN_CALLBACKS_CALLBACKS_HPP

#include <ensmallen_bits/callbacks/traits.hpp>

namespace ens {

/**
 * Callbacks are a set of functions that can be applied at given stages of the
 * optimization process. The following callbacks are available:
 *
 * - bool Evaluate(optimizer, function, coordinates, objective):
 *   called after any call to Evaluate().
 *
 * - bool StepTaken(optimizer, function, coordinates):
 *   called after any step is taken.
 *
 * - bool Gradient(optimizer, function, coordinates, gradient):
 *   called whenever the gradient is computed.
 *
 * - bool BeginEpoch(optimizer, function, coordinates, epoch, objective):
 *   called at the beginning of a pass over the data. The objective may be
 *   exact or an estimate depending on exactObjective's value.
 *
 * - bool EvaluateConstraint(optimizer, function, coordinates, constraint,
 *                           constraintValue):
 *   called after any call to EvaluateConstraint().
 *
 * - bool GradientConstraint(optimizer, function, coordinates, constraint,
 *                           constraintGradient):
 *   called after any call to GradientConstraint().
 *
 * - void BeginOptimization(optimizer, function, coordinates):
 *   called at the beginning of the optimization.
 *
 * - void EndOptimization(optimizer, function, coordinates):
 *   called at the end of the optimization.
 *
 * If true is returned to any of the bool-type callbacks, the optimization will
 * be terminated before any more steps are taken.
 */
class Callback
{
 public:
  /**
   * Invoke the BeginOptimization() callback if it exists.
   *
   * @param callback The callback to call.
   * @param optimizer The optimizer used to update the function.
   * @param function Function to optimize.
   * @param coordinates Starting point.
   */
  template<typename CallbackType,
           typename OptimizerType,
           typename FunctionType,
           typename MatType>
  static typename std::enable_if<
      callbacks::traits::HasBeginOptimizationSignature<
      CallbackType, OptimizerType, FunctionType, MatType>::value,
      void>::type
  BeginOptimizationFunction(CallbackType& callback,
                            OptimizerType& optimizer,
                            FunctionType& function,
                            MatType& coordinates)
  {
    (void) const_cast<CallbackType&>(callback).BeginOptimization(optimizer,
        function, coordinates);
  }

  template<typename CallbackType,
           typename OptimizerType,
           typename FunctionType,
           typename MatType>
  static typename std::enable_if<
      !callbacks::traits::HasBeginOptimizationSignature<
      CallbackType, OptimizerType, FunctionType, MatType>::value,
      void>::type
  BeginOptimizationFunction(CallbackType& /* callback */,
                            OptimizerType& /* optimizer */,
                            FunctionType& /* function */,
                            MatType& /* coordinates */)
  { /* Nothing to do. */ }

  /**
   * Iterate over the callbacks and invoke the BeginOptimization() callback if
   * it exists.
   *
   * @param optimizer The optimizer used to update the function.
   * @param function Function to optimize.
   * @param coordinates Starting point.
   * @param callbacks The callbacks container.
   */
  template<typename OptimizerType,
           typename FunctionType,
           typename MatType,
           typename CallbackType,
           typename... CallbackTypes>
  static void BeginOptimization(OptimizerType& optimizer,
                                FunctionType& function,
                                MatType& coordinates,
                                CallbackType& callback,
                                CallbackTypes&... otherCallbacks)
  {
    Callback::BeginOptimizationFunction(callback, optimizer, function,
        coordinates);
    Callback::BeginOptimization(optimizer, function, coordinates,
        otherCallbacks...);
  }

  template<typename OptimizerType,
           typename FunctionType,
           typename MatType>
  static void BeginOptimization(OptimizerType& /* optimizer */,
                                FunctionType& /* function */,
                                MatType& /* coordinates */)
  {
    // Base case... no callbacks left.  Nothing to do.
  }

  /**
   * Invoke the EndOptimization() callback if it exists.
   *
   * @param callback The callback to call.
   * @param optimizer The optimizer used to update the function.
   * @param function Function to optimize.
   * @param coordinates Starting point.
   */
  template<typename CallbackType,
           typename OptimizerType,
           typename FunctionType,
           typename MatType>
  static typename std::enable_if<callbacks::traits::HasEndOptimizationSignature<
      CallbackType, OptimizerType, FunctionType, MatType>::value,
      void>::type
  EndOptimizationFunction(CallbackType& callback,
                          OptimizerType& optimizer,
                          FunctionType& function,
                          MatType& coordinates)
  {
    (void) const_cast<CallbackType&>(callback).EndOptimization( optimizer,
        function, coordinates);
  }

  template<typename CallbackType,
           typename OptimizerType,
           typename FunctionType,
           typename MatType>
  static typename std::enable_if<
      !callbacks::traits::HasEndOptimizationSignature<
      CallbackType, OptimizerType, FunctionType, MatType>::value,
      void>::type
  EndOptimizationFunction(CallbackType& /* callback */,
                          OptimizerType& /* optimizer */,
                          FunctionType& /* function */,
                          MatType& /* coordinates */)
  { /* Nothing to do. */ }

  /**
   * Iterate over the callbacks and invoke the EndOptimization() callback if it
   * exists.
   *
   * @param optimizer The optimizer used to update the function.
   * @param function Function to optimize.
   * @param coordinates Starting point.
   * @param callbacks The callbacks container.
   */
  template<typename OptimizerType,
           typename FunctionType,
           typename MatType,
           typename CallbackType,
           typename... CallbackTypes>
  static void EndOptimization(OptimizerType& optimizer,
                              FunctionType& function,
                              MatType& coordinates,
                              CallbackType& callback,
                              CallbackTypes&... otherCallbacks)
  {
    Callback::EndOptimizationFunction(callback, optimizer, function,
        coordinates);
    Callback::EndOptimization(optimizer, function, coordinates,
        otherCallbacks...);
  }

  template<typename OptimizerType,
           typename FunctionType,
           typename MatType>
  static void EndOptimization(OptimizerType& /* optimizer */,
                              FunctionType& /* function */,
                              MatType& /* coordinates */)
  {
    // Base case... no callbacks left.  Nothing to do.
  }

  /**
   * Invoke the Evaluate() callback if it exists.
   *
   * @param callback The callback to call.
   * @param optimizer The optimizer used to update the function.
   * @param function Function to optimize.
   * @param coordinates Starting point.
   * @param objective Objective value of the current point.
   */
  template<typename CallbackType,
           typename OptimizerType,
           typename FunctionType,
           typename MatType>
  static typename std::enable_if<callbacks::traits::HasEvaluateSignature<
      CallbackType, OptimizerType, FunctionType, MatType>::hasBool,
      bool>::type
  EvaluateFunction(CallbackType& callback,
                   OptimizerType& optimizer,
                   FunctionType& function,
                   const MatType& coordinates,
                   const double objective)
  {
    return const_cast<CallbackType&>(callback).Evaluate(optimizer, function,
        coordinates, objective);
  }

  template<typename CallbackType,
           typename OptimizerType,
           typename FunctionType,
           typename MatType>
  static typename std::enable_if<callbacks::traits::HasEvaluateSignature<
      CallbackType, OptimizerType, FunctionType, MatType>::hasVoid,
      bool>::type
  EvaluateFunction(CallbackType& callback,
                   OptimizerType& optimizer,
                   FunctionType& function,
                   const MatType& coordinates,
                   const double objective)
  {
    const_cast<CallbackType&>(callback).Evaluate(optimizer, function,
        coordinates, objective);
    return false;
  }

  template<typename CallbackType,
           typename OptimizerType,
           typename FunctionType,
           typename MatType>
  static typename std::enable_if<callbacks::traits::HasEvaluateSignature<
      CallbackType, OptimizerType, FunctionType, MatType>::hasNone,
      bool>::type
  EvaluateFunction(CallbackType& /* callback */,
                   OptimizerType& /* optimizer */,
                   FunctionType& /* function */,
                   const MatType& /* coordinates */,
                   const double /* objective */)
  { return false; }

  /**
   * Iterate over the callbacks and invoke the Evaluate() callback if it exists.
   *
   * @param optimizer The optimizer used to update the function.
   * @param function Function to optimize.
   * @param coordinates Starting point.
   * @param objective Objective value of the current point.
   * @param callbacks The callbacks container.
   */
  template<typename OptimizerType,
           typename FunctionType,
           typename MatType,
           typename... CallbackTypes>
  static bool Evaluate(OptimizerType& optimizer,
                       FunctionType& function,
                       const MatType& coordinates,
                       const double objective,
                       CallbackTypes&... callbacks)
  {
    // This will return immediately once a callback returns true.
    bool result = false;
    (void)(objective);  // prevent spurious compiler warnings
    (void)std::initializer_list<bool>{ result =
        result || Callback::EvaluateFunction(callbacks, optimizer, function,
        coordinates, objective)... };
     return result;
  }

  /**
   * Invoke the EvaluateConstraint() callback if it exists.
   *
   * @param callback The callback to call.
   * @param optimizer The optimizer used to update the function.
   * @param function Function to optimize.
   * @param coordinates Starting point.
   * @param constraint The index of the constraint.
   * @param constraintValue Constraint value of the current point.
   */
  template<typename CallbackType,
           typename OptimizerType,
           typename FunctionType,
           typename MatType>
  static typename std::enable_if<
      callbacks::traits::HasEvaluateConstraintSignature<
      CallbackType, OptimizerType, FunctionType, MatType>::hasBool,
      bool>::type
  EvaluateConstraintFunction(CallbackType& callback,
                             OptimizerType& optimizer,
                             FunctionType& function,
                             const MatType& coordinates,
                             const size_t constraint,
                             const double constraintValue)
  {
    return const_cast<CallbackType&>(callback).EvaluateConstraint(
        optimizer, function, coordinates, constraint, constraintValue);
  }

  template<typename CallbackType,
           typename OptimizerType,
           typename FunctionType,
           typename MatType>
  static typename std::enable_if<
      callbacks::traits::HasEvaluateConstraintSignature<
      CallbackType, OptimizerType, FunctionType, MatType>::hasVoid,
      bool>::type
  EvaluateConstraintFunction(CallbackType& callback,
                             OptimizerType& optimizer,
                             FunctionType& function,
                             const MatType& coordinates,
                             const size_t constraint,
                             const double constraintValue)
  {
    const_cast<CallbackType&>(callback).EvaluateConstraint(
        optimizer, function, coordinates, constraint, constraintValue);
    return false;
  }

  template<typename CallbackType,
           typename OptimizerType,
           typename FunctionType,
           typename MatType>
  static typename std::enable_if<
      callbacks::traits::HasEvaluateConstraintSignature<
      CallbackType, OptimizerType, FunctionType, MatType>::hasNone,
      bool>::type
  EvaluateConstraintFunction(CallbackType& /* callback */,
                             OptimizerType& /* optimizer */,
                             FunctionType& /* function */,
                             const MatType& /* coordinates */,
                             const size_t /* constraint */,
                             const double /* constraintValue */)
  { return false; }

  /**
   * Iterate over the callbacks and invoke the EvaluateConstraint() callback if
   * it exists.
   *
   * @param optimizer The optimizer used to update the function.
   * @param function Function to optimize.
   * @param coordinates Starting point.
   * @param constraint The index of the constraint.
   * @param constraintValue Constraint value of the current point.
   * @param callbacks The callbacks container.
   */
  template<typename OptimizerType,
           typename FunctionType,
           typename MatType,
           typename... CallbackTypes>
  static bool EvaluateConstraint(OptimizerType& optimizer,
                                 FunctionType& function,
                                 const MatType& coordinates,
                                 const size_t constraint,
                                 const double constraintValue,
                                 CallbackTypes&... callbacks)
  {
    // This will return immediately once a callback returns true.
    bool result = false;
    (void)(constraint);  // prevent spurious compiler warnings
    (void)(constraintValue);
    (void)std::initializer_list<bool>{ result =
        result || Callback::EvaluateConstraintFunction(callbacks, optimizer,
            function, coordinates, constraint, constraintValue)... };
     return result;
  }

  /**
   * Invoke the Gradient() callback if it exists.
   *
   * @param callback The callback to call.
   * @param optimizer The optimizer used to update the function.
   * @param function Function to optimize.
   * @param coordinates Starting point.
   * @param gradient Matrix that holds the gradient.
   */
  template<typename CallbackType,
           typename OptimizerType,
           typename FunctionType,
           typename MatType,
           typename GradType>
  static typename std::enable_if<callbacks::traits::HasGradientSignature<
      CallbackType, OptimizerType, FunctionType, MatType, GradType>::hasBool,
      bool>::type
  GradientFunction(CallbackType& callback,
                   OptimizerType& optimizer,
                   FunctionType& function,
                   const MatType& coordinates,
                   GradType& gradient)
  {
    return const_cast<CallbackType&>(callback).Gradient(optimizer, function,
        coordinates, gradient);
  }

  template<typename CallbackType,
           typename OptimizerType,
           typename FunctionType,
           typename MatType,
           typename GradType>
  static typename std::enable_if<callbacks::traits::HasGradientSignature<
      CallbackType, OptimizerType, FunctionType, MatType, GradType>::hasVoid,
      bool>::type
  GradientFunction(CallbackType& callback,
                   OptimizerType& optimizer,
                   FunctionType& function,
                   const MatType& coordinates,
                   GradType& gradient)
  {
    const_cast<CallbackType&>(callback).Gradient(
        optimizer, function, coordinates, gradient);
    return false;
  }

  template<typename CallbackType,
           typename OptimizerType,
           typename FunctionType,
           typename MatType,
           typename GradType>
  static typename std::enable_if<callbacks::traits::HasGradientSignature<
      CallbackType, OptimizerType, FunctionType, MatType, GradType>::hasNone,
      bool>::type
  GradientFunction(CallbackType& /* callback */,
                   OptimizerType& /* optimizer */,
                   FunctionType& /* function */,
                   const MatType& /* coordinates */,
                   GradType& /* gradient */)
  { return false; }

  /**
   * Iterate over the callbacks and invoke the Gradient() callback if it exists.
   *
   * @param optimizer The optimizer used to update the function.
   * @param function Function to optimize.
   * @param coordinates Starting point.
   * @param gradient Matrix that holds the gradient.
   * @param callbacks The callbacks container.
   */
  template<typename OptimizerType,
           typename FunctionType,
           typename MatType,
           typename GradType,
           typename... CallbackTypes>
  static bool Gradient(OptimizerType& optimizer,
                       FunctionType& function,
                       const MatType& coordinates,
                       GradType& gradient,
                       CallbackTypes&... callbacks)
  {
    // This will return immediately once a callback returns true.
    bool result = false;
    (void)std::initializer_list<bool>{ result =
        result || Callback::GradientFunction(callbacks, optimizer, function,
        coordinates, gradient)... };
     return result;
  }

  /**
   * Invoke the GradientConstraint() callback if it exists.
   *
   * @param callback The callback to call.
   * @param optimizer The optimizer used to update the function.
   * @param function Function to optimize.
   * @param coordinates Starting point.
   * @param gradient Matrix that holds the gradient.
   */
  template<typename CallbackType,
           typename OptimizerType,
           typename FunctionType,
           typename MatType,
           typename GradType>
  static typename std::enable_if<
      callbacks::traits::HasGradientConstraintSignature<
      CallbackType, OptimizerType, FunctionType, MatType, GradType>::hasBool,
      bool>::type
  GradientConstraintFunction(CallbackType& callback,
                             OptimizerType& optimizer,
                             FunctionType& function,
                             const MatType& coordinates,
                             const size_t constraint,
                             GradType& gradient)
  {
    return const_cast<CallbackType&>(callback).GradientConstraint(optimizer,
        function, coordinates, constraint, gradient);
  }

  template<typename CallbackType,
           typename OptimizerType,
           typename FunctionType,
           typename MatType,
           typename GradType>
  static typename std::enable_if<
      callbacks::traits::HasGradientConstraintSignature<
      CallbackType, OptimizerType, FunctionType, MatType, GradType>::hasVoid,
      bool>::type
  GradientConstraintFunction(CallbackType& callback,
                             OptimizerType& optimizer,
                             FunctionType& function,
                             const MatType& coordinates,
                             const size_t constraint,
                             GradType& gradient)
  {
    const_cast<CallbackType&>(callback).GradientConstraint(
        optimizer, function, coordinates, constraint, gradient);
    return false;
  }

  template<typename CallbackType,
           typename OptimizerType,
           typename FunctionType,
           typename MatType,
           typename GradType>
  static typename std::enable_if<
      callbacks::traits::HasGradientConstraintSignature<
      CallbackType, OptimizerType, FunctionType, MatType, GradType>::hasNone,
      bool>::type
  GradientConstraintFunction(CallbackType& /* callback */,
                             OptimizerType& /* optimizer */,
                             FunctionType& /* function */,
                             const MatType& /* coordinates */,
                             const size_t /* constraint */,
                             GradType& /* gradient */)
  { return false; }

  /**
   * Iterate over the callbacks and invoke the GradientConstraint() callback if
   * it exists.
   *
   * @param optimizer The optimizer used to update the function.
   * @param function Function to optimize.
   * @param coordinates Starting point.
   * @param gradient Matrix that holds the gradient.
   * @param callbacks The callbacks container.
   */
  template<typename OptimizerType,
           typename FunctionType,
           typename MatType,
           typename GradType,
           typename... CallbackTypes>
  static bool Gradient(OptimizerType& optimizer,
                       FunctionType& function,
                       const MatType& coordinates,
                       const size_t constraint,
                       GradType& gradient,
                       CallbackTypes&... callbacks)
  {
    // This will return immediately once a callback returns true.
    bool result = false;
    (void)(constraint);  // prevent spurious compiler warnings
    (void)std::initializer_list<bool>{ result =
        result || Callback::GradientConstraintFunction(callbacks, optimizer,
        function, coordinates, constraint, gradient)... };
     return result;
  }

  /**
   * Iterate over the callbacks and invoke the Evaluate() and Gradient()
   * callback if it exists.
   *
   * @param optimizer The optimizer used to update the function.
   * @param function Function to optimize.
   * @param coordinates Starting point.
   * @param objective Objective value of the current point.
   * @param gradient Matrix that holds the gradient.
   * @param callbacks The callbacks container.
   */
  template<typename OptimizerType,
           typename FunctionType,
           typename MatType,
           typename GradType,
           typename... CallbackTypes>
  static bool EvaluateWithGradient(OptimizerType& optimizer,
                                   FunctionType& function,
                                   const MatType& coordinates,
                                   const double objective,
                                   GradType& gradient,
                                   CallbackTypes&... callbacks)
  {
    // This will return immediately once a callback returns true.
    bool result = false;
    (void)(objective);  // prevent spurious compiler warnings
    (void)std::initializer_list<bool>{ result =
        result || Callback::EvaluateFunction(callbacks, optimizer, function,
        coordinates, objective)... };

    (void)std::initializer_list<bool>{ result =
        result || Callback::GradientFunction(callbacks, optimizer, function,
        coordinates, gradient)... };
     return result;
  }

  /**
   * Invoke the BeginEpoch() callback if it exists.
   *
   * @param callback The callback to call.
   * @param optimizer The optimizer used to update the function.
   * @param function Function to optimize.
   * @param coordinates Starting point.
   * @param epoch The index of the current epoch.
   * @param objective Objective value of the current point.
   */
  template<typename CallbackType,
           typename OptimizerType,
           typename FunctionType,
           typename MatType>
  static typename std::enable_if<callbacks::traits::HasBeginEpochSignature<
      CallbackType, OptimizerType, FunctionType, MatType>::hasBool, bool>::type
  BeginEpochFunction(CallbackType& callback,
                     OptimizerType& optimizer,
                     FunctionType& function,
                     const MatType& coordinates,
                     const size_t epoch,
                     const double objective)
  {
    return const_cast<CallbackType&>(callback).BeginEpoch(
        optimizer, function, coordinates, epoch, objective);
  }

  template<typename CallbackType,
           typename OptimizerType,
           typename FunctionType,
           typename MatType>
  static typename std::enable_if<callbacks::traits::HasBeginEpochSignature<
      CallbackType, OptimizerType, FunctionType, MatType>::hasVoid, bool>::type
  BeginEpochFunction(CallbackType& callback,
                     OptimizerType& optimizer,
                     FunctionType& function,
                     const MatType& coordinates,
                     const size_t epoch,
                     const double objective)
  {
    const_cast<CallbackType&>(callback).BeginEpoch(
        optimizer, function, coordinates, epoch, objective);
    return false;
  }

  template<typename CallbackType,
           typename OptimizerType,
           typename FunctionType,
           typename MatType>
  static typename std::enable_if<callbacks::traits::HasBeginEpochSignature<
      CallbackType, OptimizerType, FunctionType, MatType>::hasNone, bool>::type
  BeginEpochFunction(CallbackType& /* callback  */,
                     OptimizerType& /* optimizer */,
                     FunctionType& /* function  */,
                     const MatType& /* coordinates  */,
                     const size_t /* epoch  */,
                     const double /* objective */)
  { return false; }

  /**
   * Iterate over all callbacks and invoke the BeginEpoch() callback if it
   * exists.
   *
   * @param optimizer The optimizer used to update the function.
   * @param function Function to optimize.
   * @param coordinates Starting point.
   * @param epoch The index of the current epoch.
   * @param objective Objective value of the current point.
   * @param callbacks The callbacks container.
   */
  template<typename OptimizerType,
           typename FunctionType,
           typename MatType,
           typename... CallbackTypes>
  static bool BeginEpoch(OptimizerType& optimizer,
                         FunctionType& function,
                         const MatType& coordinates,
                         const size_t epoch,
                         const double objective,
                         CallbackTypes&... callbacks)
  {
    // This will return immediately once a callback returns true.
    bool result = false;
    (void)(epoch);  // prevent spurious compiler warnings
    (void)(objective);
    (void)std::initializer_list<bool>{ result =
        result || Callback::BeginEpochFunction(callbacks, optimizer, function,
        coordinates, epoch, objective)... };
     return result;
  }

  /**
   * Invoke the EndEpoch() callback if it exists.
   *
   * @param callback The callback to call.
   * @param optimizer The optimizer used to update the function.
   * @param function Function to optimize.
   * @param coordinates Starting point.
   * @param epoch The index of the current epoch.
   * @param objective Objective value of the current point.
   */
  template<typename CallbackType,
           typename OptimizerType,
           typename FunctionType,
           typename MatType>
  static typename std::enable_if<callbacks::traits::HasEndEpochSignature<
      CallbackType, OptimizerType, FunctionType, MatType>::hasBool, bool>::type
  EndEpochFunction(CallbackType& callback,
                   OptimizerType& optimizer,
                   FunctionType& function,
                   const MatType& coordinates,
                   const size_t epoch,
                   const double objective)
  {
    return const_cast<CallbackType&>(callback).EndEpoch(
        optimizer, function, coordinates, epoch, objective);
  }

  template<typename CallbackType,
           typename OptimizerType,
           typename FunctionType,
           typename MatType>
  static typename std::enable_if<callbacks::traits::HasEndEpochSignature<
      CallbackType, OptimizerType, FunctionType, MatType>::hasVoid, bool>::type
  EndEpochFunction(CallbackType& callback,
                   OptimizerType& optimizer,
                   FunctionType& function,
                   const MatType& coordinates,
                   const size_t epoch,
                   const double objective)
  {
    const_cast<CallbackType&>(callback).EndEpoch(
        optimizer, function, coordinates, epoch, objective);
    return false;
  }

  template<typename CallbackType,
           typename OptimizerType,
           typename FunctionType,
           typename MatType>
  static typename std::enable_if<callbacks::traits::HasEndEpochSignature<
      CallbackType, OptimizerType, FunctionType, MatType>::hasNone, bool>::type
  EndEpochFunction(CallbackType& /* callback */,
                   OptimizerType& /* optimizer */,
                   FunctionType& /* function */,
                   const MatType& /* coordinates */,
                   const size_t /* epoch */,
                   const double /* objective */)
  { return false; }

  /**
   * Iterate over all callbacks and invoke the EndEpoch() callback if it exists.
   *
   * @param optimizer The optimizer used to update the function.
   * @param function Function to optimize.
   * @param coordinates Starting point.
   * @param epoch The index of the current epoch.
   * @param objective Objective value of the current point.
   * @param callbacks The callbacks container.
   */
  template<typename OptimizerType,
           typename FunctionType,
           typename MatType,
           typename... CallbackTypes>
  static bool EndEpoch(OptimizerType& optimizer,
                       FunctionType& function,
                       const MatType& coordinates,
                       const size_t epoch,
                       const double objective,
                       CallbackTypes&... callbacks)
  {
    // This will return immediately once a callback returns true.
    bool result = false;
    (void)(epoch);  // prevent spurious compiler warnings
    (void)(objective);
    (void)std::initializer_list<bool>{ result =
        result || Callback::EndEpochFunction(callbacks, optimizer, function,
        coordinates, epoch, objective)... };
     return result;
  }

  /**
   * Invoke the StepTaken() callback if it exists.
   *
   * @param callback The callback to call.
   * @param optimizer The optimizer used to update the function.
   * @param function Function to optimize.
   * @param coordinates Starting point.
   */
  template<typename CallbackType,
           typename OptimizerType,
           typename FunctionType,
           typename MatType>
  static typename std::enable_if<
      callbacks::traits::HasStepTakenSignature<
      CallbackType, OptimizerType, FunctionType, MatType>::hasBool,
      bool>::type
  StepTakenFunction(CallbackType& callback,
                    OptimizerType& optimizer,
                    FunctionType& function,
                    MatType& coordinates)
  {
    return const_cast<CallbackType&>(callback).StepTaken(optimizer,
        function, coordinates);
  }

  template<typename CallbackType,
           typename OptimizerType,
           typename FunctionType,
           typename MatType>
  static typename std::enable_if<
      callbacks::traits::HasStepTakenSignature<
      CallbackType, OptimizerType, FunctionType, MatType>::hasVoid,
      bool>::type
  StepTakenFunction(CallbackType& callback,
                    OptimizerType& optimizer,
                    FunctionType& function,
                    MatType& coordinates)
  {
    const_cast<CallbackType&>(callback).StepTaken(optimizer, function,
        coordinates);
    return false;
  }

  template<typename CallbackType,
           typename OptimizerType,
           typename FunctionType,
           typename MatType>
  static typename std::enable_if<
      callbacks::traits::HasStepTakenSignature<
      CallbackType, OptimizerType, FunctionType, MatType>::hasNone,
      bool>::type
  StepTakenFunction(CallbackType& /* callback */,
                    OptimizerType& /* optimizer */,
                    FunctionType& /* function */,
                    MatType& /* coordinates */)
  { return false; }

  /**
   * Iterate over the callbacks and invoke the StepTaken() callback if it
   * exists.
   *
   * @param optimizer The optimizer used to update the function.
   * @param function Function to optimize.
   * @param coordinates Starting point.
   * @param callbacks The callbacks container.
   */
  template<typename OptimizerType,
           typename FunctionType,
           typename MatType,
           typename... CallbackTypes>
  static bool StepTaken(OptimizerType& optimizer,
                        FunctionType& function,
                        MatType& coordinates,
                        CallbackTypes&... callbacks)
  {
    // This will return immediately once a callback returns true.
    bool result = false;
    (void)std::initializer_list<bool>{ result =
        result || Callback::StepTakenFunction(callbacks, optimizer,
            function, coordinates)... };
     return result;
  }

 /**
  * Invoke the GenerationalStepTaken() callback if it exists.
  * Specialization for MultiObjective case.
  *
  * @param callback The callback to call.
  * @param optimizer The optimizer used to update the function.
  * @param function Function to optimize.
  * @param coordinates Starting point.
  * @param objectives The set of calculated objectives so far.
  * @param frontIndices The indices of the members belonging to Pareto Front.
  */
  template<typename CallbackType,
           typename OptimizerType,
           typename FunctionType,
           typename MatType,
           typename ObjectivesVecType,
           typename IndicesType>
  static typename std::enable_if<
      callbacks::traits::HasGenerationalStepTakenSignature<
      CallbackType, OptimizerType, FunctionType, MatType, ObjectivesVecType,
      IndicesType>::hasBool, bool>::type
  GenerationalStepTakenFunction(CallbackType& callback,
                                OptimizerType& optimizer,
                                FunctionType& function,
                                MatType& coordinates,
                                ObjectivesVecType& objectives,
                                IndicesType& frontIndices)
  {
    return const_cast<CallbackType&>(callback).GenerationalStepTaken(
        optimizer, function, coordinates, objectives, frontIndices);
  }

  template<typename CallbackType,
           typename OptimizerType,
           typename FunctionType,
           typename MatType,
           typename ObjectivesVecType,
           typename IndicesType>
  static typename std::enable_if<
      callbacks::traits::HasGenerationalStepTakenSignature<
      CallbackType, OptimizerType, FunctionType, MatType, ObjectivesVecType,
      IndicesType>::hasVoid, bool>::type
  GenerationalStepTakenFunction(CallbackType& callback,
                                OptimizerType& optimizer,
                                FunctionType& function,
                                MatType& coordinates,
                                ObjectivesVecType& objectives,
                                IndicesType& frontIndices)
  {
    const_cast<CallbackType&>(callback).GenerationalStepTaken(
        optimizer, function, coordinates, objectives, frontIndices);
    return false;
  }

  template<typename CallbackType,
           typename OptimizerType,
           typename FunctionType,
           typename MatType,
           typename ObjectivesVecType,
           typename IndicesType>
  static typename std::enable_if<
      callbacks::traits::HasGenerationalStepTakenSignature<
      CallbackType, OptimizerType, FunctionType, MatType, ObjectivesVecType,
      IndicesType>::hasNone, bool>::type
  GenerationalStepTakenFunction(CallbackType& /* callback */,
                                OptimizerType& /* optimizer */,
                                FunctionType& /* function */,
                                MatType& /* coordinates */,
                                ObjectivesVecType& /* objectives */,
                                IndicesType& /* frontIndices */)
  { return false; }

  /**
   * Iterate over the callbacks and invoke the GenerationalStepTaken() callback if it
   * exists.
   *
   * Specialization for MultiObjective case.
   *
   * @param optimizer The optimizer used to update the function.
   * @param function Function to optimize.
   * @param coordinates Starting point.
   * @param objectives The set of calculated objectives so far.
   * @param frontIndices The indices of the members belonging to Pareto Front.
   * @param callbacks The callbacks container.
   */
  template<typename OptimizerType,
           typename FunctionType,
           typename ObjectivesVecType,
           typename IndicesType,
           typename MatType,
           typename ...CallbackTypes>
  static bool GenerationalStepTaken(OptimizerType& optimizer,
                                    FunctionType& functions,
                                    MatType& coordinates,
                                    ObjectivesVecType& objectives,
                                    IndicesType& frontIndices,
                                    CallbackTypes&... callbacks)
  {
    // This will return immediately once a callback returns true.
    bool result = false;
    (void)std::initializer_list<bool>{ result = result ||
        Callback::GenerationalStepTakenFunction(callbacks, optimizer, functions,
        coordinates, objectives, frontIndices)... };
    return result;
  }
};

} // namespace ens

#endif
/**
 * @file early_stop_at_min_loss.hpp
 * @author Marcus Edel
 * @author Omar Shrit
 *
 * Implementation of the early stop at minimum loss callback function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_CALLBACKS_EARLY_STOP_AT_MIN_LOSS_HPP
#define ENSMALLEN_CALLBACKS_EARLY_STOP_AT_MIN_LOSS_HPP

#include <functional>

namespace ens {

/**
 * Early stopping to terminate the optimization process early if the loss stops
 * decreasing.
 */
template<typename MatType = arma::mat>
class EarlyStopAtMinLossType
{
 public:
  /**
   * Set up the early stop at min loss class, which keeps track of the minimum
   * loss and stops the optimization process if the loss stops decreasing.
   *
   * @param patienceIn The number of epochs to wait after the minimum loss has
   *    been reached or no improvement has been made (Default: 10).
   */
  EarlyStopAtMinLossType(const size_t patienceIn = 10) :
      callbackUsed(false),
      patience(patienceIn),
      bestObjective(std::numeric_limits<double>::max()),
      steps(0)
  { /* Nothing to do here */ }

  /**
   * Set up the early stop at min loss class, which keeps track of the minimum
   * loss and stops the optimization process if the loss stops decreasing.
   *
   * @param func, callback to return immediate loss evaluated by the function
   * @param patienceIn The number of epochs to wait after the minimum loss has
   *    been reached or no improvement has been made (Default: 10).
   */
  EarlyStopAtMinLossType(
      std::function<double(const MatType&)> func,
      const size_t patienceIn = 10)
    : callbackUsed(true),
      patience(patienceIn),
      bestObjective(std::numeric_limits<double>::max()),
      steps(0),
      localFunc(func)
  {
    // Nothing to do here
  }

  /**
   * Callback function called at the end of a pass over the data.
   *
   * @param optimizer The optimizer used to update the function.
   * @param function Function to optimize.
   * @param coordinates Starting point.
   * @param epoch The index of the current epoch.
   * @param objective Objective value of the current point.
   */
  template<typename OptimizerType, typename FunctionType>
  bool EndEpoch(OptimizerType& /* optimizer */,
                FunctionType& /* function */,
                const MatType& coordinates,
                const size_t /* epoch */,
                double objective)
  {
    if (callbackUsed)
    {
      objective = localFunc(coordinates);
    }

    if (objective < bestObjective)
    {
      steps = 0;
      bestObjective = objective;
      return false;
    }

    steps++;
    if (steps >= patience)
    {
      Info << "Minimum loss reached; terminate optimization." << std::endl;
      return true;
    }

    return false;
  }

 private:
  //! False if the first constructor is called, true if the user passed a
  //! lambda.
  bool callbackUsed;

  //! The number of epochs to wait before terminating the optimization process.
  size_t patience;

  //! Locally-stored best objective.
  double bestObjective;

  //! Locally-stored number of steps since the loss improved.
  size_t steps;

  //! Function to call at the end of the epoch.
  std::function<double(const MatType&)> localFunc;
};

/*
 * Note that the using definition is temporary, this definition should
 * be removed when releasing ensmallen 3.0
 * The renaming of the class is only to avoid a major version bump
 * because if the template type added to this class
 */
using EarlyStopAtMinLoss = EarlyStopAtMinLossType<arma::mat>;

} // namespace ens

#endif
/**
 * @file grad_clip_by_norm.hpp
 * @author Marcus Edel
 *
 * Clip the gradients by multiplying the unit vector of the gradients with the
 * threshold.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_CALLBACKS_GRAD_CLIP_BY_NORM_HPP
#define ENSMALLEN_CALLBACKS_GRAD_CLIP_BY_NORM_HPP

namespace ens {

/**
 * Clip the gradients by multiplying the unit vector of the gradients with the
 * threshold.
 */
class GradClipByNorm
{
 public:
  /**
   * Set up the gradient clip by norm callback class with the maximum clipping
   * value.
   *
   * @param maxNorm The maximum clipping value.
   */
  GradClipByNorm(const double maxNorm) : maxNorm(maxNorm)
  { /* Nothing to do here. */ }

  /**
   * Callback function called at any call to Gradient().
   *
   * @param optimizer The optimizer used to update the function.
   * @param function Function to optimize.
   * @param coordinates Starting point.
   * @param gradient Matrix that holds the gradient.
   */
  template<typename OptimizerType, typename FunctionType, typename MatType>
  bool Gradient(OptimizerType& /* optimizer */,
                FunctionType& /* function */,
                const MatType& /* coordinates */,
                MatType& gradient)
  {
    const double gradientNorm = arma::norm(gradient);
    if (gradientNorm > maxNorm)
      gradient = maxNorm * gradient / gradientNorm;
    return false;
  }

 private:
  //! The maximum clipping value for gradient clipping.
  const double maxNorm;
};

} // namespace ens

#endif
/**
 * @file grad_clip_by_value.hpp
 * @author Marcus Edel
 *
 * Clips the gradient to a specified min and max.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_CALLBACKS_GRAD_CLIP_BY_VALUE_HPP
#define ENSMALLEN_CALLBACKS_GRAD_CLIP_BY_VALUE_HPP

namespace ens {

/**
 * Clip the gradient to a specified min and max.
 */
class GradClipByValue
{
 public:
  /**
   * Set up the gradient clip by value callback class with the min and max
   * value.
   *
   * @param min The minimum value to clip to.
   * @param max The maximum value to clip to.
   */
  GradClipByValue(const double min, const double max) : lower(min), upper(max)
  { /* Nothing to do here. */ }

  /**
   * Callback function called at any call to Gradient().
   *
   * @param optimizer The optimizer used to update the function.
   * @param function Function to optimize.
   * @param coordinates Starting point.
   * @param gradient Matrix that holds the gradient.
   */
  template<typename OptimizerType, typename FunctionType, typename MatType>
  bool Gradient(OptimizerType& /* optimizer */,
                FunctionType& /* function */,
                const MatType& /* coordinates */,
                MatType& gradient)
  {
    gradient = arma::clamp(gradient, lower, upper);
    return false;
  }

 private:
  //! The minimum value to clip to.
  const double lower;

  //! The maximum value to clip to.
  const double upper;
};

} // namespace ens

#endif
/**
 * @file print_loss.hpp
 * @author Marcus Edel
 *
 * Implementation of the print loss callback function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_CALLBACKS_PRINT_LOSS_HPP
#define ENSMALLEN_CALLBACKS_PRINT_LOSS_HPP

namespace ens {

/**
 * Print loss function, based on the EndEpoch callback function.
 */
class PrintLoss
{
 public:
  /**
   * Set up the print loss callback class with the width and output stream.
   *
   * @param ostream Ostream which receives output from this object.
   */
  PrintLoss(std::ostream& output = arma::get_cout_stream()) : output(output)
  { /* Nothing to do here. */ }

  /**
   * Callback function called at the end of a pass over the data.
   *
   * @param optimizer The optimizer used to update the function.
   * @param function Function to optimize.
   * @param coordinates Starting point.
   * @param epoch The index of the current epoch.
   * @param objective Objective value of the current point.
   */
  template<typename OptimizerType, typename FunctionType, typename MatType>
  bool EndEpoch(OptimizerType& /* optimizer */,
                FunctionType& /* function */,
                const MatType& /* coordinates */,
                const size_t /* epoch */,
                const double objective)
  {
    output << objective << std::endl;
    return false;
  }

 private:
  //! The output stream that all data is to be sent to; example: std::cout.
  std::ostream& output;
};

} // namespace ens

#endif
/**
 * @file progress_bar.hpp
 * @author Marcus Edel
 *
 * Implementation of a simple progress bar callback function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_CALLBACKS_PROGRESS_BAR_HPP
#define ENSMALLEN_CALLBACKS_PROGRESS_BAR_HPP

#include <ensmallen_bits/function.hpp>

namespace ens {

/**
 * A simple progress bar, based on the maximum number of optimizer iterations,
 * batch-size, number of functions and the StepTaken callback function.
 */
class ProgressBar
{
 public:
  /**
   * Set up the progress bar callback class with the given width and output
   * stream.
   *
   * @param widthIn Width of the bar.
   * @param ostream Ostream which receives output from this object.
   */
  ProgressBar(const size_t widthIn = 70,
              std::ostream& output = arma::get_cout_stream()) :
      width(100.0 / widthIn),
      output(output),
      objective(0),
      epochs(0),
      epochSize(0),
      step(1),
      steps(0),
      newEpoch(false),
      epoch(1)

  { /* Nothing to do here. */ }

  /**
   * Callback function called at the begin of the optimization process.
   *
   * @param optimizer The optimizer used to update the function.
   * @param function Function to optimize.
   * @param coordinates Starting point.
   */
  template<typename OptimizerType, typename FunctionType, typename MatType>
  void BeginOptimization(OptimizerType& optimizer,
                         FunctionType& function,
                         MatType& /* coordinates */)
  {
    static_assert(traits::HasBatchSizeSignature<
      OptimizerType>::value,
      "The OptimizerType does not have a correct definition of BatchSize(). "
      "Please check that the OptimizerType fully satisfies the requirements "
      "of the ProgressBar API; see the callbacks documentation for more "
      "details.");

    static_assert(traits::HasMaxIterationsSignature<
      OptimizerType>::value,
      "The OptimizerType does not have a correct definition of MaxIterations()."
      " Please check that the OptimizerType fully satisfies the requirements "
      "of the ProgressBar API; see the callbacks documentation for more "
      "details.");

    static_assert(traits::HasNumFunctionsSignature<
      FunctionType>::value,
      "The OptimizerType does not have a correct definition of NumFunctions(). "
      "Please check that the OptimizerType fully satisfies the requirements "
      "of the ProgressBar API; see the callbacks documentation for more "
      "details.");

    epochSize = function.NumFunctions() / optimizer.BatchSize();
    if (function.NumFunctions() % optimizer.BatchSize() > 0)
      epochSize++;

    epochs = optimizer.MaxIterations() / function.NumFunctions();
    if (optimizer.MaxIterations() % function.NumFunctions() > 0)
      epochs++;

    stepTimer.tic();
  }

  /**
   * Callback function called at the begin of a pass over the data.
   *
   * @param optimizer The optimizer used to update the function.
   * @param function Function to optimize.
   * @param coordinates Starting point.
   * @param epochIn The index of the current epoch.
   * @param objective Objective value of the current point.
   */
  template<typename OptimizerType, typename FunctionType, typename MatType>
  bool BeginEpoch(OptimizerType& /* optimizer */,
                  FunctionType& /* function */,
                  const MatType& /* coordinates */,
                  const size_t epochIn,
                  const double /* objective */)
  {
    // Start the timer.
    epochTimer.tic();

    // Reset epoch parameter.
    objective = 0;
    step = 1;

    epoch = epochIn;
    newEpoch = true;

    return false;
  }

  /**
   * Callback function called once a step is taken.
   *
   * @param optimizer The optimizer used to update the function.
   * @param function Function to optimize.
   * @param coordinates Starting point.
   * @param objective Objective value of the current point.
   */
  template<typename OptimizerType, typename FunctionType, typename MatType>
  bool StepTaken(OptimizerType& /* optimizer */,
                 FunctionType& /* function */,
                 const MatType& /* coordinates */)
  {
    if (newEpoch)
    {
      output << "Epoch " << epoch;
      if (epochs > 0)
      {
        output << "/" << epochs;
      }
      output << '\n';
      newEpoch = false;
    }

    const size_t progress = ((double) step / epochSize) * 100;
    output << step++ << "/" << epochSize << " [";
    for (size_t i = 0; i < 100; i += width)
    {
      if (i < progress)
      {
        output << "=";
      }
      else if (i == progress)
      {
        output << ">";
      }
      else
      {
        output << ".";
      }
    }

    output << "] " << progress << "% - ETA: " << (size_t) (stepTimer.toc() *
        (epochSize - step + 1)) % 60 << "s - loss: " <<
        objective / (double) step <<  "\r";
    output.flush();

    stepTimer.tic();

    return false;
  }

  /**
   * Callback function called at any call to Evaluate().
   *
   * @param optimizer The optimizer used to update the function.
   * @param function Function to optimize.
   * @param coordinates Starting point.
   * @param objectiveIn Objective value of the current point.
   */
  template<typename OptimizerType, typename FunctionType, typename MatType>
  bool Evaluate(OptimizerType& optimizer,
                FunctionType& /* function */,
                const MatType& /* coordinates */,
                const double objectiveIn)
  {
    objective += objectiveIn / optimizer.BatchSize();
    steps++;
    return false;
  }

  /**
   * Callback function called at the end of a pass over the data.
   *
   * @param optimizer The optimizer used to update the function.
   * @param function Function to optimize.
   * @param coordinates Starting point.
   * @param epoch The index of the current epoch.
   * @param objective Objective value of the current point.
   */
  template<typename OptimizerType, typename FunctionType, typename MatType>
  bool EndEpoch(OptimizerType& /* optimizer */,
                FunctionType& /* function */,
                const MatType& /* coordinates */,
                const size_t /* epoch */,
                const double objective)
  {
    const size_t progress = ((double) (step - 1) / epochSize) * 100;
    output << step - 1 << "/" << epochSize << " [";
    for (size_t i = 0; i < 100; i += width)
    {
      if (i < progress)
      {
        output << "=";
      }
      else if (i == progress)
      {
        output << ">";
      }
      else
      {
        output << ".";
      }
    }
    const double epochTimerElapsed = epochTimer.toc();
    const size_t stepTime = epochTimerElapsed / (double) epochSize * 1000;
    output << "] " << progress << "% - " << epochTimerElapsed
        << "s/epoch; " << stepTime << "ms/step; loss: " << objective  <<  "\n";
    output.flush();
    return false;
  }

 private:
  //! Length of a single step (1%).
  double width;

  //! The output stream that all data is to be sent to; example: std::cout.
  std::ostream& output;

  //! Objective over the current epoch.
  double objective;

  //! Total number of epochs
  size_t epochs;

  //! Number of steps per epoch.
  size_t epochSize;

  //! Current step number.
  size_t step;

  //! Number of steps taken.
  size_t steps;

  //! Indicates a new epoch.
  bool newEpoch;

  //! Locally-stored epoch.
  size_t epoch;

  //! Locally-stored step timer object.
  arma::wall_clock stepTimer;

  //! Locally-stored epoch timer object.
  arma::wall_clock epochTimer;
};

} // namespace ens

#endif
/**
 * @file query_front.hpp
 * @author Nanubala Gnana Sai
 *
 * Implementation of the query front callback function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_CALLBACKS_QUERY_FRONT_HPP
#define ENSMALLEN_CALLBACKS_QUERY_FRONT_HPP

namespace ens {

/**
 * Query the current Pareto Front after every GenerationalStepTaken callback function.
 */
class QueryFront
{
 public:
  /**
   * Set up the query front callback class with the specified inputs.
   *
   * @param queryRate The frequency at which the Pareto Front is queried.
   * @param paretoFrontArray A reference to a vector of cube to store the
   *     queried fronts.
   */
  QueryFront(const size_t queryRate,
             std::vector<arma::cube>& paretoFrontArray) :
      queryRate(queryRate),
      paretoFrontArray(paretoFrontArray),
      genCounter(0)
  { /* Nothing to do here */ }

  /**
   * Callback function called at the end of a single generational run.
   *
   * @param optimizer The optimizer used to update the function.
   * @param function Function to optimize.
   * @param coordinates Starting point.
   * @param objectives The set of calculated objectives so far.
   * @param frontIndices The indices of the members belonging to Pareto Front.
   */
  template<typename OptimizerType,
           typename FunctionType,
           typename MatType,
           typename ObjectivesVecType,
           typename IndicesType>
  bool GenerationalStepTaken(OptimizerType& opt,
                             FunctionType& /* function */,
                             const MatType& /* coordinates */,
                             const ObjectivesVecType& objectives,
                             const IndicesType& frontIndices)
  {
    arma::cube currentParetoFront{};

    if (genCounter % queryRate == 0)
    {
      currentParetoFront.resize(objectives[0].n_rows, objectives[0].n_cols,
          frontIndices[0].size());
      for (size_t solutionIdx = 0; solutionIdx < frontIndices[0].size();
          ++solutionIdx)
      {
        currentParetoFront.slice(solutionIdx) = arma::conv_to<arma::mat>::from(
            objectives[frontIndices[0][solutionIdx]]);
      }

      paretoFrontArray.emplace_back(std::move(currentParetoFront));
    }

    ++genCounter;
    return false;
  }


 private:
  //! The rate of query.
  size_t queryRate;
  //! A reference to the array of pareto fronts.
  std::vector<arma::cube>& paretoFrontArray;
  //! A counter for the current generation.
  size_t genCounter;
};

} // namespace ens

#endif
/**
 * @file report.hpp
 * @author Marcus Edel
 *
 * Implementation of a simple report callback function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_CALLBACKS_REPORT_HPP
#define ENSMALLEN_CALLBACKS_REPORT_HPP

#include <ensmallen_bits/function.hpp>
#include <iomanip>

namespace ens {

/**
 * A simple optimization report.
 */
class Report
{
 public:
  /**
   * Set up the report callback class with the given output stream.
   *
   * @param iterationsPercentageIn The number of iterations to report in
   *     percent, between [0, 1]).
   * @param outputIn Ostream which receives output from this object.
   * @param outputMatrixSizeIn The number of values to output for the function
   *     coordinates.
   */
  Report(const double iterationsPercentageIn = 0.1,
         std::ostream& outputIn = arma::get_cout_stream(),
         const size_t outputMatrixSizeIn = 4) :
      iterationsPercentage(iterationsPercentageIn),
      output(outputIn),
      outputMatrixSize(outputMatrixSizeIn),
      objective(0),
      gradientNorm(0),
      hasGradient(false),
      hasEndEpoch(false),
      gradientCalls(0),
      evaluateCalls(0),
      epochCalls(0)
  { /* Nothing to do here. */ }

  /**
   * Callback function called at the begin of the optimization process.
   *
   * @param optimizer The optimizer used to update the function.
   * @param function Function to optimize.
   * @param coordinates Starting point.
   */
  template<typename OptimizerType, typename FunctionType, typename MatType>
  void BeginOptimization(OptimizerType& /* optimizer */,
                         FunctionType& /* function */,
                         MatType& coordinates)
  {
    initialCoordinates = coordinates;
    optimizationTimer.tic();
  }

  /**
   * Callback function called at the begin of the optimization process.
   *
   * @param optimizer The optimizer used to update the function.
   * @param function Function to optimize.
   * @param coordinates Starting point.
   */
  template<typename OptimizerType, typename FunctionType, typename MatType>
  void EndOptimization(OptimizerType& optimizer,
                       FunctionType& function,
                       MatType& coordinates)
  {
    output << "Optimization Report" << std::endl;
    output << std::string(80, '-') << std::endl << std::endl;

    std::streamsize streamPrecision = output.precision(4);

    if (coordinates.n_rows > outputMatrixSize ||
        coordinates.n_cols > outputMatrixSize)
    {
      output << "Initial coordinates: " << std::endl;
      TruncatePrint(initialCoordinates, outputMatrixSize);
      output << std::endl << "Final coordinates: " << std::endl;
      TruncatePrint(coordinates, outputMatrixSize);
      output << std::endl;
    }
    else
    {
      output << "Initial Coordinates:" << std::endl << initialCoordinates.t();
      output << std::endl << "Final coordinates:" << std::endl
          << coordinates.t() << std::endl;
    }

    PrettyPrintElement("iter");
    PrettyPrintElement("loss");
    PrettyPrintElement("loss change");

    if (hasGradient)
      PrettyPrintElement("|gradient|");

    if (!stepsizes.empty())
      PrettyPrintElement("step size");

    PrettyPrintElement("total time");
    output << std::endl;

    size_t iterationStep = objectives.size() / (iterationsPercentage * 100);
    if (iterationStep <= 0)
      iterationStep = 1;

    for (size_t i = 0; i < objectives.size(); i += iterationStep)
    {
      PrettyPrintElement(i);
      PrettyPrintElement(objectives[i]);
      PrettyPrintElement(
          i > 0 ? objectives[i - iterationStep] - objectives[i] : 0);

      if (hasGradient)
        PrettyPrintElement(gradientsNorm[i]);

      if (!stepsizes.empty())
        PrettyPrintElement(stepsizes[i]);

      PrettyPrintElement(timings[i]);
      output << std::endl;
    }

    output << std::endl << std::string(80, '-') << std::endl << std::endl;
    output << "Version:" << std::endl;
    PrettyPrintElement("ensmallen:", 30);
    output << ens::version::as_string() << std::endl;
    PrettyPrintElement("armadillo:", 30);
    output << arma::arma_version::as_string() << std::endl << std::endl;

    output << "Function:" << std::endl;
    std::stringstream functionStream;

    PrintNumFunctions(function, functionStream);
    if (functionStream.rdbuf()->in_avail() > 0)
      output << functionStream.str();

    PrettyPrintElement("Coordinates rows:", 30);
    output << coordinates.n_rows << std::endl;
    PrettyPrintElement("Coordinates columns:", 30);
    output << coordinates.n_cols << std::endl;
    output << std::endl;

    // If we did not take any steps, at least fill what the initial objective
    // was.
    const bool tookStep = (objectives.size() > 0);
    if (objectives.size() == 0 && evaluateCalls > 0)
    {
      objectives.push_back(objective);
      timings.push_back(optimizationTimer.toc());
    }
    else if (evaluateCalls == 0)
    {
      // It's not entirely clear how to compute the objective (since the
      // function could implement many different ways of evaluating the
      // objective), so issue an error and return.
      output << "Objective never computed.  Did the optimization fail?"
          << std::endl;
      PrettyPrintElement("Time (in seconds):", 30);
      output << optimizationTimer.toc() << std::endl;
      return;
    }

    output << "Loss:" << std::endl;
    PrettyPrintElement("Initial", 30);
    output << objectives[0] << std::endl;
    PrettyPrintElement("Final", 30);
    output << objectives[objectives.size() - 1] << std::endl;
    PrettyPrintElement("Change", 30);
    output << objectives[0] - objectives[objectives.size() - 1] << std::endl;

    output << std::endl << "Optimizer:" << std::endl;
    std::stringstream optimizerStream;

    PrintMaxIterations(optimizer, optimizerStream);
    PrintBatchSize(optimizer, optimizerStream);
    if (functionStream.rdbuf()->in_avail() > 0)
      output << optimizerStream.str();

    PrettyPrintElement("Iterations:", 30);
    if (tookStep)
      output << objectives.size() << std::endl;
    else
      output << "0 (No steps taken! Did the optimization fail?)" << std::endl;

    if (epochCalls > 0)
    {
      PrettyPrintElement("Number of epochs:", 30);
      output << epochCalls << std::endl;
    }

    if (!stepsizes.empty())
    {
      PrettyPrintElement("Initial step size:", 30);
      output << stepsizes.front() << std::endl;

      PrettyPrintElement("Final step size:", 30);
      output << stepsizes.back() << std::endl;
    }

    if (hasGradient && gradientsNorm.size() > 0)
    {
      PrettyPrintElement("Coordinates max. norm:", 30);
      output << *std::max_element(std::begin(gradientsNorm),
          std::end(gradientsNorm)) << std::endl;
    }

    PrettyPrintElement("Evaluate calls:", 30);
    output << evaluateCalls << std::endl;

    if (hasGradient)
    {
      PrettyPrintElement("Gradient calls:", 30);
      output << gradientCalls << std::endl;
    }

    PrettyPrintElement("Time (in seconds):", 30);
    output << timings[timings.size() - 1] << std::endl;

    // Restore precision.
    output.precision(streamPrecision);
  }

  /**
   * Callback function called at the beginning of a pass over the data.
   *
   * @param optimizer The optimizer used to update the function.
   * @param function Function to optimize.
   * @param coordinates Starting point.
   * @param epoch The index of the current epoch.
   * @param objective Objective value of the current point.
   */
  template<typename OptimizerType, typename FunctionType, typename MatType>
  bool BeginEpoch(OptimizerType& /* optimizer */,
                  FunctionType& /* function */,
                  const MatType& /* coordinates */,
                  const size_t /* epoch */,
                  const double /* objective */)
  {
    epochCalls++;
    return false;
  }

  /**
   * Callback function called at the end of a pass over the data.
   *
   * @param optimizer The optimizer used to update the function.
   * @param function Function to optimize.
   * @param coordinates Starting point.
   * @param epoch The index of the current epoch.
   * @param objective Objective value of the current point.
   */
  template<typename OptimizerType, typename FunctionType, typename MatType>
  bool EndEpoch(OptimizerType& optimizer,
                FunctionType& /* function */,
                const MatType& /* coordinates */,
                const size_t /* epoch */,
                const double objective)
  {
    // In case StepTaken() has been called first we clear the existing data.
    if (!hasEndEpoch)
    {
      hasEndEpoch = true;

      objectives.clear();
      timings.clear();
      gradientsNorm.clear();
      stepsizes.clear();
    }

    objectives.push_back(objective);
    timings.push_back(optimizationTimer.toc());

    if (hasGradient)
      gradientsNorm.push_back(gradientNorm);

    SaveStepSize(optimizer);
    return false;
  }

  /**
   * Callback function called once a step is taken.
   *
   * @param optimizer The optimizer used to update the function.
   * @param function Function to optimize.
   * @param coordinates Starting point.
   * @param objective Objective value of the current point.
   */
  template<typename OptimizerType, typename FunctionType, typename MatType>
  bool StepTaken(OptimizerType& optimizer,
                 FunctionType& /* function */,
                 const MatType& /* coordinates */)
  {
    if (!hasEndEpoch)
    {
      objectives.push_back(objective);
      timings.push_back(optimizationTimer.toc());

      if (hasGradient)
        gradientsNorm.push_back(gradientNorm);

      SaveStepSize(optimizer);
    }
    return false;
  }

  /**
   * Callback function called at any call to Evaluate().
   *
   * @param optimizer The optimizer used to update the function.
   * @param function Function to optimize.
   * @param coordinates Starting point.
   * @param objectiveIn Objective value of the current point.
   */
  template<typename OptimizerType, typename FunctionType, typename MatType>
  bool Evaluate(OptimizerType& /* optimizer */,
                FunctionType& /* function */,
                const MatType& /* coordinates */,
                const double objectiveIn)
  {
    objective = objectiveIn;
    evaluateCalls++;
    return false;
  }

  /**
    * Callback function called at any call to EvaluateConstraint().
    *
    * @param optimizer The optimizer used to update the function.
    * @param function Function to optimize.
    * @param coordinates Starting point.
    * @param constraint The index of the constraint;
    * @param objectiveIn Objective value of the current point.
    */
  template<typename OptimizerType, typename FunctionType, typename MatType>
  bool EvaluateConstraint(OptimizerType& /* optimizer */,
                          FunctionType& /* function */,
                          const MatType& /* coordinates */,
                          const size_t /* constraint */,
                          const double objectiveIn)
  {
    objective += objectiveIn;
    evaluateCalls++;
    return false;
  }

  /**
   * Callback function called at any call to Gradient().
   *
   * @param optimizer The optimizer used to update the function.
   * @param function Function to optimize.
   * @param coordinates Starting point.
   * @param gradientIn Matrix that holds the gradient.
   */
  template<typename OptimizerType, typename FunctionType, typename MatType>
  bool Gradient(OptimizerType& /* optimizer */,
                FunctionType& /* function */,
                const MatType& /* coordinates */,
                const MatType& gradientIn)
  {
    hasGradient = true;
    gradientNorm = arma::norm(gradientIn);
    gradientCalls++;
    return false;
  }

  /**
   * Callback function called at any call to GradientConstraint().
   *
   * @param optimizer The optimizer used to update the function.
   * @param function Function to optimize.
   * @param coordinates Starting point.
   * @param constraint The index of the constraint;
   * @param gradient Matrix that holds the gradient;
   */
  template<typename OptimizerType, typename FunctionType, typename MatType>
  bool GradientConstraint(OptimizerType& optimizer,
                          FunctionType& function,
                          const MatType& coordinates,
                          const size_t /* constraint */,
                          const MatType& gradient)
  {
    Gradient(optimizer, function, coordinates, gradient);
    return false;
  }

 private:
  /**
   * Helper function to print the number of function to the specified output
   * stream.
   *
   * @param function The instantiated function that implements NumFunctions().
   * @param stream The output stream.
   */
  template<typename FunctionType>
  typename std::enable_if<
      traits::HasNumFunctionsSignature<FunctionType>::value, void>::type
  PrintNumFunctions(const FunctionType& function, std::stringstream& stream)
  {
    PrettyPrintElement(stream, "Number of functions:", 30);
    stream << function.NumFunctions() << std::endl;
  }

  template<typename FunctionType>
  typename std::enable_if<
      !traits::HasNumFunctionsSignature<FunctionType>::value, void>::type
  PrintNumFunctions(const FunctionType& /* function */,
                    std::stringstream& /* stream */) { }

  /**
   * Helper function to output the max-iterations to the specified output
   * stream.
   *
   * @param optimizer The instantiated optimizer that implements
   *     MaxIterations().
   * @param stream The output stream.
   */
  template<typename OptimizerType>
  typename std::enable_if<
      traits::HasMaxIterationsSignature<OptimizerType>::value, void>::type
  PrintMaxIterations(const OptimizerType& optimizer, std::stringstream& stream)
  {
    PrettyPrintElement(stream, "Maximum iterations:", 30);
    stream << optimizer.MaxIterations() << std::endl;

    PrettyPrintElement(stream, "Reached maximum iterations:", 30);
    stream << std::string(optimizer.MaxIterations() == objectives.size() ?
        "true" : "false") << std::endl;
  }

  template<typename OptimizerType>
  typename std::enable_if<
      !traits::HasMaxIterationsSignature<OptimizerType>::value, void>::type
  PrintMaxIterations(const OptimizerType& /* optimizer */,
                     std::stringstream& /* stream */) { }

  /**
   * Helper function to output the batch-size to the specified output stream.
   *
   * @param optimizer The instantiated optimizer that implements BatchSize().
   * @param stream The output stream.
   */
  template<typename OptimizerType>
  typename std::enable_if<traits::HasBatchSizeSignature<OptimizerType>::value,
      void>::type
  PrintBatchSize(const OptimizerType& optimizer, std::stringstream& stream)
  {
    PrettyPrintElement(stream, "Batch size:", 30);
    stream << optimizer.BatchSize() << std::endl;
  }

  template<typename OptimizerType>
  typename std::enable_if<!traits::HasBatchSizeSignature<OptimizerType>::value,
      void>::type
  PrintBatchSize(const OptimizerType& /* optimizer */,
                 std::stringstream& /* stream */) { }

  /**
   * Output formatted data.
   *
   * @param out Output stream.
   * @param data The data to print on the given stream.
   * @param width The width of the the formatted output data.
   */
  template<typename T>
  void PrettyPrintElement(std::ostream& out,
                          const T& data,
                          const size_t width = 14)
  {
    out << std::left << std::setw(width) << std::setfill(' ')
        << std::setprecision(3) << data;
  }

  /**
   * Output formatted data.
   *
   * @param data The data to print on the given stream.
   * @param width The width of the the formatted output data.
   */
  template<typename T>
  void PrettyPrintElement(const T& data, const size_t width = 14)
  {
    PrettyPrintElement(output, data, width);
  }

  /**
   * Outputs the given matrix in a truncated format. For example, the matrix:
   *
   * 1 2 3 4 5
   * 6 7 8 9 10
   * 11 12 13 14
   * 15 16 17 18
   *
   * will be truncated to:
   *
   * 1 2 ... 5
   * 6 7 ... 10
   * ...
   * 15 16 ... 18
   *
   * @param data The data to print on the given stream in a truncated format.
   * @param size The number of elements per column/row.
   */
  template<typename T>
  void TruncatePrint(const T& data, const size_t size)
  {
    // We can't directly output the result of submat or use .print, because
    // both introduce a new line at the end, so we iterate over the elements.
    for (size_t c = 0, n = 0; c < data.n_cols; ++c)
    {
      // Skip to the last column.
      if (c >= (size - 1))
      {
        output << "..." << std::endl;
        n = (data.n_cols - 2) * data.n_rows - 1;
      }

      for (size_t r = 0; r < data.n_rows; ++r)
      {
        // Check if need to skip to the last row.
        if (r < (size - 1))
        {
          output << std::fixed;

          // Add space for positive value, to align with negative values.
          if (data(n) >= 0)
            output << " ";

          output << data(n++) << " ";
        }
        else
        {
          n = (c + 1) * data.n_rows - 1;
          output << " ... " << data(n) << std::endl;
          break;
        }
      }

      if (c >= (size - 1))
        break;
    }
  }

  /**
   * Helper function to store the step-size.
   *
   * @param optimizer The instantiated optimzer that implements StepSize().
   */
  template<typename OptimizerType>
  typename std::enable_if<traits::HasStepSizeSignature<OptimizerType>::value,
      void>::type
  SaveStepSize(const OptimizerType& optimizer)
  {
    stepsizes.push_back(optimizer.StepSize());
  }

  template<typename OptimizerType>
  typename std::enable_if<!traits::HasStepSizeSignature<OptimizerType>::value,
      void>::type
  SaveStepSize(const OptimizerType& /* optimizer */) { }

  //! The number of iterations to print in percent.
  double iterationsPercentage;

  //! The output stream that all data is to be sent to; example: std::cout.
  std::ostream& output;

  //! The number of values to print for the function coordinates.
  size_t outputMatrixSize;
  //! The initial coordinates.
  arma::mat initialCoordinates;

  //! Gradient norm storage.
  std::vector<double> gradientsNorm;

  //! Objective storage.
  std::vector<double> objectives;

  //! Timing storage.
  std::vector<double> timings;

  //! Step-size storage.
  std::vector<double> stepsizes;

  //! Objective over the current epoch.
  double objective;

  //! Locally-stored gradient norm for a single step.
  double gradientNorm;

  //! Whether Gradient() was called.
  bool hasGradient;

  //! Whether EndEpoch() was called.
  bool hasEndEpoch;

  //! The number of Gradient() calls.
  size_t gradientCalls;

  //! The number of Evaluate() calls.
  size_t evaluateCalls;

  //! The number of BeginEpoch() calls.
  size_t epochCalls;

  //! Locally-stored optimization step timer object.
  arma::wall_clock optimizationTimer;
};

} // namespace ens

#endif
/**
 * @file store_best_coordinates.hpp
 * @author Marcus Edel
 *
 * Implementation of the store best coordinates callback function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_CALLBACKS_STORE_BEST_COORDINATES_HPP
#define ENSMALLEN_CALLBACKS_STORE_BEST_COORDINATES_HPP

namespace ens {

/**
 * Store best coordinates function, based on the Evaluate callback function.
 *
 * @tparam MatType Type of the model coordinates (arma::colvec, arma::mat,
 *     arma::sp_mat or arma::cube).
 */
template<typename ModelMatType = arma::mat>
class StoreBestCoordinates
{
 public:
  /**
   * Set up the store best model class, which keeps the best-performing
   * coordinates and objective.
   */
  StoreBestCoordinates() : bestObjective(std::numeric_limits<double>::max())
  { /* Nothing to do here. */ }

  /**
   * Callback function called after any call to Evaluate().
   *
   * @param optimizer The optimizer used to update the function.
   * @param function Function to optimize.
   * @param coordinates Starting point.
   * @param objective Objective value of the current point.
   */
  template<typename OptimizerType, typename FunctionType, typename MatType>
  bool Evaluate(OptimizerType& /* optimizer */,
                FunctionType& /* function */,
                const MatType& coordinates,
                const double objective)
  {
    if (objective < bestObjective)
    {
      bestObjective = objective;
      bestCoordinates = coordinates;
    }
    return false;
  }

  //! Get the best coordinates.
  ModelMatType const& BestCoordinates() const { return bestCoordinates; }
  //! Modify the best coordinates.
  ModelMatType& BestCoordinates() { return bestCoordinates; }

  //! Get the best objective.
  double const& BestObjective() const { return bestObjective; }
  //! Modify the best objective.
  double& BestObjective() { return bestObjective; }

 private:
  //! Locally-stored best objective.
  double bestObjective;

  //! Locally-stored best model coordinates.
  ModelMatType bestCoordinates;
};

} // namespace ens

#endif
/**
 * @file timer_stop.hpp
 * @author Marcus Edel
 *
 * Implementation of the timer stop callback function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_CALLBACKS_TIMER_STOP_HPP
#define ENSMALLEN_CALLBACKS_TIMER_STOP_HPP

namespace ens {

/**
 * Timer stop function, is based on the BeginOptimization callback function to
 * start the timer and the EndEpoch callback function to update the timer.
 */
class TimerStop
{
 public:
  /**
   * Set up the print loss callback class with the width and output stream.
   *
   * @param durationIn The duration of the timer in seconds.
   */
  TimerStop(const double durationIn) : duration(durationIn)
  { /* Nothing to do here. */ }

  /**
   * Callback function called at the start of the optimization process.
   *
   * @param optimizer The optimizer used to update the function.
   * @param function Function to optimize.
   * @param coordinates Starting point.
   */
  template<typename OptimizerType, typename FunctionType, typename MatType>
  void BeginOptimization(OptimizerType& /* optimizer */,
                         FunctionType& /* function */,
                         MatType& /* coordinates */)
  {
    // Start the timer.
    timer.tic();
  }

  /**
   * Callback function called at the end of a pass over the data.
   *
   * @param optimizer The optimizer used to update the function.
   * @param function Function to optimize.
   * @param coordinates Starting point.
   * @param epoch The index of the current epoch.
   * @param objective Objective value of the current point.
   */
  template<typename OptimizerType, typename FunctionType, typename MatType>
  bool EndEpoch(OptimizerType& /* optimizer */,
                FunctionType& /* function */,
                const MatType& /* coordinates */,
                const size_t /* epoch */,
                const double /* objective */)
  {
    if (timer.toc() > duration)
    {
      Info << "Timer timeout reached; terminate optimization." << std::endl;
      return true;
    }

    return false;
  }

 private:
  //! The duration in seconds.
  double duration;

  //! Locally-stored timer object.
  arma::wall_clock timer;
};

} // namespace ens

#endif
/**
 * @file traits.hpp
 * @author Marcus Edel
 *
 * This file provides metaprogramming utilities for detecting certain members of
 * CallbackType classes.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_CALLBACKS_TRAITS_HPP
#define ENSMALLEN_CALLBACKS_TRAITS_HPP

#include <ensmallen_bits/function/sfinae_utility.hpp>

namespace ens {
namespace callbacks {
namespace traits {

//! Detect an Evaluate() method.
ENS_HAS_EXACT_METHOD_FORM(Evaluate, HasEvaluate)
//! Detect an EvaluateConstraint() method.
ENS_HAS_EXACT_METHOD_FORM(EvaluateConstraint, HasEvaluateConstraint)
//! Detect an Gradient() method.
ENS_HAS_EXACT_METHOD_FORM(Gradient, HasGradient)
//! Detect an GradientConstraint() method.
ENS_HAS_EXACT_METHOD_FORM(GradientConstraint, HasGradientConstraint)
//! Detect an BeginOptimization() method.
ENS_HAS_EXACT_METHOD_FORM(BeginOptimization, HasBeginOptimization)
//! Detect an EndOptimization() method.
ENS_HAS_EXACT_METHOD_FORM(EndOptimization, HasEndOptimization)
//! Detect an BeginEpoch() method.
ENS_HAS_EXACT_METHOD_FORM(BeginEpoch, HasBeginEpoch)
//! Detect an EndEpoch() method.
ENS_HAS_EXACT_METHOD_FORM(EndEpoch, HasEndEpoch)
//! Detect an StepTaken() method.
ENS_HAS_EXACT_METHOD_FORM(StepTaken, HasStepTaken)
//! Detect an GenerationalStepTaken() method.
ENS_HAS_EXACT_METHOD_FORM(GenerationalStepTaken, HasGenerationalStepTaken)

template<typename OptimizerType,
         typename FunctionType,
         typename MatType,
         typename GradType = MatType>
struct TypedForms
{
  //! This is the form of a bool Evaluate() callback method.
  template<typename CallbackType>
  using EvaluateBoolForm =
      bool(CallbackType::*)(OptimizerType&,
                            FunctionType&,
                            const MatType&,
                            const double);

  //! This is the form of a void Evaluate() callback method.
  template<typename CallbackType>
  using EvaluateVoidForm =
      void(CallbackType::*)(OptimizerType&,
                            FunctionType&,
                            const MatType&,
                            const double);

  //! This is the form of a bool EvaluateConstraint() callback method.
  template<typename CallbackType>
  using EvaluateConstraintBoolForm =
      bool(CallbackType::*)(OptimizerType&,
                            FunctionType&,
                            const MatType&,
                            const size_t,
                            const double);

  //! This is the form of a void EvaluateConstraint() callback method.
  template<typename CallbackType>
  using EvaluateConstraintVoidForm =
      void(CallbackType::*)(OptimizerType&,
                            FunctionType&,
                            const MatType&,
                            const size_t,
                            const double);

  //! This is the form of a bool Gradient() callback method.
  template<typename CallbackType>
  using GradientBoolForm =
      bool(CallbackType::*)(OptimizerType&,
                            FunctionType&,
                            const MatType&,
                            const MatType&);

  //! This is the form of a bool Gradient() callback method where the gradient
  //! is modifiable.
  template<typename CallbackType>
  using GradientBoolModifiableForm =
      bool(CallbackType::*)(OptimizerType&,
                            FunctionType&,
                            const MatType&,
                            MatType&);

  //! This is the form of a void Gradient() callback method.
  template<typename CallbackType>
  using GradientVoidForm =
      void(CallbackType::*)(OptimizerType&,
                            FunctionType&,
                            const MatType&,
                            const MatType&);

  //! This is the form of a void Gradient() callback method where the gradient
  //! is modifiable.
  template<typename CallbackType>
  using GradientVoidModifiableForm =
      void(CallbackType::*)(OptimizerType&,
                            FunctionType&,
                            const MatType&,
                            MatType&);

  //! This is the form of a bool GradientConstraint() callback method.
  template<typename CallbackType>
  using GradientConstraintBoolForm =
      bool(CallbackType::*)(OptimizerType&,
                            FunctionType&,
                            const MatType&,
                            const size_t,
                            const MatType&);

  //! This is the form of a bool GradientConstraint() callback method where the
  //! gradient is modifiable.
  template<typename CallbackType>
  using GradientConstraintBoolModifiableForm =
      bool(CallbackType::*)(OptimizerType&,
                            FunctionType&,
                            const MatType&,
                            const size_t,
                            MatType&);

  //! This is the form of a void GradientConstraint() callback method.
  template<typename CallbackType>
  using GradientConstraintVoidForm =
      void(CallbackType::*)(OptimizerType&,
                            FunctionType&,
                            const MatType&,
                            const size_t,
                            const MatType&);

  //! This is the form of a void GradientConstraint() callback method where the
  //! gradient is modifiable.
  template<typename CallbackType>
  using GradientConstraintVoidModifiableForm =
      void(CallbackType::*)(OptimizerType&,
                            FunctionType&,
                            const MatType&,
                            const size_t,
                            MatType&);

  //! This is the form of a bool BeginOptimization() callback method.
  template<typename CallbackType>
  using BeginOptimizationBoolForm =
      bool(CallbackType::*)(OptimizerType&,
                            FunctionType&,
                            MatType&);

  //! This is the form of a void BeginOptimization() callback method.
  template<typename CallbackType>
  using BeginOptimizationVoidForm =
      void(CallbackType::*)(OptimizerType&,
                            FunctionType&,
                            MatType&);

  //! This is the form of a bool EndOptimization() callback method.
  template<typename CallbackType>
  using EndOptimizationBoolForm =
      bool(CallbackType::*)(OptimizerType&,
                            FunctionType&,
                            MatType&);

  //! This is the form of a void EndOptimization() callback method.
  template<typename CallbackType>
  using EndOptimizationVoidForm =
      void(CallbackType::*)(OptimizerType&,
                            FunctionType&,
                            MatType&);

  //! This is the form of a bool BeginEpoch() callback method.
  template<typename CallbackType>
  using BeginEpochBoolForm =
      bool(CallbackType::*)(OptimizerType&,
                            FunctionType&,
                            const MatType&,
                            const size_t,
                            const double);

  //! This is the form of a void BeginEpoch() callback method.
  template<typename CallbackType>
  using BeginEpochVoidForm =
      void(CallbackType::*)(OptimizerType&,
                            FunctionType&,
                            const MatType&,
                            const size_t,
                            const double);

  //! This is the form of a bool EndEpoch() callback method.
  template<typename CallbackType>
  using EndEpochBoolForm =
      bool(CallbackType::*)(OptimizerType&,
                            FunctionType&,
                            const MatType&,
                            const size_t,
                            const double);

  //! This is the form of a void EndEpoch() callback method.
  template<typename CallbackType>
  using EndEpochVoidForm =
      void(CallbackType::*)(OptimizerType&,
                            FunctionType&,
                            const MatType&,
                            const size_t,
                            const double);

  //! This is the form of a bool StepTaken() callback method.
  template<typename CallbackType>
  using StepTakenBoolForm =
      bool(CallbackType::*)(OptimizerType&,
                            FunctionType&,
                            const MatType&);

  //! This is the form of a void StepTaken() callback method.
  template<typename CallbackType>
  using StepTakenVoidForm =
      void(CallbackType::*)(OptimizerType&,
                            FunctionType&,
                            const MatType&);
};

//! Utility struct, check if either void BeginOptimization() or
//! bool BeginOptimization() exists.
template<typename CallbackType,
         typename OptimizerType,
         typename FunctionType,
         typename MatType>
struct HasBeginOptimizationSignature
{
  constexpr static bool value =
      HasBeginOptimization<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType>::template BeginOptimizationBoolForm>::value ||
      HasBeginOptimization<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType>::template BeginOptimizationVoidForm>::value;
};

//! Utility struct, check if either void Evaluate() or bool Evaluate()
//! exists.
template<typename CallbackType,
         typename OptimizerType,
         typename FunctionType,
         typename MatType>
struct HasEvaluateSignature
{
  constexpr static bool hasBool =
      HasEvaluate<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType>::template EvaluateBoolForm>::value &&
      !HasEvaluate<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType>::template EvaluateVoidForm>::value;

  constexpr static bool hasVoid =
      !HasEvaluate<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType>::template EvaluateBoolForm>::value &&
      HasEvaluate<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType>::template EvaluateVoidForm>::value;

  constexpr static bool hasNone =
      !HasEvaluate<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType>::template EvaluateBoolForm>::value &&
      !HasEvaluate<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType>::template EvaluateVoidForm>::value;
};

//! Utility struct, check if either void EvaluateConstraint() or
//! bool EvaluateConstraint() exists.
template<typename CallbackType,
         typename OptimizerType,
         typename FunctionType,
         typename MatType>
struct HasEvaluateConstraintSignature
{
  constexpr static bool hasBool =
      HasEvaluateConstraint<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType>::template EvaluateConstraintBoolForm>::value &&
      !HasEvaluateConstraint<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType>::template EvaluateConstraintVoidForm>::value;

  constexpr static bool hasVoid =
      !HasEvaluateConstraint<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType>::template EvaluateConstraintBoolForm>::value &&
      HasEvaluateConstraint<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType>::template EvaluateConstraintVoidForm>::value;

  constexpr static bool hasNone =
      !HasEvaluateConstraint<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType>::template EvaluateConstraintBoolForm>::value &&
      !HasEvaluateConstraint<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType>::template EvaluateConstraintVoidForm>::value;
};

//! Utility struct, check if either void Gradient() or bool Gradient()
//! exists.
template<typename CallbackType,
         typename OptimizerType,
         typename FunctionType,
         typename MatType,
         typename Gradient>
struct HasGradientSignature
{
  constexpr static bool hasBool =
      (HasGradient<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType, Gradient>::template GradientBoolForm>::value ||
      HasGradient<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType, Gradient>::template
          GradientBoolModifiableForm>::value) &&
      (!HasGradient<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType, Gradient>::template GradientVoidForm>::value ||
      !HasGradient<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType, Gradient>::template
          GradientVoidModifiableForm>::value);

  constexpr static bool hasVoid =
      (!HasGradient<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType, Gradient>::template GradientBoolForm>::value ||
      !HasGradient<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType, Gradient>::template
          GradientBoolModifiableForm>::value) &&
      (HasGradient<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType, Gradient>::template GradientVoidForm>::value ||
      HasGradient<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType, Gradient>::template
          GradientVoidModifiableForm>::value);

  constexpr static bool hasNone =
      !HasGradient<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType, Gradient>::template GradientBoolForm>::value &&
      !HasGradient<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType, Gradient>::template
          GradientBoolModifiableForm>::value &&
      !HasGradient<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType, Gradient>::template GradientVoidForm>::value &&
      !HasGradient<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType, Gradient>::template
          GradientVoidModifiableForm>::value;
};

//! Utility struct, check if either void GradientConstraint() or
//! bool GradientConstraint() exists.
template<typename CallbackType,
         typename OptimizerType,
         typename FunctionType,
         typename MatType,
         typename Gradient>
struct HasGradientConstraintSignature
{
  constexpr static bool hasBool =
      HasGradientConstraint<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType, Gradient>::template
          GradientConstraintBoolForm>::value &&
      !HasGradientConstraint<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType, Gradient>::template
          GradientConstraintVoidForm>::value;

  constexpr static bool hasVoid =
      !HasGradientConstraint<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType, Gradient>::template
          GradientConstraintBoolForm>::value &&
      HasGradientConstraint<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType, Gradient>::template
          GradientConstraintVoidForm>::value;

  constexpr static bool hasNone =
      !HasGradientConstraint<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType, Gradient>::template
          GradientConstraintBoolForm>::value &&
      !HasGradientConstraint<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType, Gradient>::template
          GradientConstraintVoidForm>::value;
};

//! Utility struct, check if either void EndOptimization() or
//! bool EndOptimization() exists.
template<typename CallbackType,
         typename OptimizerType,
         typename FunctionType,
         typename MatType>
struct HasEndOptimizationSignature
{
  constexpr static bool value =
      HasEndOptimization<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType>::template EndOptimizationBoolForm>::value ||
      HasEndOptimization<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType>::template EndOptimizationVoidForm>::value;
};

//! Utility struct, check if either void BeginEpoch() or bool BeginEpoch()
//! exists.
template<typename CallbackType,
         typename OptimizerType,
         typename FunctionType,
         typename MatType>
struct HasBeginEpochSignature
{
  constexpr static bool hasBool =
      HasBeginEpoch<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType>::template BeginEpochBoolForm>::value &&
      !HasBeginEpoch<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType>::template BeginEpochVoidForm>::value;

  constexpr static bool hasVoid =
      !HasBeginEpoch<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType>::template BeginEpochBoolForm>::value &&
      HasBeginEpoch<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType>::template BeginEpochVoidForm>::value;

  constexpr static bool hasNone =
      !HasBeginEpoch<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType>::template BeginEpochBoolForm>::value &&
      !HasBeginEpoch<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType>::template BeginEpochVoidForm>::value;
};

//! Utility struct, check if either void EndEpoch() or bool EndEpoch()
//! exists.
template<typename CallbackType,
         typename OptimizerType,
         typename FunctionType,
         typename MatType>
struct HasEndEpochSignature
{
  constexpr static bool hasBool =
      HasEndEpoch<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType>::template EndEpochBoolForm>::value &&
      !HasEndEpoch<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType>::template EndEpochVoidForm>::value;

  constexpr static bool hasVoid =
      !HasEndEpoch<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType>::template EndEpochBoolForm>::value &&
      HasEndEpoch<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType>::template EndEpochVoidForm>::value;

  constexpr static bool hasNone =
      !HasEndEpoch<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType>::template EndEpochBoolForm>::value &&
      !HasEndEpoch<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType>::template EndEpochVoidForm>::value;
};

//! Utility struct, check if either void StepTaken() or bool StepTaken() exists.
template<typename CallbackType,
         typename OptimizerType,
         typename FunctionType,
         typename MatType>
struct HasStepTakenSignature
{
  constexpr static bool hasBool =
      HasStepTaken<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType>::template StepTakenBoolForm>::value &&
      !HasStepTaken<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType>::template StepTakenVoidForm>::value;

  constexpr static bool hasVoid =
      !HasStepTaken<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType>::template StepTakenBoolForm>::value &&
      HasStepTaken<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType>::template StepTakenVoidForm>::value;

  constexpr static bool hasNone =
      !HasStepTaken<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType>::template StepTakenBoolForm>::value &&
      !HasStepTaken<CallbackType, TypedForms<OptimizerType,
          FunctionType, MatType>::template StepTakenVoidForm>::value;
};

//! A utility struct for Typed Forms required in
//! callbacks for MultiObjective Optimizers.
template<typename OptimizerType,
         typename FunctionType,
         typename MatType,
         typename ObjectivesVecType,
         typename IndicesType,
         typename GradType = MatType>
struct MOOTypedForms
{
  //! This is the form of a bool GenerationalStepTaken() for MOO callback method.
  template<typename CallbackType>
  using GenerationalStepTakenBoolForm =
      bool(CallbackType::*)(OptimizerType&,
                            FunctionType&,
                            const MatType&,
                            const ObjectivesVecType&,
                            const IndicesType&);

  //! This is the form of a void StepTaken() for MOO callback method.
  template<typename CallbackType>
  using GenerationalStepTakenVoidForm =
      void(CallbackType::*)(OptimizerType&,
                            FunctionType&,
                            const MatType&,
                            const ObjectivesVecType&,
                            const IndicesType&);
};

//! Utility struct, check if either void StepTaken() or bool StepTaken() exists.
//! Specialization for Multiobjective case.
template<typename CallbackType,
         typename OptimizerType,
         typename FunctionType,
         typename ObjectivesVecType,
         typename IndicesType,
         typename MatType>
 struct HasGenerationalStepTakenSignature
{
  constexpr static bool hasBool =
    HasGenerationalStepTaken<CallbackType, MOOTypedForms<OptimizerType,
        FunctionType, MatType, ObjectivesVecType, IndicesType>::
        template GenerationalStepTakenBoolForm>::value &&
    !HasGenerationalStepTaken<CallbackType, MOOTypedForms<OptimizerType,
        FunctionType, MatType, ObjectivesVecType, IndicesType>::
        template GenerationalStepTakenVoidForm>::value;

  constexpr static bool hasVoid =
    !HasGenerationalStepTaken<CallbackType, MOOTypedForms<OptimizerType,
        FunctionType, MatType, ObjectivesVecType, IndicesType>::
        template GenerationalStepTakenBoolForm>::value &&
    HasGenerationalStepTaken<CallbackType, MOOTypedForms<OptimizerType,
        FunctionType, MatType, ObjectivesVecType, IndicesType>::
        template GenerationalStepTakenVoidForm>::value;

  constexpr static bool hasNone =
    !HasGenerationalStepTaken<CallbackType, MOOTypedForms<OptimizerType,
        FunctionType, MatType, ObjectivesVecType, IndicesType>::
        template GenerationalStepTakenBoolForm>::value &&
    !HasGenerationalStepTaken<CallbackType, MOOTypedForms<OptimizerType,
        FunctionType, MatType, ObjectivesVecType, IndicesType>::
        template GenerationalStepTakenVoidForm>::value;
};
} // namespace traits
} // namespace callbacks
} // namespace ens

#endif
/**
 * @file cd.hpp
 * @author Shikhar Bhardwaj
 *
 * Coordinate Descent (CD).
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_CD_CD_HPP
#define ENSMALLEN_CD_CD_HPP

#include "descent_policies/cyclic_descent.hpp"
#include "descent_policies/random_descent.hpp"
#include "descent_policies/greedy_descent.hpp"

namespace ens {

/**
 * Stochastic Coordinate descent is a technique for minimizing a function by
 * doing a line search along a single direction at the current point in the
 * iteration. The direction (or "coordinate") can be chosen cyclically, randomly
 * or in a greedy fashion(depending on the DescentPolicy).
 *
 * This optimizer is useful for problems with a smooth multivariate function
 * where computing the entire gradient for an update is infeasable. CD method
 * typically significantly outperform GD, especially on sparse problems with a
 * very large number variables/coordinates.
 *
 * For more information, see the following.
 * @code
 * @inproceedings{Shalev-Shwartz2009,
 *   author    = {Shalev-Shwartz, Shai and Tewari, Ambuj},
 *   title     = {Stochastic Methods for L1 Regularized Loss Minimization},
 *   booktitle = {Proceedings of the 26th Annual International Conference on
 *                Machine Learning},
 *   series    = {ICML '09},
 *   year      = {2009},
 *   isbn = {978-1-60558-516-1}
 * }
 * @endcode
 *
 * CD can optimize partially differentiable functions.  For more details, see
 * the documentation on function types included with this distribution or on the
 * ensmallen website.
 *
 * @tparam DescentPolicy Descent policy to decide the order in which the
 *     coordinate for descent is selected.
 */
template <typename DescentPolicyType = RandomDescent>
class CD
{
 public:
  /**
   * Construct the CD optimizer with the given function and parameters. The
   * default value here are not necessarily good for every problem, so it is
   * suggested that the values used are tailored for the task at hand. The
   * maximum number of iterations refers to the maximum number of "descents"
   * the algorithm does (in one iteration, the algorithm updates the
   * decision variable numFeatures times).
   *
   * @param stepSize Step size for each iteration.
   * @param maxIterations Maximum number of iterations allowed (0 means to
   *    limit).
   * @param tolerance Maximum absolute tolerance to terminate the algorithm.
   * @param updateInterval The interval at which the objective is to be
   *    reported and checked for convergence.
   * @param descentPolicy The policy to use for picking up the coordinate to
   *    descend on.
   */
  CD(const double stepSize = 0.01,
     const size_t maxIterations = 100000,
     const double tolerance = 1e-5,
     const size_t updateInterval = 1e3,
     const DescentPolicyType descentPolicy = DescentPolicyType());

  /**
   * Optimize the given function using stochastic coordinate descent. The
   * given starting point will be modified to store the finishing point of
   * the optimization, and the final objective value is returned.
   *
   * @tparam ResolvableFunctionType Type of the function to be optimized.
   * @tparam MatType Type of matrix to optimize with.
   * @tparam GradType Type of matrix to use to represent function gradients.
   * @tparam CallbackTypes Types of callback functions.
   * @param function Function to optimize.
   * @param iterate Starting point (will be modified).
   * @param callbacks Callback functions.
   * @return Objective value at the final point.
   */
  template<typename ResolvableFunctionType,
           typename MatType,
           typename GradType,
           typename... CallbackTypes>
  typename std::enable_if<IsArmaType<GradType>::value,
      typename MatType::elem_type>::type
  Optimize(ResolvableFunctionType& function,
           MatType& iterate,
           CallbackTypes&&... callbacks);

  //! Forward arma::SpMat<typename MatType::elem_type> as GradType.
  template<typename SeparableFunctionType,
           typename MatType,
           typename... CallbackTypes>
  typename MatType::elem_type Optimize(SeparableFunctionType& function,
                                       MatType& iterate,
                                       CallbackTypes&&... callbacks)
  {
    return Optimize<SeparableFunctionType, MatType,
        arma::SpMat<typename MatType::elem_type>, CallbackTypes...>(
        function, iterate, std::forward<CallbackTypes>(callbacks)...);
  }

  //! Get the step size.
  double StepSize() const { return stepSize; }
  //! Modify the step size.
  double& StepSize() { return stepSize; }

  //! Get the maximum number of iterations (0 indicates no limit).
  size_t MaxIterations() const { return maxIterations; }
  //! Modify the maximum number of iterations (0 indicates no limit).
  size_t& MaxIterations() { return maxIterations; }

  //! Get the tolerance for termination.
  double Tolerance() const { return tolerance; }
  //! Modify the tolerance for termination.
  double& Tolerance() { return tolerance; }

  //! Get the update interval for reporting objective.
  size_t UpdateInterval() const { return updateInterval; }
  //! Modify the update interval for reporting objective.
  size_t& UpdateInterval() { return updateInterval; }

  //! Get the descent policy.
  DescentPolicyType DescentPolicy() const { return descentPolicy; }
  //! Modify the descent policy.
  DescentPolicyType& DescentPolicy() { return descentPolicy; }

 private:
  //! The step size for each example.
  double stepSize;

  //! The maximum number of allowed iterations.
  size_t maxIterations;

  //! The tolerance for termination.
  double tolerance;

  //! The update interval for reporting objective and testing for convergence.
  size_t updateInterval;

  //! The descent policy used to pick the coordinates for the update.
  DescentPolicyType descentPolicy;
};

} // namespace ens

// Include implementation.
#include "cd_impl.hpp"

namespace ens {

/**
 * Backwards-compatibility alias; this can be removed after ensmallen 3.10.0.
 * The history here is that CD was originally named SCD, but that is an
 * inaccurate name because this is not a stochastic technique; thus, it was
 * renamed SCD.
 */
template<typename DescentPolicyType = RandomDescent>
using SCD = CD<DescentPolicyType>;

// Convenience typedefs.
using RandomCD = CD<RandomDescent>;
using GreedyCD = CD<GreedyDescent>;
using CyclicCD = CD<CyclicDescent>;

} // namespace ens

#endif
/**
 * @file cd_impl.hpp
 * @author Shikhar Bhardwaj
 *
 * Implementation of coordinate descent.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_CD_CD_IMPL_HPP
#define ENSMALLEN_CD_CD_IMPL_HPP

// In case it hasn't been included yet.
#include "cd.hpp"

#include <ensmallen_bits/function.hpp>

namespace ens {

template <typename DescentPolicyType>
CD<DescentPolicyType>::CD(
    const double stepSize,
    const size_t maxIterations,
    const double tolerance,
    const size_t updateInterval,
    const DescentPolicyType descentPolicy) :
    stepSize(stepSize),
    maxIterations(maxIterations),
    tolerance(tolerance),
    updateInterval(updateInterval),
    descentPolicy(descentPolicy)
{ /* Nothing to do */ }

//! Optimize the function (minimize).
template <typename DescentPolicyType>
template <typename ResolvableFunctionType,
          typename MatType,
          typename GradType,
          typename... CallbackTypes>
typename std::enable_if<IsArmaType<GradType>::value,
typename MatType::elem_type>::type
CD<DescentPolicyType>::Optimize(
    ResolvableFunctionType& function,
    MatType& iterateIn,
    CallbackTypes&&... callbacks)
{
  // Convenience typedefs.
  typedef typename MatType::elem_type ElemType;
  typedef typename MatTypeTraits<MatType>::BaseMatType BaseMatType;
  typedef typename MatTypeTraits<GradType>::BaseMatType BaseGradType;

  // Make sure we have the methods that we need.
  traits::CheckResolvableFunctionTypeAPI<ResolvableFunctionType, BaseMatType,
      BaseGradType>();
  RequireFloatingPointType<BaseMatType>();
  RequireFloatingPointType<BaseGradType>();

  ElemType overallObjective = 0;
  ElemType lastObjective = std::numeric_limits<ElemType>::max();

  BaseMatType& iterate = (BaseMatType&) iterateIn;
  BaseGradType gradient;

  // Controls early termination of the optimization process.
  bool terminate = false;

  // Start iterating.
  Callback::BeginOptimization(*this, function, iterate, callbacks...);
  for (size_t i = 1; i != maxIterations && !terminate; ++i)
  {
    // Get the coordinate to descend on.
    size_t featureIdx = descentPolicy.template DescentFeature<
        ResolvableFunctionType, BaseMatType, BaseGradType>(i, iterate,
        function);

    // Get the partial gradient with respect to this feature.
    function.PartialGradient(iterate, featureIdx, gradient);

    terminate |= Callback::Gradient(*this, function, iterate, overallObjective,
        gradient, callbacks...);
    if (terminate)
      break;

    // Update the decision variable with the partial gradient.
    iterate.col(featureIdx) -= stepSize * gradient.col(featureIdx);
    terminate |= Callback::StepTaken(*this, function, iterate, callbacks...);

    // Check for convergence.
    if (i % updateInterval == 0)
    {
      overallObjective = function.Evaluate(iterate);
      terminate |= Callback::Evaluate(*this, function, iterate,
          overallObjective, callbacks...);

      // Output current objective function.
      Info << "CD: iteration " << i << ", objective " << overallObjective
          << "." << std::endl;

      if (std::isnan(overallObjective) || std::isinf(overallObjective))
      {
        Warn << "CD: converged to " << overallObjective << "; terminating"
            << " with failure.  Try a smaller step size?" << std::endl;

        Callback::EndOptimization(*this, function, iterate, callbacks...);
        return overallObjective;
      }

      if (std::abs(lastObjective - overallObjective) < tolerance)
      {
        Info << "CD: minimized within tolerance " << tolerance << "; "
            << "terminating optimization." << std::endl;

        Callback::EndOptimization(*this, function, iterate, callbacks...);
        return overallObjective;
      }

      lastObjective = overallObjective;
    }
  }

  Info << "CD: maximum iterations (" << maxIterations << ") reached; "
      << "terminating optimization." << std::endl;

  // Calculate and return final objective.  No need to pay attention to the
  // result of the callback.
  const ElemType objective = function.Evaluate(iterate);
  (void) Callback::Evaluate(*this, function, iterate, objective, callbacks...);

  Callback::EndOptimization(*this, function, iterate, callbacks...);
  return objective;
}

} // namespace ens

#endif
/**
 * @file cyclic_descent.hpp
 * @author Shikhar Bhardwaj
 *
 * Cyclic descent policy for Stochastic Coordinate Descent (SCD).
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_SCD_DESCENT_POLICIES_CYCLIC_HPP
#define ENSMALLEN_SCD_DESCENT_POLICIES_CYCLIC_HPP

namespace ens {

/**
 * Cyclic descent policy for Stochastic Coordinate Descent(SCD). This
 * descent scheme picks a the co-ordinate for the descent in a cyclic manner
 * serially.
 *
 * For more information, see the following.
 * @code
 * @inproceedings{Shalev-Shwartz2009,
 *   author    = {Shalev-Shwartz, Shai and Tewari, Ambuj},
 *   title     = {Stochastic Methods for L1 Regularized Loss Minimization},
 *   booktitle = {Proceedings of the 26th Annual International Conference on
 *                Machine Learning},
 *   series    = {ICML '09},
 *   year      = {2009},
 *   isbn      = {978-1-60558-516-1}
 * }
 * @endcode
 */
class CyclicDescent
{
 public:
  /**
   * The DescentFeature method is used to get the descent coordinate for the
   * current iteration.
   *
   * @tparam ResolvableFunctionType The type of the function to be optimized.
   * @param iteration The iteration number for which the feature is to be
   *    obtained.
   * @param iterate The current value of the decision variable.
   * @param function The function to be optimized.
   * @return The index of the coordinate to be descended.
   */
  template<typename ResolvableFunctionType, typename MatType, typename GradType>
  static size_t DescentFeature(const size_t iteration,
                               const MatType& /* iterate */,
                               const ResolvableFunctionType& function)
  {
    return iteration % function.NumFeatures();
  }
};

} // namespace ens

#endif
/**
 * @file greedy_descent.hpp
 * @author Shikhar Bhardwaj
 *
 * Greedy descent policy for Stochastic Coordinate Descent (SCD).
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_SCD_DESCENT_POLICIES_GREEDY_HPP
#define ENSMALLEN_SCD_DESCENT_POLICIES_GREEDY_HPP

namespace ens {

/**
 * Greedy descent policy for Stochastic Co-ordinate Descent(SCD). This
 * descent scheme picks a the co-ordinate for the descent with the maximum
 * guaranteed descent, according to the Gauss-Southwell rule. This is a
 * deterministic approach and is generally more expensive to calculate.
 *
 * For more information, refer to the following.
 * @code
 * @misc{Nutini2015,
 *   author = {Julie Nutini and Mark Schmidt and Issam H.
 *             Laradji and Michael Friedlander and Hoyt Koepke},
 *   title  = {Coordinate Descent Converges Faster with the Gauss-Southwell Rule
 *             Than Random Selection},
 *   year   = {2015},
 *   eprint = {arXiv:1506.00552}
 * }
 * @endcode
 */
class GreedyDescent
{
 public:
  /**
   * The DescentFeature method is used to get the descent coordinate for the
   * current iteration.
   *
   * @tparam ResolvableFunctionType The type of the function to be optimized.
   * @param iteration The iteration number for which the feature is to be
   *    obtained.
   * @param iterate The current value of the decision variable.
   * @param function The function to be optimized.
   * @return The index of the coordinate to be descended.
   */
  template<typename ResolvableFunctionType, typename MatType, typename GradType>
  static size_t DescentFeature(const size_t /* iteration */,
                               const MatType& iterate,
                               const ResolvableFunctionType& function)
  {
    typedef typename MatType::elem_type ElemType;

    size_t bestFeature = 0;
    ElemType bestDescent = 0;
    for (size_t i = 0; i < function.NumFeatures(); ++i)
    {
      GradType fGrad;

      function.PartialGradient(iterate, i, fGrad);

      ElemType descent = arma::accu(fGrad);
      if (descent > bestDescent)
      {
        bestFeature = i;
        bestDescent = descent;
      }
    }

    return bestFeature;
  }
};

} // namespace ens

#endif
/**
 * @file random_descent.hpp
 * @author Shikhar Bhardwaj
 *
 * Random descent policy for Stochastic Coordinate Descent (SCD).
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_SCD_DESCENT_POLICIES_RANDOM_HPP
#define ENSMALLEN_SCD_DESCENT_POLICIES_RANDOM_HPP

namespace ens {

/**
 * Random descent policy for Stochastic Coordinate Descent(SCD). This
 * descent scheme picks a the co-ordinate for the descent uniformly randomly.
 *
 * For more information, see the following.
 * @code
 * @inproceedings{ShalevShwartz2009,
 *   author    = {Shalev-Shwartz, Shai and Tewari, Ambuj},
 *   title     = {Stochastic Methods for L1 Regularized Loss Minimization},
 *   booktitle = {Proceedings of the 26th Annual International Conference on
 *                Machine Learning},
 *   series    = {ICML '09},
 *   year      = {2009},
 *   isbn      = {978-1-60558-516-1}
 * }
 * @endcode
 */
class RandomDescent
{
 public:
  /**
   * The DescentFeature method is used to get the descent coordinate for the
   * current iteration of the SCD optimizer. For more information regarding the
   * interface of this policy with the optimizer, have a look at the SCD
   * implementation.
   *
   * @tparam ResolvableFunctionType The type of the function to be optimized.
   * @param iteration The iteration number for which the feature is to be
   *    obtained.
   * @param iterate The current value of the decision variable.
   * @param function The function to be optimized.
   * @return The index of the coordinate to be descended.
   */
  template<typename ResolvableFunctionType, typename MatType, typename GradType>
  static size_t DescentFeature(const size_t /* iteration */,
                               const MatType& /* iterate */,
                               const ResolvableFunctionType& function)
  {
    return arma::as_scalar(arma::randi<arma::uvec>(
          1, arma::distr_param(0, function.NumFeatures() - 1)));
  }
};

} // namespace ens

#endif
/**
 * @file active_cmaes.hpp
 * @author Marcus Edel
 * @author Suvarsha Chennareddy
 *
 * Definition of the Active Covariance Matrix Adaptation Evolution Strategy 
 * as proposed by G.A Jastrebski and D.V Arnold in "Improving Evolution 
 * Strategies through Active Covariance Matrix Adaptation".
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_CMAES_ACTIVE_CMAES_HPP
#define ENSMALLEN_CMAES_ACTIVE_CMAES_HPP

#include "full_selection.hpp"
#include "random_selection.hpp"
#include "transformation_policies/empty_transformation.hpp"
#include "transformation_policies/boundary_box_constraint.hpp"

namespace ens {

/**
 * Active CMA-ES is a variant of the stochastic search algorithm
 * CMA-ES - Covariance Matrix Adaptation Evolution Strategy.
 * Active CMA-ES actively reduces the uncertainty in unfavourable directions by
 * exploiting the information about bad mutations in the covariance matrix 
 * update step. This isn't for the purpose of accelerating progress, but 
 * instead for speeding up the adaptation of the covariance matrix (which, in 
 * turn, will lead to faster progress).
 *
 * For more information, please refer to:
 *
 * @code
 * @INPROCEEDINGS{1688662,
 *   author={Jastrebski, G.A. and Arnold, D.V.},
 *   booktitle={2006 IEEE International Conference on Evolutionary 
                Computation},
 *   title={Improving Evolution Strategies through Active Covariance 
            Matrix Adaptation},
 *   year={2006},
 *   volume={},
 *   number={},
 *   pages={2814-2821},
 *   doi={10.1109/CEC.2006.1688662}}
 * @endcode
 *
 * Active CMA-ES can optimize separable functions.  For more details, see the
 * documentation on function types included with this distribution or on the
 * ensmallen website.
 *
 * @tparam SelectionPolicy The selection strategy used for the evaluation step.
 * @tparam TransformationPolicy The transformation strategy used to 
 *       map decision variables to the desired domain during fitness evaluation
 *       and termination. Use EmptyTransformation if the domain isn't bounded.
 */
template<typename SelectionPolicyType = FullSelection,
         typename TransformationPolicyType = EmptyTransformation<>>
class ActiveCMAES
{
 public:
  /**
   * Construct the Active CMA-ES optimizer with the given function and parameters. The
   * defaults here are not necessarily good for the given problem, so it is
   * suggested that the values used be tailored to the task at hand.  The
   * maximum number of iterations refers to the maximum number of points that
   * are processed (i.e., one iteration equals one point; one iteration does not
   * equal one pass over the dataset).
   *
   * @param lambda The population size (0 use the default size).
   * @param transformationPolicy Instantiated transformation policy used to 
   *     map the coordinates to the desired domain.
   * @param batchSize Batch size to use for the objective calculation.
   * @param maxIterations Maximum number of iterations allowed (0 means no
   *     limit).
   * @param tolerance Maximum absolute tolerance to terminate algorithm.
   * @param selectionPolicy Instantiated selection policy used to calculate the
   *     objective.
   * @param stepSize Starting sigma/step size (will be modified).
   */
  ActiveCMAES(
      const size_t lambda = 0,
      const TransformationPolicyType& 
          transformationPolicy = TransformationPolicyType(),
      const size_t batchSize = 32,
      const size_t maxIterations = 1000,
      const double tolerance = 1e-5,
      const SelectionPolicyType& selectionPolicy = SelectionPolicyType(),
      double stepSize = 0);

  /**
   * Construct the Active CMA-ES optimizer with the given function and parameters 
   * (including lower and upper bounds). The defaults here are not necessarily 
   * good for the given problem, so it is suggested that the values used be 
   * tailored to the task at hand.  The maximum number of iterations refers to 
   * the maximum number of points that are processed (i.e., one iteration 
   * equals one point; one iteration does not equal one pass over the dataset). 
   *
   * @param lambda The population size(0 use the default size).
   * @param lowerBound Lower bound of decision variables.
   * @param upperBound Upper bound of decision variables.
   * @param batchSize Batch size to use for the objective calculation.
   * @param maxIterations Maximum number of iterations allowed(0 means no
      limit).
   * @param tolerance Maximum absolute tolerance to terminate algorithm.
   * @param selectionPolicy Instantiated selection policy used to calculate the
   * objective.
   * @param stepSize Starting sigma/step size (will be modified).
   */
  ActiveCMAES(
      const size_t lambda = 0,
      const double lowerBound = -10,
      const double upperBound = 10,
      const size_t batchSize = 32,
      const size_t maxIterations = 1000,
      const double tolerance = 1e-5,
      const SelectionPolicyType& selectionPolicy = SelectionPolicyType(),
      double stepSize = 0);

  /**
   * Optimize the given function using Active CMA-ES. The given starting point will be
   * modified to store the finishing point of the algorithm, and the final
   * objective value is returned.
   *
   * @tparam SeparableFunctionType Type of the function to be optimized.
   * @tparam MatType Type of matrix to optimize.
   * @tparam CallbackTypes Types of callback functions.
   * @param function Function to optimize.
   * @param iterate Starting point (will be modified).
   * @param callbacks Callback functions.
   * @return Objective value of the final point.
   */
  template<typename SeparableFunctionType,
      typename MatType,
      typename... CallbackTypes>
      typename MatType::elem_type Optimize(
          SeparableFunctionType& function,
          MatType& iterate,
          CallbackTypes&&... callbacks);

  //! Get the population size.
  size_t PopulationSize() const { return lambda; }
  //! Modify the population size.
  size_t& PopulationSize() { return lambda; }

  //! Get the batch size.
  size_t BatchSize() const { return batchSize; }
  //! Modify the batch size.
  size_t& BatchSize() { return batchSize; }

  //! Get the maximum number of iterations (0 indicates no limit).
  size_t MaxIterations() const { return maxIterations; }
  //! Modify the maximum number of iterations (0 indicates no limit).
  size_t& MaxIterations() { return maxIterations; }

  //! Get the tolerance for termination.
  double Tolerance() const { return tolerance; }
  //! Modify the tolerance for termination.
  double& Tolerance() { return tolerance; }

  //! Get the selection policy.
  const SelectionPolicyType& SelectionPolicy() const { return selectionPolicy; }
  //! Modify the selection policy.
  SelectionPolicyType& SelectionPolicy() { return selectionPolicy; }

  //! Get the transformation policy.
  const TransformationPolicyType& TransformationPolicy() const
  { return transformationPolicy; }
  //! Modify the transformation policy.
  TransformationPolicyType& TransformationPolicy() 
  { return transformationPolicy; }

  //! Get the step size.
  double StepSize() const
  { return stepSize; }
  //! Modify the step size.
  double& StepSize()
  { return stepSize; }

 private:
  //! Population size.
  size_t lambda;

  //! The batch size for processing.
  size_t batchSize;

  //! The maximum number of allowed iterations.
  size_t maxIterations;

  //! The tolerance for termination.
  double tolerance;

  //! The selection policy used to calculate the objective.
  SelectionPolicyType selectionPolicy;

  //! The transformationPolicy used to map coordinates to the suitable domain
  //! while evaluating fitness. This mapping is also done after optimization 
  //! has completed.
  TransformationPolicyType transformationPolicy;

  //! The step size.
  double stepSize;
};

/**
 * Convenient typedef for Active CMAES approximation.
 */
template<typename TransformationPolicyType = EmptyTransformation<>,
         typename SelectionPolicyType = RandomSelection>
using ApproxActiveCMAES = ActiveCMAES<SelectionPolicyType, TransformationPolicyType>;

} // namespace ens

// Include implementation.
#include "active_cmaes_impl.hpp"

#endif
/**
 * @file active_cmaes_impl.hpp
 * @author Marcus Edel
 * @author Suvarsha Chennareddy
 *
 * Implementation of the Active Covariance Matrix Adaptation Evolution Strategy
 * as proposed by G.A Jastrebski and D.V Arnold in "Improving Evolution
 * Strategies through Active Covariance Matrix Adaptation".
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_CMAES_ACTIVE_CMAES_IMPL_HPP
#define ENSMALLEN_CMAES_ACTIVE_CMAES_IMPL_HPP

// In case it hasn't been included yet.
#include "active_cmaes.hpp"

#include "not_empty_transformation.hpp"
#include <ensmallen_bits/function.hpp>

namespace ens {

template<typename SelectionPolicyType, typename TransformationPolicyType>
ActiveCMAES<SelectionPolicyType, TransformationPolicyType>::ActiveCMAES(
                                  const size_t lambda,
                                  const TransformationPolicyType& 
                                        transformationPolicy,
                                  const size_t batchSize,
                                  const size_t maxIterations,
                                  const double tolerance,
                                  const SelectionPolicyType& selectionPolicy,
                                  double stepSizeIn) :
    lambda(lambda),
    batchSize(batchSize),
    maxIterations(maxIterations),
    tolerance(tolerance),
    selectionPolicy(selectionPolicy),
    transformationPolicy(transformationPolicy),
    stepSize(stepSizeIn)
{ /* Nothing to do. */ }

template<typename SelectionPolicyType, typename TransformationPolicyType>
ActiveCMAES<SelectionPolicyType, TransformationPolicyType>::ActiveCMAES(
                                  const size_t lambda,
                                  const double lowerBound,
                                  const double upperBound,
                                  const size_t batchSize,
                                  const size_t maxIterations,
                                  const double tolerance,
                                  const SelectionPolicyType& selectionPolicy,
                                  double stepSizeIn) :
    lambda(lambda),
    batchSize(batchSize),
    maxIterations(maxIterations),
    tolerance(tolerance),
    selectionPolicy(selectionPolicy),
    stepSize(stepSizeIn)
{
  Warn << "This is a deprecated constructor and will be removed in a "
    "future version of ensmallen" << std::endl;
  NotEmptyTransformation<TransformationPolicyType, EmptyTransformation<>> d;
  d.Assign(transformationPolicy, lowerBound, upperBound);
}

//! Optimize the function (minimize).
template<typename SelectionPolicyType, typename TransformationPolicyType>
template<typename SeparableFunctionType,
         typename MatType,
         typename... CallbackTypes>
typename MatType::elem_type ActiveCMAES<SelectionPolicyType, 
  TransformationPolicyType>::Optimize(
    SeparableFunctionType& function,
    MatType& iterateIn,
    CallbackTypes&&... callbacks)
{
  // Convenience typedefs.
  typedef typename MatType::elem_type ElemType;
  typedef typename MatTypeTraits<MatType>::BaseMatType BaseMatType;

  // Make sure that we have the methods that we need.  Long name...
  traits::CheckArbitrarySeparableFunctionTypeAPI<
      SeparableFunctionType, BaseMatType>();
  RequireDenseFloatingPointType<BaseMatType>();

  BaseMatType& iterate = (BaseMatType&) iterateIn;

  // Find the number of functions to use.
  const size_t numFunctions = function.NumFunctions();

  // Population size.
  if (lambda == 0)
    lambda = (4 + std::round(3 * std::log(iterate.n_elem))) * 10;

  // Parent number.
  const size_t mu = std::round(lambda / 4);

  // Recombination weight (w = 1 / (parent number)).
  const ElemType w = 1.0 / mu;

  // Number of effective solutions.
  const ElemType muEffective = mu;

  // Step size control parameters.
  BaseMatType sigma(2, 1); // sigma is vector-shaped.
  if (stepSize == 0) 
    sigma(0) = transformationPolicy.InitialStepSize();
  else 
    sigma(0) = stepSize;

  const ElemType cs = 4.0 / (iterate.n_elem + 4);
  const ElemType ds = 1 + cs;
  const ElemType enn = std::sqrt(iterate.n_elem) * (1.0 - 1.0 /
      (4.0 * iterate.n_elem) + 1.0 / (21 * std::pow(iterate.n_elem, 2)));

  // Covariance update parameters. Cumulation for distribution.
  const ElemType cc = cs;
  const ElemType ccov = 2.0 / std::pow((iterate.n_elem + std::sqrt(2)), 2);
  const ElemType beta = (4.0 * mu - 2.0) / (std::pow((iterate.n_elem + 12), 2) 
      + 4 * mu);

  std::vector<BaseMatType> mPosition(2, BaseMatType(iterate.n_rows,
      iterate.n_cols));
  mPosition[0] = iterate;

  BaseMatType step(iterate.n_rows, iterate.n_cols);
  step.zeros();

  BaseMatType transformedIterate = transformationPolicy.Transform(iterate);

  // Controls early termination of the optimization process.
  bool terminate = false;

  // Calculate the first objective function.
  ElemType currentObjective = 0;
  for (size_t f = 0; f < numFunctions; f += batchSize)
  {
    const size_t effectiveBatchSize = std::min(batchSize, numFunctions - f);
    const ElemType objective = function.Evaluate(transformedIterate, f,
        effectiveBatchSize);
    currentObjective += objective;

    terminate |= Callback::Evaluate(*this, function, transformedIterate,
        objective, callbacks...);
  }

  ElemType overallObjective = currentObjective;
  ElemType lastObjective = std::numeric_limits<ElemType>::max();

  // Population parameters.
  std::vector<BaseMatType> pStep(lambda, BaseMatType(iterate.n_rows,
      iterate.n_cols));
  std::vector<BaseMatType> pPosition(lambda, BaseMatType(iterate.n_rows,
      iterate.n_cols));
  BaseMatType pObjective(lambda, 1); // pObjective is vector-shaped.
  std::vector<BaseMatType> ps(2, BaseMatType(iterate.n_rows, iterate.n_cols));
  ps[0].zeros();
  ps[1].zeros();
  std::vector<BaseMatType> pc = ps;
  std::vector<BaseMatType> C(2, BaseMatType(iterate.n_elem, iterate.n_elem));
  C[0].eye();

  // Covariance matrix parameters.
  arma::Col<ElemType> eigval;
  BaseMatType eigvec;
  BaseMatType eigvalZero(iterate.n_elem, 1); // eigvalZero is vector-shaped.
  eigvalZero.zeros();

  // The current visitation order (sorted by population objectives).
  arma::uvec idx = arma::linspace<arma::uvec>(0, lambda - 1, lambda);

  // Now iterate!
  Callback::BeginOptimization(*this, function, transformedIterate,
      callbacks...);

  size_t idx0, idx1;

  // The number of generations to wait after the minimum loss has
  // been reached or no improvement has been made before terminating.
  size_t patience = 10 + (30 * iterate.n_elem / lambda) + 1;
  size_t steps = 0;

  for (size_t i = 1; (i != maxIterations) && !terminate; ++i)
  {
    // To keep track of where we are.
    idx0 = (i - 1) % 2;
    idx1 = i % 2;

    // Perform Cholesky decomposition. If the matrix is not positive definite,
    // add a small value and try again.
    BaseMatType covLower;
    while (!arma::chol(covLower, C[idx0], "lower"))
      C[idx0].diag() += std::numeric_limits<ElemType>::epsilon();

    arma::eig_sym(eigval, eigvec, C[idx0]);

    for (size_t j = 0; j < lambda; ++j)
    {
      if (iterate.n_rows > iterate.n_cols)
      {
        pStep[idx(j)] = covLower *
          arma::randn<BaseMatType>(iterate.n_rows, iterate.n_cols);
      }
      else
      {
        pStep[idx(j)] = arma::randn<BaseMatType>(iterate.n_rows, iterate.n_cols)
          * covLower.t();
      }

      pPosition[idx(j)] = mPosition[idx0] + sigma(idx0) * pStep[idx(j)];

      // Calculate the objective function.
      pObjective(idx(j)) = selectionPolicy.Select(function, batchSize,
          transformationPolicy.Transform(pPosition[idx(j)]), terminate,
          callbacks...);
    }

    // Sort population.
    idx = arma::sort_index(pObjective);

    step = w * pStep[idx(0)];
    for (size_t j = 1; j < mu; ++j)
      step += w * pStep[idx(j)];

    mPosition[idx1] = mPosition[idx0] + sigma(idx0) * step;

    // Calculate the objective function.
    currentObjective = selectionPolicy.Select(function, batchSize,
        transformationPolicy.Transform(mPosition[idx1]), terminate,
        callbacks...);

    // Update best parameters.
    if (currentObjective < overallObjective)
    {
      overallObjective = currentObjective;
      iterate = mPosition[idx1];

      transformedIterate = transformationPolicy.Transform(iterate);
      terminate |= Callback::StepTaken(*this, function,
          transformedIterate, callbacks...);
    }

    // Update Step Size.
    if (iterate.n_rows > iterate.n_cols)
    {
      ps[idx1] = (1 - cs) * ps[idx0] + std::sqrt(
        cs * (2 - cs) * muEffective) *
        eigvec * diagmat(1 / eigval) * eigvec.t() * step;
    }
    else
    {
      ps[idx1] = (1 - cs) * ps[idx0] + std::sqrt(
          cs * (2 - cs) * muEffective) * step *
          eigvec * diagmat(1 / eigval) * eigvec.t();
    }

    const ElemType psNorm = arma::norm(ps[idx1]);
    sigma(idx1) = sigma(idx0) * std::exp(cs / ds * (psNorm / enn - 1));

    if (std::isnan(sigma(idx1)) || sigma(idx1) > 1e14)
    {
      Warn << "The step size diverged to " << sigma(idx1) << "; "
          << "terminating with failure.  Try a smaller step size?" << std::endl;

      iterate = transformationPolicy.Transform(iterate);

      Callback::EndOptimization(*this, function, iterate, callbacks...);
      return overallObjective;
    }

    pc[idx1] = (1 - cc) * pc[idx0] + std::sqrt(cc * (2 - cc) *
        muEffective) * step;

    if (iterate.n_rows > iterate.n_cols)
    {
      C[idx1] = (1 - ccov) * C[idx0] + ccov *
          (pc[idx1] * pc[idx1].t());

      for (size_t j = 0; j < mu; ++j)
      {
        C[idx1] = C[idx1] + beta * w *
            pStep[idx(j)] * pStep[idx(j)].t();
      }

      for (size_t j = lambda - mu; j < lambda; ++j)
      {
        C[idx1] = C[idx1] - beta * w *
            pStep[idx(j)] * pStep[idx(j)].t();
      }
    }
    else
    {
      C[idx1] = (1 - ccov) * C[idx0] + ccov *
          (pc[idx1].t() * pc[idx1]);

      for (size_t j = 0; j < mu; ++j)
      {
        C[idx1] = C[idx1] + beta * w *
            pStep[idx(j)].t() * pStep[idx(j)];
      }

      for (size_t j = lambda - mu; j < lambda; ++j)
      {
        C[idx1] = C[idx1] - beta * w *
            pStep[idx(j)].t() * pStep[idx(j)];
      }
    }

    arma::eig_sym(eigval, eigvec, C[idx1]);
    const arma::uvec negativeEigval = arma::find(eigval < 0, 1);
    if (!negativeEigval.is_empty())
    {
      if (negativeEigval(0) == 0)
      {
        C[idx1].zeros();
      }
      else
      {
        C[idx1] = eigvec.cols(0, negativeEigval(0) - 1) *
            arma::diagmat(eigval.subvec(0, negativeEigval(0) - 1)) *
            eigvec.cols(0, negativeEigval(0) - 1).t();
      }
    }

    // Output current objective function.
    Info << "Active CMA-ES: iteration " << i << ", objective " << overallObjective
        << "." << std::endl;

    if (std::isnan(overallObjective) || std::isinf(overallObjective))
    {
      Warn << "Active CMA-ES: converged to " << overallObjective << "; "
          << "terminating with failure.  Try a smaller step size?" << std::endl;

      iterate = transformationPolicy.Transform(iterate);
      Callback::EndOptimization(*this, function, iterate, callbacks...);
      return overallObjective;
    }

    if (std::abs(lastObjective - overallObjective) < tolerance)
    {
      if (steps > patience)
      {
        Info << "Active CMA-ES: minimized within tolerance " << tolerance << "; "
            << "terminating optimization." << std::endl;

        iterate = transformationPolicy.Transform(iterate);
        Callback::EndOptimization(*this, function, iterate, callbacks...);
        return overallObjective;
      }
    }
    else
    {
      steps = 0;
    }

    steps++;
    lastObjective = overallObjective;
  }

  iterate = transformationPolicy.Transform(iterate);
  Callback::EndOptimization(*this, function, iterate, callbacks...);
  return overallObjective;
}

} // namespace ens

#endif
/**
 * @file cmaes.hpp
 * @author Marcus Edel
 * @author Kartik Nighania
 *
 * Definition of the Covariance Matrix Adaptation Evolution Strategy as proposed
 * by N. Hansen et al. in "Completely Derandomized Self-Adaptation in Evolution
 * Strategies".
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_CMAES_CMAES_HPP
#define ENSMALLEN_CMAES_CMAES_HPP

#include "full_selection.hpp"
#include "random_selection.hpp"
#include "transformation_policies/empty_transformation.hpp"
#include "transformation_policies/boundary_box_constraint.hpp"

namespace ens {

/**
 * CMA-ES - Covariance Matrix Adaptation Evolution Strategy is s a stochastic
 * search algorithm. CMA-ES is a second order approach estimating a positive
 * definite matrix within an iterative procedure using the covariance matrix.
 *
 * For more information, please refer to:
 *
 * @code
 * @article{Hansen2001
 *   author    = {Hansen, Nikolaus and Ostermeier, Andreas},
 *   title     = {Completely Derandomized Self-Adaptation in Evolution
 *                Strategies},
 *   journal   = {Evol. Comput.},
 *   volume    = {9},
 *   number    = {2},
 *   year      = {2001},
 *   pages     = {159--195},
 *   publisher = {MIT Press},
 * }
 * @endcode
 *
 * CMA-ES can optimize separable functions.  For more details, see the
 * documentation on function types included with this distribution or on the
 * ensmallen website.
 *
 * @tparam SelectionPolicy The selection strategy used for the evaluation step.
 * @tparam TransformationPolicy The transformation strategy used to 
 *       map decision variables to the desired domain during fitness evaluation
 *       and termination. Use EmptyTransformation if the domain isn't bounded.
 */
template<typename SelectionPolicyType = FullSelection,
         typename TransformationPolicyType = EmptyTransformation<>>
class CMAES
{
 public:
  /**
   * Construct the CMA-ES optimizer with the given function and parameters. The
   * defaults here are not necessarily good for the given problem, so it is
   * suggested that the values used be tailored to the task at hand.  The
   * maximum number of iterations refers to the maximum number of points that
   * are processed (i.e., one iteration equals one point; one iteration does not
   * equal one pass over the dataset).
   *
   * @param lambda The population size (0 use the default size).
   * @param transformationPolicy Instantiated transformation policy used to 
   *     map the coordinates to the desired domain.
   * @param batchSize Batch size to use for the objective calculation.
   * @param maxIterations Maximum number of iterations allowed (0 means no
   *     limit).
   * @param tolerance Maximum absolute tolerance to terminate algorithm.
   * @param selectionPolicy Instantiated selection policy used to calculate the
   *     objective.
   * @param stepSize Starting sigma/step size (will be modified).
   */
  CMAES(const size_t lambda = 0,
        const TransformationPolicyType& 
              transformationPolicy = TransformationPolicyType(),
        const size_t batchSize = 32,
        const size_t maxIterations = 1000,
        const double tolerance = 1e-5,
        const SelectionPolicyType& selectionPolicy = SelectionPolicyType(),
        double stepSize = 0);

  /**
   * Construct the CMA-ES optimizer with the given function and parameters 
   * (including lower and upper bounds). The defaults here are not necessarily 
   * good for the given problem, so it is suggested that the values used be 
   * tailored to the task at hand.  The maximum number of iterations refers to 
   * the maximum number of points that are processed (i.e., one iteration 
   * equals one point; one iteration does not equal one pass over the dataset).
   *
   * @param lambda The population size(0 use the default size).
   * @param lowerBound Lower bound of decision variables.
   * @param upperBound Upper bound of decision variables.
   * @param batchSize Batch size to use for the objective calculation.
   * @param maxIterations Maximum number of iterations allowed(0 means no
      limit).
   * @param tolerance Maximum absolute tolerance to terminate algorithm.
   * @param selectionPolicy Instantiated selection policy used to calculate the
   * objective.
   * @param stepSize Starting sigma/step size (will be modified).
   */
  CMAES(const size_t lambda = 0,
        const double lowerBound = -10,
        const double upperBound = 10,
        const size_t batchSize = 32,
        const size_t maxIterations = 1000,
        const double tolerance = 1e-5,
        const SelectionPolicyType& selectionPolicy = SelectionPolicyType(),
        double stepSize = 0);

  /**
   * Optimize the given function using CMA-ES. The given starting point will be
   * modified to store the finishing point of the algorithm, and the final
   * objective value is returned.
   *
   * @tparam SeparableFunctionType Type of the function to be optimized.
   * @tparam MatType Type of matrix to optimize.
   * @tparam CallbackTypes Types of callback functions.
   * @param function Function to optimize.
   * @param iterate Starting point (will be modified).
   * @param callbacks Callback functions.
   * @return Objective value of the final point.
   */
  template<typename SeparableFunctionType,
      typename MatType,
      typename... CallbackTypes>
      typename MatType::elem_type Optimize(SeparableFunctionType& function,
          MatType& iterate,
          CallbackTypes&&... callbacks);

  //! Get the population size.
  size_t PopulationSize() const { return lambda; }
  //! Modify the population size.
  size_t& PopulationSize() { return lambda; }

  //! Get the batch size.
  size_t BatchSize() const { return batchSize; }
  //! Modify the batch size.
  size_t& BatchSize() { return batchSize; }

  //! Get the maximum number of iterations (0 indicates no limit).
  size_t MaxIterations() const { return maxIterations; }
  //! Modify the maximum number of iterations (0 indicates no limit).
  size_t& MaxIterations() { return maxIterations; }

  //! Get the tolerance for termination.
  double Tolerance() const { return tolerance; }
  //! Modify the tolerance for termination.
  double& Tolerance() { return tolerance; }

  //! Get the selection policy.
  const SelectionPolicyType& SelectionPolicy() const { return selectionPolicy; }
  //! Modify the selection policy.
  SelectionPolicyType& SelectionPolicy() { return selectionPolicy; }

  //! Get the transformation policy.
  const TransformationPolicyType& TransformationPolicy() const
  { return transformationPolicy; }
  //! Modify the transformation policy.
  TransformationPolicyType& TransformationPolicy() 
  { return transformationPolicy; }

  //! Get the step size.
  double StepSize() const
  { return stepSize; }
  //! Modify the step size.
  double& StepSize()
  { return stepSize; }

 private:
  //! Population size.
  size_t lambda;

  //! The batch size for processing.
  size_t batchSize;

  //! The maximum number of allowed iterations.
  size_t maxIterations;

  //! The tolerance for termination.
  double tolerance;

  //! The selection policy used to calculate the objective.
  SelectionPolicyType selectionPolicy;

  //! The transformationPolicy used to map coordinates to the suitable domain
  //! while evaluating fitness. This mapping is also done after optimization 
  //! has completed.
  TransformationPolicyType transformationPolicy;

  //! The step size.
  double stepSize;
};

/**
 * Convenient typedef for CMAES approximation.
 */
template<typename TransformationPolicyType = EmptyTransformation<>,
         typename SelectionPolicyType = RandomSelection>
using ApproxCMAES = CMAES<SelectionPolicyType, TransformationPolicyType>;

} // namespace ens

// Include implementation.
#include "cmaes_impl.hpp"

#endif
/**
 * @file cmaes_impl.hpp
 * @author Marcus Edel
 * @author Kartik Nighania
 *
 * Implementation of the Covariance Matrix Adaptation Evolution Strategy as
 * proposed by N. Hansen et al. in "Completely Derandomized Self-Adaptation in
 * Evolution Strategies".
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_CMAES_CMAES_IMPL_HPP
#define ENSMALLEN_CMAES_CMAES_IMPL_HPP

// In case it hasn't been included yet.
#include "cmaes.hpp"

#include "not_empty_transformation.hpp"
#include <ensmallen_bits/function.hpp>

namespace ens {

template<typename SelectionPolicyType, typename TransformationPolicyType>
CMAES<SelectionPolicyType, TransformationPolicyType>::CMAES(const size_t lambda,
                                  const TransformationPolicyType& 
                                        transformationPolicy,
                                  const size_t batchSize,
                                  const size_t maxIterations,
                                  const double tolerance,
                                  const SelectionPolicyType& selectionPolicy,
                                  double stepSizeIn) :
    lambda(lambda),
    batchSize(batchSize),
    maxIterations(maxIterations),
    tolerance(tolerance),
    selectionPolicy(selectionPolicy),
    transformationPolicy(transformationPolicy),
    stepSize(stepSizeIn)
{ /* Nothing to do. */ }

template<typename SelectionPolicyType, typename TransformationPolicyType>
CMAES<SelectionPolicyType, TransformationPolicyType>::CMAES(const size_t lambda,
                                  const double lowerBound,
                                  const double upperBound,
                                  const size_t batchSize,
                                  const size_t maxIterations,
                                  const double tolerance,
                                  const SelectionPolicyType& selectionPolicy,
                                  double stepSizeIn) :
    lambda(lambda),
    batchSize(batchSize),
    maxIterations(maxIterations),
    tolerance(tolerance),
    selectionPolicy(selectionPolicy),
    stepSize(stepSizeIn)
{
  Warn << "This is a deprecated constructor and will be removed in a "
    "future version of ensmallen" << std::endl;
  NotEmptyTransformation<TransformationPolicyType, EmptyTransformation<>> d;
  d.Assign(transformationPolicy, lowerBound, upperBound);
}


//! Optimize the function (minimize).
template<typename SelectionPolicyType, typename TransformationPolicyType>
template<typename SeparableFunctionType,
         typename MatType,
         typename... CallbackTypes>
typename MatType::elem_type CMAES<SelectionPolicyType, 
  TransformationPolicyType>::Optimize(
    SeparableFunctionType& function,
    MatType& iterateIn,
    CallbackTypes&&... callbacks)
{
  // Convenience typedefs.
  typedef typename MatType::elem_type ElemType;
  typedef typename MatTypeTraits<MatType>::BaseMatType BaseMatType;

  // Make sure that we have the methods that we need.  Long name...
  traits::CheckArbitrarySeparableFunctionTypeAPI<
      SeparableFunctionType, BaseMatType>();
  RequireDenseFloatingPointType<BaseMatType>();

  BaseMatType& iterate = (BaseMatType&) iterateIn;

  // Find the number of functions to use.
  const size_t numFunctions = function.NumFunctions();

  // Population size.
  if (lambda == 0)
    lambda = (4 + std::round(3 * std::log(iterate.n_elem))) * 10;

  // Parent weights.
  const size_t mu = std::round(lambda / 2);
  BaseMatType w = std::log(mu + 0.5) - arma::log(
      arma::linspace<BaseMatType>(0, mu - 1, mu) + 1.0);
  w /= arma::accu(w);

  // Number of effective solutions.
  const double muEffective = 1 / arma::accu(arma::pow(w, 2));

  // Step size control parameters.
  BaseMatType sigma(2, 1); // sigma is vector-shaped.
  if (stepSize == 0) 
    sigma(0) = transformationPolicy.InitialStepSize();
  else 
    sigma(0) = stepSize;

  const double cs = (muEffective + 2) / (iterate.n_elem + muEffective + 5);
  const double ds = 1 + cs + 2 * std::max(std::sqrt((muEffective - 1) /
      (iterate.n_elem + 1)) - 1, 0.0);
  const double enn = std::sqrt(iterate.n_elem) * (1.0 - 1.0 /
      (4.0 * iterate.n_elem) + 1.0 / (21 * std::pow(iterate.n_elem, 2)));

  // Covariance update parameters.
  // Cumulation for distribution.
  const double cc = (4 + muEffective / iterate.n_elem) /
      (4 + iterate.n_elem + 2 * muEffective / iterate.n_elem);
  const double h = (1.4 + 2.0 / (iterate.n_elem + 1.0)) * enn;

  const double c1 = 2 / (std::pow(iterate.n_elem + 1.3, 2) + muEffective);
  const double alphaMu = 2;
  const double cmu = std::min(1 - c1, alphaMu * (muEffective - 2 + 1 /
      muEffective) / (std::pow(iterate.n_elem + 2, 2) +
      alphaMu * muEffective / 2));

  std::vector<BaseMatType> mPosition(2, BaseMatType(iterate.n_rows,
      iterate.n_cols));
  mPosition[0] = iterate;

  BaseMatType step(iterate.n_rows, iterate.n_cols);
  step.zeros();

  BaseMatType transformedIterate = transformationPolicy.Transform(iterate);

  // Controls early termination of the optimization process.
  bool terminate = false;

  // Calculate the first objective function.
  ElemType currentObjective = 0;
  for (size_t f = 0; f < numFunctions; f += batchSize)
  {
    const size_t effectiveBatchSize = std::min(batchSize, numFunctions - f);
    const ElemType objective = function.Evaluate(transformedIterate, f,
        effectiveBatchSize);
    currentObjective += objective;

    terminate |= Callback::Evaluate(*this, function, transformedIterate,
        objective, callbacks...);
  }

  ElemType overallObjective = currentObjective;
  ElemType lastObjective = std::numeric_limits<ElemType>::max();

  // Population parameters.
  std::vector<BaseMatType> pStep(lambda, BaseMatType(iterate.n_rows,
      iterate.n_cols));
  std::vector<BaseMatType> pPosition(lambda, BaseMatType(iterate.n_rows,
      iterate.n_cols));
  BaseMatType pObjective(lambda, 1); // pObjective is vector-shaped.
  std::vector<BaseMatType> ps(2, BaseMatType(iterate.n_rows, iterate.n_cols));
  ps[0].zeros();
  ps[1].zeros();
  std::vector<BaseMatType> pc = ps;
  std::vector<BaseMatType> C(2, BaseMatType(iterate.n_elem, iterate.n_elem));
  C[0].eye();

  // Covariance matrix parameters.
  arma::Col<ElemType> eigval; // TODO: might need a more general type.
  BaseMatType eigvec;
  BaseMatType eigvalZero(iterate.n_elem, 1); // eigvalZero is vector-shaped.
  eigvalZero.zeros();

  // The current visitation order (sorted by population objectives).
  arma::uvec idx = arma::linspace<arma::uvec>(0, lambda - 1, lambda);

  // Now iterate!
  Callback::BeginOptimization(*this, function, transformedIterate,
      callbacks...);

  // The number of generations to wait after the minimum loss has
  // been reached or no improvement has been made before terminating.
  size_t patience = 10 + (30 * iterate.n_elem / lambda) + 1;
  size_t steps = 0;

  for (size_t i = 1; (i != maxIterations) && !terminate; ++i)
  {
    // To keep track of where we are.
    const size_t idx0 = (i - 1) % 2;
    const size_t idx1 = i % 2;

    // Perform Cholesky decomposition. If the matrix is not positive definite,
    // add a small value and try again.
    BaseMatType covLower;
    while (!arma::chol(covLower, C[idx0], "lower"))
      C[idx0].diag() += std::numeric_limits<ElemType>::epsilon();

    arma::eig_sym(eigval, eigvec, C[idx0]);

    for (size_t j = 0; j < lambda; ++j)
    {
      if (iterate.n_rows > iterate.n_cols)
      {
        pStep[idx(j)] = covLower *
          arma::randn<BaseMatType>(iterate.n_rows, iterate.n_cols);
      }
      else
      {
        pStep[idx(j)] = arma::randn<BaseMatType>(iterate.n_rows, iterate.n_cols)
          * covLower.t();
      }

      pPosition[idx(j)] = mPosition[idx0] + sigma(idx0) * pStep[idx(j)];

      // Calculate the objective function.
      pObjective(idx(j)) = selectionPolicy.Select(function, batchSize,
          transformationPolicy.Transform(pPosition[idx(j)]), terminate,
          callbacks...);
    }

    // Sort population.
    idx = arma::sort_index(pObjective);

    step = w(0) * pStep[idx(0)];
    for (size_t j = 1; j < mu; ++j)
      step += w(j) * pStep[idx(j)];

    mPosition[idx1] = mPosition[idx0] + sigma(idx0) * step;

    // Calculate the objective function.
    currentObjective = selectionPolicy.Select(function, batchSize,
        transformationPolicy.Transform(mPosition[idx1]), terminate,
        callbacks...);

    // Update best parameters.
    if (currentObjective < overallObjective)
    {
      overallObjective = currentObjective;
      iterate = mPosition[idx1];

      transformedIterate = transformationPolicy.Transform(iterate);
      terminate |= Callback::StepTaken(*this, function,
        transformedIterate, callbacks...);
    }

    // Update Step Size.
    if (iterate.n_rows > iterate.n_cols)
    {
      ps[idx1] = (1 - cs) * ps[idx0] + std::sqrt(
        cs * (2 - cs) * muEffective) *
        eigvec * diagmat(1 / eigval) * eigvec.t() * step;
    }
    else
    {
      ps[idx1] = (1 - cs) * ps[idx0] + std::sqrt(
        cs * (2 - cs) * muEffective) * step *
        eigvec * diagmat(1 / eigval) * eigvec.t();
    }

    const ElemType psNorm = arma::norm(ps[idx1]);
    sigma(idx1) = sigma(idx0) * std::exp(cs / ds * (psNorm / enn - 1));

    if (std::isnan(sigma(idx1)) || sigma(idx1) > 1e14)
    {
      Warn << "The step size diverged to " << sigma(idx1) << "; "
        << "terminating with failure.  Try a smaller step size?" << std::endl;

      iterate = transformationPolicy.Transform(iterate);

      Callback::EndOptimization(*this, function, iterate, callbacks...);
      return overallObjective;
    }

    // Update covariance matrix.
    if ((psNorm / sqrt(1 - std::pow(1 - cs, 2 * i))) < h)
    {
      pc[idx1] = (1 - cc) * pc[idx0] + std::sqrt(cc * (2 - cc) *
        muEffective) * step;

      if (iterate.n_rows > iterate.n_cols)
      {
        C[idx1] = (1 - c1 - cmu) * C[idx0] + c1 *
          (pc[idx1] * pc[idx1].t());
      }
      else
      {
        C[idx1] = (1 - c1 - cmu) * C[idx0] + c1 *
          (pc[idx1].t() * pc[idx1]);
      }
    }
    else
    {
      pc[idx1] = (1 - cc) * pc[idx0];

      if (iterate.n_rows > iterate.n_cols)
      {
        C[idx1] = (1 - c1 - cmu) * C[idx0] + c1 * (pc[idx1] *
          pc[idx1].t() + (cc * (2 - cc)) * C[idx0]);
      }
      else
      {
        C[idx1] = (1 - c1 - cmu) * C[idx0] + c1 *
          (pc[idx1].t() * pc[idx1] + (cc * (2 - cc)) * C[idx0]);
      }
    }

    if (iterate.n_rows > iterate.n_cols)
    {
      for (size_t j = 0; j < mu; ++j)
      {
        C[idx1] = C[idx1] + cmu * w(j) *
          pStep[idx(j)] * pStep[idx(j)].t();
      }
    }
    else
    {
      for (size_t j = 0; j < mu; ++j)
      {
        C[idx1] = C[idx1] + cmu * w(j) *
          pStep[idx(j)].t() * pStep[idx(j)];
      }
    }

    arma::eig_sym(eigval, eigvec, C[idx1]);
    const arma::uvec negativeEigval = arma::find(eigval < 0, 1);
    if (!negativeEigval.is_empty())
    {
      if (negativeEigval(0) == 0)
      {
        C[idx1].zeros();
      }
      else
      {
        C[idx1] = eigvec.cols(0, negativeEigval(0) - 1) *
          arma::diagmat(eigval.subvec(0, negativeEigval(0) - 1)) *
          eigvec.cols(0, negativeEigval(0) - 1).t();
      }
    }

    // Output current objective function.
    Info << "CMA-ES: iteration " << i << ", objective " << overallObjective
      << "." << std::endl;

    if (std::isnan(overallObjective) || std::isinf(overallObjective))
    {
      Warn << "CMA-ES: converged to " << overallObjective << "; "
        << "terminating with failure.  Try a smaller step size?" << std::endl;

      iterate = transformationPolicy.Transform(iterate);
      Callback::EndOptimization(*this, function, iterate, callbacks...);
      return overallObjective;
    }

    if (std::abs(lastObjective - overallObjective) < tolerance)
    {
      if (steps > patience) {
        Info << "CMA-ES: minimized within tolerance " << tolerance << "; "
          << "terminating optimization." << std::endl;

        iterate = transformationPolicy.Transform(iterate);
        Callback::EndOptimization(*this, function, iterate, callbacks...);
        return overallObjective;
      }
    }
    else {
      steps = 0;
    }

    steps++;

    lastObjective = overallObjective;
  }

  iterate = transformationPolicy.Transform(iterate);
  Callback::EndOptimization(*this, function, iterate, callbacks...);
  return overallObjective;
}

} // namespace ens

#endif
/**
 * @file full_selection.hpp
 * @author Marcus Edel
 *
 * Select the full dataset for use in the Evaluation step.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_CMAES_FULL_SELECTION_HPP
#define ENSMALLEN_CMAES_FULL_SELECTION_HPP

namespace ens {

/*
 * Select the full dataset for use in the Evaluation step.
 */
class FullSelection
{
 public:
  /**
   * Select the full dataset to calculate the objective function.
   *
   * @tparam SeparableFunctionType Type of the function to be evaluated.
   * @param function Function to optimize.
   * @param batchSize Batch size to use for each step.
   * @param terminate Whether optimization should be terminated after this call.
   * @param iterate starting point.
   */
  template<typename SeparableFunctionType,
           typename MatType,
           typename... CallbackTypes>
  double Select(SeparableFunctionType& function,
                const size_t batchSize,
                const MatType& iterate,
                bool& terminate,
                CallbackTypes&... callbacks)
  {
    // Find the number of functions to use.
    const size_t numFunctions = function.NumFunctions();

    typename MatType::elem_type objective = 0;
    for (size_t f = 0; f < numFunctions; f += batchSize)
    {
      const size_t effectiveBatchSize = std::min(batchSize, numFunctions - f);
      objective += function.Evaluate(iterate, f, effectiveBatchSize);

      terminate |= Callback::Evaluate(*this, f, iterate, objective,
          callbacks...);
    }

    return objective;
  }
};

} // namespace ens

#endif
/**
 * @file not_empty_transformation.hpp
 * @author Suvarsha Chennareddy
 *
 * Check whether TransformationPolicyType is EmptyTransformation.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef NOT_EMPTY_TRANSFORMATION
#define NOT_EMPTY_TRANSFORMATION

 /*
  This partial specialization is used to throw an exception when the
  TransformationPolicyType is EmptyTransformation and call a
  constructor with parameters 'lowerBound' and 'upperBound' otherwise.
  This shall be removed when the deprecated constructor is removed in
  the next major version of ensmallen.
 */
template<typename T1, typename T2>
struct NotEmptyTransformation : std::true_type {
  void Assign(T1& obj, double lowerBound, double upperBound) {
    obj = T1(lowerBound, upperBound);
  }
};

template<template<typename...> class T, typename... A, typename... B>
struct NotEmptyTransformation<T<A...>, T<B...>> : std::false_type {
  void Assign(T<A...>& obj, double lowerBound, double upperBound) {
    throw std::logic_error("TransformationPolicyType is EmptyTransformation");
  }
};

#endif
/**
 * @file random_selection.hpp
 * @author Marcus Edel
 *
 * Randomly select dataset points for use in the Evaluation step.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_CMAES_RANDOM_SELECTION_HPP
#define ENSMALLEN_CMAES_RANDOM_SELECTION_HPP

namespace ens {

/*
 * Randomly select dataset points for use in the Evaluation step.
 */
class RandomSelection
{
 public:
  /**
   * Constructor for the random selection strategy.
   *
   * @param fraction The dataset fraction used for the selection (Default 0.3).
   */
  RandomSelection(const double fraction = 0.3) : fraction(fraction)
  {
    // Nothing to do here.
  }

  //! Get the dataset fraction.
  double Fraction() const { return fraction; }
  //! Modify the dataset fraction.
  double& Fraction() { return fraction; }

  /**
   * Randomly select dataset points to calculate the objective function.
   *
   * @tparam SeparableFunctionType Type of the function to be evaluated.
   * @param function Function to optimize.
   * @param batchSize Batch size to use for each step.
   * @param terminate Whether optimization should be terminated after this call.
   * @param iterate starting point.
   */
  template<typename SeparableFunctionType,
           typename MatType,
           typename... CallbackTypes>
  double Select(SeparableFunctionType& function,
                const size_t batchSize,
                const MatType& iterate,
                bool& terminate,
                CallbackTypes&... callbacks)
  {
    // Find the number of functions to use.
    const size_t numFunctions = function.NumFunctions();

    typename MatType::elem_type objective = 0;
    for (size_t f = 0; f < std::floor(numFunctions * fraction); f += batchSize)
    {
      const size_t selection = arma::as_scalar(arma::randi<arma::uvec>(
          1, arma::distr_param(0, numFunctions - 1)));
      const size_t effectiveBatchSize = std::min(batchSize,
          numFunctions - selection);

      objective += function.Evaluate(iterate, selection, effectiveBatchSize);

      terminate |= Callback::Evaluate(*this, f, iterate, objective,
          callbacks...);
    }

    return objective;
  }

 private:
  //! Dataset fraction parameter.
  double fraction;
};

} // namespace ens

#endif
/**
 * @file boundary_box_constraint.hpp
 * @author Suvarsha Chennareddy
 *
 * Boundary Box Transformation.
 *
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_CMAES_BOUNDARY_BOX_TRANSFORMATION_HPP
#define ENSMALLEN_CMAES_BOUNDARY_BOX_TRANSFORMATION_HPP

namespace ens {

/**
 * More often than not, coordinates must be bounded by some constraints.
 * In a particular case, the domain of a specific function is restricted 
 * by boundaries.
 * The implemented transformation transforms given coordinates into a region 
 * bounded by the given lower and upper bounds (a box). First, the 
 * coordinates are shifted into a feasible preimage bounded by lowerBound - al
 * and upperBound + au where al and au and calculated internally. 
 * These shifted coordinates are then transformed into coordinates bounded by
 * lower_bound and upper_bound. It is an identity transformation in between
 * the lower and upper bounds.
 * 
 * For more information, check the original implementation in C by N. Hansen:
 * https://github.com/CMA-ES/c-cmaes/blob/master/src/boundary_transformation.c
 *
 * @tparam MatType The matrix type of the coordinates and bounds.
 */
template<typename MatType = arma::mat>
class BoundaryBoxConstraint
{
public:

  /**
   * Construct the boundary box constraint policy.
   */
  BoundaryBoxConstraint()
  { /* Nothing to do. */ }

  /**
   * Construct the boundary box constraint policy.
   *
   * @param lowerBound The lower bound of the coordinates.
   * @param upperBound The upper bound of the coordinates.
   */
  BoundaryBoxConstraint(const MatType& lowerBound,
                        const MatType& upperBound) :
      lowerBound(lowerBound),
      upperBound(upperBound)
  {}
  
  /**
   * Construct the boundary box constraint policy.
   *
   * @param lowerBound The lower bound (for every dimension) of the coordinates.
   * @param upperBound The upper bound (for every dimension) of the coordinates.
   */
  BoundaryBoxConstraint(const typename MatType::elem_type lowerBound,
                        const typename MatType::elem_type upperBound) :
      lowerBound({ (typename MatType::elem_type) lowerBound }),
      upperBound({ (typename MatType::elem_type) upperBound })
  {}

  /**
   * Map the given coordinates to the range 
   * [lowerBound, upperBound]
   *
   * @param x Given coordinates.
   * @return Transformed coordinates.
   */
  MatType Transform(const MatType& x)
  {
    typedef typename MatType::elem_type ElemType;
    double diff, al, au, xlow, xup, r;
    size_t Bi, Bj;
    MatType y = x;
    for (size_t i = 0; i < x.n_rows; i++)
    {
      Bi = (i < lowerBound.n_rows) ? i : (lowerBound.n_rows - 1);
      for (size_t j = 0; j < x.n_cols; j++)
      {
        Bj = (j < lowerBound.n_cols) ? j : (lowerBound.n_cols - 1);

        diff = (upperBound(Bi, Bj) - lowerBound(Bi, Bj)) / 2.0;
        al = std::min(diff, (1 + std::abs(lowerBound(Bi, Bj))) / 20.0);
        au = std::min(diff, (1 + std::abs(upperBound(Bi, Bj))) / 20.0);
        xlow = lowerBound(Bi, Bj) - 2 * al - diff;
        xup = upperBound(Bi, Bj) + 2 * au + diff;
        r = 2 * (2 * diff + al + au);

        // Shift y into feasible pre-image.
        if (y(i, j) < xlow)
        {
          y(i,j) += (ElemType)(r * (1 + (int)((xlow - y(i, j)) / r)));
        }
        if (y(i, j) > xup)
        {
          y(i, j) -= (ElemType)(r * (1 + (int)((y(i, j) - xup) / r)));
        }
        if (y(i, j) < lowerBound(Bi, Bj) - al)
        {
          y(i, j) += (ElemType)(2 * (lowerBound(Bi, Bj) - al - y(i, j)));
        }
        if (y(i, j) > upperBound(Bi, Bj) + au)
        {
          y(i, j) -= (ElemType)(2 * (y(i, j) - upperBound(Bi, Bj) - au));
        }

        // Boundary transformation.
        if (y(i, j) < lowerBound(Bi, Bj) + al)
        {
          y(i, j) = (ElemType)(lowerBound(Bi, Bj) +
            (y(i, j) - (lowerBound(Bi, Bj) - al)) *
            (y(i, j) - (lowerBound(Bi, Bj) - al)) / 4.0 / al);
        }
        else if (y(i,j) > upperBound(Bi,Bj) - au)
        {
          y(i, j) = (ElemType)(upperBound(Bi, Bj) -
            (y(i, j) - (upperBound(Bi, Bj) + au)) *
            (y(i, j) - (upperBound(Bi, Bj) + au)) / 4.0 / au);
        }
      }
    }

    return y;
  }

  /**
   * Return a suitable initial step size.
   *
   * @return initial step size.
   */
  typename MatType::elem_type InitialStepSize()
  { return 0.3 * (upperBound - lowerBound).min(); }

  //! Get the lower bound of decision variables.
  MatType LowerBound() const { return lowerBound; }
  //! Modify the lower bound of decision variables.
  MatType& LowerBound() { return lowerBound; }

  //! Get the upper bound of decision variables.
  MatType UpperBound() const { return upperBound; }
  //! Modify the upper bound of decision variables.
  MatType& UpperBound() { return upperBound; }

private:
  //! Lower bound of decision variables.
  MatType lowerBound;

  //! Upper bound of decision variables.
  MatType upperBound;
};

} // namespace ens

#endif
/**
 * @file empty_transformation.hpp
 * @author Suvarsha Chennareddy
 *
 * Empty Transformation, can also be called an Indentity Transformation.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_CMAES_EMPTY_TRANSFORMATION_HPP
#define ENSMALLEN_CMAES_EMPTY_TRANSFORMATION_HPP

namespace ens {

/**
 * This is an empty transformation. As the name indicates, it does
 * not do anything. It is essentially an identity 
 * transformation and is meant to be used when there are no
 * sorts of constraints on the coordinates.
 *
 * @tparam MatType The matrix type of the coordinates.
 */
template<typename MatType = arma::mat>
class EmptyTransformation
{
 public:
  /**
   * Transforms coordinates to themselves (effectively no transformation).
   *
   * @param x Input coordinates.
   * @return Transformed coordinates (the coordinates themselves).
   */
  MatType Transform(const MatType& x) { return x; }

  /**
   * Return a suitable initial step size.
   *
   * @return initial step size.
   */
  typename MatType::elem_type InitialStepSize() { return 1; }
};

} // namespace ens

#endif
/**
 * @file cne.hpp
 * @author Marcus Edel
 * @author Kartik Nighania
 *
 * Conventional Neural Evolution
 * An optimizer that works like biological evolution which selects best
 * candidates based on their fitness scores and creates new generation by
 * mutation and crossover of population.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_CNE_CNE_HPP
#define ENSMALLEN_CNE_CNE_HPP

namespace ens {

/**
 * Conventional Neural Evolution (CNE) is a class of evolutionary algorithms
 * focused on dealing with fixed topology. This class implements this algorithm
 * as an optimization technique to converge a given function to minima.
 *
 * The algorithm works by creating a fixed number of candidates, with random
 * weights.  Each candidate is tested upon the training set, and a fitness score
 * is assigned to it. Given the selection percentage of best candidates by the
 * user, for a single generation that many percentage of candidates are selected
 * for the next generation and the rest are removed The selected candidates for
 * a particular generation then become the parents for the next generation and
 * evolution takes place.
 *
 * The evolution process basically takes place in two types:
 * - Crossover
 * - Mutation
 *
 * Crossover takes two parents and generates two children from them. Both the
 * children have properties inherited by their parents. The parameters of the
 * parents are mixed using equal probability selection, creating two children.
 * This is just a mix of link weights or the parameters.
 *
 * In mutation parameters are updated by pertubating small noise.
 * If \f$ \Lambda \f$ is the number of weights in the network.
 *
 * \f[ \sum_{n=1}^{\Lambda}\omega_n = \omega_n + \rho, \f]
 *
 * where \f$ \rho \f$ is the small pertubation value determined randomly between
 * 0 and the mutation size given by the user as a constructor parameter. Also
 * the mutation probability taken as a constructor parameter decides the amount
 * of mutation addition into the network.
 *
 * Both the above mentioned processes create new candidates as well as change
 * the existing candidates to obtain better candidates in the next generation.
 *
 * The whole process then repeats for multiple generation until at least one of
 * the termination criteria is met:
 *
 * 1) The final value of the objective function (Not considered if not
 *    provided).
 * 2) The maximum number of generation reached (optional but highly
 *    recommended).
 * 3) Minimum change in best fitness values between two consecutive generations
 *    should be greater than a threshold value (Not considered if not provided).
 *
 * The final value and the parameters are returned by the Optimize() method.
 *
 * CNE can optimize arbitrary functions.  For more details, see the
 * documentation on function types included with this distribution or on the
 * ensmallen website.
 */
class CNE
{
 public:
  /**
   * Constructor for the CNE optimizer.
   *
   * The default values provided over here are not necessarily suitable for a
   * given function. Therefore it is highly recommended to adjust the
   * parameters according to the problem.
   *
   * @param populationSize The number of candidates in the population.
   *     This should be at least 4 in size.
   * @param maxGenerations The maximum number of generations allowed for CNE.
   * @param mutationProb Probability that a weight will get mutated.
   * @param mutationSize The range of mutation noise to be added. This range
   *     is between 0 and mutationSize.
   * @param selectPercent The percentage of candidates to select to become the
   *     the next generation.
   * @param tolerance The final value of the objective function for termination.
   *     If set to negative value, tolerance is not considered.
   */
  CNE(const size_t populationSize = 500,
      const size_t maxGenerations = 5000,
      const double mutationProb = 0.1,
      const double mutationSize = 0.02,
      const double selectPercent = 0.2,
      const double tolerance = 1e-5);

  /**
   * Optimize the given function using CNE. The given
   * starting point will be modified to store the finishing point of the
   * algorithm, and the final objective value is returned.
   *
   * @tparam ArbitraryFunctionType Type of the function to be optimized.
   * @tparam MatType Type of matrix to optimize.
   * @tparam CallbackTypes Types of callback functions.
   * @param function Function to optimize.
   * @param iterate Starting point (will be modified).
   * @param callbacks Callback functions.
   * @return Objective value of the final point.
   */
  template<typename ArbitraryFunctionType,
           typename MatType,
           typename... CallbackTypes>
  typename MatType::elem_type Optimize(ArbitraryFunctionType& function,
                                       MatType& iterate,
                                       CallbackTypes&&... callbacks);

  //! Get the population size.
  size_t PopulationSize() const { return populationSize; }
  //! Modify the population size.
  size_t& PopulationSize() { return populationSize; }

  //! Get maximum number of generations.
  size_t MaxGenerations() const { return maxGenerations; }
  //! Modify maximum number of generations.
  size_t& MaxGenerations() { return maxGenerations; }

  //! Get the mutation probability.
  double MutationProbability() const { return mutationProb; }
  //! Modify the mutation probability.
  double& MutationProbability() { return mutationProb; }

  //! Get the mutation size.
  double MutationSize() const { return mutationSize; }
  //! Modify the mutation size.
  double& MutationSize() { return mutationSize; }

  //! Get the selection percentage.
  double SelectionPercentage() const { return selectPercent; }
  //! Modify the selection percentage.
  double& SelectionPercentage() { return selectPercent; }

  //! Get the tolerance.
  double Tolerance() const { return tolerance; }
  //! Modify the tolerance.
  double& Tolerance() { return tolerance; }

 private:
  //! Reproduce candidates to create the next generation.
  template<typename MatType>
  void Reproduce(std::vector<MatType>& population,
                 const MatType& fitnessValues,
                 arma::uvec& index);

  //! Modify weights with some noise for the evolution of next generation.
  template<typename MatType>
  void Mutate(std::vector<MatType>& population, arma::uvec& index);

  /**
   * Crossover parents and create new childs. Two parents create two new childs.
   *
   * @param mom First parent from the elite population.
   * @param dad Second parent from the elite population.
   * @param dropout1 The place to delete the candidate of the present
   *                 generation and place a child over there for the
   *                 next generation.
   * @param dropout2 The place to delete the candidate of the present
   *                 generation and place a child over there for the
   *                 next generation.
   */
  template<typename MatType>
  void Crossover(std::vector<MatType>& population,
                 const size_t mom,
                 const size_t dad,
                 const size_t dropout1,
                 const size_t dropout2);

  //! The number of candidates in the population.
  size_t populationSize;

  //! Maximum number of generations before termination criteria is met.
  size_t maxGenerations;

  //! Probability that a weight will get mutated.
  double mutationProb;

  //! The range of mutation noise to be added.
  double mutationSize;

  //! The percentage of best candidates to be selected for parents.
  double selectPercent;

  //! The final value of the objective function.
  double tolerance;

  //! Number of candidates to become parent for the next generation.
  size_t numElite;

  //! Store the number of elements in a cube slice or a matrix column.
  size_t elements;
};

} // namespace ens

// Include implementation.
#include "cne_impl.hpp"

#endif
/**
 * @file cne_impl.hpp
 * @author Marcus Edel
 * @author Kartik Nighania
 *
 * Conventional Neural Evolution
 * An optimizer that works like biological evolution which selects best
 * candidates based on their fitness scores and creates new generation by
 * mutation and crossover of population.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_CNE_CNE_IMPL_HPP
#define ENSMALLEN_CNE_CNE_IMPL_HPP

#include "cne.hpp"

namespace ens {

inline CNE::CNE(const size_t populationSize,
                const size_t maxGenerations,
                const double mutationProb,
                const double mutationSize,
                const double selectPercent,
                const double tolerance) :
    populationSize(populationSize),
    maxGenerations(maxGenerations),
    mutationProb(mutationProb),
    mutationSize(mutationSize),
    selectPercent(selectPercent),
    tolerance(tolerance),
    numElite(0),
    elements(0)
{ /* Nothing to do here. */ }

//! Optimize the function.
template<typename ArbitraryFunctionType,
         typename MatType,
         typename... CallbackTypes>
typename MatType::elem_type CNE::Optimize(ArbitraryFunctionType& function,
                                          MatType& iterateIn,
                                          CallbackTypes&&... callbacks)
{
  // Convenience typedefs.
  typedef typename MatType::elem_type ElemType;
  typedef typename MatTypeTraits<MatType>::BaseMatType BaseMatType;

  // Make sure that we have the methods that we need.  Long name...
  traits::CheckArbitraryFunctionTypeAPI<ArbitraryFunctionType,
      BaseMatType>();
  RequireDenseFloatingPointType<BaseMatType>();

  // Vector of fitness values corresponding to each candidate.
  BaseMatType fitnessValues;
  //! Index of sorted fitness values.
  arma::uvec index;

  // Make sure for evolution to work at least four candidates are present.
  if (populationSize < 4)
  {
    throw std::logic_error("CNE::Optimize(): population size should be at least"
        " 4!");
  }

  // Find the number of elite canditates from population.
  numElite = floor(selectPercent * populationSize);

  // Making sure we have even number of candidates to remove and create.
  if ((populationSize - numElite) % 2 != 0)
    numElite--;

  // Terminate if two parents can not be created.
  if (numElite < 2)
  {
    throw std::logic_error("CNE::Optimize(): unable to select two parents. "
        "Increase selection percentage.");
  }

  // Terminate if at least two childs are not possible.
  if ((populationSize - numElite) < 2)
  {
    throw std::logic_error("CNE::Optimize(): no space to accomodate even 2 "
        "children. Increase population size.");
  }

  BaseMatType& iterate = (BaseMatType&) iterateIn;

  // Generate the population based on a Gaussian distribution around the given
  // starting point.
  std::vector<BaseMatType> population;
  for (size_t i = 0 ; i < populationSize; ++i)
  {
    population.push_back(arma::randn<BaseMatType>(iterate.n_rows,
        iterate.n_cols) + iterate);
  }

  // Store the number of elements in the objective matrix.
  elements = iterate.n_rows * iterate.n_cols;

  // Initialize helper variables.
  fitnessValues.set_size(populationSize);

  // Controls early termination of the optimization process.
  bool terminate = false;

  Info << "CNE initialized successfully. Optimization started."
      << std::endl;

  // Find the fitness before optimization using given iterate parameters.
  ElemType lastBestFitness = function.Evaluate(iterate);
  terminate |= Callback::Evaluate(*this, function, iterate, lastBestFitness,
      callbacks...);

  // Iterate until maximum number of generations is obtained.
  Callback::BeginOptimization(*this, function, iterate, callbacks...);
  for (size_t gen = 1; gen <= maxGenerations && !terminate; gen++)
  {
    // Calculating fitness values of all candidates.
    for (size_t i = 0; i < populationSize; i++)
    {
        // Select a candidate and insert the parameters in the function.
        iterate = population[i];
        terminate |= Callback::StepTaken(*this, function, iterate,
            callbacks...);

        // Find fitness of candidate.
        fitnessValues[i] = function.Evaluate(iterate);

        terminate |= Callback::Evaluate(*this, function, iterate,
            fitnessValues[i], callbacks...);
    }

    Info << "Generation number: " << gen << " best fitness = "
        << fitnessValues.min() << std::endl;

    // Create next generation of species.
    Reproduce(population, fitnessValues, index);

    // Check for termination criteria.
    if (std::abs(lastBestFitness - fitnessValues.min()) < tolerance)
    {
      Info << "CNE: minimized within tolerance " << tolerance << "; "
            << "terminating optimization." << std::endl;
      break;
    }

    // Store the best fitness of present generation.
    lastBestFitness = fitnessValues.min();
  }

  // Set the best candidate into the network parameters.
  iterateIn = population[index(0)];

  // The output of the callback doesn't matter because the optimization is
  // finished.
  const ElemType objective = function.Evaluate(iterate);
  (void) Callback::Evaluate(*this, function, iterate, objective, callbacks...);

  Callback::EndOptimization(*this, function, iterate, callbacks...);
  return objective;
}

//! Reproduce candidates to create the next generation.
template<typename MatType>
inline void CNE::Reproduce(std::vector<MatType>& population,
                           const MatType& fitnessValues,
                           arma::uvec& index)
{
  // Sort fitness values. Smaller fitness value means better performance.
  index = arma::sort_index(fitnessValues);

  // First parent.
  size_t mom;

  // Second parent.
  size_t dad;

  for (size_t i = numElite; i < populationSize - 1; i++)
  {
    // Select 2 different parents from elite group randomly [0, numElite).
    mom = arma::as_scalar(arma::randi<arma::uvec>(
          1, arma::distr_param(0, numElite - 1)));

    dad = arma::as_scalar(arma::randi<arma::uvec>(
          1, arma::distr_param(0, numElite - 1)));

    // Making sure both parents are not the same.
    if (mom == dad)
    {
      if (dad != numElite - 1)
      {
        dad++;
      }
      else
      {
        dad--;
      }
    }

    // Parents generate 2 children replacing the dropped-out candidates.
    // Also finding the index of these candidates in the population matrix.
    Crossover(population, index[mom], index[dad], index[i], index[i + 1]);
  }

  // Mutating the weights with small noise values.
  // This is done to bring change in the next generation.
  Mutate(population, index);
}

//! Crossover parents to create new children.
template<typename MatType>
inline void CNE::Crossover(std::vector<MatType>& population,
                           const size_t mom,
                           const size_t dad,
                           const size_t child1,
                           const size_t child2)
{
  // Replace the candidates with parents at their place.
  population[child1] = population[mom];
  population[child2] = population[dad];

  // Randomly alter mom and dad genome weights to get two different children.
  for (size_t i = 0; i < elements; i++)
  {
    // Using it to alter the weights of the children.
    const double random = arma::randu<typename MatType::elem_type>();
    if (random > 0.5)
    {
      population[child1](i) = population[mom](i);
      population[child2](i) = population[dad](i);
    }
    else
    {
      population[child1](i) = population[dad](i);
      population[child2](i) = population[mom](i);
    }
  }
}

//! Modify weights with some noise for the evolution of next generation.
template<typename MatType>
inline void CNE::Mutate(std::vector<MatType>& population, arma::uvec& index)
{
  // Mutate the whole matrix with the given rate and probability.
  // The best candidate is not altered.
  for (size_t i = 1; i < populationSize; i++)
  {
    population[index(i)] += (arma::randu<MatType>(population[index(i)].n_rows,
        population[index(i)].n_cols) < mutationProb) %
        (mutationSize * arma::randn<MatType>(population[index(i)].n_rows,
        population[index(i)].n_cols));
  }
}

} // namespace ens

#endif
/**
 * @file config.hpp
 * @author Conrad Sanderson
 * @author Marcus Edel
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */


#if !defined(ENS_PRINT_INFO)
  // #define ENS_PRINT_INFO
#endif

#if !defined(ENS_PRINT_WARN)
  // #define ENS_PRINT_WARN
#endif

#if defined(ARMA_USE_OPENMP)
  #undef  ENS_USE_OPENMP
  #define ENS_USE_OPENMP
#endif


//


#if defined(ENS_DONT_PRINT_INFO)
  #undef ENS_PRINT_INFO
#endif

#if defined(ENS_DONT_PRINT_WARN)
  #undef ENS_PRINT_WARN
#endif

#if defined(ENS_DONT_USE_OPENMP)
  #undef ENS_USE_OPENMP
#endif


//


#if defined(ENS_USE_OPENMP)
  #define ENS_PRAGMA_OMP_PARALLEL _Pragma("omp parallel")
  #define ENS_PRAGMA_OMP_ATOMIC   _Pragma("omp atomic")
  #define ENS_PRAGMA_OMP_CRITICAL _Pragma("omp critical")
  #define ENS_PRAGMA_OMP_CRITICAL_NAMED _Pragma("omp critical(section)")
#else
  #define ENS_PRAGMA_OMP_PARALLEL
  #define ENS_PRAGMA_OMP_ATOMIC
  #define ENS_PRAGMA_OMP_CRITICAL
  #define ENS_PRAGMA_OMP_CRITICAL_NAMED
#endif


// Define ens_deprecated for deprecated functionality.
// This is adapted from Armadillo's implementation.
#if defined(_MSC_VER)
  #define ens_deprecated __declspec(deprecated)
#elif defined(__GNUG__) && (!defined(__clang__))
  #define ens_deprecated __attribute__((__deprecated__))
#elif defined(__clang__)
  #if __has_attribute(__deprecated__)
    #define ens_deprecated __attribute__((__deprecated__))
  #else
    #define ens_deprecated
  #endif
#else
  #define ens_deprecated
#endif

// undefine conflicting macros
#if defined(As)
  #pragma message ("WARNING: undefined conflicting 'As' macro")
  #undef As
#endif
/**
 * @file de.hpp
 * @author Rahul Ganesh Prabhu
 *
 * Differential Evolution is a method used for global optimization of arbitrary
 * functions that optimizes a problem by iteratively trying to improve a
 * candidate solution.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */

#ifndef ENSMALLEN_DE_DE_HPP
#define ENSMALLEN_DE_DE_HPP

namespace ens {

/**
 * Differential evolution is a stochastic evolutionary algorithm used for global
 * optimization. This class implements the best/1/bin strategy of differential
 * evolution to converge a given function to minima.
 *
 * The algorithm works by generating a fixed number of candidates from the
 * given starting point. At each pass through the population, the algorithm
 * mutates each candidate solution to create a trial solution. If the trial
 * solution is better than the candidate, it is replaced in the
 * population.
 *
 * The evolution takes place in two steps:
 * - Mutation
 * - Crossover
 *
 * Mutation is done by generating a new candidate solution from the best
 * candidate of the previous solution and two random other candidates.
 *
 * Crossover is done by mixing the parameters of the candidate solution and the
 * mutant solution. This is done only if a randomly generated number between 0
 * and 1 is greater than the crossover rate.
 *
 * The final value and the parameters are returned by the Optimize() method.
 *
 * For more information, see the following:
 *
 * @code
 * @techreport{storn1995,
 *   title    = {Differential Evolution‚Äîa simple and efficient adaptive scheme
 *               for global optimization over continuous spaces},
 *   author   = {Storn, Rainer and Price, Kenneth},
 *   year     = 1995
 * }
 * @endcode
 *
 * DE can optimize arbitrary functions.  For more details, see the
 * documentation on function types included with this distribution or on the
 * ensmallen website.
 */
class DE
{
 public:
  /**
   * Constructor for the DE optimizer
   *
   * The default values provided over here are not necessarily suitable for a
   * given function. Therefore it is highly recommended to adjust the
   * parameters according to the problem.
   *
   * @param populationSize The number of candidates in the population.
   *     This should be at least 3 in size.
   * @param maxGenerations The maximum number of generations allowed for CNE.
   * @param crossoverRate  The probability that a crossover will occur.
   * @param differentialWeight A parameter used in the mutation of candidate
   *     solutions controls amplification factor of the differentiation.
   * @param tolerance The final value of the objective function for termination.
   */
  DE(const size_t populationSize = 100,
     const size_t maxGenerations = 2000,
     const double crossoverRate = 0.6,
     const double differentialWeight = 0.8,
     const double tolerance = 1e-5);

  /**
   * Optimize the given function using DE. The given
   * starting point will be modified to store the finishing point of the
   * algorithm, and the final objective value is returned.
   *
   * @tparam FunctionType Type of the function to be optimized.
   * @tparam MatType Type of matrix to optimize.
   * @tparam CallbackTypes Types of callback functions.
   * @param function Function to optimize.
   * @param iterate Starting point (will be modified).
   * @param callbacks Callback functions.
   * @return Objective value of the final point.
   */
  template<typename FunctionType,
           typename MatType,
           typename... CallbackTypes>
  typename MatType::elem_type Optimize(FunctionType& function,
                                       MatType& iterate,
                                       CallbackTypes&&... callbacks);

  //! Get the population size.
  size_t PopulationSize() const { return populationSize; }
  //! Modify the population size.
  size_t& PopulationSize() { return populationSize; }

  //! Get maximum number of generations.
  size_t MaxGenerations() const { return maxGenerations; }
  //! Modify maximum number of generations.
  size_t& MaxGenerations() { return maxGenerations; }

  //! Get crossover rate.
  double CrossoverRate() const { return crossoverRate; }
  //! Modify crossover rate.
  double& CrossoverRate() { return crossoverRate; }

  //! Get differential weight.
  double DifferentialWeight() const {return differentialWeight; }
  //! Modify differential weight.
  double& DifferentialWeight() { return differentialWeight; }

  //! Get the tolerance.
  double Tolerance() const { return tolerance; }
  //! Modify the tolerance.
  double& Tolerance() { return tolerance; }

 private:
  //! The number of candidates in the population.
  size_t populationSize;

  //! Maximum number of generations before termination criteria is met.
  size_t maxGenerations;

  //! Probability that crossover will occur.
  double crossoverRate;

  //! Amplification factor for differentiation.
  double differentialWeight;

  //! The tolerance for termination.
  double tolerance;
};

} // namespace ens

// Include implementation.
#include "de_impl.hpp"

#endif
/**
 * @file de_impl.hpp
 * @author Rahul Ganesh Prabhu
 *
 * Implementation of Differential Evolution an evolutionary algorithm used for
 * global optimization of arbitrary functions.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_DE_DE_IMPL_HPP
#define ENSMALLEN_DE_DE_IMPL_HPP

#include "de.hpp"

namespace ens {

inline DE::DE(const size_t populationSize ,
              const size_t maxGenerations,
              const double crossoverRate,
              const double differentialWeight,
              const double tolerance):
    populationSize(populationSize),
    maxGenerations(maxGenerations),
    crossoverRate(crossoverRate),
    differentialWeight(differentialWeight),
    tolerance(tolerance)
{ /* Nothing to do here. */ }

//!Optimize the function
template<typename FunctionType,
         typename MatType,
         typename... CallbackTypes>
typename MatType::elem_type DE::Optimize(FunctionType& function,
                                         MatType& iterateIn,
                                         CallbackTypes&&... callbacks)
{
  // Convenience typedefs.
  typedef typename MatType::elem_type ElemType;
  typedef typename MatTypeTraits<MatType>::BaseMatType BaseMatType;

  BaseMatType& iterate = (BaseMatType&) iterateIn;

  // Population matrix. Each column is a candidate.
  std::vector<BaseMatType> population;
  population.resize(populationSize);
  // Vector of fitness values corresponding to each candidate.
  arma::Col<ElemType> fitnessValues;

  // Make sure that we have the methods that we need.  Long name...
  traits::CheckArbitraryFunctionTypeAPI<
      FunctionType, BaseMatType>();
  RequireDenseFloatingPointType<BaseMatType>();

  // Population Size must be at least 3 for DE to work.
  if (populationSize < 3)
  {
    throw std::logic_error("CNE::Optimize(): population size should be at least"
        " 3!");
  }

  // Initialize helper variables.
  fitnessValues.set_size(populationSize);
  ElemType lastBestFitness = DBL_MAX;
  BaseMatType bestElement;

  // Controls early termination of the optimization process.
  bool terminate = false;

  // Generate a population based on a Gaussian distribution around the given
  // starting point. Also finds the best element of the population.
  for (size_t i = 0; i < populationSize; i++)
  {
    population[i].randn(iterate.n_rows, iterate.n_cols);
    population[i] += iterate;
    fitnessValues[i] = function.Evaluate(population[i]);

    terminate |= Callback::Evaluate(*this, function, population[i],
        fitnessValues[i], callbacks...);

    if (fitnessValues[i] < lastBestFitness)
    {
      lastBestFitness = fitnessValues[i];
      bestElement = population[i];
    }
  }

  // Iterate until maximum number of generations are completed.
  Callback::BeginOptimization(*this, function, iterate, callbacks...);
  for (size_t gen = 0; gen < maxGenerations && !terminate; gen++)
  {
    // Generate new population based on /best/1/bin strategy.
    for (size_t member = 0; member < populationSize; member++)
    {
      iterate = population[member];

      // Generate two different random numbers to choose two random members.
      size_t l = 0, m = 0;
      do
      {
        l = arma::randi<arma::uword>(arma::distr_param(0, populationSize - 1));
      }
      while (l == member);

      do
      {
        m = arma::randi<arma::uword>(arma::distr_param(0, populationSize - 1));
      }
      while (m == member && m == l);

      // Generate new "mutant" from two randomly chosen members.
      BaseMatType mutant = bestElement + differentialWeight *
          (population[l] - population[m]);

      // Perform crossover.
      const BaseMatType cr = arma::randu<BaseMatType>(iterate.n_rows);
      for (size_t it = 0; it < iterate.n_rows; it++)
      {
        if (cr[it] >= crossoverRate)
        {
          mutant[it] = iterate[it];
        }
      }

      ElemType iterateValue = function.Evaluate(iterate);
      terminate |= Callback::Evaluate(*this, function, iterate, iterateValue,
          callbacks...);

      const ElemType mutantValue = function.Evaluate(mutant);
      terminate |= Callback::Evaluate(*this, function, mutant, mutantValue,
          callbacks...);

      if (terminate)
        break;

      // Replace the current member if mutant is better.
      if (mutantValue < iterateValue)
      {
        iterate = mutant;
        iterateValue = mutantValue;

        terminate |= Callback::StepTaken(*this, function, iterate,
            callbacks...);
      }

      fitnessValues[member] = iterateValue;
      population[member] = iterate;
    }

    // Check for termination criteria.
    if (std::abs(lastBestFitness - fitnessValues.min()) < tolerance)
    {
      Info << "DE: minimized within tolerance " << tolerance << "; "
          << "terminating optimization." << std::endl;
      break;
    }

    // Update helper variables.
    lastBestFitness = fitnessValues.min();
    for (size_t it = 0; it < populationSize; it++)
    {
      if (fitnessValues[it] == lastBestFitness)
      {
        bestElement = population[it];
        break;
      }
    }
  }

  iterate = bestElement;

  Callback::EndOptimization(*this, function, iterate, callbacks...);
  return lastBestFitness;
}

} // namespace ens

#endif
/**
 * @file demon_adam.hpp
 * @author Marcus Edel
 *
 * Definition of DemonAdam.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_DEMON_ADAM_DEMON_ADAM_HPP
#define ENSMALLEN_DEMON_ADAM_DEMON_ADAM_HPP

#include "../sgd/sgd.hpp"
#include "../adam/adam_update.hpp"
#include "../adam/adamax_update.hpp"
#include "../adam/amsgrad_update.hpp"
#include "../adam/nadam_update.hpp"
#include "../adam/nadamax_update.hpp"
#include "../adam/optimisticadam_update.hpp"
#include "demon_adam_update.hpp"

namespace ens {

/**
 * DemonAdam automatically decays momentum, motivated by decaying the total
 * contribution of a gradient to all future updates.
 *
 * For more information, see the following.
 *
 * @code
 * @misc{
 *   title   = {Decaying momentum helps neural network training},
 *   author  = {John Chen and Cameron Wolfe and Zhao Li
 *              and Anastasios Kyrillidis},
 *   url     = {https://arxiv.org/abs/1910.04952}
 *   year    = {2019}
 * }
 *
 * DemonAdam can optimize differentiable separable functions. For more details,
 * see the documentation on function types include with this distribution or on
 * the ensmallen website.
 *
 * @tparam UpdateRule Adam optimizer update rule to be used.
 */
template<typename UpdateRule = AdamUpdate>
class DemonAdamType
{
 public:
  /**
   * Construct the DemonAdam optimizer with the given function and parameters.
   * The defaults here are not necessarily good for the given problem, so it is
   * suggested that the values used be tailored to the task at hand.  The
   * maximum number of iterations refers to the maximum number of points that
   * are processed (i.e., one iteration equals one point; one iteration does not
   * equal one pass over the dataset).
   *
   * @param stepSize Step size for each iteration.
   * @param batchSize Number of points to process in a single step.
   * @param momentum The initial momentum coefficient.
   * @param maxIterations Maximum number of iterations allowed (0 means no
   *     limit).
   * @param beta1 Exponential decay rate for the first moment estimates.
   * @param beta2 Exponential decay rate for the weighted infinity norm
   *     estimates.
   * @param eps Value used to initialise the mean squared gradient parameter.
      * @param tolerance Maximum absolute tolerance to terminate algorithm.
   * @param shuffle If true, the function order is shuffled; otherwise, each
   *     function is visited in linear order.
   * @param resetPolicy If true, parameters are reset before every Optimize
   *     call; otherwise, their values are retained.
   * @param exactObjective Calculate the exact objective (Default: estimate the
   *     final objective obtained on the last pass over the data).
   */
  DemonAdamType(const double stepSize = 0.001,
                const size_t batchSize = 32,
                const double momentum = 0.9,
                const double beta1 = 0.9,
                const double beta2 = 0.999,
                const double eps = 1e-8,
                const size_t maxIterations = 100000,
                const double tolerance = 1e-5,
                const bool shuffle = true,
                const bool resetPolicy = true,
                const bool exactObjective = false) :
      optimizer(stepSize,
                batchSize,
                maxIterations,
                tolerance,
                shuffle,
                DemonAdamUpdate<UpdateRule>(maxIterations * batchSize,
                    momentum, UpdateRule(eps, beta1, beta2)),
                NoDecay(),
                resetPolicy,
                exactObjective)
  { /* Nothing to do here. */ }

  /**
   * Optimize the given function using DemonAdam. The given starting point will
   * be modified to store the finishing point of the algorithm, and the final
   * objective value is returned.
   *
   * @tparam SeparableFunctionType Type of the function to optimize.
   * @tparam MatType Type of matrix to optimize with.
   * @tparam GradType Type of matrix to use to represent function gradients.
   * @tparam CallbackTypes Types of callback functions.
   * @param function Function to optimize.
   * @param iterate Starting point (will be modified).
   * @param callbacks Callback functions.
   * @return Objective value of the final point.
   */
  template<typename SeparableFunctionType,
           typename MatType,
           typename GradType,
           typename... CallbackTypes>
  typename MatType::elem_type Optimize(SeparableFunctionType& function,
                                       MatType& iterate,
                                       CallbackTypes&&... callbacks)
  {
    return optimizer.template Optimize<
        SeparableFunctionType, MatType, GradType, CallbackTypes...>(
        function, iterate, std::forward<CallbackTypes>(callbacks)...);
  }

  //! Forward the MatType as GradType.
  template<typename SeparableFunctionType,
           typename MatType,
           typename... CallbackTypes>
  typename MatType::elem_type Optimize(SeparableFunctionType& function,
                                       MatType& iterate,
                                       CallbackTypes&&... callbacks)
  {
    return Optimize<SeparableFunctionType, MatType, MatType,
        CallbackTypes...>(function, iterate,
        std::forward<CallbackTypes>(callbacks)...);
  }

  //! Get the step size.
  double StepSize() const { return optimizer.StepSize(); }
  //! Modify the step size.
  double& StepSize() { return optimizer.StepSize(); }

  //! Get the batch size.
  size_t BatchSize() const { return optimizer.BatchSize(); }
  //! Modify the batch size.
  size_t& BatchSize() { return optimizer.BatchSize(); }

  //! Get the moment coefficient.
  double Momentum() const { return optimizer.UpdatePolicy().Momentum(); }
  //! Modify the moment coefficient.
  double& Momentum() { return optimizer.UpdatePolicy().Momentum(); }

  //! Get the momentum iteration number.
  size_t MomentumIterations() const
  { return optimizer.UpdatePolicy().MomentumIterations(); }
  //! Modify the momentum iteration number.
  size_t& MomentumIterations()
  { return optimizer.UpdatePolicy().MomentumIterations(); }

  //! Get the maximum number of iterations (0 indicates no limit).
  size_t MaxIterations() const { return optimizer.MaxIterations(); }
  //! Modify the maximum number of iterations (0 indicates no limit).
  size_t& MaxIterations() { return optimizer.MaxIterations(); }

  //! Get the tolerance for termination.
  double Tolerance() const { return optimizer.Tolerance(); }
  //! Modify the tolerance for termination.
  double& Tolerance() { return optimizer.Tolerance(); }

  //! Get whether or not the individual functions are shuffled.
  bool Shuffle() const { return optimizer.Shuffle(); }
  //! Modify whether or not the individual functions are shuffled.
  bool& Shuffle() { return optimizer.Shuffle(); }

  //! Get whether or not the actual objective is calculated.
  bool ExactObjective() const { return optimizer.ExactObjective(); }
  //! Modify whether or not the actual objective is calculated.
  bool& ExactObjective() { return optimizer.ExactObjective(); }

  //! Get whether or not the update policy parameters
  //! are reset before Optimize call.
  bool ResetPolicy() const { return optimizer.ResetPolicy(); }
  //! Modify whether or not the update policy parameters
  //! are reset before Optimize call.
  bool& ResetPolicy() { return optimizer.ResetPolicy(); }

 private:
  //! The Stochastic Gradient Descent object with DemonAdam policy.
  SGD<DemonAdamUpdate<UpdateRule>> optimizer;
};

using DemonAdam = DemonAdamType<AdamUpdate>;

using DemonAdaMax = DemonAdamType<AdaMaxUpdate>;

using DemonAMSGrad = DemonAdamType<AMSGradUpdate>;

using DemonNadam = DemonAdamType<NadamUpdate>;

using DemonNadaMax = DemonAdamType<NadaMaxUpdate>;

using DemonOptimisticAdam = DemonAdamType<OptimisticAdamUpdate>;

} // namespace ens

#endif
/**
 * @file demon_sgd_update.hpp
 * @author Marcus Edel
 *
 * Implementation of DemonAdam.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_DEMON_ADAM_DEMON_ADAM_UPDATE_HPP
#define ENSMALLEN_DEMON_ADAM_DEMON_ADAM_UPDATE_HPP

#include <assert.h>

namespace ens {

/**
 * DemonAdam automatically decays momentum, motivated by decaying the total
 * contribution of a gradient to all future updates.
 *
 * For more information, see the following.
 *
 * @code
 * @misc{
 *   title   = {Decaying momentum helps neural network training},
 *   author  = {John Chen and Cameron Wolfe and Zhao Li
 *              and Anastasios Kyrillidis},
 *   url     = {https://arxiv.org/abs/1910.04952}
 *   year    = {2019}
 * }
 * @endcode
 *
 * @tparam UpdateRule DemonAdam optimizer update rule to be used.
 */
template<typename UpdateRule>
class DemonAdamUpdate
{
 public:
  /**
   * Construct the DemonAdam update policy with the given parameters.
   *
   * @param momentumIterations The number of iterations before the momentum
   *     will decay to zero.
   * @param momentum The initial momentum coefficient.
   * @param adamUpdate Instantiated Adam update policy used to adjust the given
   *     parameters.
   */
  DemonAdamUpdate(const size_t momentumIterations = 100,
                  const double momentum = 0.9,
                  const UpdateRule& adamUpdate = UpdateRule()) :
      T(momentumIterations),
      betaInit(momentum),
      t(0),
      adamUpdateInst(adamUpdate)
  {
    // Make sure the momentum iterations parameter is non-zero.
    assert(momentumIterations != 0 && "The number of iterations before the "
        "momentum will decay is zero, make sure the max iterations and "
        "batch size parameter is set correctly. "
        "Default: momentumIterations = maxIterations / batchSize.");
  }

  //! Get the momentum coefficient.
  double Momentum() const { return betaInit; }
  //! Modify the momentum coefficient.
  double& Momentum() { return betaInit; }

  //! Get the current iteration number.
  size_t Iteration() const { return t; }
  //! Modify the current iteration number.
  size_t& Iteration() { return t; }

  //! Get the momentum ion number.
  size_t MomentumIterations() const { return T; }
  //! Modify the momentum iteration number.
  size_t& MomentumIterations() { return T; }

  /**
   * The UpdatePolicyType policy classes must contain an internal 'Policy'
   * template class with two template arguments: MatType and GradType.  This is
   * instantiated at the start of the optimization, and holds parameters
   * specific to an individual optimization.
   */
  template<typename MatType, typename GradType>
  class Policy
  {
   public:
    // Convenient typedef.
    typedef typename UpdateRule::template Policy<MatType, GradType>
        InstUpdateRuleType;

    /**
     * This constructor is called by the SGD Optimize() method before the start
     * of the iteration update process.
     *
     * @param parent Instantiated PadamUpdate parent object.
     * @param rows Number of rows in the gradient matrix.
     * @param cols Number of columns in the gradient matrix.
     */
    Policy(DemonAdamUpdate& parent,
           const size_t rows,
           const size_t cols) :
      parent(parent),
      adamUpdate(new InstUpdateRuleType(parent.adamUpdateInst, rows, cols))
    { /* Nothing to do here */ }

    /**
     * Clean any memory associated with the Polciy object.
     */
    ~Policy()
    {
      delete adamUpdate;
    }

    /**
     * Update step for DamonAdam.
     *
     * @param iterate Parameters that minimize the function.
     * @param stepSize Step size to be used for the given iteration.
     * @param gradient The gradient matrix.
     */
    void Update(MatType& iterate,
                const double stepSize,
                const GradType& gradient)
    {
      double decayRate = 1;
      if (parent.t > 0)
        decayRate = 1.0 - (double) parent.t / (double) parent.T;

      const double betaDecay = parent.betaInit * decayRate;
      const double beta = betaDecay / ((1.0 - parent.betaInit) + betaDecay);

      // Perform the update.
      iterate *= beta;

      // Apply the adam update.
      adamUpdate->Update(iterate, stepSize, gradient);

      // Increment the iteration counter variable.
      ++parent.t;
    }

   private:
    //! Instantiated parent object.
    DemonAdamUpdate<UpdateRule>& parent;

    //! The update policy.
    InstUpdateRuleType* adamUpdate;
  };

 private:
  //! The number of momentum iterations.
  size_t T;

  //! Initial momentum coefficient.
  double betaInit;

  //! The number of iterations.
  size_t t;

  //! The adam update policy.
  UpdateRule adamUpdateInst;
};

} // namespace ens

#endif
/**
 * @file demon_sgd.hpp
 * @author Marcus Edel
 *
 * Definition of DemonSGD.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_DEMON_SGD_DEMON_SGD_HPP
#define ENSMALLEN_DEMON_SGD_DEMON_SGD_HPP

#include "../sgd/sgd.hpp"
#include "demon_sgd_update.hpp"

namespace ens {

/**
 * DemonSGD automatically decays momentum, motivated by decaying the total
 * contribution of a gradient to all future updates.
 *
 * For more information, see the following.
 *
 * @code
 * @misc{
 *   title   = {Decaying momentum helps neural network training},
 *   author  = {John Chen and Cameron Wolfe and Zhao Li
 *              and Anastasios Kyrillidis},
 *   url     = {https://arxiv.org/abs/1910.04952}
 *   year    = {2019}
 * }
 *
 * DemonSGD can optimize differentiable separable functions. For more details,
 * see the documentation on function types include with this distribution or on
 * the ensmallen website.
 */
class DemonSGD
{
 public:
  /**
   * Construct the DemonSGD optimizer with the given function and parameters.
   * The defaults here are not necessarily good for the given problem, so it is
   * suggested that the values used be tailored to the task at hand.  The
   * maximum number of iterations refers to the maximum number of points that
   * are processed (i.e., one iteration equals one point; one iteration does not
   * equal one pass over the dataset).
   *
   * @param stepSize Step size for each iteration.
   * @param batchSize Number of points to process in a single step.
   * @param momentum The initial momentum coefficient.
   * @param maxIterations Maximum number of iterations allowed (0 means no
   *     limit).
   * @param tolerance Maximum absolute tolerance to terminate algorithm.
   * @param shuffle If true, the function order is shuffled; otherwise, each
   *     function is visited in linear order.
   * @param resetPolicy If true, parameters are reset before every Optimize
   *     call; otherwise, their values are retained.
   * @param exactObjective Calculate the exact objective (Default: estimate the
   *     final objective obtained on the last pass over the data).
   */
  DemonSGD(const double stepSize = 0.001,
           const size_t batchSize = 32,
           const double momentum = 0.9,
           const size_t maxIterations = 100000,
           const double tolerance = 1e-5,
           const bool shuffle = true,
           const bool resetPolicy = true,
           const bool exactObjective = false) :
      optimizer(stepSize,
                batchSize,
                maxIterations,
                tolerance,
                shuffle,
                DemonSGDUpdate(maxIterations * batchSize, momentum),
                NoDecay(),
                resetPolicy,
                exactObjective)
  { /* Nothing to do here. */ }

  /**
   * Optimize the given function using DemonSGD. The given starting point will
   * be modified to store the finishing point of the algorithm, and the final
   * objective value is returned.
   *
   * @tparam SeparableFunctionType Type of the function to optimize.
   * @tparam MatType Type of matrix to optimize with.
   * @tparam GradType Type of matrix to use to represent function gradients.
   * @tparam CallbackTypes Types of callback functions.
   * @param function Function to optimize.
   * @param iterate Starting point (will be modified).
   * @param callbacks Callback functions.
   * @return Objective value of the final point.
   */
  template<typename SeparableFunctionType,
           typename MatType,
           typename GradType,
           typename... CallbackTypes>
  typename MatType::elem_type Optimize(SeparableFunctionType& function,
                                       MatType& iterate,
                                       CallbackTypes&&... callbacks)
  {
    return optimizer.template Optimize<
        SeparableFunctionType, MatType, GradType, CallbackTypes...>(
        function, iterate, std::forward<CallbackTypes>(callbacks)...);
  }

  //! Forward the MatType as GradType.
  template<typename SeparableFunctionType,
           typename MatType,
           typename... CallbackTypes>
  typename MatType::elem_type Optimize(SeparableFunctionType& function,
                                       MatType& iterate,
                                       CallbackTypes&&... callbacks)
  {
    return Optimize<SeparableFunctionType, MatType, MatType,
        CallbackTypes...>(function, iterate,
        std::forward<CallbackTypes>(callbacks)...);
  }

  //! Get the step size.
  double StepSize() const { return optimizer.StepSize(); }
  //! Modify the step size.
  double& StepSize() { return optimizer.StepSize(); }

  //! Get the batch size.
  size_t BatchSize() const { return optimizer.BatchSize(); }
  //! Modify the batch size.
  size_t& BatchSize() { return optimizer.BatchSize(); }

  //! Get the moment coefficient.
  double Momentum() const { return optimizer.UpdatePolicy().Momentum(); }
  //! Modify the moment coefficient.
  double& Momentum() { return optimizer.UpdatePolicy().Momentum(); }

  //! Get the momentum iteration number.
  size_t MomentumIterations() const
  { return optimizer.UpdatePolicy().MomentumIterations(); }
  //! Modify the momentum iteration number.
  size_t& MomentumIterations()
  { return optimizer.UpdatePolicy().MomentumIterations(); }

  //! Get the maximum number of iterations (0 indicates no limit).
  size_t MaxIterations() const { return optimizer.MaxIterations(); }
  //! Modify the maximum number of iterations (0 indicates no limit).
  size_t& MaxIterations() { return optimizer.MaxIterations(); }

  //! Get the tolerance for termination.
  double Tolerance() const { return optimizer.Tolerance(); }
  //! Modify the tolerance for termination.
  double& Tolerance() { return optimizer.Tolerance(); }

  //! Get whether or not the individual functions are shuffled.
  bool Shuffle() const { return optimizer.Shuffle(); }
  //! Modify whether or not the individual functions are shuffled.
  bool& Shuffle() { return optimizer.Shuffle(); }

  //! Get whether or not the actual objective is calculated.
  bool ExactObjective() const { return optimizer.ExactObjective(); }
  //! Modify whether or not the actual objective is calculated.
  bool& ExactObjective() { return optimizer.ExactObjective(); }

  //! Get whether or not the update policy parameters
  //! are reset before Optimize call.
  bool ResetPolicy() const { return optimizer.ResetPolicy(); }
  //! Modify whether or not the update policy parameters
  //! are reset before Optimize call.
  bool& ResetPolicy() { return optimizer.ResetPolicy(); }

 private:
  //! The Stochastic Gradient Descent object with DemonSGD policy.
  SGD<DemonSGDUpdate> optimizer;
};

} // namespace ens

#endif
/**
 * @file demon_sgd_update.hpp
 * @author Marcus Edel
 *
 * Implementation of DemonSGD.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_DEMON_SGD_DEMON_SGD_UPDATE_HPP
#define ENSMALLEN_DEMON_SGD_DEMON_SGD_UPDATE_HPP

namespace ens {

/**
 * DemonSGD automatically decays momentum, motivated by decaying the total
 * contribution of a gradient to all future updates.
 *
 * For more information, see the following.
 *
 * @code
 * @misc{
 *   title   = {Decaying momentum helps neural network training},
 *   author  = {John Chen and Cameron Wolfe and Zhao Li
 *              and Anastasios Kyrillidis},
 *   url     = {https://arxiv.org/abs/1910.04952}
 *   year    = {2019}
 * }
 * @endcode
 */
class DemonSGDUpdate
{
 public:
  /**
   * Construct the DemonSGD update policy with the given parameters.
   *
   * @param momentumIterations The number of iterations before the momentum
   *     will decay to zero.
   * @param momentum The initial momentum coefficient.
   */
  DemonSGDUpdate(const size_t momentumIterations = 100,
                 const double momentum = 0.9) :
      T(momentumIterations),
      betaInit(momentum),
      t(0)
  {
    // Make sure the momentum iterations parameter is non-zero.
    assert(momentumIterations != 0 && "The number of iterations before the "
        "momentum will decay is zero, make sure the max iterations and "
        "batch size parameter is set correctly. "
        "Default: momentumIterations = maxIterations * batchSize.");
  }

  //! Get the momentum coefficient.
  double Momentum() const { return betaInit; }
  //! Modify the momentum coefficient.
  double& Momentum() { return betaInit; }

  //! Get the current iteration number.
  size_t Iteration() const { return t; }
  //! Modify the current iteration number.
  size_t& Iteration() { return t; }

  //! Get the momentum iteration number.
  size_t MomentumIterations() const { return T; }
  //! Modify the momentum iteration number.
  size_t& MomentumIterations() { return T; }

  /**
   * The UpdatePolicyType policy classes must contain an internal 'Policy'
   * template class with two template arguments: MatType and GradType.  This is
   * instantiated at the start of the optimization, and holds parameters
   * specific to an individual optimization.
   */
  template<typename MatType, typename GradType>
  class Policy
  {
   public:
    /**
     * This constructor is called by the SGD Optimize() method before the start
     * of the iteration update process.
     *
     * @param parent Instantiated PadamUpdate parent object.
     * @param rows Number of rows in the gradient matrix.
     * @param cols Number of columns in the gradient matrix.
     */
    Policy(DemonSGDUpdate& parent,
           const size_t /* rows */,
           const size_t /* cols */) :
      parent(parent)
    { /* Nothing to do here */ }

    /**
     * Update step for DemonSGD.
     *
     * @param iterate Parameters that minimize the function.
     * @param stepSize Step size to be used for the given iteration.
     * @param gradient The gradient matrix.
     */
    void Update(MatType& iterate,
                const double stepSize,
                const GradType& gradient)
    {
      double decayRate = 1;
      if (parent.t > 0)
        decayRate = 1.0 - (double) parent.t / (double) parent.T;

      const double betaDecay = parent.betaInit * decayRate;
      const double beta = betaDecay / ((1.0 - parent.betaInit) + betaDecay);

      // Perform the update.
      iterate *= beta;
      iterate -= stepSize * gradient;

      // Increment the iteration counter variable.
      ++parent.t;
    }

   private:
    //! Instantiated parent object.
    DemonSGDUpdate& parent;
  };

 private:
  //! The number of momentum iterations.
  size_t T;

  //! Initial momentum coefficient.
  double betaInit;

  //! The number of iterations.
  size_t t;
};

} // namespace ens

#endif
/**
 * @file ens_version.hpp
 * @author Conrad Sanderson
 * @author Ryan Curtin
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */


// This follows the Semantic Versioning pattern defined in https://semver.org/.

#define ENS_VERSION_MAJOR 2
// The minor version is two digits so regular numerical comparisons of versions
// work right.  The first minor version of a release is always 10.
#define ENS_VERSION_MINOR 20
#define ENS_VERSION_PATCH 0
// If this is a release candidate, it will be reflected in the version name
// (i.e. the version name will be "RC1", "RC2", etc.).  Otherwise the version
// name will typically be a seemingly arbitrary set of words that does not
// contain the capitalized string "RC".
#define ENS_VERSION_NAME "Stripped Bolt Head"
// Incorporate the date the version was released.
#define ENS_VERSION_YEAR "2023"
#define ENS_VERSION_MONTH "10"
#define ENS_VERSION_DAY "02"

namespace ens {

struct version
{
  static const unsigned int major = ENS_VERSION_MAJOR;
  static const unsigned int minor = ENS_VERSION_MINOR;
  static const unsigned int patch = ENS_VERSION_PATCH;

  static inline std::string as_string()
  {
    const char* nickname = ENS_VERSION_NAME;

    std::stringstream ss;
    ss << version::major << '.' << version::minor << '.' << version::patch
       << " (" << nickname << ')';

    return ss.str();
  }
    
  static inline std::string date()
  {
    std::stringstream ss;
    ss << ENS_VERSION_YEAR << '-' << ENS_VERSION_MONTH << '-' << ENS_VERSION_DAY;

    return ss.str();
  }
};

} // namespace ens
/**
 * @file eve.hpp
 * @author Marcus Edel
 *
 * Eve: a gradient based optimization method with Locally
 * and globally adaptive learning rates.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_EVE_EVE_HPP
#define ENSMALLEN_EVE_EVE_HPP

namespace ens {

/**
 * Eve is a stochastic gradient based optimization method with locally and
 * globally adaptive learning rates. Stochastic Gradient Descent is a
 * technique for minimizing a function which can be expressed as a sum of other
 * functions.
 *
 * For more information, see the following.
 *
 * @code
 * @article{Koushik2016,
 *   author  = {Jayanth Koushik and Hiroaki Hayashi},
 *   title   = {Improving Stochastic Gradient Descent with Feedback},
 *   journal = {CoRR},
 *   year    = {2016},
 *   url     = {http://arxiv.org/abs/1611.01505}
 * }
 * @endcode
 *
 * For Eve to work, a SeparableFunctionType template parameter is required.
 * This class must implement the following function:
 *
 *   size_t NumFunctions();
 *   double Evaluate(const arma::mat& coordinates,
 *                   const size_t i,
 *                   const size_t batchSize);
 *   void Gradient(const arma::mat& coordinates,
 *                 const size_t i,
 *                 arma::mat& gradient,
 *                 const size_t batchSize);
 *
 * Eve can optimize differentiable separable functions.  For more details,
 * see the documentation on function types included with this distribution or on
 * the ensmallen website.
 */
class Eve
{
 public:
  /**
   * Construct the Eve optimizer with the given function and parameters. The
   * defaults here are not necessarily good for the given problem, so it is
   * suggested that the values used be tailored to the task at hand.  The
   * maximum number of iterations refers to the maximum number of points that
   * are processed (i.e., one iteration equals one point; one iteration does not
   * equal one pass over the dataset).
   *
   * @param stepSize Step size for each iteration.
   * @param batchSize Number of points to process in a single step.
   * @param beta1 Exponential decay rate for the first moment estimates.
   * @param beta2 Exponential decay rate for the weighted infinity norm
   *        estimates.
   * @param beta3 Exponential decay rate for relative change.
   * @param epsilon Value used to initialise the mean squared gradient parameter.
   * @param clip Clipping range to avoid extreme valus.
   * @param maxIterations Maximum number of iterations allowed (0 means no
   *        limit).
   * @param tolerance Maximum absolute tolerance to terminate algorithm.
   * @param shuffle If true, the function order is shuffled; otherwise, each
   *        function is visited in linear order.
   * @param exactObjective Calculate the exact objective (Default: estimate the
   *        final objective obtained on the last pass over the data).
   */
  Eve(const double stepSize = 0.001,
      const size_t batchSize = 32,
      const double beta1 = 0.9,
      const double beta2 = 0.999,
      const double beta3 = 0.999,
      const double epsilon = 1e-8,
      const double clip = 10,
      const size_t maxIterations = 100000,
      const double tolerance = 1e-5,
      const bool shuffle = true,
      const bool exactObjective = false);

  /**
   * Optimize the given function using Eve. The given starting point will be
   * modified to store the finishing point of the algorithm, and the final
   * objective value is returned.
   *
   * @tparam SeparableFunctionType Type of the function to be optimized.
   * @tparam MatType Type of the parameters matrix.
   * @tparam GradType Type of the gradient matrix.
   * @tparam CallbackTypes Types of callback functions.
   * @param function Function to optimize.
   * @param iterate Starting point (will be modified).
   * @param callbacks Callback functions.
   * @return Objective value of the final point.
   */
  template<typename SeparableFunctionType,
           typename MatType,
           typename GradType,
           typename... CallbackTypes>
  typename std::enable_if<IsArmaType<GradType>::value,
      typename MatType::elem_type>::type
  Optimize(SeparableFunctionType& function,
           MatType& iterate,
           CallbackTypes&&... callbacks);

  //! Forward the MatType as GradType.
  template<typename SeparableFunctionType,
           typename MatType,
           typename... CallbackTypes>
  typename MatType::elem_type Optimize(SeparableFunctionType& function,
                                       MatType& iterate,
                                       CallbackTypes&&... callbacks)
  {
    return Optimize<SeparableFunctionType, MatType, MatType,
        CallbackTypes...>(function, iterate,
        std::forward<CallbackTypes>(callbacks)...);
  }

  //! Get the step size.
  double StepSize() const { return stepSize; }
  //! Modify the step size.
  double& StepSize() { return stepSize; }

  //! Get the batch size.
  size_t BatchSize() const { return batchSize; }
  //! Modify the batch size.
  size_t& BatchSize() { return batchSize; }

  //! Get the smoothing parameter.
  double Beta1() const { return beta1; }
  //! Modify the smoothing parameter.
  double& Beta1() { return beta1; }

  //! Get the second moment coefficient.
  double Beta2() const { return beta2; }
  //! Modify the second moment coefficient.
  double& Beta2() { return beta2; }

  //! Get the exponential decay rate for relative change.
  double Beta3() const { return beta3; }
  //! Modify the exponential decay rate for relative change.
  double& Beta3() { return beta3; }

  //! Get the value used to initialise the mean squared gradient parameter.
  double Epsilon() const { return epsilon; }
  //! Modify the value used to initialise the mean squared gradient parameter.
  double& Epsilon() { return epsilon; }

  //! Get the clipping range to avoid extreme valus.
  double Clip() const { return clip; }
  //! Modify the clipping range to avoid extreme valus.
  double& Clip() { return clip; }

  //! Get the maximum number of iterations (0 indicates no limit).
  size_t MaxIterations() const { return maxIterations; }
  //! Modify the maximum number of iterations (0 indicates no limit).
  size_t& MaxIterations() { return maxIterations; }

  //! Get the tolerance for termination.
  double Tolerance() const { return tolerance; }
  //! Modify the tolerance for termination.
  double& Tolerance() { return tolerance; }

  //! Get whether or not the individual functions are shuffled.
  bool Shuffle() const { return shuffle; }
  //! Modify whether or not the individual functions are shuffled.
  bool& Shuffle() { return shuffle; }

  //! Get whether or not the actual objective is calculated.
  bool ExactObjective() const { return exactObjective; }
  //! Modify whether or not the actual objective is calculated.
  bool& ExactObjective() { return exactObjective; }

 private:
  //! The step size for each example.
  double stepSize;

  //! The batch size for processing.
  size_t batchSize;

  //! The smoothing parameter.
  double beta1;

  //! The second moment coefficient.
  double beta2;

  //! The third moment coefficient.
  double beta3;

  //! The epsilon value used to initialise the squared gradient parameter.
  double epsilon;

  //! The clip value used to clip the term to avoid extreme values.
  double clip;

  //! The maximum number of allowed iterations.
  size_t maxIterations;

  //! The tolerance for termination.
  double tolerance;

  //! Controls whether or not the individual functions are shuffled when
  //! iterating.
  bool shuffle;

  //! Controls whether or not the actual Objective value is calculated.
  bool exactObjective;
};

} // namespace ens

// Include implementation.
#include "eve_impl.hpp"

#endif
/**
 * @file eve_impl.hpp
 * @author Marcus Edel
 *
 * Implementation of Eve: a gradient based optimization method with Locally
 * and globally adaptive learning rates.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_EVE_EVE_IMPL_HPP
#define ENSMALLEN_EVE_EVE_IMPL_HPP

// In case it hasn't been included yet.
#include "eve.hpp"

#include <ensmallen_bits/function.hpp>

namespace ens {

inline Eve::Eve(const double stepSize,
                const size_t batchSize,
                const double beta1,
                const double beta2,
                const double beta3,
                const double epsilon,
                const double clip,
                const size_t maxIterations,
                const double tolerance,
                const bool shuffle,
                const bool exactObjective) :
    stepSize(stepSize),
    batchSize(batchSize),
    beta1(beta1),
    beta2(beta2),
    beta3(beta3),
    epsilon(epsilon),
    clip(clip),
    maxIterations(maxIterations),
    tolerance(tolerance),
    shuffle(shuffle),
    exactObjective(exactObjective)
{ /* Nothing to do. */ }

//! Optimize the function (minimize).
template<typename SeparableFunctionType,
         typename MatType,
         typename GradType,
         typename... CallbackTypes>
typename std::enable_if<IsArmaType<GradType>::value,
typename MatType::elem_type>::type
Eve::Optimize(SeparableFunctionType& function,
              MatType& iterateIn,
              CallbackTypes&&... callbacks)
{
  // Convenience typedefs.
  typedef typename MatType::elem_type ElemType;
  typedef typename MatTypeTraits<MatType>::BaseMatType BaseMatType;
  typedef typename MatTypeTraits<GradType>::BaseMatType BaseGradType;

  typedef Function<SeparableFunctionType, BaseMatType, BaseGradType>
      FullFunctionType;
  FullFunctionType& f(static_cast<FullFunctionType&>(function));

  // Make sure we have all the methods that we need.
  traits::CheckSeparableFunctionTypeAPI<FullFunctionType, BaseMatType,
      BaseGradType>();
  RequireFloatingPointType<BaseMatType>();
  RequireFloatingPointType<BaseGradType>();
  RequireSameInternalTypes<BaseMatType, BaseGradType>();

  BaseMatType& iterate = (BaseMatType&) iterateIn;

  // Find the number of functions to use.
  const size_t numFunctions = f.NumFunctions();

  // To keep track of where we are and how things are going.
  size_t currentFunction = 0;
  size_t epoch = 1;
  ElemType overallObjective = 0;
  ElemType lastOverallObjective = DBL_MAX;

  ElemType objective = 0;
  ElemType lastObjective = 0;
  ElemType dt = 1;

  // Controls early termination of the optimization process.
  bool terminate = false;

  // The exponential moving average of gradient values.
  BaseGradType m(iterate.n_rows, iterate.n_cols);
  m.zeros();

  // The exponential moving average of squared gradient values.
  BaseGradType v(iterate.n_rows, iterate.n_cols);
  v.zeros();

  // Now iterate!
  Callback::BeginOptimization(*this, f, iterate, callbacks...);
  BaseGradType gradient(iterate.n_rows, iterate.n_cols);
  const size_t actualMaxIterations = (maxIterations == 0) ?
      std::numeric_limits<size_t>::max() : maxIterations;
  for (size_t i = 0; i < actualMaxIterations && !terminate;
      /* incrementing done manually */)
  {
    // Find the effective batch size; we have to take the minimum of three
    // things:
    // - the batch size can't be larger than the user-specified batch size;
    // - the batch size can't be larger than the number of iterations left
    //       before actualMaxIterations is hit;
    // - the batch size can't be larger than the number of functions left.
    const size_t effectiveBatchSize = std::min(
        std::min(batchSize, actualMaxIterations - i),
        numFunctions - currentFunction);

    // Technically we are computing the objective before we take the step, but
    // for many FunctionTypes it may be much quicker to do it like this.
    objective = f.EvaluateWithGradient(iterate, currentFunction,
        gradient, effectiveBatchSize);
    overallObjective += objective;

    terminate |= Callback::EvaluateWithGradient(*this, f, iterate,
        objective, gradient, callbacks...);
    if (terminate)
      break;

    m *= beta1;
    m += (1 - beta1) * gradient;

    v *= beta2;
    v += (1 - beta2) * (gradient % gradient);

    const double biasCorrection1 = 1.0 - std::pow(beta1, (double) (i + 1));
    const double biasCorrection2 = 1.0 - std::pow(beta2, (double) (i + 1));

    if (i > 0)
    {
      const ElemType d = std::abs(objective - lastObjective) /
          (std::min(objective, lastObjective) + epsilon);

      dt *= beta3;
      dt += (1 - beta3) * std::min(std::max(d, ElemType(1.0 / clip)),
          ElemType(clip));
    }

    lastObjective = objective;

    iterate -= stepSize / dt * (m / biasCorrection1) /
        (arma::sqrt(v / biasCorrection2) + epsilon);

    terminate |= Callback::StepTaken(*this, f, iterate, callbacks...);

    i += effectiveBatchSize;
    currentFunction += effectiveBatchSize;

    // Is this iteration the start of a sequence?
    if ((currentFunction % numFunctions) == 0)
    {
      terminate |= Callback::EndEpoch(*this, f, iterate, epoch++,
          overallObjective / (ElemType) numFunctions, callbacks...);

      // Output current objective function.
      Info << "Eve: iteration " << i << ", objective " << overallObjective
          << "." << std::endl;

      if (std::isnan(overallObjective) || std::isinf(overallObjective))
      {
        Warn << "Eve: converged to " << overallObjective << "; terminating"
            << " with failure.  Try a smaller step size?" << std::endl;

        Callback::EndOptimization(*this, f, iterate, callbacks...);
        return overallObjective;
      }

      if (std::abs(lastOverallObjective - overallObjective) < tolerance)
      {
        Info << "Eve: minimized within tolerance " << tolerance << "; "
            << "terminating optimization." << std::endl;

        Callback::EndOptimization(*this, f, iterate, callbacks...);
        return overallObjective;
      }

      terminate |= Callback::BeginEpoch(*this, f, iterate, epoch,
          overallObjective, callbacks...);

      // Reset the counter variables.
      lastOverallObjective = overallObjective;
      overallObjective = 0;
      currentFunction = 0;

      if (shuffle) // Determine order of visitation.
        f.Shuffle();
    }
  }

  Info << "Eve: maximum iterations (" << maxIterations << ") reached; "
      << "terminating optimization." << std::endl;

  // Calculate final objective if exactObjective is set to true.
  if (exactObjective)
  {
    overallObjective = 0;
    for (size_t i = 0; i < numFunctions; i += batchSize)
    {
      const size_t effectiveBatchSize = std::min(batchSize, numFunctions - i);
      const ElemType objective = f.Evaluate(iterate, i, effectiveBatchSize);
      overallObjective += objective;

      // The optimization is finished, so we don't need to care about the result
      // of the callback.
      (void) Callback::Evaluate(*this, f, iterate, objective, callbacks...);
    }
  }

  Callback::EndOptimization(*this, f, iterate, callbacks...);
  return overallObjective;
}

} // namespace ens

#endif
/**
 * @file ftml.hpp
 * @author Marcus Edel
 *
 * Definition of Follow the Moving Leader (FTML).
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_FTML_FTML_HPP
#define ENSMALLEN_FTML_FTML_HPP

#include <ensmallen_bits/sgd/sgd.hpp>

#include "ftml_update.hpp"

namespace ens {

/**
 * Follow the Moving Leader (FTML) is an optimizer where recent samples are
 * weighted more heavily in each iteration, so FTML can adapt more quickly to
 * changes.
 *
 * For more information, see the following.
 *
 * @code
 * @inproceedings{Zheng2017,
 *   author    = {Shuai Zheng and James T. Kwok},
 *   title     = {Follow the Moving Leader in Deep Learning},
 *   year      = {2017}
 *   booktitle = {Proceedings of the 34th International Conference on Machine
 *                Learning},
 *   pages     = {4110--4119},
 *   series    = {Proceedings of Machine Learning Research},
 *   publisher = {PMLR},
 * }
 * @endcode
 *
 * FTML can optimize differentiable separable functions.  For more details, see
 * the documentation on function types include with this distribution or on the
 * ensmallen website.
 */
class FTML
{
 public:
  /**
   * Construct the FTML optimizer with the given function and parameters. The
   * defaults here are not necessarily good for the given problem, so it is
   * suggested that the values used be tailored to the task at hand.  The
   * maximum number of iterations refers to the maximum number of points that
   * are processed (i.e., one iteration equals one point; one iteration does not
   * equal one pass over the dataset).
   *
   * @param stepSize Step size for each iteration.
   * @param batchSize Number of points to process in a single step.
   * @param beta1 Exponential decay rate for the first moment estimates.
   * @param beta2 Exponential decay rate for the weighted infinity norm
            estimates.
   * @param epsilon Epsilon is the minimum allowed gradient.
   * @param maxIterations Maximum number of iterations allowed (0 means no
   *        limit).
   * @param tolerance Maximum absolute tolerance to terminate algorithm.
   * @param shuffle If true, the function order is shuffled; otherwise, each
   *        function is visited in linear order.
   * @param resetPolicy If true, parameters are reset before every Optimize
   *        call; otherwise, their values are retained.
   * @param exactObjective Calculate the exact objective (Default: estimate the
   *        final objective obtained on the last pass over the data).
   */
  FTML(const double stepSize = 0.001,
       const size_t batchSize = 32,
       const double beta1 = 0.9,
       const double beta2 = 0.999,
       const double epsilon = 1e-8,
       const size_t maxIterations = 100000,
       const double tolerance = 1e-5,
       const bool shuffle = true,
       const bool resetPolicy = true,
       const bool exactObjective = false);

  /**
   * Optimize the given function using FTML. The given starting point will
   * be modified to store the finishing point of the algorithm, and the final
   * objective value is returned.
   *
   * @tparam SeparableFunctionType Type of the function to be optimized.
   * @tparam MatType Type of matrix to optimize with.
   * @tparam GradType Type of matrix to use to represent function gradients.
   * @tparam CallbackTypes Types of callback functions.
   * @param function Function to optimize.
   * @param iterate Starting point (will be modified).
   * @param callbacks Callback functions.
   * @return Objective value of the final point.
   */
  template<typename SeparableFunctionType,
           typename MatType,
           typename GradType,
           typename... CallbackTypes>
  typename std::enable_if<IsArmaType<GradType>::value,
      typename MatType::elem_type>::type
  Optimize(SeparableFunctionType& function,
           MatType& iterate,
           CallbackTypes&&... callbacks)
  {
    return optimizer.Optimize<SeparableFunctionType, MatType, GradType,
        CallbackTypes...>(function, iterate,
        std::forward<CallbackTypes>(callbacks)...);
  }

  //! Forward the MatType as GradType.
  template<typename SeparableFunctionType,
           typename MatType,
           typename... CallbackTypes>
  typename MatType::elem_type Optimize(SeparableFunctionType& function,
                                       MatType& iterate,
                                       CallbackTypes&&... callbacks)
  {
    return Optimize<SeparableFunctionType, MatType, MatType,
        CallbackTypes...>(function, iterate,
        std::forward<CallbackTypes>(callbacks)...);
  }

  //! Get the step size.
  double StepSize() const { return optimizer.StepSize(); }
  //! Modify the step size.
  double& StepSize() { return optimizer.StepSize(); }

  //! Get the batch size.
  size_t BatchSize() const { return optimizer.BatchSize(); }
  //! Modify the batch size.
  size_t& BatchSize() { return optimizer.BatchSize(); }

  //! Get the smoothing parameter.
  double Beta1() const { return optimizer.UpdatePolicy().Beta1(); }
  //! Modify the smoothing parameter.
  double& Beta1() { return optimizer.UpdatePolicy().Beta1(); }

  //! Get the second moment coefficient.
  double Beta2() const { return optimizer.UpdatePolicy().Beta2(); }
  //! Modify the second moment coefficient.
  double& Beta2() { return optimizer.UpdatePolicy().Beta2(); }

  //! Get the value used to initialise the mean squared gradient parameter.
  double Epsilon() const { return optimizer.UpdatePolicy().Epsilon(); }
  //! Modify the value used to initialise the mean squared gradient parameter.
  double& Epsilon() { return optimizer.UpdatePolicy().Epsilon(); }

  //! Get the maximum number of iterations (0 indicates no limit).
  size_t MaxIterations() const { return optimizer.MaxIterations(); }
  //! Modify the maximum number of iterations (0 indicates no limit).
  size_t& MaxIterations() { return optimizer.MaxIterations(); }

  //! Get the tolerance for termination.
  double Tolerance() const { return optimizer.Tolerance(); }
  //! Modify the tolerance for termination.
  double& Tolerance() { return optimizer.Tolerance(); }

  //! Get whether or not the individual functions are shuffled.
  bool Shuffle() const { return optimizer.Shuffle(); }
  //! Modify whether or not the individual functions are shuffled.
  bool& Shuffle() { return optimizer.Shuffle(); }

  //! Get whether or not the actual objective is calculated.
  bool ExactObjective() const { return optimizer.ExactObjective(); }
  //! Modify whether or not the actual objective is calculated.
  bool& ExactObjective() { return optimizer.ExactObjective(); }

  //! Get whether or not the update policy parameters
  //! are reset before Optimize call.
  bool ResetPolicy() const { return optimizer.ResetPolicy(); }
  //! Modify whether or not the update policy parameters
  //! are reset before Optimize call.
  bool& ResetPolicy() { return optimizer.ResetPolicy(); }

 private:
  //! The Stochastic Gradient Descent object with the FTMLUpdate update policy.
  SGD<FTMLUpdate> optimizer;
};

} // namespace ens

// Include implementation.
#include "ftml_impl.hpp"

#endif
/**
 * @file ftml_impl.hpp
 * @author Marcus Edel
 *
 * Implementation of the Follow the Moving Leader (FTML) optimizer.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_FTML_FTML_IMPL_HPP
#define ENSMALLEN_FTML_FTML_IMPL_HPP

// In case it hasn't been included yet.
#include "ftml.hpp"

namespace ens {

inline FTML::FTML(const double stepSize,
                  const size_t batchSize,
                  const double beta1,
                  const double beta2,
                  const double epsilon,
                  const size_t maxIterations,
                  const double tolerance,
                  const bool shuffle,
                  const bool resetPolicy,
                  const bool exactObjective) :
    optimizer(stepSize,
              batchSize,
              maxIterations,
              tolerance,
              shuffle,
              FTMLUpdate(epsilon, beta1, beta2),
              NoDecay(),
              resetPolicy,
              exactObjective)
{ /* Nothing to do. */ }

} // namespace ens

#endif
/**
 * @file ftml_update.hpp
 * @author Marcus Edel
 *
 * FTML update for Follow the Moving Leader.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_FTML_FTML_UPDATE_HPP
#define ENSMALLEN_FTML_FTML_UPDATE_HPP

namespace ens {

/**
 * Follow the Moving Leader (FTML) is an optimizer where recent samples are
 * weighted more heavily in each iteration, so FTML can adapt more quickly to
 * changes.
 *
 * For more information, see the following.
 *
 * @code
 * @inproceedings{Zheng2017,
 *   author    = {Shuai Zheng and James T. Kwok},
 *   title     = {Follow the Moving Leader in Deep Learning},
 *   year      = {2017}
 *   booktitle = {Proceedings of the 34th International Conference on Machine
 *                Learning},
 *   pages     = {4110--4119},
 *   series    = {Proceedings of Machine Learning Research},
 *   publisher = {PMLR},
 * }
 * @endcode
 */
class FTMLUpdate
{
 public:
  /**
   * Construct the FTML update policy with given epsilon parameter.
   *
   * @param epsilon Epsilon is the minimum allowed gradient.
   * @param beta1 Exponential decay rate for the first moment estimates.
   * @param beta2 Exponential decay rate for the weighted infinity norm
   *        estimates.
   */
  FTMLUpdate(const double epsilon = 1e-8,
             const double beta1 = 0.9,
             const double beta2 = 0.999) :
      epsilon(epsilon),
      beta1(beta1),
      beta2(beta2)
  { /* Do nothing. */ }

  //! Get the value used to initialise the squared gradient parameter.
  double Epsilon() const { return epsilon; }
  //! Modify the value used to initialise the squared gradient parameter.
  double& Epsilon() { return epsilon; }

  //! Get the smoothing parameter.
  double Beta1() const { return beta1; }
  //! Modify the smoothing parameter.
  double& Beta1() { return beta1; }

  //! Get the second moment coefficient.
  double Beta2() const { return beta2; }
  //! Modify the second moment coefficient.
  double& Beta2() { return beta2; }

  /**
   * The UpdatePolicyType policy classes must contain an internal 'Policy'
   * template class with two template arguments: MatType and GradType.  This is
   * instantiated at the start of the optimization, and holds parameters
   * specific to an individual optimization.
   */
  template<typename MatType, typename GradType>
  class Policy
  {
   public:
    /**
     * This constructor is called by the SGD Optimize() method before the start
     * of the iteration update process.
     *
     * @param parent AdamUpdate object.
     * @param rows Number of rows in the gradient matrix.
     * @param cols Number of columns in the gradient matrix.
     */
    Policy(FTMLUpdate& parent, const size_t rows, const size_t cols) :
        parent(parent)
    {
      v.zeros(rows, cols);
      z.zeros(rows, cols);
      d.zeros(rows, cols);
    }

    /**
     * Update step for FTML.
     *
     * @param iterate Parameter that minimizes the function.
     * @param stepSize Step size to be used for the given iteration.
     * @param gradient The gradient matrix.
     */
    void Update(MatType& iterate,
                const double stepSize,
                const GradType& gradient)
    {
      // Increment the iteration counter variable.
      ++iteration;

      // And update the iterate.
      v *= parent.beta2;
      v += (1 - parent.beta2) * (gradient % gradient);

      const double biasCorrection1 = 1.0 - std::pow(parent.beta1, iteration);
      const double biasCorrection2 = 1.0 - std::pow(parent.beta2, iteration);

      MatType sigma = -parent.beta1 * d;
      d = biasCorrection1 / stepSize *
        (arma::sqrt(v / biasCorrection2) + parent.epsilon);
      sigma += d;

      z *= parent.beta1;
      z += (1 - parent.beta1) * gradient - sigma % iterate;
      iterate = -z / d;
    }

   private:
    // Reference to instantiated parent object.
    FTMLUpdate& parent;

    // The exponential moving average of gradient values.
    GradType v;

    // The exponential moving average of squared gradient values.
    GradType z;

    // Parameter update term.
    MatType d;

    // The number of iterations.
    size_t iteration;
  };

 private:
  // The epsilon value used to initialise the squared gradient parameter.
  double epsilon;

  // The smoothing parameter.
  double beta1;

  // The second moment coefficient.
  double beta2;
};

} // namespace ens

#endif
/**
 * @file function.hpp
 * @author Ryan Curtin
 *
 * The Function class is a wrapper class for any objective function that
 * provides any of the functions that an optimizer might use.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_FUNCTION_HPP
#define ENSMALLEN_FUNCTION_HPP

namespace ens {

template<typename FunctionType, typename MatType, typename GradType>
class Function;

} // namespace ens

#include "function/traits.hpp"
#include "function/static_checks.hpp"
#include "function/add_evaluate.hpp"
#include "function/add_gradient.hpp"
#include "function/add_evaluate_with_gradient.hpp"
#include "function/add_separable_evaluate.hpp"
#include "function/add_separable_gradient.hpp"
#include "function/add_separable_evaluate_with_gradient.hpp"

namespace ens {

/**
 * The Function class is a wrapper class for any FunctionType that will add any
 * possible derived methods.  For instance, if the given FunctionType has
 * Evaluate() and Gradient(), then Function<FunctionType> will have
 * EvaluateWithGradient().  This infrastructure allows two things:
 *
 *   1. Optimizers can expect FunctionTypes to have a wider array of functions
 *      than those FunctionTypes may actually implement.
 *
 *   2. FunctionTypes don't need to implement every single method that an
 *      optimizer might require, just those from which every method can be
 *      inferred.
 *
 * This class works by inheriting from a large set of "mixin" classes that
 * provide missing functions, if needed.  For instance, the AddGradient<> mixin
 * will provide a Gradient() method if the given FunctionType implements an
 * EvaluateWithGradient() method.
 *
 * Since all of the casting is static and each of the mixin classes is an empty
 * class, there should be no runtime overhead at all for this functionality.  In
 * addition, this class does not (to the best of my knowledge) rely on any
 * undefined behavior.
 */
template<typename FunctionType, typename MatType, typename GradType>
class Function :
    public AddSeparableEvaluateWithGradientStatic<FunctionType, MatType,
        GradType>,
    public AddSeparableEvaluateWithGradientConst<FunctionType, MatType,
        GradType>,
    public AddSeparableEvaluateWithGradient<FunctionType, MatType, GradType>,
    public AddSeparableGradientStatic<FunctionType, MatType, GradType>,
    public AddSeparableGradientConst<FunctionType, MatType, GradType>,
    public AddSeparableGradient<FunctionType, MatType, GradType>,
    public AddSeparableEvaluateStatic<FunctionType, MatType, GradType>,
    public AddSeparableEvaluateConst<FunctionType, MatType, GradType>,
    public AddSeparableEvaluate<FunctionType, MatType, GradType>,
    public AddEvaluateWithGradientStatic<FunctionType, MatType, GradType>,
    public AddEvaluateWithGradientConst<FunctionType, MatType, GradType>,
    public AddEvaluateWithGradient<FunctionType, MatType, GradType>,
    public AddGradientStatic<FunctionType, MatType, GradType>,
    public AddGradientConst<FunctionType, MatType, GradType>,
    public AddGradient<FunctionType, MatType, GradType>,
    public AddEvaluateStatic<FunctionType, MatType, GradType>,
    public AddEvaluateConst<FunctionType, MatType, GradType>,
    public AddEvaluate<FunctionType, MatType, GradType>,
    public FunctionType
{
 public:
  // All of the mixin classes either reflect existing functionality or provide
  // an unconstructable overload with the same name, so we can use using
  // declarations here to ensure that they are all accessible.  Since we don't
  // know what FunctionType has, we can't use any using declarations there.
  using AddSeparableEvaluateWithGradientStatic<
      FunctionType, MatType, GradType>::EvaluateWithGradient;
  using AddSeparableEvaluateWithGradientConst<
      FunctionType, MatType, GradType>::EvaluateWithGradient;
  using AddSeparableEvaluateWithGradient<
      FunctionType, MatType, GradType>::EvaluateWithGradient;
  using AddSeparableGradientStatic<
      FunctionType, MatType, GradType>::Gradient;
  using AddSeparableGradientConst<FunctionType, MatType, GradType>::Gradient;
  using AddSeparableGradient<FunctionType, MatType, GradType>::Gradient;
  using AddSeparableEvaluateStatic<
      FunctionType, MatType, GradType>::Evaluate;
  using AddSeparableEvaluateConst<FunctionType, MatType, GradType>::Evaluate;
  using AddSeparableEvaluate<FunctionType, MatType, GradType>::Evaluate;
  using AddEvaluateWithGradientStatic<FunctionType, MatType, GradType>::EvaluateWithGradient;
  using AddEvaluateWithGradientConst<FunctionType, MatType, GradType>::EvaluateWithGradient;
  using AddEvaluateWithGradient<FunctionType, MatType, GradType>::EvaluateWithGradient;
  using AddGradientStatic<FunctionType, MatType, GradType>::Gradient;
  using AddGradientConst<FunctionType, MatType, GradType>::Gradient;
  using AddGradient<FunctionType, MatType, GradType>::Gradient;
  using AddEvaluateStatic<FunctionType, MatType, GradType>::Evaluate;
  using AddEvaluateConst<FunctionType, MatType, GradType>::Evaluate;
  using AddEvaluate<FunctionType, MatType, GradType>::Evaluate;
};

} // namespace ens

#endif
/**
 * @file add_evaluate.hpp
 * @author Ryan Curtin
 *
 * This file defines a mixin for the Function class that will ensure that the
 * function Evaluate() is avaliable if EvaluateWithGradient() is available.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_FUNCTION_ADD_EVALUATE_HPP
#define ENSMALLEN_FUNCTION_ADD_EVALUATE_HPP

#include "traits.hpp"

namespace ens {

/**
 * The AddEvaluate mixin class will provide an Evaluate() method if the given
 * FunctionType has EvaluateWithGradient(), or nothing otherwise.
 */
template<typename FunctionType,
         typename MatType,
         typename GradType,
         bool HasEvaluateWithGradient =
             traits::HasEvaluateWithGradient<FunctionType,
                 traits::TypedForms<MatType, GradType>::template
                     EvaluateWithGradientForm
              >::value,
         bool HasEvaluate =
             traits::HasEvaluate<FunctionType,
                  traits::TypedForms<MatType, GradType>::template
                     EvaluateForm>::value>
class AddEvaluate
{
 public:
  // Provide a dummy overload so the name 'Evaluate' exists for this object.
  typename MatType::elem_type Evaluate(traits::UnconstructableType&);
};

/**
 * Reflect the existing Evaluate().
 */
template<typename FunctionType,
         typename MatType,
         typename GradType,
         bool HasEvaluateWithGradient>
class AddEvaluate<FunctionType,
                  MatType,
                  GradType,
                  HasEvaluateWithGradient,
                  true>
{
 public:
  // Reflect the existing Evaluate().
  typename MatType::elem_type Evaluate(const MatType& coordinates)
  {
    return static_cast<FunctionType*>(
        static_cast<Function<FunctionType,
                             MatType, GradType>*>(this))->Evaluate(coordinates);
  }
};

/**
 * If we have EvaluateWithGradient() but no existing Evaluate(), add an
 * Evaluate() method.
 */
template<typename FunctionType, typename MatType, typename GradType>
class AddEvaluate<FunctionType, MatType, GradType, true, false>
{
 public:
  /**
   * Return the objective function for the given coordinates.
   *
   * @param coordinates Coordinates to evaluate the function at.
   */
  typename MatType::elem_type Evaluate(const MatType& coordinates)
  {
    GradType gradient; // This will be ignored.
    return static_cast<Function<FunctionType,
                                MatType,
                                GradType>*>(this)->EvaluateWithGradient(
        coordinates, gradient);
  }
};

/**
 * The AddEvaluateConst mixin class will provide a const Evaluate() method if
 * the given FunctionType has EvaluateWithGradient() const, or nothing
 * otherwise.
 */
template<typename FunctionType,
         typename MatType,
         typename GradType,
         bool HasEvaluateWithGradient =
             traits::HasEvaluateWithGradient<FunctionType,
                 traits::TypedForms<MatType,
                                    GradType>::template
                     EvaluateWithGradientConstForm
             >::value,
         bool HasEvaluate =
             traits::HasEvaluate<FunctionType,
                 traits::TypedForms<MatType, GradType>::template
                     EvaluateConstForm
             >::value>
class AddEvaluateConst
{
 public:
  // Provide a dummy overload so the name 'Evaluate' exists for this object.
  typename MatType::elem_type Evaluate(traits::UnconstructableType&) const;
};

/**
 * Reflect the existing Evaluate().
 */
template<typename FunctionType,
         typename MatType,
         typename GradType,
         bool HasEvaluateWithGradient>
class AddEvaluateConst<FunctionType,
                       MatType,
                       GradType,
                       HasEvaluateWithGradient,
                       true>
{
 public:
  // Reflect the existing Evaluate().
  typename MatType::elem_type Evaluate(const MatType& coordinates) const
  {
    return static_cast<const FunctionType*>(
        static_cast<const Function<FunctionType,
                                   MatType,
                                   GradType>*>(this))->Evaluate(coordinates);
  }
};

/**
 * If we have EvaluateWithGradient() but no existing Evaluate(), add an
 * Evaluate() without a using directive to make the base Evaluate() accessible.
 */
template<typename FunctionType, typename MatType, typename GradType>
class AddEvaluateConst<FunctionType, MatType, GradType, true, false>
{
 public:
  /**
   * Return the objective function for the given coordinates.
   *
   * @param coordinates Coordinates to evaluate the function at.
   */
  typename MatType::elem_type Evaluate(const MatType& coordinates) const
  {
    GradType gradient; // This will be ignored.
    return static_cast<
        const Function<FunctionType,
                       MatType,
                       GradType>*>(this)->EvaluateWithGradient(coordinates,
                                                               gradient);
  }
};

/**
 * The AddEvaluateStatic mixin class will provide a static Evaluate() method if
 * the given FunctionType has EvaluateWithGradient() static, or nothing
 * otherwise.
 */
template<typename FunctionType,
         typename MatType,
         typename GradType,
         bool HasEvaluateWithGradient =
             traits::HasEvaluateWithGradient<FunctionType,
                 traits::TypedForms<MatType,
                                    GradType>::template
                 EvaluateWithGradientStaticForm
             >::value,
         bool HasEvaluate =
             traits::HasEvaluate<FunctionType,
                 traits::TypedForms<MatType, GradType>::template
                 EvaluateStaticForm
             >::value>
class AddEvaluateStatic
{
 public:
  // Provide a dummy overload so the name 'Evaluate' exists for this object.
  static typename MatType::elem_type Evaluate(traits::UnconstructableType&);
};

/**
 * Reflect the existing Evaluate().
 */
template<typename FunctionType,
         typename MatType,
         typename GradType,
         bool HasEvaluateWithGradient>
class AddEvaluateStatic<FunctionType,
                        MatType,
                        GradType,
                        HasEvaluateWithGradient,
                        true>
{
 public:
  // Reflect the existing Evaluate().
  static typename MatType::elem_type Evaluate(
      const MatType& coordinates)
  {
    return FunctionType::Evaluate(coordinates);
  }
};

/**
 * If we have EvaluateWithGradient() but no existing Evaluate(), add an
 * Evaluate() without a using directive to make the base Evaluate() accessible.
 */
template<typename FunctionType, typename MatType, typename GradType>
class AddEvaluateStatic<FunctionType, MatType, GradType, true, false>
{
 public:
  /**
   * Return the objective function for the given coordinates.
   *
   * @param coordinates Coordinates to evaluate the function at.
   */
  static typename MatType::elem_type Evaluate(const MatType& coordinates)
  {
    GradType gradient; // This will be ignored.
    return FunctionType::EvaluateWithGradient(coordinates, gradient);
  }
};

} // namespace ens

#endif
/**
 * @file add_evaluate_with_gradient.hpp
 * @author Ryan Curtin
 *
 * This file defines a mixin for the Function class that will ensure that the
 * EvaluateWithGradient() function is available if possible.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_FUNCTION_ADD_EVALUATE_WITH_GRADIENT_HPP
#define ENSMALLEN_FUNCTION_ADD_EVALUATE_WITH_GRADIENT_HPP

#include "sfinae_utility.hpp"
#include "traits.hpp"

namespace ens {

/**
 * The AddEvaluateWithGradient mixin class will provide an
 * EvaluateWithGradient() method if the given FunctionType has both Evaluate()
 * and Gradient(), or it will provide nothing otherwise.
 */
template<typename FunctionType,
         typename MatType,
         typename GradType,
         // Check if there is at least one non-const Evaluate() or Gradient().
         bool HasEvaluateGradient = traits::HasNonConstSignatures<
             FunctionType,
             traits::HasEvaluate,
             traits::TypedForms<MatType, GradType>::template EvaluateForm,
             traits::TypedForms<MatType, GradType>::template EvaluateConstForm,
             traits::TypedForms<MatType, GradType>::template EvaluateStaticForm,
             traits::HasGradient,
             traits::TypedForms<MatType, GradType>::template GradientForm,
             traits::TypedForms<MatType, GradType>::template GradientConstForm,
             traits::TypedForms<MatType, GradType>::template GradientStaticForm
         >::value,
         bool HasEvaluateWithGradient = traits::HasEvaluateWithGradient<
             FunctionType,
             traits::TypedForms<MatType, GradType>::template
                 EvaluateWithGradientForm>::value>
class AddEvaluateWithGradient
{
 public:
  // Provide a dummy overload so the name 'EvaluateWithGradient' exists for this
  // object.
  typename MatType::elem_type EvaluateWithGradient(
      traits::UnconstructableType&);
};

/**
 * Reflect the existing EvaluateWithGradient().
 */
template<typename FunctionType,
         typename MatType,
         typename GradType,
         bool HasEvaluateGradient>
class AddEvaluateWithGradient<FunctionType,
                              MatType,
                              GradType,
                              HasEvaluateGradient,
                              true>
{
 public:
  // Reflect the existing EvaluateWithGradient().
  typename MatType::elem_type EvaluateWithGradient(
      const MatType& coordinates, GradType& gradient)
  {
    return static_cast<FunctionType*>(
        static_cast<Function<FunctionType,
                             MatType,
                             GradType>*>(this))->EvaluateWithGradient(
        coordinates, gradient);
  }
};

/**
 * If the FunctionType has Evaluate() and Gradient(), provide
 * EvaluateWithGradient().
 */
template<typename FunctionType, typename MatType, typename GradType>
class AddEvaluateWithGradient<FunctionType, MatType, GradType, true, false>
{
 public:
  /**
   * Return both the evaluated objective function and its gradient, storing the
   * gradient in the given matrix.
   *
   * @param coordinates Coordinates to evaluate the function at.
   * @param gradient Matrix to store the gradient into.
   */
  typename MatType::elem_type EvaluateWithGradient(const MatType& coordinates,
                                                   GradType& gradient)
  {
    const typename MatType::elem_type objective =
        static_cast<Function<FunctionType,
                             MatType, GradType>*>(this)->Evaluate(coordinates);
    static_cast<Function<FunctionType,
                         MatType,
                         GradType>*>(this)->Gradient(coordinates, gradient);
    return objective;
  }
};

/**
 * The AddEvaluateWithGradient mixin class will provide an
 * EvaluateWithGradient() const method if the given FunctionType has both
 * Evaluate() const and Gradient() const, or it will provide nothing otherwise.
 */
template<typename FunctionType,
         typename MatType,
         typename GradType,
         // Check if there is at least one const Evaluate() or Gradient().
         bool HasEvaluateGradient = traits::HasConstSignatures<
             FunctionType,
             traits::HasEvaluate,
             traits::TypedForms<MatType, GradType>::template EvaluateConstForm,
             traits::TypedForms<MatType, GradType>::template EvaluateStaticForm,
             traits::HasGradient,
             traits::TypedForms<MatType, GradType>::template GradientConstForm,
             traits::TypedForms<MatType, GradType>::template GradientStaticForm
         >::value,
         bool HasEvaluateWithGradient = traits::HasEvaluateWithGradient<
             FunctionType,
             traits::TypedForms<
                 MatType, GradType
             >::template EvaluateWithGradientConstForm>::value>
class AddEvaluateWithGradientConst
{
 public:
  // Provide a dummy overload so the name 'EvaluateWithGradient' exists for this
  // object.
  typename MatType::elem_type EvaluateWithGradient(
      traits::UnconstructableType&) const;
};

/**
 * Reflect the existing EvaluateWithGradient().
 */
template<typename FunctionType,
         typename MatType,
         typename GradType,
         bool HasEvaluateGradient>
class AddEvaluateWithGradientConst<FunctionType,
                                   MatType,
                                   GradType,
                                   HasEvaluateGradient,
                                   true>
{
 public:
  // Reflect the existing EvaluateWithGradient().
  typename MatType::elem_type EvaluateWithGradient(
      const MatType& coordinates, GradType& gradient) const
  {
    return static_cast<const FunctionType*>(
        static_cast<const Function<FunctionType,
                                   MatType,
                                   GradType>*>(this))->EvaluateWithGradient(
        coordinates, gradient);
  }
};

/**
 * If the FunctionType has Evaluate() const and Gradient() const, provide
 * EvaluateWithGradient() const.
 */
template<typename FunctionType, typename MatType, typename GradType>
class AddEvaluateWithGradientConst<FunctionType, MatType, GradType, true, false>
{
 public:
  /**
   * Return both the evaluated objective function and its gradient, storing the
   * gradient in the given matrix.
   *
   * @param coordinates Coordinates to evaluate the function at.
   * @param gradient Matrix to store the gradient into.
   */
  typename MatType::elem_type EvaluateWithGradient(const MatType& coordinates,
                                                   GradType& gradient) const
  {
    const typename MatType::elem_type objective =
        static_cast<const Function<FunctionType,
                                   MatType,
                                   GradType>*>(this)->Evaluate(coordinates);
    static_cast<const Function<FunctionType,
                               MatType,
                               GradType>*>(this)->Gradient(coordinates,
                                                           gradient);
    return objective;
  }
};

/**
 * The AddEvaluateWithGradientStatic mixin class will provide a
 * static EvaluateWithGradient() method if the given FunctionType has both
 * static Evaluate() and static Gradient(), or it will provide nothing
 * otherwise.
 */
template<typename FunctionType,
         typename MatType,
         typename GradType,
         bool HasEvaluateGradient =
             traits::HasEvaluate<FunctionType,
                 traits::TypedForms<MatType, GradType>::template
                     EvaluateStaticForm
             >::value &&
             traits::HasGradient<FunctionType,
                 traits::TypedForms<MatType, GradType>::template
                     GradientStaticForm
             >::value,
         bool HasEvaluateWithGradient =
             traits::HasEvaluateWithGradient<FunctionType,
                 traits::TypedForms<MatType,
                                    GradType>::template
                     EvaluateWithGradientStaticForm
             >::value>
class AddEvaluateWithGradientStatic
{
 public:
  // Provide a dummy overload so the name 'EvaluateWithGradient' exists for this
  // object.
  static typename MatType::elem_type EvaluateWithGradient(
      traits::UnconstructableType&);
};

/**
 * Reflect the existing EvaluateWithGradient().
 */
template<typename FunctionType,
         typename MatType,
         typename GradType,
         bool HasEvaluateGradient>
class AddEvaluateWithGradientStatic<FunctionType,
                                    MatType,
                                    GradType,
                                    HasEvaluateGradient,
                                    true>
{
 public:
  // Reflect the existing EvaluateWithGradient().
  static typename MatType::elem_type EvaluateWithGradient(
      const MatType& coordinates, GradType& gradient)
  {
    return FunctionType::EvaluateWithGradient(coordinates, gradient);
  }
};

/**
 * If the FunctionType has static Evaluate() and static Gradient(), provide
 * static EvaluateWithGradient().
 */
template<typename FunctionType, typename MatType, typename GradType>
class AddEvaluateWithGradientStatic<FunctionType,
                                    MatType,
                                    GradType,
                                    true,
                                    false>
{
 public:
  /**
   * Return both the evaluated objective function and its gradient, storing the
   * gradient in the given matrix.
   *
   * @param coordinates Coordinates to evaluate the function at.
   * @param gradient Matrix to store the gradient into.
   */
  static typename MatType::elem_type EvaluateWithGradient(
      const MatType& coordinates, GradType& gradient)
  {
    const typename MatType::elem_type objective =
        FunctionType::Evaluate(coordinates);
    FunctionType::Gradient(coordinates, gradient);
    return objective;
  }
};

} // namespace ens

#endif
/**
 * @file add_gradient.hpp
 * @author Ryan Curtin
 *
 * This file defines a mixin for the Function class that will ensure that the
 * function Gradient() is avaiable if EvaluateWithGradient() is available.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_FUNCTION_ADD_GRADIENT_HPP
#define ENSMALLEN_FUNCTION_ADD_GRADIENT_HPP

#include "traits.hpp"

namespace ens {

/**
 * The AddGradient mixin class will provide a Gradient() method if the given
 * FunctionType has EvaluateWithGradient(), or nothing otherwise.
 */
template<typename FunctionType,
         typename MatType,
         typename GradType,
         bool HasEvaluateWithGradient =
             traits::HasEvaluateWithGradient<FunctionType,
                 traits::TypedForms<MatType, GradType>::template
                     EvaluateWithGradientForm
             >::value,
         bool HasGradient = traits::HasGradient<FunctionType,
             traits::TypedForms<MatType, GradType>::template 
                     GradientForm>::value>
class AddGradient
{
 public:
  // Provide a dummy overload so the name 'Gradient' exists for this object.
  void Gradient(traits::UnconstructableType&) { }
};

/**
 * Reflect the existing Gradient().
 */
template<typename FunctionType,
         typename MatType,
         typename GradType,
         bool HasEvaluateWithGradient>
class AddGradient<FunctionType,
                  MatType,
                  GradType,
                  HasEvaluateWithGradient,
                  true>
{
 public:
  // Reflect the existing Gradient().
  void Gradient(const MatType& coordinates, GradType& gradient)
  {
    static_cast<FunctionType*>(
        static_cast<Function<FunctionType,
                             MatType,
                             GradType>*>(this))->Gradient(coordinates,
                                                          gradient);
  }
};

/**
 * If we have EvaluateWithGradient() but no existing Gradient(), add an
 * Gradient() without a using directive to make the base Gradient() accessible.
 */
template<typename FunctionType, typename MatType, typename GradType>
class AddGradient<FunctionType, MatType, GradType, true, false>
{
 public:
  /**
   * Calculate the gradient and store it in the given matrix.
   *
   * @param coordinates Coordinates to evaluate the function at.
   * @param gradient Matrix to store the gradient into.
   */
  void Gradient(const MatType& coordinates, GradType& gradient)
  {
    // The returned objective value will be ignored.
    (void) static_cast<Function<FunctionType,
                                MatType,
                                GradType>*>(this)->EvaluateWithGradient(
        coordinates, gradient);
  }
};

/**
 * The AddGradient mixin class will provide a const Gradient() method if the
 * given FunctionType has EvaluateWithGradient() const, or nothing otherwise.
 */
template<typename FunctionType,
         typename MatType,
         typename GradType,
         bool HasEvaluateWithGradient =
             traits::HasEvaluateWithGradient<FunctionType,
                 traits::TypedForms<MatType,
                                    GradType>::template
                     EvaluateWithGradientConstForm
             >::value,
         bool HasGradient = traits::HasGradient<FunctionType,
             traits::TypedForms<MatType, GradType>::template GradientConstForm
         >::value>
class AddGradientConst
{
 public:
  // Provide a dummy overload so the name 'Gradient' exists for this object.
  void Gradient(traits::UnconstructableType&) const { }
};

/**
 * Reflect the existing Gradient().
 */
template<typename FunctionType,
         typename MatType,
         typename GradType,
         bool HasEvaluateWithGradient>
class AddGradientConst<FunctionType,
                       MatType,
                       GradType,
                       HasEvaluateWithGradient,
                       true>
{
 public:
  // Reflect the existing Gradient().
  void Gradient(const MatType& coordinates, GradType& gradient) const
  {
    static_cast<const FunctionType*>(
        static_cast<const Function<FunctionType,
                                   MatType,
                                   GradType>*>(this))->Gradient(coordinates,
                                                                gradient);
  }
};

/**
 * If we have EvaluateWithGradient() but no existing Gradient(), add a
 * Gradient() without a using directive to make the base Gradient() accessible.
 */
template<typename FunctionType, typename MatType, typename GradType>
class AddGradientConst<FunctionType, MatType, GradType, true, false>
{
 public:
  /**
   * Calculate the gradient and store it in the given matrix.
   *
   * @param coordinates Coordinates to evaluate the function at.
   * @param gradient Matrix to store the gradient into.
   */
  void Gradient(const MatType& coordinates, GradType& gradient) const
  {
    // The returned objective value will be ignored.
    (void) static_cast<
        const Function<FunctionType,
                       MatType,
                       GradType>*>(this)->EvaluateWithGradient(coordinates,
                                                               gradient);
  }
};

/**
 * The AddGradient mixin class will provide a static Gradient() method if the
 * given FunctionType has static EvaluateWithGradient(), or nothing otherwise.
 */
template<typename FunctionType,
         typename MatType,
         typename GradType,
         bool HasEvaluateWithGradient =
             traits::HasEvaluateWithGradient<FunctionType,
                 traits::TypedForms<MatType,
                                    GradType>::template
                     EvaluateWithGradientStaticForm
             >::value,
         bool HasGradient = traits::HasGradient<FunctionType,
             traits::TypedForms<MatType, GradType>::template GradientStaticForm
         >::value>
class AddGradientStatic
{
 public:
  // Provide a dummy overload so the name 'Gradient' exists for this object.
  static void Gradient(traits::UnconstructableType&) { }
};

/**
 * Reflect the existing Gradient().
 */
template<typename FunctionType,
         typename MatType,
         typename GradType,
         bool HasEvaluateWithGradient>
class AddGradientStatic<FunctionType,
                        MatType,
                        GradType,
                        HasEvaluateWithGradient,
                        true>
{
 public:
  // Reflect the existing Gradient().
  static void Gradient(const MatType& coordinates, GradType& gradient)
  {
    FunctionType::Gradient(coordinates, gradient);
  }
};

/**
 * If we have EvaluateWithGradient() but no existing Gradient(), add a
 * Gradient() without a using directive to make the base Gradient() accessible.
 */
template<typename FunctionType, typename MatType, typename GradType>
class AddGradientStatic<FunctionType, MatType, GradType, true, false>
{
 public:
  /**
   * Calculate the gradient and store it in the given matrix.
   *
   * @param coordinates Coordinates to evaluate the function at.
   * @param gradient Matrix to store the gradient into.
   */
  static void Gradient(const MatType& coordinates, GradType& gradient)
  {
    // The returned objective value will be ignored.
    (void) FunctionType::EvaluateWithGradient(coordinates, gradient);
  }
};

} // namespace ens

#endif
/**
 * @file add_separable_evaluate.hpp
 * @author Ryan Curtin
 *
 * Adds a separable Evaluate() function if a separable
 * EvaluateWithGradient() function exists.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_FUNCTION_ADD_DECOMPOSABLE_EVALUATE_HPP
#define ENSMALLEN_FUNCTION_ADD_DECOMPOSABLE_EVALUATE_HPP

#include "traits.hpp"

namespace ens {

/**
 * The AddSeparableEvaluate mixin class will add a separable Evaluate()
 * method if a separable EvaluateWithGradient() function exists, or nothing
 * otherwise.
 */
template<typename FunctionType,
         typename MatType,
         typename GradType,
         bool HasSeparableEvaluateWithGradient =
             traits::HasEvaluateWithGradient<FunctionType,
                 traits::TypedForms<MatType, GradType>::template
                     SeparableEvaluateWithGradientForm
             >::value,
         bool HasSeparableEvaluate =
             traits::HasEvaluate<FunctionType,
                 traits::TypedForms<MatType, GradType>::template
                      SeparableEvaluateForm>::value>
class AddSeparableEvaluate
{
 public:
  // Provide a dummy overload so the name 'Evaluate' exists for this object.
  typename MatType::elem_type Evaluate(traits::UnconstructableType&,
                                       const size_t,
                                       const size_t);
};

/**
 * Reflect the existing Evaluate().
 */
template<typename FunctionType,
         typename MatType,
         typename GradType,
         bool HasSeparableEvaluateWithGradient>
class AddSeparableEvaluate<FunctionType, MatType, GradType,
    HasSeparableEvaluateWithGradient, true>
{
 public:
  // Reflect the existing Evaluate().
  typename MatType::elem_type Evaluate(const MatType& coordinates,
                                       const size_t begin,
                                       const size_t batchSize)
  {
    return static_cast<FunctionType*>(
        static_cast<Function<FunctionType,
                             MatType,
                             GradType>*>(this))->Evaluate(coordinates,
                                                          begin,
                                                          batchSize);
  }
};

/**
 * If we have a separable EvaluateWithGradient() but not a separable
 * Evaluate(), add a separable Evaluate() method.
 */
template<typename FunctionType, typename MatType, typename GradType>
class AddSeparableEvaluate<FunctionType, MatType, GradType, true, false>
{
 public:
  /**
   * Return the objective function for the given coordinates, starting at the
   * given separable function using the given batch size.
   *
   * @param coordinates Coordinates to evaluate the function at.
   * @param begin Index of first function to evaluate.
   * @param batchSize Number of functions to evaluate.
   */
  double Evaluate(const MatType& coordinates,
                  const size_t begin,
                  const size_t batchSize)
  {
    GradType gradient; // This will be ignored.
    return static_cast<Function<FunctionType,
                                MatType,
                                GradType>*>(this)->EvaluateWithGradient(
        coordinates, begin, gradient, batchSize);
  }
};

/**
 * The AddSeparableEvaluateConst mixin class will add a separable const
 * Evaluate() method if a separable const EvaluateWithGradient() function
 * exists, or nothing otherwise.
 */
template<typename FunctionType,
         typename MatType,
         typename GradType,
         bool HasSeparableEvaluateWithGradient =
             traits::HasEvaluateWithGradient<FunctionType,
                 traits::TypedForms<MatType, GradType>::template
                     SeparableEvaluateWithGradientConstForm>::value,
         bool HasSeparableEvaluate =
             traits::HasEvaluate<FunctionType,
                 traits::TypedForms<MatType, GradType>::template
                     SeparableEvaluateConstForm>::value>
class AddSeparableEvaluateConst
{
 public:
  // Provide a dummy overload so the name 'Evaluate' exists for this object.
  typename MatType::elem_type Evaluate(traits::UnconstructableType&,
                                       const size_t,
                                       const size_t) const;
};

/**
 * Reflect the existing Evaluate().
 */
template<typename FunctionType,
         typename MatType,
         typename GradType,
         bool HasSeparableEvaluateWithGradient>
class AddSeparableEvaluateConst<FunctionType, MatType, GradType,
    HasSeparableEvaluateWithGradient, true>
{
 public:
  // Reflect the existing Evaluate().
  typename MatType::elem_type Evaluate(const MatType& coordinates,
                                       const size_t begin,
                                       const size_t batchSize) const
  {
    return static_cast<const FunctionType*>(
        static_cast<const Function<FunctionType,
                                   MatType,
                                   GradType>*>(this))->Evaluate(coordinates,
                                                                begin,
                                                                batchSize);
  }
};

/**
 * If we have a separable const EvaluateWithGradient() but not a separable
 * const Evaluate(), add a separable const Evaluate() method.
 */
template<typename FunctionType, typename MatType, typename GradType>
class AddSeparableEvaluateConst<FunctionType, MatType, GradType, true, false>
{
 public:
  /**
   * Return the objective function for the given coordinates, starting at the
   * given separable function using the given batch size.
   *
   * @param coordinates Coordinates to evaluate the function at.
   * @param begin Index of first function to evaluate.
   * @param batchSize Number of functions to evaluate.
   */
  typename MatType::elem_type Evaluate(const MatType& coordinates,
                                       const size_t begin,
                                       const size_t batchSize) const
  {
    GradType gradient; // This will be ignored.
    return static_cast<const Function<FunctionType,
                                      MatType,
                                      GradType>*>(this)->EvaluateWithGradient(
        coordinates, begin, gradient, batchSize);
  }
};

/**
 * The AddSeparableEvaluateStatic mixin class will add a separable static
 * Evaluate() method if a separable static EvaluateWithGradient() function
 * exists, or nothing otherwise.
 */
template<typename FunctionType,
         typename MatType,
         typename GradType,
         bool HasSeparableEvaluateWithGradient =
             traits::HasEvaluateWithGradient<FunctionType,
                 traits::TypedForms<MatType, GradType>::template
                     SeparableEvaluateWithGradientStaticForm>::value,
         bool HasSeparableEvaluate =
             traits::HasEvaluate<FunctionType,
                 traits::TypedForms<MatType, GradType>::template
                     SeparableEvaluateStaticForm>::value>
class AddSeparableEvaluateStatic
{
 public:
  // Provide a dummy overload so the name 'Evaluate' exists for this object.
  static typename MatType::elem_type Evaluate(traits::UnconstructableType&,
                                              const size_t,
                                              const size_t);
};

/**
 * Reflect the existing Evaluate().
 */
template<typename FunctionType,
         typename MatType,
         typename GradType,
         bool HasSeparableEvaluateWithGradient>
class AddSeparableEvaluateStatic<FunctionType, MatType, GradType,
    HasSeparableEvaluateWithGradient, true>
{
 public:
  // Reflect the existing Evaluate().
  static typename MatType::elem_type Evaluate(const MatType& coordinates,
                                              const size_t begin,
                                              const size_t batchSize)
  {
    return FunctionType::Evaluate(coordinates, begin, batchSize);
  }
};

/**
 * If we have a separable EvaluateWithGradient() but not a separable
 * Evaluate(), add a separable Evaluate() method.
 */
template<typename FunctionType, typename MatType, typename GradType>
class AddSeparableEvaluateStatic<FunctionType, MatType, GradType, true,
    false>
{
 public:
  /**
   * Return the objective function for the given coordinates, starting at the
   * given separable function using the given batch size.
   *
   * @param coordinates Coordinates to evaluate the function at.
   * @param begin Index of first function to evaluate.
   * @param batchSize Number of functions to evaluate.
   */
  static typename MatType::elem_type Evaluate(const MatType& coordinates,
                                              const size_t begin,
                                              const size_t batchSize)
  {
    GradType gradient; // This will be ignored.
    return FunctionType::EvaluateWithGradient(coordinates, begin, gradient,
        batchSize);
  }
};

} // namespace ens

#endif
/**
 * @file add_separable_evaluate_with_gradient.hpp
 * @author Ryan Curtin
 *
 * Adds a separable EvaluateWithGradient() function if both a separable
 * Evaluate() and a separable Gradient() function exist.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_FUNCTION_ADD_DECOMPOSABLE_EVALUATE_W_GRADIENT_HPP
#define ENSMALLEN_FUNCTION_ADD_DECOMPOSABLE_EVALUATE_W_GRADIENT_HPP

#include "traits.hpp"

namespace ens {

/**
 * The AddSeparableEvaluateWithGradient mixin class will add a separable
 * EvaluateWithGradient() method if a separable Evaluate() method and a
 * separable Gradient() method exists, or nothing otherwise.
 */
template<typename FunctionType,
         typename MatType,
         typename GradType,
         // Check if there is at least one non-const Evaluate() or Gradient().
         bool HasSeparableEvaluateGradient = traits::HasNonConstSignatures<
             FunctionType,
             traits::HasEvaluate,
             traits::TypedForms<MatType, GradType>::template
                 SeparableEvaluateForm,
             traits::TypedForms<MatType, GradType>::template
                 SeparableEvaluateConstForm,
             traits::TypedForms<MatType, GradType>::template
                 SeparableEvaluateStaticForm,
             traits::HasGradient,
             traits::TypedForms<MatType, GradType>::template
                 SeparableGradientForm,
             traits::TypedForms<MatType, GradType>::template
                 SeparableGradientConstForm,
             traits::TypedForms<MatType, GradType>::template
                 SeparableGradientStaticForm>::value,
         bool HasSeparableEvaluateWithGradient =
             traits::HasEvaluateWithGradient<FunctionType,
                 traits::TypedForms<MatType, GradType>::template
                     SeparableEvaluateWithGradientForm>::value>
class AddSeparableEvaluateWithGradient
{
 public:
  // Provide a dummy overload so the name 'EvaluateWithGradient' exists for this
  // object.
  typename MatType::elem_type EvaluateWithGradient(
      traits::UnconstructableType&,
      const size_t,
      const size_t);
};

/**
 * Reflect the existing EvaluateWithGradient().
 */
template<typename FunctionType,
         typename MatType,
         typename GradType,
         bool HasSeparableEvaluateGradient>
class AddSeparableEvaluateWithGradient<FunctionType, MatType, GradType,
    HasSeparableEvaluateGradient, true>
{
 public:
  // Reflect the existing EvaluateWithGradient().
  typename MatType::elem_type EvaluateWithGradient(const MatType& coordinates,
                                                   const size_t begin,
                                                   GradType& gradient,
                                                   const size_t batchSize)
  {
    return static_cast<FunctionType*>(
        static_cast<Function<FunctionType,
                             MatType,
                             GradType>*>(this))->EvaluateWithGradient(
        coordinates, begin, gradient, batchSize);
  }
};

/**
 * If we have a both separable Evaluate() and a separable Gradient() but
 * not a separable EvaluateWithGradient(), add a separable
 * EvaluateWithGradient() method.
 */
template<typename FunctionType, typename MatType, typename GradType>
class AddSeparableEvaluateWithGradient<FunctionType, MatType, GradType, true,
    false>
{
 public:
  /**
   * Return both the evaluated objective function and its gradient, storing the
   * gradient in the given matrix, starting at the given separable function
   * and using the given batch size.
   *
   * @param coordinates Coordinates to evaluate the function at.
   * @param begin Index of separable function to begin with.
   * @param gradient Matrix to store the gradient into.
   * @param batchSize Number of separable functions to evaluate.
   */
  typename MatType::elem_type EvaluateWithGradient(const MatType& coordinates,
                                                   const size_t begin,
                                                   GradType& gradient,
                                                   const size_t batchSize)
  {
    const typename MatType::elem_type objective =
        static_cast<Function<FunctionType, MatType, GradType>*>(this)->Evaluate(
        coordinates, begin, batchSize);
    static_cast<Function<FunctionType, MatType, GradType>*>(this)->Gradient(
        coordinates, begin, gradient, batchSize);
    return objective;
  }
};

/**
 * The AddSeparableEvaluateWithGradientConst mixin class will add a
 * separable const EvaluateWithGradient() method if both a separable const
 * Evaluate() and a separable const Gradient() function exist, or nothing
 * otherwise.
 */
template<typename FunctionType,
         typename MatType,
         typename GradType,
         // Check if there is at least one const Evaluate() or Gradient().
         bool HasSeparableEvaluateGradient = traits::HasConstSignatures<
             FunctionType,
             traits::HasEvaluate,
             traits::TypedForms<MatType, GradType>::template
                 SeparableEvaluateConstForm,
             traits::TypedForms<MatType, GradType>::template
                 SeparableEvaluateStaticForm,
             traits::HasGradient,
             traits::TypedForms<MatType, GradType>::template
                 SeparableGradientConstForm,
             traits::TypedForms<MatType, GradType>::template
                 SeparableGradientStaticForm>::value,
         bool HasSeparableEvaluateWithGradient =
             traits::HasEvaluateWithGradient<FunctionType,
                 traits::TypedForms<MatType, GradType>::template
                     SeparableEvaluateWithGradientConstForm>::value>
class AddSeparableEvaluateWithGradientConst
{
 public:
  // Provide a dummy overload so the name 'EvaluateWithGradient' exists for this
  // object.
  typename MatType::elem_type EvaluateWithGradient(
      traits::UnconstructableType&,
      const size_t,
      const size_t) const;
};

/**
 * Reflect the existing EvaluateWithGradient().
 */
template<typename FunctionType,
         typename MatType,
         typename GradType,
         bool HasSeparableEvaluateGradient>
class AddSeparableEvaluateWithGradientConst<FunctionType, MatType, GradType,
    HasSeparableEvaluateGradient, true>
{
 public:
  // Reflect the existing Evaluate().
  typename MatType::elem_type EvaluateWithGradient(const MatType& coordinates,
                                                   const size_t begin,
                                                   GradType& gradient,
                                                   const size_t batchSize) const
  {
    return static_cast<const FunctionType*>(
        static_cast<const Function<FunctionType,
                                   MatType,
                                   GradType>*>(this))->EvaluateWithGradient(
        coordinates, begin, gradient, batchSize);
  }
};

/**
 * If we have both a separable const Evaluate() and a separable const
 * Gradient() but not a separable const EvaluateWithGradient(), add a
 * separable const EvaluateWithGradient() method.
 */
template<typename FunctionType, typename MatType, typename GradType>
class AddSeparableEvaluateWithGradientConst<FunctionType, MatType, GradType,
    true, false>
{
 public:
  /**
   * Return both the evaluated objective function and its gradient, storing the
   * gradient in the given matrix, starting at the given separable function
   * and using the given batch size.
   *
   * @param coordinates Coordinates to evaluate the function at.
   * @param begin Index of separable function to begin with.
   * @param gradient Matrix to store the gradient into.
   * @param batchSize Number of separable functions to evaluate.
   */
  typename MatType::elem_type EvaluateWithGradient(const MatType& coordinates,
                                                   const size_t begin,
                                                   GradType& gradient,
                                                   const size_t batchSize) const
  {
    const typename MatType::elem_type objective =
        static_cast<const Function<FunctionType,
                                   MatType,
                                   GradType>*>(this)->Evaluate(coordinates,
        begin, batchSize);
    static_cast<const Function<FunctionType,
                               MatType,
                               GradType>*>(this)->Gradient(coordinates,
        begin, gradient, batchSize);
    return objective;
  }
};

/**
 * The AddSeparableEvaluateWithGradientStatic mixin class will add a
 * separable static EvaluateWithGradient() method if both a separable
 * static Evaluate() and a separable static gradient() function exist, or
 * nothing otherwise.
 */
template<typename FunctionType,
         typename MatType,
         typename GradType,
         bool HasSeparableEvaluateGradient =
             traits::HasEvaluate<FunctionType,
                 traits::TypedForms<MatType, GradType>::template
                     SeparableEvaluateStaticForm>::value &&
             traits::HasGradient<FunctionType,
                 traits::TypedForms<MatType, GradType>::template
                     SeparableGradientStaticForm>::value,
         bool HasSeparableEvaluateWithGradient =
             traits::HasEvaluateWithGradient<FunctionType,
                 traits::TypedForms<MatType, GradType>::template
                     SeparableEvaluateWithGradientStaticForm>::value>
class AddSeparableEvaluateWithGradientStatic
{
 public:
  // Provide a dummy overload so the name 'EvaluateWithGradient' exists for this
  // object.
  static typename MatType::elem_type EvaluateWithGradient(
      traits::UnconstructableType&,
      const size_t,
      const size_t);
};

/**
 * Reflect the existing EvaluateWithGradient().
 */
template<typename FunctionType,
         typename MatType,
         typename GradType,
         bool HasSeparableEvaluateGradient>
class AddSeparableEvaluateWithGradientStatic<FunctionType, MatType, GradType,
    HasSeparableEvaluateGradient, true>
{
 public:
  // Reflect the existing Evaluate().
  static typename MatType::elem_type EvaluateWithGradient(
      const MatType& coordinates,
      const size_t begin,
      GradType& gradient,
      const size_t batchSize)
  {
    return FunctionType::EvaluateWithGradient(coordinates, begin, gradient,
        batchSize);
  }
};

/**
 * If we have a separable static Evaluate() and a separable static
 * Gradient() but not a separable static EvaluateWithGradient(), add a
 * separable static Gradient() method.
 */
template<typename FunctionType, typename MatType, typename GradType>
class AddSeparableEvaluateWithGradientStatic<FunctionType, MatType, GradType,
    true, false>
{
 public:
  /**
   * Return both the evaluated objective function and its gradient, storing the
   * gradient in the given matrix, starting at the given separable function
   * and using the given batch size.
   *
   * @param coordinates Coordinates to evaluate the function at.
   * @param begin Index of separable function to begin with.
   * @param gradient Matrix to store the gradient into.
   * @param batchSize Number of separable functions to evaluate.
   */
  typename MatType::elem_type EvaluateWithGradient(
      const MatType& coordinates,
      const size_t begin,
      GradType& gradient,
      const size_t batchSize) const
  {
    const typename MatType::elem_type objective = FunctionType::Evaluate(
        coordinates, begin, batchSize);
    FunctionType::Gradient(coordinates, begin, gradient, batchSize);
    return objective;
  }
};

} // namespace ens

#endif
/**
 * @file add_separable_gradient.hpp
 * @author Ryan Curtin
 *
 * Adds a separable Gradient() function if a separable
 * EvaluateWithGradient() function exists.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_FUNCTION_ADD_DECOMPOSABLE_GRADIENT_HPP
#define ENSMALLEN_FUNCTION_ADD_DECOMPOSABLE_GRADIENT_HPP

#include "traits.hpp"

namespace ens {

/**
 * The AddSeparableGradient mixin class will add a separable Gradient()
 * method if a separable EvaluateWithGradient() function exists, or nothing
 * otherwise.
 */
template<typename FunctionType,
         typename MatType,
         typename GradType,
         bool HasSeparableEvaluateWithGradient =
             traits::HasEvaluateWithGradient<FunctionType,
                 traits::TypedForms<MatType, GradType>::template
                     SeparableEvaluateWithGradientForm>::value,
         bool HasSeparableGradient =
             traits::HasGradient<FunctionType,
                 traits::TypedForms<MatType, GradType>::template
                     SeparableGradientForm>::value>
class AddSeparableGradient
{
 public:
  // Provide a dummy overload so the name 'Gradient' exists for this object.
  void Gradient(traits::UnconstructableType&, const size_t, const size_t);
};

/**
 * Reflect the existing Gradient().
 */
template<typename FunctionType,
         typename MatType,
         typename GradType,
         bool HasSeparableEvaluateWithGradient>
class AddSeparableGradient<FunctionType, MatType, GradType,
    HasSeparableEvaluateWithGradient, true>
{
 public:
  // Reflect the existing Gradient().
  void Gradient(const MatType& coordinates,
                const size_t begin,
                GradType& gradient,
                const size_t batchSize)
  {
    static_cast<FunctionType*>(
        static_cast<Function<FunctionType,
                             MatType,
                             GradType>*>(this))->Gradient(
        coordinates, begin, gradient, batchSize);
  }
};

/**
 * If we have a separable EvaluateWithGradient() but not a separable
 * Gradient(), add a separable Evaluate() method.
 */
template<typename FunctionType, typename MatType, typename GradType>
class AddSeparableGradient<FunctionType, MatType, GradType, true, false>
{
 public:
  /**
   * Calculate the gradient and store it in the given matrix, starting at the
   * given separable function index and using the given batch size.
   *
   * @param coordinates Coordinates to evaluate the function at.
   * @param begin Index of separable function to start at.
   * @param gradient Matrix to store the gradient into.
   * @param batchSize Number of separable functions to calculate for.
   */
  void Gradient(const MatType& coordinates,
                const size_t begin,
                GradType& gradient,
                const size_t batchSize)
  {
    // The returned objective value will be ignored.
    (void) static_cast<Function<FunctionType,
                                MatType,
                                GradType>*>(this)->EvaluateWithGradient(
        coordinates, begin, gradient, batchSize);
  }
};

/**
 * The AddSeparableGradientConst mixin class will add a separable const
 * Gradient() method if a separable const EvaluateWithGradient() function
 * exists, or nothing otherwise.
 */
template<typename FunctionType,
         typename MatType,
         typename GradType,
         bool HasSeparableEvaluateWithGradient =
             traits::HasEvaluateWithGradient<FunctionType,
                 traits::TypedForms<MatType, GradType>::template
                     SeparableEvaluateWithGradientConstForm>::value,
         bool HasSeparableGradient =
             traits::HasGradient<FunctionType,
                 traits::TypedForms<MatType, GradType>::template
                     SeparableGradientConstForm>::value>
class AddSeparableGradientConst
{
 public:
  // Provide a dummy overload so the name 'Gradient' exists for this object.
  void Gradient(traits::UnconstructableType&, const size_t, const size_t) const;
};

/**
 * Reflect the existing Gradient().
 */
template<typename FunctionType,
         typename MatType,
         typename GradType,
         bool HasSeparableEvaluateWithGradient>
class AddSeparableGradientConst<FunctionType, MatType, GradType,
    HasSeparableEvaluateWithGradient, true>
{
 public:
  // Reflect the existing Gradient().
  void Gradient(const MatType& coordinates,
                const size_t begin,
                GradType& gradient,
                const size_t batchSize) const
  {
    static_cast<const FunctionType*>(
        static_cast<const Function<FunctionType,
                                   MatType,
                                   GradType>*>(this))->Gradient(coordinates,
        begin, gradient, batchSize);
  }
};

/**
 * If we have a separable const EvaluateWithGradient() but not a separable
 * const Gradient(), add a separable const Gradient() method.
 */
template<typename FunctionType, typename MatType, typename GradType>
class AddSeparableGradientConst<FunctionType, MatType, GradType, true, false>
{
 public:
  /**
   * Calculate the gradient and store it in the given matrix, starting at the
   * given separable function index and using the given batch size.
   *
   * @param coordinates Coordinates to evaluate the function at.
   * @param begin Index of separable function to start at.
   * @param gradient Matrix to store the gradient into.
   * @param batchSize Number of separable functions to calculate for.
   */
  void Gradient(const MatType& coordinates,
                const size_t begin,
                GradType& gradient,
                const size_t batchSize) const
  {
    // The returned objective value will be ignored.
    (void) static_cast<
        const Function<FunctionType,
                       MatType,
                       GradType>*>(this)->EvaluateWithGradient(
        coordinates, begin, gradient, batchSize);
  }
};

/**
 * The AddSeparableEvaluateStatic mixin class will add a separable static
 * Gradient() method if a separable static EvaluateWithGradient() function
 * exists, or nothing otherwise.
 */
template<typename FunctionType,
         typename MatType,
         typename GradType,
         bool HasSeparableEvaluateWithGradient =
             traits::HasEvaluateWithGradient<FunctionType,
                 traits::TypedForms<MatType, GradType>::template
                     SeparableEvaluateWithGradientStaticForm>::value,
         bool HasSeparableGradient =
             traits::HasGradient<FunctionType,
                 traits::TypedForms<MatType, GradType>::template
                     SeparableGradientStaticForm>::value>
class AddSeparableGradientStatic
{
 public:
  // Provide a dummy overload so the name 'Gradient' exists for this object.
  static void Gradient(traits::UnconstructableType&,
                       const size_t,
                       const size_t);
};

/**
 * Reflect the existing Gradient().
 */
template<typename FunctionType,
         typename MatType,
         typename GradType,
         bool HasSeparableEvaluateWithGradient>
class AddSeparableGradientStatic<FunctionType, MatType, GradType,
    HasSeparableEvaluateWithGradient, true>
{
 public:
  // Reflect the existing Gradient().
  static void Gradient(const MatType& coordinates,
                       const size_t begin,
                       GradType& gradient,
                       const size_t batchSize)
  {
    FunctionType::Gradient(coordinates, begin, gradient, batchSize);
  }
};

/**
 * If we have a separable EvaluateWithGradient() but not a separable
 * Gradient(), add a separable Gradient() method.
 */
template<typename FunctionType, typename MatType, typename GradType>
class AddSeparableGradientStatic<FunctionType, MatType, GradType, true,
    false>
{
 public:
  /**
   * Calculate the gradient and store it in the given matrix, starting at the
   * given separable function index and using the given batch size.
   *
   * @param coordinates Coordinates to evaluate the function at.
   * @param begin Index of separable function to start at.
   * @param gradient Matrix to store the gradient into.
   * @param batchSize Number of separable functions to calculate for.
   */
  static void Gradient(const MatType& coordinates,
                       const size_t begin,
                       GradType& gradient,
                       const size_t batchSize)
  {
    // The returned objective value will be ignored.
    (void) FunctionType::EvaluateWithGradient(coordinates, begin, gradient,
        batchSize);
  }
};

} // namespace ens

#endif
/**
 * @file arma_traits.hpp
 * @author Ryan Curtin
 *
 * Given an Armadillo type, determine its "true" base type.
 */
#ifndef ENSMALLEN_FUNCTION_ARMA_TRAITS_HPP
#define ENSMALLEN_FUNCTION_ARMA_TRAITS_HPP

namespace ens {

/**
 * Extract the base type of a matrix (i.e. if it is a column, return the matrix
 * type).  If the type is unknown (or not a derived type) we just return the
 * type itself as the typedef BaseMatType.
 */

template<typename MatType>
struct MatTypeTraits
{
  typedef MatType BaseMatType;
};

template<typename eT>
struct MatTypeTraits<arma::Col<eT>>
{
  typedef arma::Mat<eT> BaseMatType;
};

template<typename eT>
struct MatTypeTraits<arma::Row<eT>>
{
  typedef arma::Mat<eT> BaseMatType;
};

template<typename eT>
struct MatTypeTraits<arma::SpCol<eT>>
{
  typedef arma::SpMat<eT> BaseMatType;
};

template<typename eT>
struct MatTypeTraits<arma::SpRow<eT>>
{
  typedef arma::SpMat<eT> BaseMatType;
};

/**
 * Disable usage of arma::subviews and related types for optimizers.  It might
 * be nice to also explicitly disable Armadillo expressions, but we'll hope for
 * now nobody even tries that, since those aren't even lvalues and thus can't
 * really work.
 */

template<typename eT>
struct MatTypeTraits<arma::subview<eT>>
{
  static_assert(sizeof(arma::subview<eT>) == 0,
      "Armadillo subviews cannot be passed to Optimize()!  Create a matrix "
      "or a matrix alias instead!");
};

template<typename eT>
struct MatTypeTraits<arma::subview_col<eT>>
{
  static_assert(sizeof(arma::subview_col<eT>) == 0,
      "Armadillo subviews cannot be passed to Optimize()!  Create a matrix "
      "or a matrix alias instead!");
};

template<typename eT>
struct MatTypeTraits<arma::SpSubview<eT>>
{
  static_assert(sizeof(arma::SpSubview<eT>) == 0,
      "Armadillo subviews cannot be passed to Optimize()!  Create a matrix "
      "or a matrix alias instead!");
};


#if ((ARMA_VERSION_MAJOR >= 10) || \
    ((ARMA_VERSION_MAJOR == 9) && (ARMA_VERSION_MINOR >= 869)))

// Armadillo 9.869+ has SpSubview_col and SpSubview_row

template<typename eT>
struct MatTypeTraits<arma::SpSubview_col<eT>>
{
  static_assert(sizeof(arma::SpSubview_col<eT>) == 0,
      "Armadillo subviews cannot be passed to Optimize()!  Create a matrix "
      "or a matrix alias instead!");
};

template<typename eT>
struct MatTypeTraits<arma::SpSubview_row<eT>>
{
  static_assert(sizeof(arma::SpSubview_row<eT>) == 0,
      "Armadillo subviews cannot be passed to Optimize()!  Create a matrix "
      "or a matrix alias instead!");
};

#endif


template<typename eT>
struct MatTypeTraits<arma::Cube<eT>>
{
  static_assert(sizeof(arma::Cube<eT>) == 0,
      "Armadillo cubes cannot be passed to Optimize()!  Create a matrix "
      "or a matrix alias instead!");
};

/**
 * Issue a fatal error if the type is not an Armadillo double or floating point
 * sparse or dense matrix.
 */

template<typename MatType>
void RequireDenseFloatingPointType()
{
#ifndef ENS_DISABLE_TYPE_CHECKS
  static_assert(sizeof(MatType) == 0,
      "The given MatType must be arma::mat or arma::fmat or it is not known "
      "to work!  If you would like to try anyway, set the preprocessor macro "
      "ENS_DISABLE_TYPE_CHECKS before including ensmallen.hpp.  However, you "
      "get to pick up all the pieces if there is a failure!");
#endif
}

template<>
inline void RequireDenseFloatingPointType<arma::mat>() { }
template<>
inline void RequireDenseFloatingPointType<arma::fmat>() { }

template<typename MatType>
void RequireFloatingPointType()
{
#ifndef ENS_DISABLE_TYPE_CHECKS
  static_assert(sizeof(MatType) == 0,
      "The given MatType must be arma::mat, arma::fmat, arma::sp_mat, or "
      "arma::sp_fmat, or it is not known to work!  If you would like to try "
      "anyway, set the preprocessor macro ENS_DISABLE_TYPE_CHECKS before "
      "including ensmallen.hpp.  However, you get to pick up all the pieces if "
      "there is a failure!");
#endif
}

template<>
inline void RequireFloatingPointType<arma::mat>() { }
template<>
inline void RequireFloatingPointType<arma::fmat>() { }
template<>
inline void RequireFloatingPointType<arma::sp_mat>() { }
template<>
inline void RequireFloatingPointType<arma::sp_fmat>() { }

/**
 * Require that the internal element type of the matrix type and gradient type
 * are the same.  A static_assert() will fail if not.
 */
template<typename MatType, typename GradType>
void RequireSameInternalTypes()
{
#ifndef ENS_DISABLE_TYPE_CHECKS
  static_assert(std::is_same<typename MatType::elem_type,
                             typename GradType::elem_type>::value,
      "The internal element types of the given MatType and GradType must be "
      "identical, or it is not known to work!  If you would like to try "
      "anyway, set the preprocessor macro ENS_DISABLE_TYPE_CHECKS before "
      "including ensmallen.hpp.  However, you get to pick up all the pieces if "
      "there is a failure!");
#endif
}

} // namespace ens

#endif
/**
 * @file sfinae_utility.hpp
 * @author Trironk Kiatkungwanglai
 * @author Kirill Mishchenko
 *
 * This file contains macro utilities for the SFINAE Paradigm. These utilities
 * determine if classes passed in as template parameters contain members at
 * compile time, which is useful for changing functionality depending on what
 * operations an object is capable of performing.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_CORE_SFINAE_UTILITY
#define ENSMALLEN_CORE_SFINAE_UTILITY

#include <type_traits>
#include <cstring>

namespace ens {
namespace sfinae {

// TODO: I think a lot of this can be stripped for ensmallen.

/*
 * MethodFormDetector is a tool that helps to find out whether a given class has
 * a method of the requested form. For that purpose MethodFormDetector defines
 * an operator() that accepts a class member pointer for the given class. If the
 * operator()(&Class::Method) call can be compiled, then the given class has a
 * method of the requested form. For any provided AdditionalArgsCount, the check
 * succeeds only if the given class has exactly one method of the requested form
 * with AdditionalArgsCount additional arguments.
 *
 * The tool is dedicated to be used in type functions (structs) generated by the
 * macro ENS_HAS_METHOD_FORM.
 *
 * @tparam MethodForm A template class member pointer type to a method of the
 *   form to look for.
 * @tparam Class A class in which a method of the requested form should be
 *   looked for.
 * @tparam AdditionalArgsCount A number of additional arguments.
 */
template<typename Class,
         template<typename...> class MethodForm,
         size_t AdditionalArgsCount>
struct MethodFormDetector;

template<typename Class, template<typename...> class MethodForm>
struct MethodFormDetector<Class, MethodForm, 0>
{
  void operator()(MethodForm<Class>);
};

template<typename Class, template<typename...> class MethodForm>
struct MethodFormDetector<Class, MethodForm, 1>
{
  template<class T1>
  void operator()(MethodForm<Class, T1>);
};

template<typename Class, template<typename...> class MethodForm>
struct MethodFormDetector<Class, MethodForm, 2>
{
  template<class T1, class T2>
  void operator()(MethodForm<Class, T1, T2>);
};

template<typename Class, template<typename...> class MethodForm>
struct MethodFormDetector<Class, MethodForm, 3>
{
  template<class T1, class T2, class T3>
  void operator()(MethodForm<Class, T1, T2, T3>);
};

template<typename Class, template<typename...> class MethodForm>
struct MethodFormDetector<Class, MethodForm, 4>
{
  template<class T1, class T2, class T3, class T4>
  void operator()(MethodForm<Class, T1, T2, T3, T4>);
};

template<typename Class, template<typename...> class MethodForm>
struct MethodFormDetector<Class, MethodForm, 5>
{
  template<class T1, class T2, class T3, class T4, class T5>
  void operator()(MethodForm<Class, T1, T2, T3, T4, T5>);
};

template<typename Class, template<typename...> class MethodForm>
struct MethodFormDetector<Class, MethodForm, 6>
{
  template<class T1, class T2, class T3, class T4, class T5, class T6>
  void operator()(MethodForm<Class, T1, T2, T3, T4, T5, T6>);
};

template<typename Class, template<typename...> class MethodForm>
struct MethodFormDetector<Class, MethodForm, 7>
{
  template<class T1, class T2, class T3, class T4, class T5, class T6, class T7>
  void operator()(MethodForm<Class, T1, T2, T3, T4, T5, T6, T7>);
};

//! Utility struct for checking signatures.
template<typename U, U> struct SigCheck : std::true_type {};

template<typename... Args>
struct pack {};

template<typename Func>
struct FunctionTypes {};

template<typename R, typename... A>
struct FunctionTypes<R(A...)>
{
  typedef R Ret;
  using Args = pack<A...>;
};

template<typename R, typename C, typename... A>
struct FunctionTypes<R(C::*)(A...)>
{
  typedef R Ret;
  typedef C Class;
  using Args = pack<A...>;
};

} // namespace sfinae
} // namespace ens

/*
 * Constructs a template supporting the SFINAE pattern.
 *
 * This macro generates a template struct that is useful for enabling/disabling
 * a method if the template class passed in contains a member function matching
 * a given signature with a specified name.
 *
 * The generated struct should be used in conjunction with std::enable_if_t.
 *
 * For general references, see:
 * http://stackoverflow.com/a/264088/391618
 *
 * @param NAME the name of the struct to construct. For example: HasToString
 * @param FUNC the name of the function to check for. For example: ToString
 */
#undef  ENS_HAS_MEM_FUNC
#define ENS_HAS_MEM_FUNC(FUNC, NAME)                                           \
template<typename T, typename sig, typename = std::true_type>                  \
struct NAME : std::false_type {};                                              \
                                                                               \
template<typename T, typename sig>                                             \
struct NAME                                                                    \
<                                                                              \
  T,                                                                           \
  sig,                                                                         \
  std::is_same<decltype(std::declval<T>().FUNC(std::declval<                   \
      ens::sfinae::FunctionTypes<sig>::A...>()...)),                           \
      ens::sfinae::FunctionTypes<sig>::Ret>::type>                             \
> : std::true_type {};

/**
 * Base macro for ENS_HAS_METHOD_FORM() and ENS_HAS_EXACT_METHOD_FORM() macros.
 */
#undef  ENS_HAS_METHOD_FORM_BASE
#define ENS_HAS_METHOD_FORM_BASE(METHOD, NAME, MAXN)                           \
template<typename Class,                                                       \
         template<typename...> class MF /* MethodForm */,                      \
         size_t MinN = 0 /* MinNumberOfAdditionalArgs */>                      \
struct NAME                                                                    \
{                                                                              \
  /* Making a short alias for MethodFormDetector */                            \
  template<typename C, template<typename...> class MethodForm, int N>          \
  using MFD = ens::sfinae::MethodFormDetector<C, MethodForm, N>;            \
                                                                               \
  template<size_t N>                                                           \
  struct WithNAdditionalArgs                                                   \
  {                                                                            \
    using yes = char[1];                                                       \
    using no = char[2];                                                        \
                                                                               \
    template<typename T, typename ResultType>                                  \
    using EnableIfVoid =                                                       \
        typename std::enable_if<std::is_void<T>::value, ResultType>::type;     \
                                                                               \
    template<typename C>                                                       \
    static EnableIfVoid<decltype(MFD<C, MF, N>()(&C::METHOD)), yes&> chk(int); \
    template<typename>                                                         \
    static no& chk(...);                                                       \
                                                                               \
    static const bool value = sizeof(chk<Class>(0)) == sizeof(yes);            \
  };                                                                           \
                                                                               \
  template<size_t N>                                                           \
  struct WithGreaterOrEqualNumberOfAdditionalArgs                              \
  {                                                                            \
    using type = typename std::conditional<                                    \
        WithNAdditionalArgs<N>::value,                                         \
        std::true_type,                                                        \
        typename std::conditional<                                             \
            N < MAXN,                                                          \
            WithGreaterOrEqualNumberOfAdditionalArgs<N + 1>,                   \
            std::false_type>::type>::type;                                     \
    static const bool value = type::value;                                     \
  };                                                                           \
                                                                               \
  static const bool value =                                                    \
      WithGreaterOrEqualNumberOfAdditionalArgs<MinN>::value;                   \
};

/**
 * Constructs a template structure, which will define a boolean static
 * variable, to true, if the passed template parameter, has a member function
 * with the specified name. The check does not care about the signature or the
 * function parameters.
 *
 * @param FUNC the name of the function, whose existence is to be detected
 * @param NAME the name of the structure that will be generated
 *
 * Use this like: NAME<ClassName>::value to check for the existence of the
 * function in the given class name.
 * This can also be used in conjunction with std::enable_if.
 */
#undef  ENS_HAS_ANY_METHOD_FORM
#define ENS_HAS_ANY_METHOD_FORM(FUNC, NAME)                                  \
template <typename T>                                                        \
struct NAME                                                                  \
{                                                                            \
  template <typename Q = T>                                                  \
  static typename                                                            \
  std::enable_if<std::is_member_function_pointer<decltype(&Q::FUNC)>::value, \
                 int>::type                                                  \
  f(int) { return 1;}                                                      \
                                                                             \
  template <typename Q = T>                                                  \
  static char f(char) { return 0; }                                        \
                                                                             \
  static const bool value = sizeof(f<T>(0)) != sizeof(char);                 \
};
/*
 * A macro that can be used for passing arguments containing commas to other
 * macros.
 */
#undef  ENS_SINGLE_ARG
#define ENS_SINGLE_ARG(...) __VA_ARGS__

/**
 * ENS_HAS_METHOD_FORM generates a template that allows to check at compile time
 * whether a given class has a method of the requested form. For example, for
 * the following class
 *
 * class A
 * {
 *  public:
 *   ...
 *   Train(const arma::mat&, const arma::Row<size_t>&, double);
 *   ...
 * };
 *
 * and the following form of Train methods
 *
 * template<typename Class, typename...Ts>
 * using TrainForm =
 *     void(Class::*)(const arma::mat&, const arma::Row<size_t>&, Ts...);
 *
 * we can check whether the class A has a Train method of the specified form:
 *
 * ENS_HAS_METHOD_FORM(Train, HasTrain);
 * static_assert(HasTrain<A, TrainFrom>::value, "value should be true");
 *
 * The class generated by this will also return true values if the given class
 * has a method that also has extra parameters.
 *
 * @param METHOD The name of the method to check for.
 * @param NAME The name of the struct to construct.
 * @param MAXN The maximum number of additional arguments.
 */
#undef  ENS_HAS_METHOD_FORM
#define ENS_HAS_METHOD_FORM(METHOD, NAME) \
    ENS_HAS_METHOD_FORM_BASE(ENS_SINGLE_ARG(METHOD), ENS_SINGLE_ARG(NAME), 7)

/**
 * ENS_HAS_EXACT_METHOD_FORM generates a template that allows to check at
 * compile time whether a given class has a method of the requested form. For
 * example, for the following class
 *
 * class A
 * {
 *  public:
 *   ...
 *   Train(const arma::mat&, const arma::Row<size_t>&);
 *   ...
 * };
 *
 * and the following form of Train methods
 *
 * template<typename Class>
 * using TrainForm =
 *     void(Class::*)(const arma::mat&, const arma::Row<size_t>&);
 *
 * we can check whether the class A has a Train method of the specified form:
 *
 * ENS_HAS_METHOD_FORM(Train, HasTrain);
 * static_assert(HasTrain<A, TrainFrom>::value, "value should be true");
 *
 * The class generated by this will only return true values if the signature
 * matches exactly.
 *
 * @param METHOD The name of the method to check for.
 * @param NAME The name of the struct to construct.
 * @param MAXN The maximum number of additional arguments.
 */
#undef  ENS_HAS_EXACT_METHOD_FORM
#define ENS_HAS_EXACT_METHOD_FORM(METHOD, NAME) \
    ENS_HAS_METHOD_FORM_BASE(ENS_SINGLE_ARG(METHOD), ENS_SINGLE_ARG(NAME), 0)

#endif
/**
 * @file static_checks.hpp
 * @author Shikhar Bhardwaj
 *
 * This file contains the definitions of the method forms required by the
 * FunctionType API used by the optimizers. These method forms can be used to
 * check the compliance of a user provided FunctionType with the required
 * interface from the optimizer at compile time.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_STATIC_CHECKS_HPP
#define ENSMALLEN_STATIC_CHECKS_HPP

#include "sfinae_utility.hpp"

namespace ens {
namespace traits {

/**
 * Check if a suitable overload of Evaluate() is available.
 *
 * This is required by the FunctionType API.
 */
template<typename FunctionType, typename MatType, typename GradType>
struct CheckEvaluate
{
  const static bool value =
      HasEvaluate<FunctionType,
          TypedForms<MatType, GradType>::template EvaluateForm>::value ||
      HasEvaluate<FunctionType,
          TypedForms<MatType, GradType>::template EvaluateConstForm>::value ||
      HasEvaluate<FunctionType,
          TypedForms<MatType, GradType>::template EvaluateStaticForm>::value;
};

/**
 * Check if a suitable overload of Gradient() is available.
 *
 * This is required by the FunctionType API.
 */
template<typename FunctionType, typename MatType, typename GradType>
struct CheckGradient
{
  const static bool value =
      HasGradient<FunctionType,
          TypedForms<MatType, GradType>::template GradientForm>::value ||
      HasGradient<FunctionType,
          TypedForms<MatType, GradType>::template GradientConstForm>::value ||
      HasGradient<FunctionType,
          TypedForms<MatType, GradType>::template GradientStaticForm>::value;
};

/**
 * Check if a suitable overload of NumFunctions() is available.
 *
 * This is required by the SeparableFunctionType API.
 */
template<typename FunctionType, typename MatType, typename GradType>
struct CheckNumFunctions
{
  const static bool value =
      HasNumFunctions<FunctionType, TypedForms<MatType, GradType>::template
          NumFunctionsForm>::value ||
      HasNumFunctions<FunctionType, TypedForms<MatType, GradType>::template
          NumFunctionsConstForm>::value ||
      HasNumFunctions<FunctionType, TypedForms<MatType, GradType>::template
          NumFunctionsStaticForm>::value;
};

/**
 * Check if a suitable overload of Shuffle() is available.
 *
 * This is required by the SeparableFunctionType API.
 */
template<typename FunctionType, typename MatType, typename GradType>
struct CheckShuffle
{
  const static bool value =
      HasShuffle<FunctionType, TypedForms<MatType, GradType>::template
          ShuffleForm>::value ||
      HasShuffle<FunctionType, TypedForms<MatType, GradType>::template
          ShuffleConstForm>::value ||
      HasShuffle<FunctionType, TypedForms<MatType, GradType>::template
          ShuffleStaticForm>::value;
};

/**
 * Check if a suitable separable overload of Evaluate() is available.
 *
 * This is required by the SeparableFunctionType API.
 */
template<typename FunctionType, typename MatType, typename GradType>
struct CheckSeparableEvaluate
{
  const static bool value =
      HasEvaluate<FunctionType, TypedForms<MatType, GradType>::template
          SeparableEvaluateForm>::value ||
      HasEvaluate<FunctionType, TypedForms<MatType, GradType>::template
          SeparableEvaluateConstForm>::value ||
      HasEvaluate<FunctionType, TypedForms<MatType, GradType>::template
          SeparableEvaluateStaticForm>::value;
};

/**
 * Check if a suitable separable overload of Gradient() is available.
 *
 * This is required by the SeparableFunctionType API.
 */
template<typename FunctionType, typename MatType, typename GradType>
struct CheckSeparableGradient
{
  const static bool value =
      HasGradient<FunctionType, TypedForms<MatType, GradType>::template
          SeparableGradientForm>::value ||
      HasGradient<FunctionType, TypedForms<MatType, GradType>::template
          SeparableGradientConstForm>::value ||
      HasGradient<FunctionType, TypedForms<MatType, GradType>::template
          SeparableGradientStaticForm>::value;
};

/**
 * Check if a suitable overload of NumConstraints() is available.
 *
 * This is required by the ConstrainedFunctionType API.
 */
template<typename FunctionType, typename MatType, typename GradType>
struct CheckNumConstraints
{
  const static bool value =
      HasNumConstraints<FunctionType, TypedForms<MatType, GradType>::template
          NumConstraintsForm>::value ||
      HasNumConstraints<FunctionType, TypedForms<MatType, GradType>::template
          NumConstraintsConstForm>::value ||
      HasNumConstraints<FunctionType, TypedForms<MatType, GradType>::template
          NumConstraintsStaticForm>::value;
};

/**
 * Check if a suitable overload of EvaluateConstraint() is available.
 *
 * This is required by the ConstrainedFunctionType API.
 */
template<typename FunctionType, typename MatType, typename GradType>
struct CheckEvaluateConstraint
{
  const static bool value =
      HasEvaluateConstraint<FunctionType,
          TypedForms<MatType, GradType>::template
              EvaluateConstraintForm>::value ||
      HasEvaluateConstraint<FunctionType,
          TypedForms<MatType, GradType>::template
              EvaluateConstraintConstForm>::value ||
      HasEvaluateConstraint<FunctionType,
          TypedForms<MatType, GradType>::template
              EvaluateConstraintStaticForm>::value;
};

/**
 * Check if a suitable overload of GradientConstraint() is available.
 *
 * This is required by the ConstrainedFunctionType API.
 */
template<typename FunctionType, typename MatType, typename GradType>
struct CheckGradientConstraint
{
  const static bool value =
      HasGradientConstraint<FunctionType,
          TypedForms<MatType, GradType>::template
              GradientConstraintForm>::value ||
      HasGradientConstraint<FunctionType,
          TypedForms<MatType, GradType>::template
              GradientConstraintConstForm>::value ||
      HasGradientConstraint<FunctionType,
          TypedForms<MatType, GradType>::template
              GradientConstraintStaticForm>::value;
};

/**
 * Check if a suitable overload of Gradient() that supports sparse gradients is
 * available.
 *
 * This is required by the SparseFunctionType API.
 */
template<typename FunctionType, typename MatType, typename GradType>
struct CheckSparseGradient
{
  const static bool value =
      HasGradient<FunctionType, TypedForms<MatType, GradType>::template
          SparseGradientForm>::value ||
      HasGradient<FunctionType, TypedForms<MatType, GradType>::template
          SparseGradientConstForm>::value ||
      HasGradient<FunctionType, TypedForms<MatType, GradType>::template
          SparseGradientStaticForm>::value;
};

/**
 * Check if a suitable overload of NumFeatures() is available.
 *
 * This is required by the ResolvableFunctionType API.
 */
template<typename FunctionType, typename MatType, typename GradType>
struct CheckNumFeatures
{
  const static bool value =
      HasNumFeatures<FunctionType, TypedForms<MatType, GradType>::template
          NumFeaturesForm>::value ||
      HasNumFeatures<FunctionType, TypedForms<MatType, GradType>::template
          NumFeaturesConstForm>::value ||
      HasNumFeatures<FunctionType, TypedForms<MatType, GradType>::template
          NumFeaturesStaticForm>::value;
};

/**
 * Check if a suitable overload of PartialGradient() is available.
 *
 * This is required by the ResolvableFunctionType API.
 */
template<typename FunctionType, typename MatType, typename GradType>
struct CheckPartialGradient
{
  const static bool value =
      HasPartialGradient<FunctionType, TypedForms<MatType, GradType>::template
          PartialGradientForm>::value ||
      HasPartialGradient<FunctionType, TypedForms<MatType, GradType>::template
          PartialGradientConstForm>::value ||
      HasPartialGradient<FunctionType, TypedForms<MatType, GradType>::template
          PartialGradientStaticForm>::value;
};

/**
 * Check if a suitable overload of EvaluateWithGradient() is available.
 *
 * This is required by the FunctionType API.
 */
template<typename FunctionType, typename MatType, typename GradType>
struct CheckEvaluateWithGradient
{
  const static bool value =
      HasEvaluateWithGradient<FunctionType,
          TypedForms<MatType, GradType>::template
              EvaluateWithGradientForm>::value ||
      HasEvaluateWithGradient<FunctionType,
          TypedForms<MatType, GradType>::template
              EvaluateWithGradientConstForm>::value ||
      HasEvaluateWithGradient<FunctionType,
          TypedForms<MatType, GradType>::template
              EvaluateWithGradientStaticForm>::value;
};

/**
 * Check if a suitable separable overload of EvaluateWithGradient() is
 * available.
 *
 * This is required by the FunctionType API.
 */
template<typename FunctionType, typename MatType, typename GradType>
struct CheckSeparableEvaluateWithGradient
{
  const static bool value =
      HasEvaluateWithGradient<FunctionType,
          TypedForms<MatType, GradType>::template
              SeparableEvaluateWithGradientForm>::value ||
      HasEvaluateWithGradient<FunctionType,
          TypedForms<MatType, GradType>::template
              SeparableEvaluateWithGradientConstForm>::value ||
      HasEvaluateWithGradient<FunctionType,
          TypedForms<MatType, GradType>::template
              SeparableEvaluateWithGradientStaticForm>::value;
};

/**
 * Perform checks for the regular FunctionType API.
 */
template<typename FunctionType, typename MatType, typename GradType>
inline void CheckFunctionTypeAPI()
{
#ifndef ENS_DISABLE_TYPE_CHECKS
  static_assert(CheckEvaluate<FunctionType, MatType, GradType>::value,
      "The FunctionType does not have a correct definition of Evaluate(). "
      "Please check that the FunctionType fully satisfies the requirements of "
      "the FunctionType API; see the optimizer tutorial for details.");

  static_assert(CheckGradient<FunctionType, MatType, GradType>::value,
      "The FunctionType does not have a correct definition of Gradient(). "
      "Please check that the FunctionType fully satisfies the requirements of "
      "the FunctionType API; see the optimizer tutorial for details.");

  static_assert(
      CheckEvaluateWithGradient<FunctionType, MatType, GradType>::value,
      "The FunctionType does not have a correct definition of "
      "EvaluateWithGradient().  Please check that the FunctionType fully "
      "satisfies the requirements of the FunctionType API; see the optimizer "
      "tutorial for more details.");
#endif
}

/**
 * Perform checks for the SeparableFunctionType API.
 */
template<typename FunctionType, typename MatType, typename GradType>
inline void CheckSeparableFunctionTypeAPI()
{
#ifndef ENS_DISABLE_TYPE_CHECKS
  static_assert(CheckSeparableEvaluate<FunctionType,
                                       MatType,
                                       GradType>::value,
      "The FunctionType does not have a correct definition of a separable "
      "Evaluate() method.  Please check that the FunctionType fully satisfies"
      " the requirements of the SeparableFunctionType API; see the optimizer"
      " tutorial for more details.");

  static_assert(CheckSeparableGradient<FunctionType,
                                       MatType,
                                       GradType>::value,
      "The FunctionType does not have a correct definition of a separable "
      "Gradient() method.  Please check that the FunctionType fully satisfies"
      " the requirements of the SeparableFunctionType API; see the optimizer"
      " tutorial for more details.");

  static_assert(CheckSeparableEvaluateWithGradient<FunctionType,
                                                   MatType,
                                                   GradType>::value,
      "The FunctionType does not have a correct definition of a separable "
      "EvaluateWithGradient() method.  Please check that the FunctionType "
      "fully satisfies the requirements of the SeparableFunctionType API; "
      "see the optimizer tutorial for more details.");

  static_assert(CheckNumFunctions<FunctionType, MatType, GradType>::value,
      "The FunctionType does not have a correct definition of NumFunctions(). "
      "Please check that the FunctionType fully satisfies the requirements of "
      "the SeparableFunctionType API; see the optimizer tutorial for more "
      "details.");

  static_assert(CheckShuffle<FunctionType, MatType, GradType>::value,
      "The FunctionType does not have a correct definition of Shuffle(). "
      "Please check that the FunctionType fully satisfies the requirements of "
      "the SeparableFunctionType API; see the optimizer tutorial for more "
      "details.");
#endif
}

/**
 * Perform checks for the SparseFunctionType API.
 */
template<typename FunctionType, typename MatType, typename GradType>
inline void CheckSparseFunctionTypeAPI()
{
#ifndef ENS_DISABLE_TYPE_CHECKS
  static_assert(CheckNumFunctions<FunctionType, MatType, GradType>::value,
      "The FunctionType does not have a correct definition of NumFunctions(). "
      "Please check that the FunctionType fully satisfies the requirements of "
      "the SparseFunctionType API; see the optimizer tutorial for more "
      "details.");

  static_assert(CheckSeparableEvaluate<FunctionType,
                                          MatType,
                                          GradType>::value,
      "The FunctionType does not have a correct definition of Evaluate(). "
      "Please check that the FunctionType fully satisfies the requirements of "
      "the SparseFunctionType API; see the optimizer tutorial for more "
      "details.");

  static_assert(CheckSparseGradient<FunctionType, MatType, GradType>::value,
      "The FunctionType does not have a correct definition of a sparse "
      "Gradient() method. Please check that the FunctionType fully satisfies "
      "the requirements of the SparseFunctionType API; see the optimizer "
      "tutorial for more details.");
#endif
}

/**
 * Perform checks for the ArbitraryFunctionType API.
 */
template<typename FunctionType, typename MatType>
inline void CheckArbitraryFunctionTypeAPI()
{
#ifndef ENS_DISABLE_TYPE_CHECKS
  static_assert(CheckEvaluate<FunctionType, MatType, MatType>::value,
      "The FunctionType does not have a correct definition of Evaluate(). "
      "Please check that the FunctionType fully satisfies the requirements of "
      "the ArbitraryFunctionType API; see the optimizer tutorial for "
      "more details.");
#endif
}

template<typename FunctionType, typename... RemainingTypes>
typename std::enable_if<(sizeof...(RemainingTypes) > 1), void>::type
CheckArbitraryFunctionTypeAPI()
{
#ifndef ENS_DISABLE_TYPE_CHECKS
  constexpr size_t size = sizeof...(RemainingTypes);
  using TupleType = typename std::tuple<RemainingTypes...>;
  using MatType = typename std::tuple_element<size - 1, TupleType>::type;

  static_assert(CheckEvaluate<FunctionType, MatType, MatType>::value,
      "One of the provided FunctionType does not have a correct definition of Evaluate(). "
      "Please check that the corresponding FunctionType fully satisfies the requirements "
      "of the ArbitraryFunctionType API; see the optimizer tutorial for "
      "more details.");

  CheckArbitraryFunctionTypeAPI<RemainingTypes...>();
#endif
}

/**
 * Perform checks for the ResolvableFunctionType API.
 */
template<typename FunctionType, typename MatType, typename GradType>
inline void CheckResolvableFunctionTypeAPI()
{
#ifndef ENS_DISABLE_TYPE_CHECKS
  static_assert(CheckNumFeatures<FunctionType, MatType, GradType>::value,
      "The FunctionType does not have a correct definition of NumFeatures(). "
      "Please check that the FunctionType fully satisfies the requirements of "
      "the ResolvableFunctionType API; see the optimizer tutorial for more "
      "details.");

  static_assert(CheckEvaluate<FunctionType, MatType, GradType>::value,
      "The FunctionType does not have a correct definition of Evaluate(). "
      "Please check that the FunctionType fully satisfies the requirements of "
      "the ResolvableFunctionType API; see the optimizer tutorial for more "
      "details.");

  static_assert(CheckPartialGradient<FunctionType, MatType, GradType>::value,
      "The FunctionType does not have a correct definition of a partial "
      "Gradient() function. Please check that the FunctionType fully satisfies "
      "the requirements of the ResolvableFunctionType API; see the optimizer "
      "tutorial for more details.");
#endif
}

/**
 * Perform checks for the ConstrainedFunctionType API.
 */
template<typename FunctionType, typename MatType, typename GradType>
inline void CheckConstrainedFunctionTypeAPI()
{
#ifndef ENS_DISABLE_TYPE_CHECKS
  static_assert(CheckEvaluate<FunctionType, MatType, GradType>::value,
      "The FunctionType does not have a correct definition of Evaluate(). "
      "Please check that the FunctionType fully satisfies the requirements of "
      "the ConstrainedFunctionType API; see the optimizer tutorial for more "
      "details.");

  static_assert(CheckGradient<FunctionType, MatType, GradType>::value,
      "The FunctionType does not have a correct definition of Gradient(). "
      "Please check that the FunctionType fully satisfies the requirements of "
      "the ConstrainedFunctionType API; see the optimizer tutorial for more "
      "details.");

  static_assert(CheckNumConstraints<FunctionType, MatType, GradType>::value,
      "The FunctionType does not have a correct definition of NumConstraints()."
      " Please check that the FunctionType fully satisfies the requirements of "
      "the ConstrainedFunctionType API; see the optimizer tutorial for more "
      "details.");

  static_assert(CheckEvaluateConstraint<FunctionType, MatType, GradType>::value,
      "The FunctionType does not have a correct definition of "
      "EvaluateConstraint(). Please check that the FunctionType fully satisfies"
      " the ConstrainedFunctionType API; see the optimizer tutorial for more "
      "details.");

  static_assert(CheckGradientConstraint<FunctionType, MatType, GradType>::value,
      "The FunctionType does not have a correct definition of "
      "GradientConstraint(). Please check that the FunctionType fully satisfies"
      " the ConstrainedFunctionType API; see the optimizer tutorial for more "
      "details.");
#endif
}

/**
 * Perform checks for the ArbitrarySeparableFunctionType API.  (I
 * know, it is a long name...)
 */
template<typename FunctionType, typename MatType>
inline void CheckArbitrarySeparableFunctionTypeAPI()
{
#ifndef ENS_DISABLE_TYPE_CHECKS
  static_assert(CheckSeparableEvaluate<FunctionType,
                                          MatType,
                                          MatType>::value,
      "The FunctionType does not have a correct definition of Evaluate(). "
      "Please check that the FunctionType fully satisfies the requirements of "
      "the ArbitrarySeparableFunctionType API; see the optimizer "
      "tutorial for more details.");
#endif
}

} // namespace traits
} // namespace ens

#endif
/**
 * @file traits.hpp
 * @author Ryan Curtin
 *
 * This file provides metaprogramming utilities for detecting certain members of
 * FunctionType classes.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_FUNCTION_TRAITS_HPP
#define ENSMALLEN_FUNCTION_TRAITS_HPP

#include "sfinae_utility.hpp"
#include "arma_traits.hpp"

namespace ens {
namespace traits {

//! Detect an Evaluate() method.
ENS_HAS_EXACT_METHOD_FORM(Evaluate, HasEvaluate)
//! Detect a Gradient() method.
ENS_HAS_EXACT_METHOD_FORM(Gradient, HasGradient)
//! Detect an EvaluateWithGradient() method.
ENS_HAS_EXACT_METHOD_FORM(EvaluateWithGradient, HasEvaluateWithGradient)
//! Detect a NumFunctions() method.
ENS_HAS_EXACT_METHOD_FORM(NumFunctions, HasNumFunctions)
//! Detect a Shuffle() method.
ENS_HAS_EXACT_METHOD_FORM(Shuffle, HasShuffle)
//! Detect a NumConstraints() method.
ENS_HAS_EXACT_METHOD_FORM(NumConstraints, HasNumConstraints)
//! Detect an EvaluateConstraint() method.
ENS_HAS_EXACT_METHOD_FORM(EvaluateConstraint, HasEvaluateConstraint)
//! Detect a GradientConstraint() method.
ENS_HAS_EXACT_METHOD_FORM(GradientConstraint, HasGradientConstraint)
//! Detect a NumFeatures() method.
ENS_HAS_EXACT_METHOD_FORM(NumFeatures, HasNumFeatures)
//! Detect a PartialGradient() method.
ENS_HAS_EXACT_METHOD_FORM(PartialGradient, HasPartialGradient)
//! Detect an MaxIterations() method.
ENS_HAS_EXACT_METHOD_FORM(MaxIterations, HasMaxIterations)
//! Detect an ResetPolicy() method.
ENS_HAS_EXACT_METHOD_FORM(ResetPolicy, HasResetPolicy)
//! Detect an BatchSize() method.
ENS_HAS_EXACT_METHOD_FORM(BatchSize, HasBatchSize)
//! Detect an StepSize() method.
ENS_HAS_EXACT_METHOD_FORM(StepSize, HasStepSize)

template<typename MatType, typename GradType>
struct TypedForms
{
  typedef typename MatTypeTraits<MatType>::BaseMatType BaseMatType;
  typedef typename MatTypeTraits<GradType>::BaseMatType BaseGradType;

  //! This is the form of a non-const Evaluate() method.
  template<typename FunctionType>
  using EvaluateForm =
      typename BaseMatType::elem_type(FunctionType::*)(const BaseMatType&);

  //! This is the form of a const Evaluate() method.
  template<typename FunctionType>
  using EvaluateConstForm = typename BaseMatType::elem_type(FunctionType::*)(
      const BaseMatType&) const;

  //! This is the form of a static Evaluate() method.
  template<typename FunctionType>
  using EvaluateStaticForm = typename BaseMatType::elem_type(*)(
      const BaseMatType&);

  //! This is the form of a non-const Gradient() method.
  template<typename FunctionType>
  using GradientForm = void(FunctionType::*)(const BaseMatType&, BaseGradType&);

  //! This is the form of a const Gradient() method.
  template<typename FunctionType>
  using GradientConstForm =
      void(FunctionType::*)(const BaseMatType&, BaseGradType&) const;

  //! This is the form of a static Gradient() method.
  template<typename FunctionType>
  using GradientStaticForm = void(*)(const BaseMatType&, BaseGradType&);

  //! This is the form of a non-const EvaluateWithGradient() method.
  template<typename FunctionType>
  using EvaluateWithGradientForm =
      typename BaseMatType::elem_type(FunctionType::*)(const BaseMatType&,
                                                       BaseGradType&);

  //! This is the form of a const EvaluateWithGradient() method.
  template<typename FunctionType>
  using EvaluateWithGradientConstForm =
      typename BaseMatType::elem_type(FunctionType::*)(const BaseMatType&,
                                                       BaseGradType&) const;

  //! This is the form of a static EvaluateWithGradient() method.
  template<typename FunctionType>
  using EvaluateWithGradientStaticForm = typename BaseMatType::elem_type(*)(
      const BaseMatType&, BaseGradType&);

  //! This is the form of a non-const NumFunctions() method.
  template <typename FunctionType>
  using NumFunctionsForm = size_t(FunctionType::*)();

  //! This is the form of a const NumFunctions() method.
  template <typename FunctionType>
  using NumFunctionsConstForm = size_t(FunctionType::*)() const;

  //! This is the form of a static NumFunctions() method.
  template<typename FunctionType>
  using NumFunctionsStaticForm = size_t(*)();

  //! This is the form of a non-const Shuffle() method.
  template<typename FunctionType>
  using ShuffleForm = void(FunctionType::*)();

  //! This is the form of a const Shuffle() method.
  template<typename FunctionType>
  using ShuffleConstForm = void(FunctionType::*)() const;

  //! This is the form of a static Shuffle() method.
  template<typename FunctionType>
  using ShuffleStaticForm = void(*)();

  //! This is the form of a separable Evaluate() method.
  template<typename FunctionType>
  using SeparableEvaluateForm =
      typename BaseMatType::elem_type(FunctionType::*)(const BaseMatType&,
                                                       const size_t,
                                                       const size_t);

  //! This is the form of a separable const Evaluate() method.
  template<typename FunctionType>
  using SeparableEvaluateConstForm =
      typename BaseMatType::elem_type(FunctionType::*)(const BaseMatType&,
                                                       const size_t,
                                                       const size_t) const;

  //! This is the form of a separable static Evaluate() method.
  template<typename FunctionType>
  using SeparableEvaluateStaticForm = typename BaseMatType::elem_type(*)(
        const BaseMatType&, const size_t, const size_t);

  //! This is the form of a separable non-const Gradient() method.
  template<typename FunctionType>
  using SeparableGradientForm = void(FunctionType::*)(
      const BaseMatType&, const size_t, BaseGradType&, const size_t);

  //! This the form of a separable const Gradient() method.
  template<typename FunctionType>
  using SeparableGradientConstForm = void(FunctionType::*)(
      const BaseMatType&, const size_t, BaseGradType&, const size_t) const;

  //! This is the form of a separable static Gradient() method.
  template<typename FunctionType>
  using SeparableGradientStaticForm = void(*)(
      const BaseMatType&, const size_t, BaseGradType&, const size_t);

  //! This is the form of a separable non-const EvaluateWithGradient()
  //! method.
  template<typename FunctionType>
  using SeparableEvaluateWithGradientForm =
      typename BaseMatType::elem_type(FunctionType::*)(const BaseMatType&,
                                                       const size_t,
                                                       BaseGradType&,
                                                       const size_t);

  //! This is the form of a separable const EvaluateWithGradient() method.
  template<typename FunctionType>
  using SeparableEvaluateWithGradientConstForm =
      typename BaseMatType::elem_type(FunctionType::*)(const BaseMatType&,
                                                       const size_t,
                                                       BaseGradType&,
                                                       const size_t) const;

  //! This is the form of a separable static EvaluateWithGradient() method.
  template<typename FunctionType>
  using SeparableEvaluateWithGradientStaticForm =
      typename BaseMatType::elem_type(*)(const BaseMatType&,
                                         const size_t,
                                         BaseGradType&,
                                         const size_t);

  //! This is the form of a non-const NumConstraints() method.
  template<typename FunctionType>
  using NumConstraintsForm = size_t(FunctionType::*)();

  //! This is the form of a const NumConstraints() method.
  template<typename FunctionType>
  using NumConstraintsConstForm = size_t(FunctionType::*)() const;

  //! This is the form of a static NumConstraints() method.
  template<typename FunctionType>
  using NumConstraintsStaticForm = size_t(*)();

  //! This is the form of a non-const EvaluateConstraint() method.
  template <typename FunctionType>
  using EvaluateConstraintForm =
      typename BaseMatType::elem_type(FunctionType::*)(const size_t,
                                                       const BaseMatType&);

  //! This is the form of a const EvaluateConstraint() method.
  template<typename FunctionType>
  using EvaluateConstraintConstForm =
      typename BaseMatType::elem_type(FunctionType::*)(const size_t,
                                                       const BaseMatType&)
          const;

  //! This is the form of a static EvaluateConstraint() method.
  template<typename FunctionType>
  using EvaluateConstraintStaticForm = typename BaseMatType::elem_type(*)(
      const size_t, const BaseMatType&);

  //! This is the form of a non-const GradientConstraint() method.
  template <typename FunctionType>
  using GradientConstraintForm = void(FunctionType::*)(
      const size_t, const BaseMatType&, BaseGradType&);

  //! This is the form of a const GradientConstraint() method.
  template<typename FunctionType>
  using GradientConstraintConstForm = void(FunctionType::*)(
      const size_t, const BaseMatType&, BaseGradType&) const;

  //! This is the form of a static GradientConstraint() method.
  template<typename Class, typename... Ts>
  using GradientConstraintStaticForm = void(*)(
      const size_t, const BaseMatType&, BaseGradType&);

  //! This is the form of a non-const sparse Gradient() method.
  //! This check isn't particularly useful---the user needs to specify a sparse
  //! gradient type...
  template<typename FunctionType>
  using SparseGradientForm = void(FunctionType::*)(
      const BaseMatType&, const size_t, BaseGradType&, const size_t);

  //! This is the form of a const sparse Gradient() method.
  //! This check isn't particularly useful---the user needs to specify a sparse
  //! gradient type...
  template<typename FunctionType>
  using SparseGradientConstForm = void(FunctionType::*)(
      const BaseMatType&, const size_t, BaseGradType&, const size_t) const;

  //! This is the form of a static sparse Gradient() method.
  //! This check isn't particularly useful---the user needs to specify a sparse
  //! gradient type...
  template<typename FunctionType>
  using SparseGradientStaticForm = void(*)(
      const BaseMatType&, const size_t, BaseGradType&, const size_t);

  //! This is the form of a non-const NumFeatures() method.
  template<typename FunctionType>
  using NumFeaturesForm = size_t(FunctionType::*)();

  //! This is the form of a const NumFeatures() method.
  template<typename FunctionType>
  using NumFeaturesConstForm = size_t(FunctionType::*)() const;

  //! This is the form of a static NumFeatures() method.
  template<typename FunctionType>
  using NumFeaturesStaticForm = size_t(*)();

  //! This is the form of a non-const PartialGradient() method.
  template<typename FunctionType>
  using PartialGradientForm = void(FunctionType::*)(
      const BaseMatType&, const size_t, BaseGradType&);

  //! This is the form of a const PartialGradient() method.
  template<typename FunctionType>
  using PartialGradientConstForm = void(FunctionType::*)(
      const BaseMatType&, const size_t, BaseGradType&) const;

  //! This is the form of a static PartialGradient() method.
  template<typename FunctionType>
  using PartialGradientStaticForm = void(*)(
      const BaseMatType&, const size_t, BaseGradType&);

  //! This is a utility struct that will match any non-const form.
  template<typename FunctionType, typename... Ts>
  using OtherForm = typename BaseMatType::elem_type(FunctionType::*)(Ts...);

  //! This is a utility struct that will match any const form.
  template<typename FunctionType, typename... Ts>
  using OtherConstForm = typename BaseMatType::elem_type(FunctionType::*)(Ts...)
      const;

  //! This is a utility struct that will match any static form.
  template<typename FunctionType, typename... Ts>
  using OtherStaticForm = typename BaseMatType::elem_type(*)(Ts...);
};

/**
 * This is a utility type used to provide unusable overloads from each of the
 * mixin classes.  If you are seeing an error mentioning this class, the most
 * likely issue is that you have not implemented the right methods for your
 * FunctionType class.
 */
struct UnconstructableType
{
 private:
  UnconstructableType() { }
};

/**
 * Utility struct: sometimes we want to know if we have two functions available,
 * and that at least one of them is non-const and non-static.  If the
 * corresponding checkers (from ENS_HAS_METHOD_FORM()) are given as CheckerA and
 * CheckerB, and the corresponding non-const, const, and static function
 * signatures are given as SignatureA, ConstSignatureA, StaticSignatureA,
 * SignatureB, ConstSignatureB, and StaticSignatureB, then 'value' will be true
 * if methods with the correct names exist in the given ClassType and at least
 * one of those two methods is non-const and non-static.
 */
template<typename ClassType,
         template<typename, template<typename...> class, size_t> class CheckerA,
         template<typename...> class SignatureA,
         template<typename...> class ConstSignatureA,
         template<typename...> class StaticSignatureA,
         template<typename, template<typename...> class, size_t> class CheckerB,
         template<typename...> class SignatureB,
         template<typename...> class ConstSignatureB,
         template<typename...> class StaticSignatureB>
struct HasNonConstSignatures
{
  // Check if any const or static version of method A exists.
  const static bool HasAnyFormA =
      CheckerA<ClassType, SignatureA, 0>::value ||
      CheckerA<ClassType, ConstSignatureA, 0>::value ||
      CheckerA<ClassType, StaticSignatureA, 0>::value;
  // Check if any const or static versino of method B exists.
  const static bool HasAnyFormB =
      CheckerB<ClassType, SignatureB, 0>::value ||
      CheckerB<ClassType, ConstSignatureB, 0>::value ||
      CheckerB<ClassType, StaticSignatureB, 0>::value;

  // Make sure at least one const version exists.
  const static bool HasEitherNonConstForm =
      CheckerA<ClassType, SignatureA, 0>::value ||
      CheckerB<ClassType, SignatureB, 0>::value;

  const static bool value = HasEitherNonConstForm && HasAnyFormA && HasAnyFormB;
};

/**
 * Utility struct: sometimes we want to know if we have two functions available,
 * and that at least one of them is const and both of them are not non-const and
 * non-static.  If the corresponding checkers (from ENS_HAS_METHOD_FORM()) are
 * given as CheckerA and CheckerB, and the corresponding const and static
 * function signatures are given as ConstSignatureA, StaticSignatureA,
 * ConstSignatureB, and StaticSignatureB, then 'value' will be true if methods
 * with the correct names exist in the given ClassType and at least one of those
 * two methods is const, and neither method is non-const and non-static.
 */
template<typename ClassType,
         template<typename, template<typename...> class, size_t> class CheckerA,
         template<typename...> class ConstSignatureA,
         template<typename...> class StaticSignatureA,
         template<typename, template<typename...> class, size_t> class CheckerB,
         template<typename...> class ConstSignatureB,
         template<typename...> class StaticSignatureB>
struct HasConstSignatures
{
  // Check if any const or static version of method A exists.
  const static bool HasAnyFormA =
      CheckerA<ClassType, ConstSignatureA, 0>::value ||
      CheckerA<ClassType, StaticSignatureA, 0>::value;
  // Check if any const or static version of method B exists.
  const static bool HasAnyFormB =
      CheckerB<ClassType, ConstSignatureB, 0>::value ||
      CheckerB<ClassType, StaticSignatureB, 0>::value;

  // Make sure at least one const version exists.
  const static bool HasEitherConstForm =
      CheckerA<ClassType, ConstSignatureA, 0>::value ||
      CheckerB<ClassType, ConstSignatureB, 0>::value;

  const static bool value = HasEitherConstForm && HasAnyFormA && HasAnyFormB;
};

//! Utility struct, check if size_t BatchSize() const or size_t BatchSize()
//! exists.
template<typename OptimizerType>
struct HasBatchSizeSignature
{
  template<typename C>
  using BatchSizeConstForm = size_t(C::*)(void) const;

  template<typename C>
  using BatchSizeForm = size_t(C::*)(void);

  const static bool value =
      HasBatchSize<OptimizerType, BatchSizeForm>::value ||
      HasBatchSize<OptimizerType, BatchSizeConstForm>::value;
};

//! Utility struct, check if size_t StepSize() const or size_t StepSize()
//! exists.
template<typename OptimizerType>
struct HasStepSizeSignature
{
  template<typename C>
  using StepSizeConstForm = double(C::*)(void) const;

  template<typename C>
  using StepSizeForm = double(C::*)(void);

  const static bool value =
      HasStepSize<OptimizerType, StepSizeForm>::value ||
      HasStepSize<OptimizerType, StepSizeConstForm>::value;
};

//! Utility struct, check if size_t MaxIterations() const exists.
template<typename OptimizerType>
struct HasMaxIterationsSignature
{
  template<typename C>
  using HasMaxIterationsForm = size_t(C::*)(void) const;

  const static bool value =
      HasMaxIterations<OptimizerType, HasMaxIterationsForm>::value;
};

//! Utility struct, check if size_t NumFunctions() const or
//! size_t NumFunctions() exists.
template<typename OptimizerType>
struct HasNumFunctionsSignature
{
  template<typename C>
  using NumFunctionsConstForm = size_t(C::*)(void) const;

  template<typename C>
  using NumFunctionsForm = size_t(C::*)(void);

  const static bool value =
      HasNumFunctions<OptimizerType, NumFunctionsForm>::value ||
      HasNumFunctions<OptimizerType, NumFunctionsConstForm>::value;
};

//! Utility struct, check if bool ResetPolicy() exists.
template<typename OptimizerType>
struct HasResetPolicySignature
{
  template<typename C>
  using HasResetPolicyForm = bool&(C::*)(void);

  const static bool value =
      HasResetPolicy<OptimizerType, HasResetPolicyForm>::value;
};

} // namespace traits
} // namespace ens

#endif
/**
 * @file atoms.hpp
 * @author Chenzhe Diao
 *
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_FW_ATOMS_HPP
#define ENSMALLEN_FW_ATOMS_HPP

#include "proximal/proximal.hpp"
#include "func_sq.hpp"

namespace ens {

/**
 * Class to hold the information and operations of current atoms in the
 * soluton space.  This is not fully templatized, and may cost some extra
 * operations for the conversion.
 */
class Atoms
{
 public:
  Atoms(){ /* Nothing to do. */ }

  /**
   * Add atom into the solution space.
   *
   * @param v new atom to be added.
   * @param c coefficient of the new atom.
   */
  void AddAtom(const arma::mat& v, FuncSq& function, const double c = 0)
  {
    if (currentAtoms.is_empty())
    {
      CurrentAtoms() = v;
      CurrentCoeffs().set_size(1);
      CurrentCoeffs().fill(c);
      atomSqTerm.set_size(1);
      atomSqTerm(0) = std::pow(norm(function.MatrixA() * v, 2), 2);
    }
    else
    {
      currentAtoms.insert_cols(0, v);
      arma::vec cVec(1);
      cVec(0) = c;
      currentCoeffs.insert_rows(0, cVec);
      double tmp = std::pow(norm(function.MatrixA() * v, 2), 2);
      arma::vec tmpVec(1);
      tmpVec(0) = tmp;
      atomSqTerm.insert_rows(0, tmpVec);
    }
  }


  //! Recover the solution coordinate from the coefficients of current atoms.
  void RecoverVector(arma::mat& x)
  {
    x = currentAtoms * currentCoeffs;
  }

  /**
   * Prune the support, delete previous atoms if they don't contribute much.
   * See Algorithm 2 of paper:
   * @code
   * @article{RaoShaWri:2015Forward--backward,
   *    Author = {Rao, Nikhil and Shah, Parikshit and Wright, Stephen},
   *    Journal = {IEEE Transactions on Signal Processing},
   *    Number = {21},
   *    Pages = {5798--5811},
   *    Publisher = {IEEE},
   *    Title = {Forward--backward greedy algorithms for atomic norm regularization},
   *    Volume = {63},
   *    Year = {2015}
   * }
   * @endcode
   *
   * @param F thresholding number.
   * @param function function to be optimized.
   */
  void PruneSupport(const double F, FuncSq& function)
  {
    arma::vec sqTerm = 0.5 * atomSqTerm % square(currentCoeffs);

    while (currentAtoms.n_cols > 1)
    {
      // Solve for current gradient.
      arma::mat x;
      RecoverVector(x);
      arma::mat gradient(arma::size(x));
      function.Gradient(x, gradient);

      // Find possible atom to be deleted.
      arma::vec gap = sqTerm -
          currentCoeffs % trans(gradient.t() * currentAtoms);
      arma::uword ind;
      gap.min(ind);

      // Try deleting the atom.
      arma::mat newAtoms(currentAtoms.n_rows, currentAtoms.n_cols - 1);
      if (ind > 0)
        newAtoms.cols(0, ind - 1) = currentAtoms.cols(0, ind - 1);
      if (ind < (currentAtoms.n_cols - 1))
      {
        newAtoms.cols(ind, newAtoms.n_cols - 1) =
            currentAtoms.cols(ind + 1, currentAtoms.n_cols - 1);
      }

      // Reoptimize the coefficients, we brute-forcely reoptimize in the span,
      // which would be used in UpdateSpan class. Alternatively, if you want to
      // add an atom norm constraint, you could use projected gradient method,
      // see the implementaton of ProjectedGradientEnhancement().
      arma::vec newCoeffs =
          solve(function.MatrixA() * newAtoms, function.Vectorb(), arma::solve_opts::fast);

      // Evaluate the function again.
      double Fnew = function.Evaluate(newAtoms * newCoeffs);

      if (Fnew > F)
        // Should not delete the atom.
        break;
      else
      {
        // Delete the atom from current atoms.
        currentAtoms = newAtoms;
        currentCoeffs = newCoeffs;
        atomSqTerm.shed_row(ind);
        sqTerm.shed_row(ind);
      } // else
    } // while
  }


  /**
   * Enhance the solution in the convex hull of current atoms with atom norm
   * constraint tau. Used in UpdateFullCorrection class for update step.
   *
   * Minimize the function in the atom domain defined by current atoms,
   * where the solution still need to have atom norm (defined by current atoms)
   * less than or equal to tau. We use projected gradient method to solve it,
   * see the "Enhancement step" of the following paper:
   * @code
   * @article{RaoShaWri:2015Forward--backward,
   *    Author = {Rao, Nikhil and Shah, Parikshit and Wright, Stephen},
   *    Journal = {IEEE Transactions on Signal Processing},
   *    Number = {21},
   *    Pages = {5798--5811},
   *    Publisher = {IEEE},
   *    Title = {Forward--backward greedy algorithms for atomic norm regularization},
   *    Volume = {63},
   *    Year = {2015}
   * }
   * @endcode
   *
   * @param function function to be minimized.
   * @param tau atom norm constraint.
   * @param stepSize step size for projected gradient method.
   * @param maxIteration maximum iteration number.
   * @param tolerance tolerance for projected gradient method.
   */
  void ProjectedGradientEnhancement(FuncSq& function,
                                    double tau,
                                    double stepSize,
                                    size_t maxIteration = 100,
                                    double tolerance = 1e-3)
  {
    arma::mat x;
    RecoverVector(x);
    double value = function.Evaluate(x);

    for (size_t iter = 1; iter<maxIteration; iter++)
    {
      // Update currentCoeffs with gradient descent method.
      arma::mat g;
      function.Gradient(x, g);
      g = currentAtoms.t() * g;
      currentCoeffs = currentCoeffs - stepSize * g;

      // Projection of currentCoeffs to satisfy the atom norm constraint.
      Proximal::ProjectToL1Ball(currentCoeffs, tau);

      RecoverVector(x);
      double valueNew = function.Evaluate(x);

      if ((value - valueNew) < tolerance)
        break;

      value = valueNew;
    }
  }


  //! Get the current atom coefficients.
  const arma::vec& CurrentCoeffs() const { return currentCoeffs; }
  //! Modify the current atom coefficients.
  arma::vec& CurrentCoeffs() { return currentCoeffs; }

  //! Get the current atoms.
  const arma::mat& CurrentAtoms() const { return currentAtoms; }
  //! Modify the current atoms.
  arma::mat& CurrentAtoms() { return currentAtoms; }

 private:
  //! Coefficients of current atoms.
  arma::vec currentCoeffs;

  //! Current atoms in the solution space.
  arma::mat currentAtoms;

  //! Atom square term: ||A * atom||^2, used in PruneSupport(). It is computed
  //! when an atom is added.
  arma::vec atomSqTerm;
}; // class Atoms

}  // namespace ens

#endif
/**
 * @file constr_lpball.hpp
 * @author Chenzhe Diao
 *
 * Lp ball constrained for FrankWolfe algorithm. Used as LinearConstrSolverType.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_FW_CONSTR_LPBALL_HPP
#define ENSMALLEN_FW_CONSTR_LPBALL_HPP

namespace ens {

/**
 * LinearConstrSolver for FrankWolfe algorithm. Constraint domain given in the
 * form of lp ball. That is, given \f$ v \f$, solve
 * \f$
 * s:=arg\min_{s\in D} <s, v>
 * \f$
 * when \f$ D \f$ is a regularized lp ball. That is,
 * \f[
 * D = \{ x: (\sum_j|\lambda_j x_j|^p)^{1/p}\leq 1 \}.
 * \f]
 * If \f$ \lambda \f$ is not given in the constructor, default is using all
 * \f$ \lambda_j = 1 \f$ for all \f$ j \f$.
 *
 * In applications such as Orthogonal Matching Pursuit (OMP), \f$ \lambda \f$
 * could be ideally set to the norm of the elements in the dictionary.
 *
 * For \f$ p=1 \f$: take (one) \f$ k = arg\max_j |v_j/\lambda_j|\f$, then the
 * solution is:
 * \f[
 * s_k = -sign(v_k)/\lambda_k, \qquad s_j = 0, \quad j\neq k.
 * \f]
 *
 * For \f$ 1<p<\infty \f$: the solution is
 * \f[
 * t_j = -sign(v_j) |v_j/\lambda_j|^{q-1}, \qquad
 * s_j = \frac{t_j}{||t||_p\cdot\lambda_j}, \quad
 * 1/p + 1/q = 1.
 * \f]
 *
 * For \f$ p=\infty \f$: the solution is
 * \f[
 * s_j = -sign(v_j)/\lambda_j
 * \f]
 *
 */
class ConstrLpBallSolver
{
 public:
  /**
   * Construct the solver of constrained problem. The constrained domain should
   * be unit lp ball for this class.
   *
   * @param p The constraint is unit lp ball.
   */
  ConstrLpBallSolver(const double p) : p(p)
  { /* Do nothing. */ }

  /**
   * Construct the solver of constrained problem, with regularization parameter
   * lambda here.
   *
   * @param p The constraint is unit lp ball.
   * @param lambda Regularization parameter.
   */
  ConstrLpBallSolver(const double p, const arma::vec lambda) :
      p(p), regFlag(true), lambda(lambda)
  { /* Do nothing. */ }


  /**
   * Optimizer of Linear Constrained Problem for FrankWolfe.
   *
   * @param v Input local gradient.
   * @param s Output optimal solution in the constrained domain (lp ball).
   */
  template<typename MatType>
  void Optimize(const MatType& v,
                MatType& s)
  {
    typedef typename MatType::elem_type ElemType;

    if (p == std::numeric_limits<double>::infinity())
    {
      // l-inf ball.
      s = -arma::sign(v);
      if (regFlag)
      {
        // Do element-wise division.
        s /= arma::conv_to<arma::Col<ElemType>>::from(lambda);
      }
    }
    else if (p > 1.0)
    {
      // lp ball with 1<p<inf.
      if (regFlag)
        s = v / arma::conv_to<arma::Col<ElemType>>::from(lambda);
      else
        s = v;

      double q = 1 / (1.0 - 1.0 / p);
      s = -arma::sign(v) % arma::pow(arma::abs(s), q - 1);
      s = arma::normalise(s, p);

      if (regFlag)
        s = s / arma::conv_to<arma::Col<ElemType>>::from(lambda);
    }
    else if (p == 1.0)
    {
      // l1 ball, also used in OMP.
      if (regFlag)
        s = arma::abs(v / arma::conv_to<arma::Col<ElemType>>::from(lambda));
      else
        s = arma::abs(v);

      arma::uword k = 0;
      s.max(k);  // k is the linear index of the largest element.
      s.zeros();
      // Take the sign of v(k).
      s(k) = -((0.0 < v(k)) - (v(k) < 0.0));

      if (regFlag)
        s = s / arma::conv_to<arma::Col<ElemType>>::from(lambda);
    }
    else
    {
      Warn << "Wrong norm p!" << std::endl;
    }

    return;
  }

  //! Get the p-norm.
  double P() const { return p; }
  //! Modify the p-norm.
  double& P() { return p;}

  //! Get regularization flag.
  bool RegFlag() const { return regFlag; }
  //! Modify regularization flag.
  bool& RegFlag() { return regFlag; }

  //! Get the regularization parameter.
  arma::vec Lambda() const { return lambda; }
  //! Modify the regularization parameter.
  arma::vec& Lambda() { return lambda; }

 private:
  //! lp norm, 1<=p<=inf;
  //! use std::numeric_limits<double>::infinity() for inf norm.
  double p;

  //! Regularization flag.
  bool regFlag = false;

  //! Regularization parameter.
  arma::vec lambda;
};

} // namespace ens

#endif
/**
 * @file constr_structure_group.hpp
 * @author Chenzhe Diao
 *
 * Solve the linear constrained problem, where the constrained domain are atom
 * domains defined by unit balls under structured group norm.
 * Used as LinearConstrSolverType in FrankWolfe.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_FW_CONSTR_STRUCTURE_GROUP_HPP
#define ENSMALLEN_FW_CONSTR_STRUCTURE_GROUP_HPP

#include "constr_lpball.hpp"

namespace ens {

/**
 * Linear Constrained Solver for FrankWolfe. Constrained domain given in the
 * form of unit ball of different structured group. That is, given original
 * vector \f$ v \f$ in high dimensional space, suppose we can map it into
 * different smaller dimensional spaces (decomposing the information):
 * \f[
 * v \rightarrow v_g, \qquad g\in G.
 * \f]
 *
 * For example, each group corresponds to a specific set of support subsets,
 * as in GroupLpBall class. Also, a norm would be equipped for each group:
 * \f$ || v_g ||_g \f$, for example lp norm could be used, as in GroupLpBall
 * class. Now, the norm defined for the original vector is:
 * \f[
 * ||v||_G := \min_{v_g} \sum_{g\in G} ||v_g||_g, \qquad
 * s.t. \quad v = \sum_{g\in G} v_g
 * \f]
 * This norm is an atom norm, and the dual norm is given by
 * \f[
 * ||y||^*_G := \max_{g\in G} ||y_g||_g^*
 * \f]
 *
 * See Jaggi's paper:
 * @code
 * @inproceedings{Jag:2013Revisiting,
 *  Author = {Jaggi, Martin},
 *  Booktitle = {ICML (1)},
 *  Pages = {427--435},
 *  Title = {Revisiting Frank-Wolfe: Projection-Free Sparse Convex Optimization.},
 *  Year = {2013}}
 * @endcode
 *
 *  For ConstrStrctGroupSolver to work, we need to use template class GroupType,
 *  which gives functions:
 *
 *    size_t NumGroups();
 *    double DualNorm(const arma::vec& yk, const int group_ind);
 *    ProjectToGroup(const arma::mat& v, const size_t groupId, arma::vec& y);
 *    void OptimalFromGroup(const arma::mat& v, const size_t groupId, arma::mat& s);
 *
 * @tparam GroupType Class that implements functions to map original vectors to
 *                   each group, and to solve linear optimization problem in the
 *                   unit ball defined by the norm of each group.
 */
template<typename GroupType>
class ConstrStructGroupSolver
{
 public:
  /**
   * Construct the structure group optimization solver.
   *
   * @param groupExtractor Class used to project to a group, recovery from a
   *                       group, and compute norm in each group.
   */
  ConstrStructGroupSolver(GroupType& groupExtractor) :
      groupExtractor(groupExtractor)
  { /* Nothing to do */ }

  /**
   * Optimizer of structure group ball constrained Problem for FrankWolfe.
   *
   * @param v Input local gradient.
   * @param s Output optimal solution in the constrained atom domain.
   */
  template<typename MatType>
  void Optimize(const MatType& v, MatType& s)
  {
    typedef typename MatType::elem_type ElemType;

    size_t nGroups = groupExtractor.NumGroups();
    ElemType dualNorm = 0;
    size_t optimalGroup = 1;

    // Find the optimal group.
    for (size_t i = 1; i <= nGroups; ++i)
    {
      MatType y;
      groupExtractor.ProjectToGroup(v, i, y);
      ElemType newNorm = groupExtractor.DualNorm(y, i);

      // Find the group with largest dual norm.
      if (newNorm > dualNorm)
      {
        optimalGroup = i;
        dualNorm = newNorm;
      }
    }

    groupExtractor.OptimalFromGroup(v, optimalGroup, s);
  }

 private:
  //! Information and methods for groups.
  GroupType& groupExtractor;
};

/**
 * Implementation of Structured Group. The projection to each group is using
 * restriction of vector support here, and the norm in each group is using lp
 * norm.
 */
class GroupLpBall
{
 public:
  /**
   * Construct the lp ball group extractor class.
   *
   * @param p lp ball.
   * @param dimOrig dimension of the original vector.
   * @param groupIndicesList vector of support indices lists of each group.
   */
  GroupLpBall(const double p,
              const size_t dimOrig,
              std::vector<arma::uvec> groupIndicesList):
    p(p), numGroups(groupIndicesList.size()),
    dimOrig(dimOrig),
    groupIndicesList(groupIndicesList),
    lpBallSolver(p)
  {/* Nothing to do. */}

  /**
   * Projection to specific group.
   *
   * @param v input vector to be projected.
   * @param groupId input ID number of the group, start from 1.
   * @param y output projection of the vector to specific group.
   */
  template<typename MatType>
  void ProjectToGroup(const MatType& v, const size_t groupId, MatType& y)
  {
    arma::uvec& indList = groupIndicesList[groupId - 1];
    size_t dim = indList.n_elem;
    y.set_size(dim, 1);

    for (size_t i = 0; i < dim; ++i)
      y(i) = v(indList(i));
  }

  /**
   * Get optimal atom, which belongs to specific group.
   * See Jaggi's paper for details.
   *
   * @param v input gradient vector.
   * @param groupId optimal atom belongs to this group.
   * @param s output optimal atom.
   */
  template<typename MatType>
  void OptimalFromGroup(const MatType& v, const size_t groupId, MatType& s)
  {
    // Project v to group.
    MatType yk;
    ProjectToGroup(v, groupId, yk);

    // Optimize in this group.
    MatType sProj(yk.n_elem, 1);
    lpBallSolver.Optimize(yk, sProj);

    // Recover s to the original dimension.
    arma::uvec& indList = groupIndicesList[groupId - 1];
    size_t dim = indList.n_elem;  // dimension of the group.
    s.zeros(dimOrig, 1);

    for (size_t i = 0; i < dim; ++i)
      s(indList(i)) = sProj(i);
  }

  //! Get the number of groups.
  size_t NumGroups() const {return numGroups;}
  //! Modify the number of groups.
  size_t& NumGroups() {return numGroups;}

  /**
   * Compute the q-norm of yk, 1/p+1/q=1.
   *
   * @param yk compute the q-norm of yk.
   * @param groupId group ID number.
   */
  template<typename MatType>
  typename MatType::elem_type DualNorm(const MatType& yk, const int groupId)
  {
    if (p == std::numeric_limits<double>::infinity())
    {
      // inf-norm, return 1-norm
      return arma::norm(yk, 1);
    }
    else if (p > 1.0)
    {
      // p norm, return q-norm
      double q = 1.0 / (1.0 - 1.0 / p);
      return arma::norm(yk, q);
    }
    else if (p == 1.0)
    {
      // 1-norm, return inf-norm
      return arma::norm(yk, "inf");
    }
    else
    {
      Log::Fatal << "Wrong norm p!" << std::endl;
      return 0.0;
    }
  }

 private:
  //! lp norm, 1<=p<=inf;
  //! use std::numeric_limits<double>::infinity() for inf norm.
  double p;

  //! Number of groups.
  size_t numGroups;

  //! Original Problem Dimension.
  size_t dimOrig;

  //! Indices list of each group, indices start from 0.
  std::vector<arma::uvec> groupIndicesList;

  //! Each group uses lp norm
  ConstrLpBallSolver lpBallSolver;
};

} // namespace ens

#endif
/**
 * @file frank_wolfe.hpp
 * @author Chenzhe Diao
 *
 * Frank-Wolfe Algorithm.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_FW_FRANK_WOLFE_HPP
#define ENSMALLEN_FW_FRANK_WOLFE_HPP

#include "update_full_correction.hpp"
#include "update_linesearch.hpp"
#include "update_classic.hpp"
#include "update_span.hpp"
#include "constr_lpball.hpp"

namespace ens {

/**
 * Frank-Wolfe is a technique to minimize a continuously differentiable convex
 * function \f$ f \f$ over a compact convex subset \f$ D \f$ of a vector space.
 * It is also known as conditional gradient method.
 *
 * To find minimum of a function using Frank-Wolfe in each iteration \f$ k \f$:
 * 1. One optimize the linearized constrained problem, using LinearConstrSolver:
 * \f[
 * s_k:= arg\min_{s\in D} <s_k, \nabla f(x_k)>
 * \f]
 *
 * 2. Update \f$ x \f$ using UpdateRule:
 * \f[
 * x_{k+1} := (1-\gamma) x_k + \gamma s_k
 * \f]
 * for some \f$ \gamma \in (0, 1) \f$, or use Fully-Corrective Variant:
 * \f[
 * x_{k+1}:= arg\min_{x\in conv(s_0, \cdots, s_k)} f(x)
 * \f]
 *
 *
 * The algorithm continues until \f$ k \f$ reaches the maximum number of
 * iterations, or when the duality gap is bounded by a certain tolerance
 * \f$ \epsilon \f$.
 * That is,
 *
 * \f[
 * g(x):= \max_{s\in D} <x-s, \nabla f(x)> \quad \leq \epsilon,
 * \f]
 *
 * we also know that \f$ g(x) \geq f(x) - f(x^*) \f$, where \f$ x^* \f$ is the
 * optimal solution.
 *
 * The parameter \f$ \epsilon \f$ is specified by the tolerance parameter to the
 * constructor.
 *
 * FrankWolfe can optimize differentiable functions.  For more details, see the
 * documentation on function types included with this distribution or on the
 * ensmallen website.
 *
 * For FrankWolfe to work, LinearConstrSolverType and UpdateRuleType
 * template parameters are required.
 * These classes must implement the following functions:
 *
 * LinearConstrSolverType:
 *
 *   void Optimize(const arma::mat& gradient,
 *                 arma::mat& s);
 *
 * UpdateRuleType:
 *
 *   void Update(const arma::mat& old_coords,
 *               const arma::mat& s,
 *               arma::mat& new_coords,
 *               const size_t num_iter);
 *
 * @tparam LinearConstrSolverType Solver for the linear constrained problem.
 * @tparam UpdateRuleType Rule to update the solution in each iteration.
 *
 */
template<
    typename LinearConstrSolverType,
    typename UpdateRuleType>
class FrankWolfe
{
 public:
  /**
   * Construct the Frank-Wolfe optimizer with the given function and
   * parameters. Notice that the constraint domain \f$ D \f$ is input
   * at the initialization of linear_constr_solver, the function to be
   * optimized is stored in update_rule.
   *
   * @param linearConstrSolver Solver for linear constrained problem.
   * @param updateRule Rule for updating solution in each iteration.
   * @param maxIterations Maximum number of iterations allowed (0 means no
   *     limit).
   * @param tolerance Maximum absolute tolerance to terminate algorithm.
   */
  FrankWolfe(const LinearConstrSolverType linearConstrSolver,
             const UpdateRuleType updateRule,
             const size_t maxIterations = 100000,
             const double tolerance = 1e-10);

  /**
   * Optimize the given function using FrankWolfe.  The given starting
   * point will be modified to store the finishing point of the algorithm,
   * the final objective value is returned.
   *
   * FunctionType template class must provide the following functions:
   *
   *   double Evaluate(const arma::mat& coordinates);
   *   void Gradient(const arma::mat& coordinates,
   *                 arma::mat& gradient);
   *
   * @tparam FunctionType Type of function to be optimized.
   * @tparam MatType Type of objective matrix.
   * @tparam GradType Type of gradient matrix (default is MatType).
   * @tparam CallbackTypes Types of callback functions.
   * @param function Function to be optimized.
   * @param iterate Input with starting point, and will be modified to save
   *                the output optimial solution coordinates.
   * @param callbacks Callback functions.
   * @return Objective value at the final solution.
   */
  template<typename FunctionType, typename MatType, typename GradType,
           typename... CallbackTypes>
  typename std::enable_if<IsArmaType<GradType>::value,
      typename MatType::elem_type>::type
  Optimize(FunctionType& function,
           MatType& iterate,
           CallbackTypes&&... callbacks);

  //! Forward the MatType as GradType.
  template<typename FunctionType,
           typename MatType,
           typename... CallbackTypes>
  typename MatType::elem_type Optimize(FunctionType& function,
                                       MatType& iterate,
                                       CallbackTypes&&... callbacks)
  {
    return Optimize<FunctionType, MatType, MatType,
        CallbackTypes...>(function, iterate,
        std::forward<CallbackTypes>(callbacks)...);
  }

  //! Get the linear constrained solver.
  const LinearConstrSolverType& LinearConstrSolver()
      const { return linearConstrSolver; }
  //! Modify the linear constrained solver.
  LinearConstrSolverType& LinearConstrSolver() { return linearConstrSolver; }

  //! Get the update rule.
  const UpdateRuleType& UpdateRule() const { return updateRule; }
  //! Modify the update rule.
  UpdateRuleType& UpdateRule() { return updateRule; }

  //! Get the maximum number of iterations (0 indicates no limit).
  size_t MaxIterations() const { return maxIterations; }
  //! Modify the maximum number of iterations (0 indicates no limit).
  size_t& MaxIterations() { return maxIterations; }

  //! Get the tolerance for termination.
  double Tolerance() const { return tolerance; }
  //! Modify the tolerance for termination.
  double& Tolerance() { return tolerance; }

 private:
  //! The solver for constrained linear problem in first step.
  LinearConstrSolverType linearConstrSolver;

  //! The rule to update, used in the second step.
  UpdateRuleType updateRule;

  //! The maximum number of allowed iterations.
  size_t maxIterations;

  //! The tolerance for termination.
  double tolerance;
};

/**
 * Orthogonal Matching Pursuit. It is a sparse approximation algorithm which
 * involves finding the "best matching" projections of multidimensional data
 * onto the span of an over-complete dictionary. To use it, the dictionary is
 * input as the columns of MatrixA() in FuncSq class, and the vector to be
 * approximated is input as the Vectorb() in FuncSq class.
 */
using OMP = FrankWolfe<ConstrLpBallSolver, UpdateSpan>;

} // namespace ens

// Include implementation.
#include "frank_wolfe_impl.hpp"

#endif
/**
 * @file frank_wolfe_impl.hpp
 * @author Chenzhe Diao
 *
 * Frank-Wolfe Algorithm.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_FW_FRANK_WOLFE_IMPL_HPP
#define ENSMALLEN_FW_FRANK_WOLFE_IMPL_HPP

// In case it hasn't been included yet.
#include "frank_wolfe.hpp"

#include <ensmallen_bits/function.hpp>

namespace ens {

//! Constructor of the FrankWolfe class.
template<
    typename LinearConstrSolverType,
    typename UpdateRuleType>
FrankWolfe<LinearConstrSolverType, UpdateRuleType>::
FrankWolfe(const LinearConstrSolverType linearConstrSolver,
           const UpdateRuleType updateRule,
           const size_t maxIterations,
           const double tolerance) :
    linearConstrSolver(linearConstrSolver),
    updateRule(updateRule),
    maxIterations(maxIterations),
    tolerance(tolerance)
{ /* Nothing to do*/ }


//! Optimize the function (minimize).
template<
    typename LinearConstrSolverType,
    typename UpdateRuleType>
template<typename FunctionType, typename MatType, typename GradType,
         typename... CallbackTypes>
typename std::enable_if<IsArmaType<GradType>::value,
typename MatType::elem_type>::type
FrankWolfe<LinearConstrSolverType, UpdateRuleType>::Optimize(
  FunctionType& function,
  MatType& iterateIn,
  CallbackTypes&&... callbacks)
{
  // Convenience typedefs.
  typedef typename MatType::elem_type ElemType;
  typedef typename MatTypeTraits<MatType>::BaseMatType BaseMatType;
  typedef typename MatTypeTraits<GradType>::BaseMatType BaseGradType;

  typedef Function<FunctionType, BaseMatType, BaseGradType> FullFunctionType;
  FullFunctionType& f = static_cast<FullFunctionType&>(function);

  // Make sure we have all necessary functions.
  traits::CheckFunctionTypeAPI<FullFunctionType, BaseMatType, BaseGradType>();
  RequireFloatingPointType<BaseMatType>();
  RequireFloatingPointType<BaseGradType>();
  RequireSameInternalTypes<BaseMatType, BaseGradType>();

  BaseMatType& iterate = (BaseMatType&) iterateIn;

  // To keep track of the function value.
  ElemType currentObjective = std::numeric_limits<ElemType>::max();

  BaseGradType gradient(iterate.n_rows, iterate.n_cols);
  BaseMatType s(iterate.n_rows, iterate.n_cols);
  BaseMatType iterateNew(iterate.n_rows, iterate.n_cols);
  double gap = 0;

  // Controls early termination of the optimization process.
  bool terminate = false;

  Callback::BeginOptimization(*this, f, iterate, callbacks...);
  for (size_t i = 1; i != maxIterations && !terminate; ++i)
  {
    currentObjective = f.EvaluateWithGradient(iterate, gradient);

    terminate |= Callback::EvaluateWithGradient(*this, f, iterate,
        currentObjective, gradient, callbacks...);

    // Output current objective function.
    Info << "FrankWolfe::Optimize(): iteration " << i << ", objective "
        << currentObjective << "." << std::endl;

    // Solve linear constrained problem, solution saved in s.
    linearConstrSolver.Optimize(gradient, s, callbacks...);

    // Check duality gap for return condition.
    gap = std::fabs(dot(iterate - s, gradient));
    if (gap < tolerance)
    {
      Info << "FrankWolfe::Optimize(): minimized within tolerance "
          << tolerance << "; " << "terminating optimization." << std::endl;

      Callback::EndOptimization(*this, f, iterate, callbacks...);
      return currentObjective;
    }

    // Update solution, save in iterateNew.
    updateRule.template Update<FunctionType, BaseMatType, BaseGradType>(f,
        iterate, s, iterateNew, i);

    iterate = std::move(iterateNew);
    terminate |= Callback::StepTaken(*this, f, iterate, callbacks...);
  }

  Info << "FrankWolfe::Optimize(): maximum iterations (" << maxIterations
      << ") reached; " << "terminating optimization." << std::endl;

  Callback::EndOptimization(*this, f, iterate, callbacks...);
  return currentObjective;
} // Optimize()

} // namespace ens

#endif
/**
 * @file func_sq.hpp
 * @author Chenzhe Diao
 *
 * Square loss function: \f$ x-> 0.5 * || Ax - b ||_2^2 \f$.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_FW_FUNC_SQ_HPP
#define ENSMALLEN_FW_FUNC_SQ_HPP

namespace ens {

/**
 * Square loss function \f$ f(x) = 0.5 * ||Ax - b||_2^2 \f$.
 *
 * Contains matrix \f$ A \f$ and vector \f$ b \f$.
 */
class FuncSq
{
 public:
  /**
   * Construct the square loss function.
   *
   * @param A matrix A.
   * @param b vector b.
   */
  FuncSq(const arma::mat& A, const arma::vec& b) : A(A), b(b)
  {/* Nothing to do. */}

  /**
   * Evaluation of the function.
   * \f$ f(x) = 0.5 * ||Ax - b||_2^2 \f$
   *
   * @param coords vector x.
   * @return \f$ f(x) \f$.
   */
  double Evaluate(const arma::mat& coords)
  {
    arma::vec r = A * coords - b;
    return arma::dot(r, r) * 0.5;
  }

  /**
   * Gradient of square loss function.
   * \f$ \nabla f(x) = A^T(Ax - b) \f$
   *
   * @param coords input vector x.
   * @param gradient output gradient vector.
   */
  void Gradient(const arma::mat& coords, arma::mat& gradient)
  {
    arma::vec r = A * coords - b;
    gradient = A.t() * r;
  }

  //! Get the matrix A.
  arma::mat MatrixA() const {return A;}
  //! Modify the matrix A.
  arma::mat& MatrixA() {return A;}

  //! Get the vector b.
  arma::vec Vectorb() const { return b; }
  //! Modify the vector b.
  arma::vec& Vectorb() { return b; }

 private:
  //! Matrix A in square loss function.
  arma::mat A;

  //! Vector b in square loss function.
  arma::vec b;
};

} // namespace ens

#endif
/**
 * @file line_search.hpp
 * @author Chenzhe Diao
 *
 * Minimize a function using line search with secant method.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_LINE_SEARCH_LINE_SEARCH_HPP
#define ENSMALLEN_LINE_SEARCH_LINE_SEARCH_HPP

namespace ens {

/**
 * Find the minimum of a function along the line between two points.
 * The solver uses the secant method to find the zero of the derivative of the
 * function along the search line.
 *
 * If the function is convex, the derivative of the function along the search
 * line will be nondecreasing, so the minimum always exists.
 * If the function is strongly convex, the derivative of the function along the
 * search line will be strictly increasing, so the minimum is unique.
 */
class LineSearch
{
 public:
  LineSearch(const size_t maxIterations = 100000,
             const double tolerance = 1e-5) :
      maxIterations(maxIterations), tolerance(tolerance)
  {/* Do nothing */ }

  /**
   * Line search to minimize function between two points with Secant method,
   * that is, to find the zero of Derivative(gamma), where gamma is in [0,1].
   *
   * The function is assumed to be convex here, otherwise might not converge.
   *
   * @param function function to be minimized.
   * @param x1 Input one end point.
   * @param x2 Input the other end point, also used as output, to store the
   *           coordinate of the optimal solution.
   * @return Minimum solution function value.
   */
  template<typename FunctionType,
           typename MatType,
           typename GradType = MatType>
  typename MatType::elem_type Optimize(FunctionType& function,
                                       const MatType& x1,
                                       MatType& x2);

  //! Get the maximum number of iterations (0 indicates no limit).
  size_t MaxIterations() const { return maxIterations; }
  //! Modify the maximum number of iterations (0 indicates no limit).
  size_t& MaxIterations() { return maxIterations; }

  //! Get the tolerance for termination.
  double Tolerance() const { return tolerance; }
  //! Modify the tolerance for termination.
  double& Tolerance() { return tolerance; }

 private:
  //! Max number of iterations.
  size_t maxIterations;

  //! Tolerance for convergence.
  double tolerance;

  /**
   * Derivative of the function along the search line.
   *
   * @param function original function.
   * @param x0 starting point.
   * @param deltaX distance between two end points.
   * @param gamma position of the point in the search line, take in [0, 1].
   *
   * @return Derivative of function(x0 + gamma * deltaX) with respect to gamma.
   */
  template<typename FunctionType, typename MatType, typename GradType>
  typename MatType::elem_type Derivative(FunctionType& function,
                                         const MatType& x0,
                                         const MatType& deltaX,
                                         const double gamma);
};  // class LineSearch
} // namespace ens

#include "line_search_impl.hpp"

#endif
/**
 * @file line_search_impl.hpp
 * @author Chenzhe Diao
 *
 * Implementation of line search with secant method.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_LINE_SEARCH_LINE_SEARCH_IMPL_HPP
#define ENSMALLEN_LINE_SEARCH_LINE_SEARCH_IMPL_HPP

// In case it hasn't been included yet.
#include "line_search.hpp"

#include <ensmallen_bits/function.hpp>

namespace ens {

template<typename FunctionType, typename MatType, typename GradType>
typename MatType::elem_type LineSearch::Optimize(FunctionType& function,
                                                 const MatType& x1,
                                                 MatType& x2)
{
  typedef typename MatType::elem_type ElemType;

  typedef Function<FunctionType, MatType, GradType> FullFunctionType;
  FullFunctionType& f = static_cast<FullFunctionType&>(function);

  // Check that we have all the functions we will need.
  traits::CheckFunctionTypeAPI<FullFunctionType, MatType, GradType>();

  // Set up the search line, that is,
  // find the zero of der(gamma) = Derivative(gamma).
  MatType deltaX = x2 - x1;
  ElemType gamma = 0;
  ElemType derivative = Derivative<FunctionType, MatType, GradType>(f, x1,
      deltaX, 0);
  ElemType derivativeNew = Derivative<FunctionType, MatType, GradType>(f, x1,
      deltaX, 1);
  ElemType secant = derivativeNew - derivative;

  if (derivative >= 0.0) // Optimal solution at left endpoint.
  {
    x2 = x1;
    return f.Evaluate(x1);
  }
  else if (derivativeNew <= 0.0) // Optimal solution at right endpoint.
  {
    return f.Evaluate(x2);
  }
  else if (secant < tolerance) // function too flat, just take left endpoint.
  {
    x2 = x1;
    return f.Evaluate(x1);
  }

  // Line search by Secant Method.
  for (size_t k = 0; k < maxIterations; ++k)
  {
    // secant should always >=0 for convex function.
    if (secant < 0.0)
    {
      Warn << "LineSearchSecant: Function is not convex!" << std::endl;
      x2 = x1;
      return function.Evaluate(x1);
    }

    // Solve new gamma.
    ElemType gammaNew = gamma - derivative / secant;
    gammaNew = std::max(gammaNew, ElemType(0.0));
    gammaNew = std::min(gammaNew, ElemType(1.0));

    // Update secant, gamma and derivative.
    derivativeNew = Derivative<FunctionType, MatType, GradType>(function, x1,
        deltaX, gammaNew);
    secant = (derivativeNew - derivative) / (gammaNew - gamma);
    gamma = gammaNew;
    derivative = derivativeNew;

    if (std::fabs(derivative) < tolerance)
    {
      Info << "LineSearchSecant: minimized within tolerance "
          << tolerance << "; " << "terminating optimization." << std::endl;
      x2 = (1 - gamma) * x1 + gamma * x2;
      return f.Evaluate(x2);
    }
  }

  Info << "LineSearchSecant: maximum iterations (" << maxIterations
      << ") reached; " << "terminating optimization." << std::endl;

  x2 = (1 - gamma) * x1 + gamma * x2;
  return f.Evaluate(x2);
}  // Optimize


//! Derivative of the function along the search line.
template<typename FunctionType, typename MatType, typename GradType>
typename MatType::elem_type LineSearch::Derivative(FunctionType& function,
                                                   const MatType& x0,
                                                   const MatType& deltaX,
                                                   const double gamma)
{
  GradType gradient(x0.n_rows, x0.n_cols);
  function.Gradient(x0 + gamma * deltaX, gradient);
  return arma::dot(gradient, deltaX);
}

} // namespace ens

#endif
/**
 * @file proximal.hpp
 * @author Chenzhe Diao
 *
 * Approximate a vector with another vector on lp ball. Currently support l0
 * ball and l1 ball with specific norm.
 * It can be used in projected gradient method.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROXIMAL_PROXIMAL_HPP
#define ENSMALLEN_PROXIMAL_PROXIMAL_HPP

namespace ens {

/**
 * Approximate a vector with another vector on lp ball. Currently support l0
 * ball and l1 ball with specific norm.
 * It can be used in projected gradient method.
 */
class Proximal
{
 public:
  /**
   * Project the vector onto the l1 ball with norm tau. That is, we will solve
   * for:
   * \f[
   * w = argmin_w ||w - v||_2, \qquad s.t. ~ ||w||_1 \leqslant tau
   * \f]
   *
   * @param v Input vector to be approxmated, the output optimal vector is
   *          also saved in v.
   * @param tau Norm of l1 ball.
   */
  template<typename MatType>
  static void ProjectToL1Ball(MatType& v, double tau);

  /**
   * Project the vector onto the l0 ball with norm tau. That is, we try to
   * approximate v with sparse vector w:
   * \f[
   * w = argmin_w ||w - v||_2, \qquad s.t. ~ ||w||_0 \leqslant tau
   * \f]
   *
   * @param v Input vector to be approxmated, the output optimal vector is
   *          also saved in v.
   * @param tau Norm of l0 ball.
   */
  template<typename MatType>
  static void ProjectToL0Ball(MatType& v, int tau);
};  // class Proximal

} // namespace ens

#include "proximal_impl.hpp"

#endif
/**
 * @file proximal_impl.hpp
 * @author Chenzhe Diao
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROXIMAL_PROXIMAL_IMPL_HPP
#define ENSMALLEN_PROXIMAL_PROXIMAL_IMPL_HPP

#include "proximal.hpp"

namespace ens {

/**
 * Projection of the vector v onto l1 ball with norm tau.
 * See the paper:
 * @code
 * @inproceedings{DucShaSin2008Efficient,
 *    author       = {Duchi, John and Shalev-Shwartz, Shai and Singer,
 *                    Yoram and Chandra, Tushar},
 *    booktitle    = {Proceedings of the 25th international conference on
 *                    Machine learning},
 *    organization = {ACM},
 *    pages        = {272--279},
 *    title        = {Efficient projections onto the l 1-ball for learning in
 *                    high dimensions},
 *    year         = {2008}}
 * @endcode
 *
 * This is just a soft thresholding.
 */
template<typename MatType>
inline void Proximal::ProjectToL1Ball(MatType& v, double tau)
{
  MatType simplexSol = arma::abs(v);

  // Already with L1 norm <= tau.
  if (arma::accu(simplexSol) <= tau)
    return;

  simplexSol = arma::sort(simplexSol, "descend");
  MatType simplexSum = arma::cumsum(simplexSol);

  double nu = 0;
  size_t rho = simplexSol.n_rows - 1;
  for (size_t j = 1; j <= simplexSol.n_rows; j++)
  {
    rho = simplexSol.n_rows - j;
    nu = simplexSol(rho) - (simplexSum(rho) - tau) / (rho + 1);
    if (nu > 0)
      break;
  }
  const double theta = (simplexSum(rho) - tau) / rho;

  // Threshold on absolute value of v with theta.
  for (arma::uword j = 0; j < simplexSol.n_rows; j++)
  {
    if (v(j) >= 0.0)
      v(j) = std::max(v(j) - theta, 0.0);
    else
      v(j) = std::min(v(j) + theta, 0.0);
  }
}

/**
 * Approximate the vector v with a tau-sparse vector.
 * This is a hard-thresholding.
 */
template<typename MatType>
inline void Proximal::ProjectToL0Ball(MatType& v, int tau)
{
  arma::uvec indices = arma::sort_index(arma::abs(v));
  arma::uword numberToKill = v.n_elem - tau;

  for (arma::uword i = 0; i < numberToKill; i++)
    v(indices(i)) = 0.0;
}

} // namespace ens

#endif
/**
 * @file update_classic.hpp
 * @author Chenzhe Diao
 *
 * Classic update method for FrankWolfe algorithm. Used as UpdateRuleType.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_FW_UPDATE_CLASSIC_HPP
#define ENSMALLEN_FW_UPDATE_CLASSIC_HPP

namespace ens {

/**
 * Use classic rule in the update step for FrankWolfe algorithm. That is,
 * take \f$ \gamma = \frac{2}{k+2} \f$, where \f$ k \f$ is the iteration
 * number. The update rule would be:
 * \f[
 * x_{k+1} = (1-\gamma) x_k + \gamma s
 * \f]
 *
 */
class UpdateClassic
{
 public:
  /**
   * Construct the classic update rule for FrankWolfe algorithm.
   */
  UpdateClassic() { /* Do nothing. */ }

  /**
   * Classic update rule for FrankWolfe.
   *
   * \f$ x_{k+1} = (1-\gamma)x_k + \gamma s \f$, where \f$ \gamma = 2/(k+2) \f$
   *
   * @param function Function to be optimized, not used in this update rule.
   * @param oldCoords Previous solution coords.
   * @param s Current linear_constr_solution result.
   * @param newCoords Output new solution coords.
   * @param numIter Current iteration number.
   */
  template<typename FunctionType, typename MatType, typename GradType>
  void Update(FunctionType& /* function */,
              const MatType& oldCoords,
              const MatType& s,
              MatType& newCoords,
              const size_t numIter)
  {
    typename MatType::elem_type gamma = 2.0 / (numIter + 2.0);
    newCoords = (1.0 - gamma) * oldCoords + gamma * s;
  }
};

} // namespace ens

#endif
/**
 * @file update_full_correction.hpp
 * @author Chenzhe Diao
 *
 * Update method for FrankWolfe algorithm, recalculate the coefficents of
 * of current atoms, while satisfying the norm constraint.
 * Used as UpdateRuleType.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_FW_UPDATE_FULL_CORRECTION_HPP
#define ENSMALLEN_FW_UPDATE_FULL_CORRECTION_HPP

#include "atoms.hpp"

namespace ens {

/**
 * Full correction approach to update the solution.
 *
 * UpdateSpan class reoptimize the solution in the span of all current atoms,
 * which is used in OMP, which only focus on sparsity.
 *
 * UpdateFullCorrection class reoptimize the solution in a similar way, however,
 * the solutions need to satisfy the constraint that the atom norm has to be
 * smaller than or equal to tau. This constraint optimization problem is solved
 * by projected gradient method. See Atoms.ProjectedEnhancement().
 *
 * Currently only works for function in FuncSq class.
 *
 */
class UpdateFullCorrection
{
 public:
  /**
   * Construct UpdateFullCorrection class.
   *
   * @param tau atom norm constraint.
   * @param stepSize step size used in projected gradient method.
   */
  UpdateFullCorrection(const double tau, const double stepSize) :
      tau(tau), stepSize(stepSize)
  { /* Do nothing. */ }

  /**
   * Update rule for FrankWolfe, recalculate the coefficents of of current
   * atoms, while satisfying the norm constraint.
   *
   * FuncSqType is an ignored type to match the requirements of the class.
   *
   * @param function Function to be optimized.
   * @param oldCoords Previous solution coords.
   * @param s Current linear_constr_solution result.
   * @param newCoords New output solution coords.
   * @param numIter Current iteration number.
   */
  template<typename FuncSqType, typename MatType, typename GradType>
  void Update(FuncSq& function,
              const MatType& oldCoords,
              const MatType& s,
              MatType& newCoords,
              const size_t /* numIter */)
  {
    // Line search, with explicit solution here.
    MatType v = tau * s - oldCoords;
    MatType b = function.Vectorb();
    MatType A = function.MatrixA();
    typename MatType::elem_type gamma = arma::dot(b - A * oldCoords, A * v);
    gamma = gamma / std::pow(arma::norm(A * v, "fro"), 2);
    gamma = std::min(gamma, 1.0);
    atoms.CurrentCoeffs() = (1.0 - gamma) * atoms.CurrentCoeffs();
    atoms.AddAtom(arma::mat(s), function, gamma * tau);

    // Projected gradient method for enhancement.
    atoms.ProjectedGradientEnhancement(function, tau, stepSize);
    arma::mat tmp;
    atoms.RecoverVector(tmp);
    newCoords = arma::conv_to<MatType>::from(tmp);
  }

 private:
  //! Atom norm constraint.
  double tau;

  //! Step size in projected gradient method.
  double stepSize;

  //! Atoms information.
  Atoms atoms;
};

} // namespace ens

#endif
/**
 * @file update_linesearch.hpp
 * @author Chenzhe Diao
 *
 * Minimize convex function with line search, using secant method.
 * In FrankWolfe algorithm, used as UpdateRuleType.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_FW_UPDATE_LINESEARCH_HPP
#define ENSMALLEN_FW_UPDATE_LINESEARCH_HPP

#include "line_search/line_search.hpp"

namespace ens {

/**
 * Use line search in the update step for FrankWolfe algorithm. That is, take
 * \f$ \gamma = arg\min_{\gamma\in [0, 1]} f((1-\gamma)x + \gamma s) \f$.
 * The update rule would be:
 * \f[
 * x_{k+1} = (1-\gamma) x_k + \gamma s
 * \f]
 *
 */
class UpdateLineSearch
{
 public:
  /**
   * Construct the line search update rule.
   *
   * @param maxIter Max number of iterations in line search.
   * @param tolerance Tolerance for termination of line search.
   */
  UpdateLineSearch(const size_t maxIterations = 100000,
                   const double tolerance = 1e-5) :
      tolerance(tolerance), maxIterations(maxIterations)
  {/* Do nothing */}

  /**
   * Update rule for FrankWolfe, optimize with line search using secant method.
   *
   * FunctionType template parameters are required.
   * This class must implement the following functions:
   *
   * FunctionType:
   *
   *   double Evaluate(const arma::mat& coordinates);
   *   Evaluation of the function at specific coordinates.
   *
   *   void Gradient(const arma::mat& coordinates,
   *                 arma::mat& gradient);
   *   Solve the gradient of the function at specific coordinate,
   *   returned in gradient.
   *
   * @param function function to be optimized,
   * @param oldCoords previous solution coordinates, one end of line search.
   * @param s current linear_constr_solution result, the other end point of
   *        line search.
   * @param newCoords output new solution coords.
   * @param numIter current iteration number, not used here.
   */
  template<typename FunctionType, typename MatType, typename GradType>
  void Update(FunctionType& function,
              const MatType& oldCoords,
              const MatType& s,
              MatType& newCoords,
              const size_t /* numIter */)

  {
    LineSearch solver(maxIterations, tolerance);

    newCoords = s;
    solver.Optimize<FunctionType, MatType, GradType>(function, oldCoords,
        newCoords);
  }

  //! Get the tolerance for termination.
  double Tolerance() const {return tolerance;}
  //! Modify the tolerance for termination.
  double& Tolerance() {return tolerance;}

  //! Get the maximum number of iterations (0 indicates no limit).
  size_t MaxIterations() const { return maxIterations; }
  //! Modify the maximum number of iterations (0 indicates no limit).
  size_t& MaxIterations() { return maxIterations; }

 private:
  //! Tolerance for convergence.
  double tolerance;

  //! Max number of iterations.
  size_t maxIterations;
};  // class UpdateLineSearch

} // namespace ens

#endif
/**
 * @file update_span.hpp
 * @author Chenzhe Diao
 *
 * Update method for FrankWolfe algorithm, recalculate the optimal in the span
 * of previous solution space. Used as UpdateRuleType.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_FW_UPDATE_SPAN_HPP
#define ENSMALLEN_FW_UPDATE_SPAN_HPP

#include "func_sq.hpp"
#include "atoms.hpp"

namespace ens {

/**
 * Recalculate the optimal solution in the span of all previous solution space,
 * used as update step for FrankWolfe algorithm.
 *
 * Currently only works for function in FuncSq class.
 */
class UpdateSpan
{
 public:
  /**
   * Construct the span update rule. The function to be optimized is input here.
   *
   * @param function Function to be optimized in FrankWolfe algorithm.
   */
  UpdateSpan(const bool isPrune = false) : isPrune(isPrune)
  { /* Do nothing. */ }

  /**
   * Update rule for FrankWolfe, reoptimize in the span of current
   * solution space.
   *
   * @param function function to be optimized.
   * @param oldCoords previous solution coords.
   * @param s current linearConstrSolution result.
   * @param newCoords output new solution coords.
   * @param numIter current iteration number.
   */
  template<typename FuncSqType, typename MatType, typename GradType>
  void Update(FuncSq& function,
              const MatType& oldCoords,
              const MatType& s,
              MatType& newCoords,
              const size_t /* numIter */)
  {
    // Add new atom into soluton space.
    atoms.AddAtom(arma::mat(s), function);

    // Reoptimize the solution in the current space.
    arma::vec b = function.Vectorb();
    atoms.CurrentCoeffs() = solve(function.MatrixA() * atoms.CurrentAtoms(), b, arma::solve_opts::fast);

    // x has coords of only the current atoms, recover the solution
    // to the original size.
    arma::mat tmp;
    atoms.RecoverVector(tmp);
    newCoords = arma::conv_to<MatType>::from(tmp);

    // Prune the support.
    if (isPrune)
    {
      double oldF = function.Evaluate(oldCoords);
      double F = 0.25 * oldF + 0.75 * function.Evaluate(newCoords);
      atoms.PruneSupport(F, function);
      atoms.RecoverVector(tmp);
      newCoords = arma::conv_to<MatType>::from(tmp);
    }
  }

 private:
  //! Atoms information.
  Atoms atoms;

  //! Flag for support prune step.
  bool isPrune;
}; // class UpdateSpan

} // namespace ens

#endif
/**
 * @file gradient_descent.hpp
 * @author Sumedh Ghaisas
 *
 * Simple Gradient Descent.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_GRADIENT_DESCENT_GRADIENT_DESCENT_HPP
#define ENSMALLEN_GRADIENT_DESCENT_GRADIENT_DESCENT_HPP

namespace ens {

/**
 * Gradient Descent is a technique to minimize a function. To find a local
 * minimum of a function using gradient descent, one takes steps proportional
 * to the negative of the gradient of the function at the current point,
 * producing the following update scheme:
 *
 * \f[
 * A_{j + 1} = A_j + \alpha \nabla F(A)
 * \f]
 *
 * where \f$ \alpha \f$ is a parameter which specifies the step size. \f$ F \f$
 * is the function being optimized. The algorithm continues until \f$ j
 * \f$ reaches the maximum number of iterations---or when an update produces
 * an improvement within a certain tolerance \f$ \epsilon \f$.  That is,
 *
 * \f[
 * | F(A_{j + 1}) - F(A_j) | < \epsilon.
 * \f]
 *
 * The parameter \f$\epsilon\f$ is specified by the tolerance parameter to the
 * constructor.
 *
 * GradientDescent can optimize differentiable functions.  For more details, see
 * the documentation on function types included with this distribution or on the
 * ensmallen website.
 */
class GradientDescent
{
 public:
  /**
   * Construct the Gradient Descent optimizer with the given function and
   * parameters.  The defaults here are not necessarily good for the given
   * problem, so it is suggested that the values used be tailored to the task
   * at hand.
   *
   * @param function Function to be optimized (minimized).
   * @param stepSize Step size for each iteration.
   * @param maxIterations Maximum number of iterations allowed (0 means no
   *     limit).
   * @param tolerance Maximum absolute tolerance to terminate algorithm.
   */
  GradientDescent(const double stepSize = 0.01,
                  const size_t maxIterations = 100000,
                  const double tolerance = 1e-5);

  /**
   * Optimize the given function using gradient descent.  The given starting
   * point will be modified to store the finishing point of the algorithm, and
   * the final objective value is returned.
   *
   * @tparam FunctionType Type of the function to optimize.
   * @tparam MatType Type of matrix to optimize with.
   * @tparam GradType Type of matrix to use to represent function gradients.
   * @tparam CallbackTypes Types of callback functions.
   * @param function Function to optimize.
   * @param iterate Starting point (will be modified).
   * @param callbacks Callback functions.
   * @return Objective value of the final point.
   */
  template<typename FunctionType,
           typename MatType,
           typename GradType,
           typename... CallbackTypes>
  typename std::enable_if<IsArmaType<GradType>::value,
      typename MatType::elem_type>::type
  Optimize(FunctionType& function,
           MatType& iterate,
           CallbackTypes&&... callbacks);

  //! Forward the MatType as GradType.
  template<typename SeparableFunctionType,
           typename MatType,
           typename... CallbackTypes>
  typename MatType::elem_type Optimize(SeparableFunctionType& function,
                                       MatType& iterate,
                                       CallbackTypes&&... callbacks)
  {
    return Optimize<SeparableFunctionType, MatType, MatType,
        CallbackTypes...>(function, iterate,
        std::forward<CallbackTypes>(callbacks)...);
  }

  /**
   * Assert all dimensions are numeric and optimize the given function using
   * gradient descent. The given starting point will be modified to store the
   * finishing point of the algorithm, and the final objective value is
   * returned.
   *
   * This overload is intended to be used primarily by the hyper-parameter
   * tuning module.
   *
   * @tparam FunctionType Type of the function to optimize.
   * @tparam MatType Type of matrix to optimize with.
   * @tparam GradType Type of matrix to use to represent function gradients.
   * @tparam CallbackTypes Types of callback functions.
   * @param function Function to optimize.
   * @param iterate Starting point (will be modified).
   * @param categoricalDimensions A vector of dimension information.  If a value
   *     is true, then that dimension is a categorical dimension.
   * @param numCategories Number of categories in each categorical dimension.
   * @param callbacks Callback functions.
   * @return Objective value of the final point.
   */
  template<typename FunctionType,
           typename MatType,
           typename GradType,
           typename... CallbackTypes>
  typename std::enable_if<IsArmaType<GradType>::value,
      typename MatType::elem_type>::type
  Optimize(FunctionType& function,
           MatType& iterate,
           const std::vector<bool>& categoricalDimensions,
           const arma::Row<size_t>& numCategories,
           CallbackTypes&&... callbacks);

  //! Forward the MatType as GradType.
  template<typename FunctionType,
           typename MatType,
           typename... CallbackTypes>
  typename MatType::elem_type Optimize(
      FunctionType& function,
      MatType& iterate,
      const std::vector<bool>& categoricalDimensions,
      const arma::Row<size_t>& numCategories,
      CallbackTypes&&... callbacks)
  {
    return Optimize<FunctionType, MatType, MatType,
        CallbackTypes...>(function, iterate, categoricalDimensions,
        numCategories, std::forward<CallbackTypes>(callbacks)...);
  }

  //! Get the step size.
  double StepSize() const { return stepSize; }
  //! Modify the step size.
  double& StepSize() { return stepSize; }

  //! Get the maximum number of iterations (0 indicates no limit).
  size_t MaxIterations() const { return maxIterations; }
  //! Modify the maximum number of iterations (0 indicates no limit).
  size_t& MaxIterations() { return maxIterations; }

  //! Get the tolerance for termination.
  double Tolerance() const { return tolerance; }
  //! Modify the tolerance for termination.
  double& Tolerance() { return tolerance; }

 private:
  //! The step size for each example.
  double stepSize;

  //! The maximum number of allowed iterations.
  size_t maxIterations;

  //! The tolerance for termination.
  double tolerance;
};

} // namespace ens

#include "gradient_descent_impl.hpp"

#endif
/**
 * @file gradient_descent_impl.hpp
 * @author Sumedh Ghaisas
 *
 * Simple gradient descent implementation.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_GRADIENT_DESCENT_GRADIENT_DESCENT_IMPL_HPP
#define ENSMALLEN_GRADIENT_DESCENT_GRADIENT_DESCENT_IMPL_HPP

// In case it hasn't been included yet.
#include "gradient_descent.hpp"

#include <ensmallen_bits/function.hpp>

namespace ens {

//! Constructor.
inline GradientDescent::GradientDescent(
    const double stepSize,
    const size_t maxIterations,
    const double tolerance) :
    stepSize(stepSize),
    maxIterations(maxIterations),
    tolerance(tolerance)
{ /* Nothing to do. */ }

//! Optimize the function (minimize).
template<typename FunctionType,
         typename MatType,
         typename GradType,
         typename... CallbackTypes>
typename std::enable_if<IsArmaType<GradType>::value,
typename MatType::elem_type>::type
GradientDescent::Optimize(FunctionType& function,
                          MatType& iterateIn,
                          CallbackTypes&&... callbacks)
{
  // Convenience typedefs.
  typedef typename MatType::elem_type ElemType;
  typedef typename MatTypeTraits<MatType>::BaseMatType BaseMatType;
  typedef typename MatTypeTraits<GradType>::BaseMatType BaseGradType;

  // Use the Function<> wrapper type to provide additional functionality.
  typedef Function<FunctionType, BaseMatType, BaseGradType> FullFunctionType;
  FullFunctionType& f(static_cast<FullFunctionType&>(function));

  // Make sure we have the methods that we need.
  traits::CheckFunctionTypeAPI<FullFunctionType, BaseMatType, BaseGradType>();
  RequireFloatingPointType<BaseMatType>();
  RequireFloatingPointType<BaseGradType>();
  RequireSameInternalTypes<BaseMatType, BaseGradType>();

  // To keep track of where we are and how things are going.
  ElemType overallObjective = std::numeric_limits<ElemType>::max();
  ElemType lastObjective = std::numeric_limits<ElemType>::max();

  BaseMatType& iterate = (BaseMatType&) iterateIn;
  BaseGradType gradient(iterate.n_rows, iterate.n_cols);

  // Controls early termination of the optimization process.
  bool terminate = false;

  // Now iterate!
  Callback::BeginOptimization(*this, f, iterate, callbacks...);
  for (size_t i = 1; i != maxIterations && !terminate; ++i)
  {
    overallObjective = f.EvaluateWithGradient(iterate, gradient);

    terminate |= Callback::EvaluateWithGradient(*this, f, iterate,
        overallObjective, gradient, callbacks...);

    // Output current objective function.
    Info << "Gradient Descent: iteration " << i << ", objective "
        << overallObjective << "." << std::endl;

    if (std::isnan(overallObjective) || std::isinf(overallObjective))
    {
      Warn << "Gradient Descent: converged to " << overallObjective
          << "; terminating" << " with failure.  Try a smaller step size?"
          << std::endl;

      Callback::EndOptimization(*this, f, iterate, callbacks...);
      return overallObjective;
    }

    if (std::abs(lastObjective - overallObjective) < tolerance)
    {
      Info << "Gradient Descent: minimized within tolerance "
          << tolerance << "; " << "terminating optimization." << std::endl;

      Callback::EndOptimization(*this, f, iterate, callbacks...);
      return overallObjective;
    }

    // Reset the counter variables.
    lastObjective = overallObjective;

    // And update the iterate.
    iterate -= stepSize * gradient;
    terminate |= Callback::StepTaken(*this, f, iterate, callbacks...);
  }

  Info << "Gradient Descent: maximum iterations (" << maxIterations
      << ") reached; " << "terminating optimization." << std::endl;

  Callback::EndOptimization(*this, f, iterate, callbacks...);
  return overallObjective;
}

template<typename FunctionType,
         typename MatType,
         typename GradType,
         typename... CallbackTypes>
typename std::enable_if<IsArmaType<GradType>::value,
typename MatType::elem_type>::type
GradientDescent::Optimize(
    FunctionType& function,
    MatType& iterate,
    const std::vector<bool>& categoricalDimensions,
    const arma::Row<size_t>& numCategories,
    CallbackTypes&&... callbacks)
{
  if (categoricalDimensions.size() != iterate.n_rows)
  {
    std::ostringstream oss;
    oss << "GradientDescent::Optimize(): expected information about "
        << iterate.n_rows << " dimensions in categoricalDimensions, "
        << "but got " << categoricalDimensions.size();
    throw std::invalid_argument(oss.str());
  }

  if (numCategories.n_elem != iterate.n_rows)
  {
    std::ostringstream oss;
    oss << "GradientDescent::Optimize(): expected numCategories to have length "
        << "equal to number of dimensions (" << iterate.n_rows << ") but it has"
        << " length " << numCategories.n_elem;
    throw std::invalid_argument(oss.str());
  }

  for (size_t i = 0; i < categoricalDimensions.size(); ++i)
  {
    if (categoricalDimensions[i])
    {
      std::ostringstream oss;
      oss << "GradientDescent::Optimize(): the dimension " << i
          << "is not numeric" << std::endl;
      throw std::invalid_argument(oss.str());
    }
  }

  return Optimize(function, iterate, callbacks...);
}

} // namespace ens

#endif
/**
 * @file grid_search.hpp
 * @author Kirill Mishchenko
 *
 * Grid-search optimization.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_GRID_SEARCH_GRID_SEARCH_HPP
#define ENSMALLEN_GRID_SEARCH_GRID_SEARCH_HPP

namespace ens {

/**
 * An optimizer that finds the minimum of a given function by iterating through
 * points on a multidimensional grid.
 *
 * GridSearch can optimize categorical functions.  For more details, see the
 * documentation on function types included with this distribution or on the
 * ensmallen website.
 */
class GridSearch
{
 public:
  /**
   * Optimize (minimize) the given function by iterating through the all
   * possible combinations of values for the parameters specified in
   * datasetInfo.
   *
   * @tparam FunctionType Type of function to optimize.
   * @tparam MatType Type of matrix to optimize with.
   * @param function Function to optimize.
   * @param bestParameters Variable for storing results.
   * @param categoricalDimensions Set of dimension types.  If a value is true,
   *     then that dimension is a categorical dimension.
   * @param numCategories Number of categories in each categorical dimension.
   * @return Objective value of the final point.
   */
  template<typename FunctionType, typename MatType>
  typename MatType::elem_type Optimize(
      FunctionType& function,
      MatType& bestParameters,
      const std::vector<bool>& categoricalDimensions,
      const arma::Row<size_t>& numCategories);

 private:
  /**
   * Iterate through the last (parameterValueCollections.size() - i) dimensions
   * of the grid and change the arguments bestObjective and bestParameters if
   * there is something better. The values for the first i dimensions
   * (parameters) are specified in the first i rows of the currentParameters
   * argument.
   */
  template<typename FunctionType, typename MatType>
  void Optimize(
      FunctionType& function,
      typename MatType::elem_type& bestObjective,
      MatType& bestParameters,
      MatType& currentParameters,
      const std::vector<bool>& categoricalDimensions,
      const arma::Row<size_t>& numCategories,
      size_t i);
};

} // namespace ens

// Include implementation
#include "grid_search_impl.hpp"

#endif
/**
 * @file grid_search_impl.hpp
 * @author Kirill Mishchenko
 *
 * Implementation of the grid-search optimization.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_GRID_SEARCH_GRID_SEARCH_IMPL_HPP
#define ENSMALLEN_GRID_SEARCH_GRID_SEARCH_IMPL_HPP

#include <limits>
#include <ensmallen_bits/function.hpp>

namespace ens {

template<typename FunctionType, typename MatType>
typename MatType::elem_type GridSearch::Optimize(
    FunctionType& function,
    MatType& bestParameters,
    const std::vector<bool>& categoricalDimensions,
    const arma::Row<size_t>& numCategories)
{
  for (size_t i = 0; i < categoricalDimensions.size(); ++i)
  {
    if (!categoricalDimensions[i])
    {
      std::ostringstream oss;
      oss << "GridSearch::Optimize(): the dimension " << i
          << " is not categorical" << std::endl;
      throw std::invalid_argument(oss.str());
    }
  }

  // Convenience typedefs.
  typedef typename MatType::elem_type ElemType;

  ElemType bestObjective = std::numeric_limits<ElemType>::max();
  bestParameters.set_size(categoricalDimensions.size(), 1);
  MatType currentParameters(categoricalDimensions.size(), 1);

  /* Initialize best parameters for the case (very unlikely though) when no set
   * of parameters gives an objective value better than
   * std::numeric_limits<double>::max() */
  for (size_t i = 0; i < categoricalDimensions.size(); ++i)
    bestParameters(i, 0) = 0;

  Optimize(function, bestObjective, bestParameters, currentParameters,
      categoricalDimensions, numCategories, 0);

  return bestObjective;
}

template<typename FunctionType, typename MatType>
void GridSearch::Optimize(
    FunctionType& function,
    typename MatType::elem_type& bestObjective,
    MatType& bestParameters,
    MatType& currentParameters,
    const std::vector<bool>& categoricalDimensions,
    const arma::Row<size_t>& numCategories,
    size_t i)
{
  // Convenience typedefs.
  typedef typename MatType::elem_type ElemType;
  typedef typename MatTypeTraits<MatType>::BaseMatType BaseMatType;

  // Make sure we have the methods that we need.  No restrictions on the matrix
  // type are needed.
  traits::CheckArbitraryFunctionTypeAPI<FunctionType, BaseMatType>();

  if (i < categoricalDimensions.size())
  {
    for (size_t j = 0; j < numCategories(i); ++j)
    {
      currentParameters(i) = j;
      Optimize(function, bestObjective, bestParameters, currentParameters,
          categoricalDimensions, numCategories, i + 1);
    }
  }
  else
  {
    ElemType objective = function.Evaluate((BaseMatType&) currentParameters);
    if (objective < bestObjective)
    {
      bestObjective = objective;
      bestParameters = currentParameters;
    }
  }
}

} // namespace ens

#endif
/**
 * @file iqn.hpp
 * @author Marcus Edel
 *
 * Definition of an incremental Quasi-Newton with local superlinear
 * convergence rate as proposed by A. Mokhtari et al. in "IQN: An Incremental
 * Quasi-Newton Method with Local Superlinear Convergence Rate".
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_IQN_IQN_HPP
#define ENSMALLEN_IQN_IQN_HPP

namespace ens {

/**
 * IQN is a technique for minimizing a function which
 * can be expressed as a sum of other functions.  That is, suppose we have
 *
 * \f[
 * f(A) = \sum_{i = 0}^{n} f_i(A)
 * \f]
 * IQN is the first stochastic quasi- Newton method proven to converge
 * superlinearly in a local neighborhood of the optimal solution.
 *
 * For more information, please refer to:
 *
 * @code
 * @misc{1106.5730,
 *   author = {Mokhtari, Aryan and Eisen, Mark and Ribeiro, Alejandro},
 *   title  = {IQN: An Incremental Quasi-Newton Method with Local Superlinear
 *             Convergence Rate},
 *   year   = {2017},
 *   eprint = {arXiv:1702.00709},
 * }
 * @endcode
 *
 * This class is useful for data-dependent functions whose objective function
 * can be expressed as a sum of objective functions operating on an individual
 * point.  Then, IQN considers the gradient of the objective function operating
 * on an individual point in its update of \f$ A \f$.
 *
 * IQN can optimize differentiable separable functions.  For more details, see
 * the documentation on function types included with this distribution or on the
 * ensmallen website.
 */
class IQN
{
 public:
  /**
   * Construct the IQN optimizer with the given function and parameters.  The
   * defaults here are not necessarily good for the given problem, so it is
   * suggested that the values used be tailored to the task at hand.  The
   * maximum number of iterations refers to the maximum number of points that
   * are processed (i.e., one iteration equals one point; one iteration does not
   * equal one pass over the dataset).
   *
   * @param stepSize Step size for each iteration.
   * @param batchSize Size of each batch.
   * @param maxIterations Maximum number of iterations allowed (0 means no
   *     limit).
   * @param tolerance Maximum absolute tolerance to terminate algorithm.
   */
  IQN(const double stepSize = 0.01,
      const size_t batchSize = 10,
      const size_t maxIterations = 100000,
      const double tolerance = 1e-5);

  /**
   * Optimize the given function using IQN. The given starting point will be
   * modified to store the finishing point of the algorithm, and the final
   * objective value is returned.
   *
   * @tparam SeparableFunctionType Type of the function to be optimized.
   * @tparam MatType Type of matrix to optimize with.
   * @tparam GradType Type of matrix to use to represent function gradients.
   * @tparam CallbackTypes Types of callback functions.
   * @param function Function to optimize.
   * @param iterate Starting point (will be modified).
   * @param callbacks Callback functions.
   * @return Objective value of the final point.
   */
  template<typename SeparableFunctionType,
           typename MatType,
           typename GradType,
           typename... CallbackTypes>
  typename std::enable_if<IsArmaType<GradType>::value,
      typename MatType::elem_type>::type
  Optimize(SeparableFunctionType& function,
                                       MatType& iterate,
                                       CallbackTypes&&... callbacks);

  //! Forward the MatType as GradType.
  template<typename SeparableFunctionType,
           typename MatType,
           typename... CallbackTypes>
  typename MatType::elem_type Optimize(SeparableFunctionType& function,
                                       MatType& iterate,
                                       CallbackTypes&&... callbacks)
  {
    return Optimize<SeparableFunctionType, MatType, MatType,
        CallbackTypes...>(function, iterate,
        std::forward<CallbackTypes>(callbacks)...);
  }

  //! Get the step size.
  double StepSize() const { return stepSize; }
  //! Modify the step size.
  double& StepSize() { return stepSize; }

  //! Get the batch size.
  size_t BatchSize() const { return batchSize; }
  //! Modify the batch size.
  size_t& BatchSize() { return batchSize; }

  //! Get the maximum number of iterations (0 indicates no limit).
  size_t MaxIterations() const { return maxIterations; }
  //! Modify the maximum number of iterations (0 indicates no limit).
  size_t& MaxIterations() { return maxIterations; }

  //! Get the tolerance for termination.
  double Tolerance() const { return tolerance; }
  //! Modify the tolerance for termination.
  double& Tolerance() { return tolerance; }

 private:
  //! The step size for each example.
  double stepSize;

  //! The size of each batch.
  size_t batchSize;

  //! The maximum number of allowed iterations.
  size_t maxIterations;

  //! The tolerance for termination.
  double tolerance;
};

} // namespace ens

// Include implementation.
#include "iqn_impl.hpp"

#endif
/**
 * @file iqn_impl.hpp
 * @author Marcus Edel
 *
 * Implementation of an incremental Quasi-Newton with local superlinear
 * convergence rate as proposed by A. Mokhtari et al. in "IQN: An Incremental
 * Quasi-Newton Method with Local Superlinear Convergence Rate".
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_IQN_IQN_IMPL_HPP
#define ENSMALLEN_IQN_IQN_IMPL_HPP

// In case it hasn't been included yet.
#include "iqn.hpp"

#include <ensmallen_bits/function.hpp>

namespace ens {

inline IQN::IQN(const double stepSize,
                const size_t batchSize,
                const size_t maxIterations,
                const double tolerance) :
    stepSize(stepSize),
    batchSize(batchSize),
    maxIterations(maxIterations),
    tolerance(tolerance)
{ /* Nothing to do. */ }

//! Optimize the function (minimize).
template<typename SeparableFunctionType,
         typename MatType,
         typename GradType,
         typename... CallbackTypes>
typename std::enable_if<IsArmaType<GradType>::value,
typename MatType::elem_type>::type
IQN::Optimize(SeparableFunctionType& functionIn,
              MatType& iterateIn,
              CallbackTypes&&... callbacks)
{
  // Convenience typedefs.
  typedef typename MatType::elem_type ElemType;
  typedef typename MatTypeTraits<MatType>::BaseMatType BaseMatType;
  typedef typename MatTypeTraits<GradType>::BaseMatType BaseGradType;

  typedef Function<SeparableFunctionType, BaseMatType, BaseGradType>
      FullFunctionType;
  FullFunctionType& function(static_cast<FullFunctionType&>(functionIn));

  // Make sure we have all the methods that we need.
  traits::CheckSeparableFunctionTypeAPI<FullFunctionType, BaseMatType,
      BaseGradType>();
  RequireDenseFloatingPointType<BaseMatType>();
  RequireDenseFloatingPointType<BaseGradType>();
  RequireSameInternalTypes<BaseMatType, BaseGradType>();

  traits::CheckSeparableFunctionTypeAPI<SeparableFunctionType,
      BaseMatType, BaseGradType>();

  // Find the number of functions.
  const size_t numFunctions = function.NumFunctions();
  size_t numBatches = numFunctions / batchSize;
  if (numFunctions % batchSize != 0)
    ++numBatches; // Capture last few.

  BaseMatType& iterate = (BaseMatType&) iterateIn;

  // To keep track of where we are and how things are going.
  ElemType overallObjective = 0;

  // Controls early termination of the optimization process.
  bool terminate = false;

  std::vector<BaseGradType> y(numBatches, BaseGradType(iterate.n_rows,
      iterate.n_cols));
  std::vector<BaseMatType> t(numBatches, BaseMatType(iterate.n_rows,
      iterate.n_cols));
  std::vector<BaseMatType> Q(numBatches, BaseMatType(iterate.n_elem,
      iterate.n_elem));
  BaseMatType initialIterate = arma::randn<arma::Mat<ElemType>>(iterate.n_rows,
      iterate.n_cols);
  BaseGradType B(iterate.n_elem, iterate.n_elem);
  B.eye();

  BaseGradType g(iterate.n_rows, iterate.n_cols);
  g.zeros();
  for (size_t i = 0, f = 0; i < numFunctions; f++)
  {
    // Find the effective batch size (the last batch may be smaller).
    const size_t effectiveBatchSize = std::min(batchSize, numFunctions - i);

    // It would be nice to avoid this copy but it is difficult to be generic to
    // any MatType and still do that.
    t[f] = initialIterate;
    function.Gradient(initialIterate, i, y[f], effectiveBatchSize);

    terminate |= Callback::Gradient(*this, function, initialIterate,
        y[f], callbacks...);

    Q[f].eye();
    g += y[f];
    y[f] /= (double) effectiveBatchSize;

    i += effectiveBatchSize;
  }
  g /= numFunctions;

  BaseGradType gradient(iterate.n_rows, iterate.n_cols);
  BaseMatType u = t[0];

  Callback::BeginOptimization(*this, function, iterate, callbacks...);
  for (size_t i = 1; i != maxIterations && !terminate; ++i)
  {
    for (size_t j = 0, f = 0; f < numFunctions; j++)
    {
      // Cyclicly iterating through the number of functions.
      const size_t it = ((j + 1) % numBatches);

      // Find the effective batch size (the last batch may be smaller).
      const size_t effectiveBatchSize = std::min(batchSize, numFunctions -
          it * batchSize);

      if (arma::norm(iterate - t[it]) > 0)
      {
        function.Gradient(iterate, it * batchSize, gradient,
            effectiveBatchSize);
        gradient /= effectiveBatchSize;

        terminate |= Callback::Gradient(*this, function, iterate, gradient,
            callbacks...);

        const BaseMatType s = arma::vectorise(iterate - t[it]);
        const BaseGradType yy = arma::vectorise(gradient - y[it]);

        const BaseGradType stochasticHessian = Q[it] + yy * yy.t() /
            arma::as_scalar(yy.t() * s) - Q[it] * s * s.t() *
            Q[it] / arma::as_scalar(s.t() * Q[it] * s);

        // Update aggregate Hessian approximation.
        B += (1.0 / numBatches) * (stochasticHessian - Q[it]);

        // Update aggregate Hessian-variable product.
        u += arma::reshape((1.0 / numBatches) * (stochasticHessian *
            arma::vectorise(iterate) - Q[it] * arma::vectorise(t[it])),
            u.n_rows, u.n_cols);;

        // Update aggregate gradient.
        g += (1.0 / numBatches) * (gradient - y[it]);

        // Update the function information tables.
        Q[it] = std::move(stochasticHessian);
        y[it] = std::move(gradient);
        t[it] = iterate;

        iterate = arma::reshape(stepSize * B.i() * (u.t() - arma::vectorise(g)),
            iterate.n_rows, iterate.n_cols) + (1 - stepSize) * iterate;

        terminate |= Callback::StepTaken(*this, function, iterate,
            callbacks...);
      }

      f += effectiveBatchSize;
    }

    overallObjective = 0;
    for (size_t f = 0; f < numFunctions; f += batchSize)
    {
      const size_t effectiveBatchSize = std::min(batchSize, numFunctions - f);
      const ElemType objective = function.Evaluate(iterate, f,
          effectiveBatchSize);
      overallObjective += objective;

      terminate |= Callback::Evaluate(*this, function, iterate, objective,
          callbacks...);
    }
    overallObjective /= numFunctions;

    // Output current objective function.
    Info << "IQN: iteration " << i << ", objective " << overallObjective
        << "." << std::endl;

    if (std::isnan(overallObjective) || std::isinf(overallObjective))
    {
      Warn << "IQN: converged to " << overallObjective << "; terminating"
          << " with failure.  Try a smaller step size?" << std::endl;

      Callback::EndOptimization(*this, function, iterate, callbacks...);
      return overallObjective;
    }

    if (overallObjective < tolerance)
    {
      Info << "IQN: minimized within tolerance " << tolerance << "; "
          << "terminating optimization." << std::endl;

      Callback::EndOptimization(*this, function, iterate, callbacks...);
      return overallObjective;
    }
  }

  Info << "IQN: maximum iterations (" << maxIterations << ") reached; "
      << "terminating optimization." << std::endl;

  Callback::EndOptimization(*this, function, iterate, callbacks...);
  return overallObjective;
}

} // namespace ens

#endif
/**
 * @file katyusha.hpp
 * @author Marcus Edel
 *
 * Katyusha a direct, primal-only stochastic gradient method.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_KATYUSHA_KATYUSHA_HPP
#define ENSMALLEN_KATYUSHA_KATYUSHA_HPP

namespace ens {

/**
 * Katyusha is a direct, primal-only stochastic gradient method which uses a
 * "negative momentum" on top of Nesterov‚Äôs momentum.
 *
 * For more information, see the following.
 *
 * @code
 * @inproceedings{Allen-Zhu2016,
 *   author    = {{Allen-Zhu}, Z.},
 *   title     = {Katyusha: The First Direct Acceleration of Stochastic Gradient
 *                Methods},
 *   booktitle = {Proceedings of the 49th Annual ACM SIGACT Symposium on Theory
 *                of Computing},
 *   pages     = {1200--1205},
 *   publisher = {ACM},
 *   year      = {2017},
 *   series    = {STOC 2017},
 * }
 * @endcode
 *
 * Katyusha can optimize differentiable separable functions.  For more details,
 * see the documentation on function types included with this distribution or on
 * the ensmallen website.
 *
 * @tparam proximal Whether the proximal update should be used or not.
 */
template<bool Proximal = false>
class KatyushaType
{
 public:
  /**
   * Construct the Katyusha optimizer with the given function and parameters.
   * The defaults here are not necessarily good for the given problem, so it is
   * suggested that the values used be tailored to the task at hand.  The
   * maximum number of iterations refers to the maximum number of points that
   * are processed (i.e., one iteration equals one point; one iteration does not
   * equal one pass over the dataset).
   *
   * @param convexity The regularization parameter.
   * @param lipschitz The Lipschitz constant.
   * @param batchSize Batch size to use for each step.
   * @param maxIterations Maximum number of iterations allowed (0 means no
   *    limit).
   * @param innerIterations The number of inner iterations allowed (0 means
   *    n / batchSize). Note that the full gradient is only calculated in
   *    the outer iteration.
   * @param tolerance Maximum absolute tolerance to terminate algorithm.
   * @param shuffle If true, the function order is shuffled; otherwise, each
   *    function is visited in linear order.
   * @param exactObjective Calculate the exact objective (Default: estimate the
   *        final objective obtained on the last pass over the data).
   */
  KatyushaType(const double convexity = 1.0,
               const double lipschitz = 10.0,
               const size_t batchSize = 32,
               const size_t maxIterations = 1000,
               const size_t innerIterations = 0,
               const double tolerance = 1e-5,
               const bool shuffle = true,
               const bool exactObjective = false);

  /**
   * Optimize the given function using Katyusha. The given starting point will
   * be modified to store the finishing point of the algorithm, and the final
   * objective value is returned.
   *
   * @tparam SeparableFunctionType Type of the function to be optimized.
   * @tparam MatType Type of matrix to optimize with.
   * @tparam GradType Type of matrix to use to represent function gradients.
   * @tparam CallbackTypes Types of callback functions.
   * @param function Function to optimize.
   * @param iterate Starting point (will be modified).
   * @param callbacks Callback functions.
   * @return Objective value of the final point.
   */
  template<typename SeparableFunctionType,
           typename MatType,
           typename GradType,
           typename... CallbackTypes>
  typename std::enable_if<IsArmaType<GradType>::value,
      typename MatType::elem_type>::type
  Optimize(SeparableFunctionType& function,
           MatType& iterate,
           CallbackTypes&&... callbacks);

  //! Forward the MatType as GradType.
  template<typename SeparableFunctionType,
           typename MatType,
           typename... CallbackTypes>
  typename MatType::elem_type Optimize(SeparableFunctionType& function,
                                       MatType& iterate,
                                       CallbackTypes&&... callbacks)
  {
    return Optimize<SeparableFunctionType, MatType, MatType,
        CallbackTypes...>(function, iterate,
        std::forward<CallbackTypes>(callbacks)...);
  }

  //! Get the convexity parameter.
  double Convexity() const { return convexity; }
  //! Modify the convexity parameter.
  double& Convexity() { return convexity; }

  //! Get the lipschitz parameter.
  double Lipschitz() const { return lipschitz; }
  //! Modify the lipschitz parameter.
  double& Lipschitz() { return lipschitz; }

  //! Get the batch size.
  size_t BatchSize() const { return batchSize; }
  //! Modify the batch size.
  size_t& BatchSize() { return batchSize; }

  //! Get the maximum number of iterations (0 indicates no limit).
  size_t MaxIterations() const { return maxIterations; }
  //! Modify the maximum number of iterations (0 indicates no limit).
  size_t& MaxIterations() { return maxIterations; }

  //! Get the maximum number of iterations (0 indicates default n / b).
  size_t InnerIterations() const { return innerIterations; }
  //! Modify the maximum number of iterations (0 indicates default n / b).
  size_t& InnerIterations() { return innerIterations; }

  //! Get the tolerance for termination.
  double Tolerance() const { return tolerance; }
  //! Modify the tolerance for termination.
  double& Tolerance() { return tolerance; }

  //! Get whether or not the individual functions are shuffled.
  bool Shuffle() const { return shuffle; }
  //! Modify whether or not the individual functions are shuffled.
  bool& Shuffle() { return shuffle; }

  //! Get whether or not the actual objective is calculated.
  bool ExactObjective() const { return exactObjective; }
  //! Modify whether or not the actual objective is calculated.
  bool& ExactObjective() { return exactObjective; }

 private:
  //! The convexity regularization term.
  double convexity;

  //! The lipschitz constant.
  double lipschitz;

  //! The batch size for processing.
  size_t batchSize;

  //! The maximum number of allowed iterations.
  size_t maxIterations;

  //! The maximum number of allowed inner iterations per epoch.
  size_t innerIterations;

  //! The tolerance for termination.
  double tolerance;

  //! Controls whether or not the individual functions are shuffled when
  //! iterating.
  bool shuffle;

  //! Controls whether or not the actual Objective value is calculated.
  bool exactObjective;
};

// Convenience typedefs.

/**
 * Katyusha using the standard update step.
 */
using Katyusha = KatyushaType<false>;

/**
 * Katyusha using the proximal update step.
 */
using KatyushaProximal = KatyushaType<true>;

} // namespace ens

// Include implementation.
#include "katyusha_impl.hpp"

#endif
/**
 * @file katyusha_impl.hpp
 * @author Marcus Edel
 *
 * Implementation of Katyusha a direct, primal-only stochastic gradient method.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_KATYUSHA_KATYUSHA_IMPL_HPP
#define ENSMALLEN_KATYUSHA_KATYUSHA_IMPL_HPP

// In case it hasn't been included yet.
#include "katyusha.hpp"

#include <ensmallen_bits/function.hpp>

namespace ens {

template<bool Proximal>
KatyushaType<Proximal>::KatyushaType(
    const double convexity,
    const double lipschitz,
    const size_t batchSize,
    const size_t maxIterations,
    const size_t innerIterations,
    const double tolerance,
    const bool shuffle,
    const bool exactObjective) :
    convexity(convexity),
    lipschitz(lipschitz),
    batchSize(batchSize),
    maxIterations(maxIterations),
    innerIterations(innerIterations),
    tolerance(tolerance),
    shuffle(shuffle),
    exactObjective(exactObjective)
{ /* Nothing to do. */ }

//! Optimize the function (minimize).
template<bool Proximal>
template<typename SeparableFunctionType,
         typename MatType,
         typename GradType,
         typename... CallbackTypes>
typename std::enable_if<IsArmaType<GradType>::value,
typename MatType::elem_type>::type
KatyushaType<Proximal>::Optimize(
    SeparableFunctionType& function,
    MatType& iterateIn,
    CallbackTypes&&... callbacks)
{
  // Convenience typedefs.
  typedef typename MatType::elem_type ElemType;
  typedef typename MatTypeTraits<MatType>::BaseMatType BaseMatType;
  typedef typename MatTypeTraits<GradType>::BaseMatType BaseGradType;

  traits::CheckSeparableFunctionTypeAPI<SeparableFunctionType,
      BaseMatType, BaseGradType>();
  RequireFloatingPointType<BaseMatType>();
  RequireFloatingPointType<BaseGradType>();
  RequireSameInternalTypes<BaseMatType, BaseGradType>();

  BaseMatType& iterate = (BaseMatType&) iterateIn;

  // Controls early termination of the optimization process.
  bool terminate = false;

  // Find the number of functions to use.
  const size_t numFunctions = function.NumFunctions();

  // Set epoch length to n / b if the user asked for.
  if (innerIterations == 0)
    innerIterations = numFunctions;

  // Find the number of batches.
  size_t numBatches = innerIterations / batchSize;
  if (numFunctions % batchSize != 0)
    ++numBatches; // Capture last few.

  const double tau1 = std::min(0.5,
      std::sqrt(batchSize * convexity / (3.0 * lipschitz)));
  const double tau2 = 0.5;
  const double alpha = 1.0 / (3.0 * tau1 * lipschitz);
  const double r = 1.0 + std::min(alpha * convexity, 1.0 /
      (4.0 / innerIterations));

  // sum_{j=0}^{m-1} 1 + std::min(alpha * convexity, 1 / (4 * m)^j).
  double normalizer = 1;
  for (size_t i = 0; i < numBatches; i++)
  {
    normalizer = r * (normalizer + 1.0);
  }
  normalizer = 1.0 / normalizer;

  // To keep track of where we are and how things are going.
  ElemType overallObjective = 0;
  ElemType lastObjective = DBL_MAX;

  // Now iterate!
  BaseGradType gradient(iterate.n_rows, iterate.n_cols);
  BaseGradType fullGradient(iterate.n_rows, iterate.n_cols);
  BaseGradType gradient0(iterate.n_rows, iterate.n_cols);

  BaseMatType iterate0 = iterate;
  BaseMatType y = iterate;
  BaseMatType z = iterate;
  BaseMatType w(iterate.n_rows, iterate.n_cols);
  w.zeros();

  const size_t actualMaxIterations = (maxIterations == 0) ?
      std::numeric_limits<size_t>::max() : maxIterations;
  Callback::BeginOptimization(*this, function, iterate, callbacks...);
  for (size_t i = 0; i < actualMaxIterations && !terminate; ++i)
  {
    // Calculate the objective function.
    overallObjective = 0;
    for (size_t f = 0; f < numFunctions; f += batchSize)
    {
      const size_t effectiveBatchSize = std::min(batchSize, numFunctions - f);
      const ElemType objective = function.Evaluate(iterate0, f,
          effectiveBatchSize);
      overallObjective += objective;

      terminate |= Callback::Evaluate(*this, function, iterate0, objective,
          callbacks...);
    }

    if (std::isnan(overallObjective) || std::isinf(overallObjective))
    {
      Warn << "Katyusha: converged to " << overallObjective
          << "; terminating  with failure.  Try a smaller step size?"
          << std::endl;

      Callback::EndOptimization(*this, function, iterate, callbacks...);
      return overallObjective;
    }

    if (std::abs(lastObjective - overallObjective) < tolerance)
    {
      Info << "Katyusha: minimized within tolerance " << tolerance
          << "; terminating optimization." << std::endl;

      Callback::EndOptimization(*this, function, iterate, callbacks...);
      return overallObjective;
    }

    lastObjective = overallObjective;

    // Compute the full gradient.
    size_t effectiveBatchSize = std::min(batchSize, numFunctions);
    function.Gradient(iterate, 0, fullGradient, effectiveBatchSize);
    terminate |= Callback::Gradient(*this, function, iterate, fullGradient,
          callbacks...);
    for (size_t f = effectiveBatchSize; f < numFunctions;
        /* incrementing done manually */)
    {
      // Find the effective batch size (the last batch may be smaller).
      effectiveBatchSize = std::min(batchSize, numFunctions - f);

      function.Gradient(iterate0, f, gradient, effectiveBatchSize);
      fullGradient += gradient;

      terminate |= Callback::Gradient(*this, function, iterate0, gradient,
          callbacks...);

      f += effectiveBatchSize;
    }
    fullGradient /= (double) numFunctions;

    // To keep track of where we are and how things are going.
    double cw = 1;
    w.zeros();

    for (size_t f = 0, currentFunction = 0; (f < innerIterations) && !terminate;
        /* incrementing done manually */)
    {
      // Is this iteration the start of a sequence?
      if ((currentFunction % numFunctions) == 0)
      {
        currentFunction = 0;

        // Determine order of visitation.
        if (shuffle)
          function.Shuffle();
      }

      // Find the effective batch size (the last batch may be smaller).
      effectiveBatchSize = std::min(batchSize, numFunctions - currentFunction);
      iterate = tau1 * z + tau2 * iterate0 + (1 - tau1 - tau2) * y;

      terminate |= Callback::StepTaken(*this, function, iterate,
            callbacks...);

      // Calculate variance reduced gradient.
      function.Gradient(iterate, currentFunction, gradient,
          effectiveBatchSize);
      terminate |= Callback::Gradient(*this, function, iterate, gradient,
          callbacks...);

      function.Gradient(iterate0, currentFunction, gradient0,
          effectiveBatchSize);
      terminate |= Callback::Gradient(*this, function, iterate0, gradient0,
          callbacks...);

      // By the minimality definition of z_{k + 1}, we have that:
      // z_{k+1} ‚àí z_k + \alpha * \sigma_{k+1} + \alpha g = 0.
      BaseMatType zNew = z - alpha * (fullGradient + (gradient - gradient0) /
          (double) batchSize);

      // Proximal update, choose between Option I and Option II. Shift relative
      // to the Lipschitz constant or take a constant step using the given step
      // size.
      if (Proximal)
      {
        // yk = x0 ‚àí 1 / (3L) * \delta1, k = 1
        // yk = x0 ‚àí 1 / (3L) * \delta2 - ((1 - tau) / (3L)) + tau * alpha)
        // * \delta1, k = 2
        // yk = x0 ‚àí 1 / (3L) * \delta3 - ((1 - tau) / (3L)) + tau * alpha)
        // * \delta2 - ((1-tau)^2 / (3L) + (1 - (1 - tau)^2) * alpha) * \delta1,
        // k = 3.
        y = iterate + 1.0 / (3.0 * lipschitz) * w;
      }
      else
      {
        y = iterate + tau1 * (zNew - z);
      }

      z = std::move(zNew);

      // sum_{j=0}^{m-1} 1 + std::min(alpha * convexity, 1 / (4 * m)^j * ys).
      w += cw * iterate;
      cw *= r;

      currentFunction += effectiveBatchSize;
      f += effectiveBatchSize;
    }
    iterate0 = normalizer * w;
  }

  Info << "Katyusha: maximum iterations (" << maxIterations << ") reached"
      << "; terminating optimization." << std::endl;

  // Calculate final objective if exactObjective is set to true.
  if (exactObjective)
  {
    overallObjective = 0;
    for (size_t i = 0; i < numFunctions; i += batchSize)
    {
      const size_t effectiveBatchSize = std::min(batchSize, numFunctions - i);
      const ElemType objective = function.Evaluate(iterate, i,
          effectiveBatchSize);
      overallObjective += objective;

      // The optimization is finished, so we don't need to care about the
      // callback result.
      (void) Callback::Evaluate(*this, function, iterate, objective,
          callbacks...);
    }
  }

  Callback::EndOptimization(*this, function, iterate, callbacks...);
  return overallObjective;
}

} // namespace ens

#endif
/**
 * @file lbfgs.hpp
 * @author Dongryeol Lee
 * @author Ryan Curtin
 *
 * The generic L-BFGS optimizer.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_LBFGS_LBFGS_HPP
#define ENSMALLEN_LBFGS_LBFGS_HPP

#include <ensmallen_bits/function.hpp>

namespace ens {

/**
 * The L-BFGS optimizer, which uses a back-tracking line search algorithm to
 * minimize a function.  The parameters for the algorithm (number of memory
 * points, maximum step size, and so forth) are all configurable via either the
 * constructor or standalone modifier functions.
 *
 * L_BFGS can optimize differentiable functions.  For more details, see the
 * documentation on function types included with this distribution or on the
 * ensmallen website.
 */
class L_BFGS
{
 public:
  /**
   * Initialize the L-BFGS object.  There are many parameters that can be set
   * for the optimization, but default values are given for each of them.
   *
   * @param numBasis Number of memory points to be stored (default 5).
   * @param maxIterations Maximum number of iterations for the optimization
   *     (0 means no limit and may run indefinitely).
   * @param armijoConstant Controls the accuracy of the line search routine for
   *     determining the Armijo condition.
   * @param wolfe Parameter for detecting the Wolfe condition.
   * @param minGradientNorm Minimum gradient norm required to continue the
   *     optimization.
   * @param factr Minimum relative function value decrease to continue
   *     the optimization.
   * @param maxLineSearchTrials The maximum number of trials for the line search
   *     (before giving up).
   * @param minStep The minimum step of the line search.
   * @param maxStep The maximum step of the line search.
   */
  L_BFGS(const size_t numBasis = 10, /* same default as scipy */
         const size_t maxIterations = 10000, /* many but not infinite */
         const double armijoConstant = 1e-4,
         const double wolfe = 0.9,
         const double minGradientNorm = 1e-6,
         const double factr = 1e-15,
         const size_t maxLineSearchTrials = 50,
         const double minStep = 1e-20,
         const double maxStep = 1e20);

  /**
   * Use L-BFGS to optimize the given function, starting at the given iterate
   * point and finding the minimum.  The maximum number of iterations is set in
   * the constructor (or with MaxIterations()).  Alternately, another overload
   * is provided which takes a maximum number of iterations as a parameter.  The
   * given starting point will be modified to store the finishing point of the
   * algorithm, and the final objective value is returned.
   *
   * @tparam FunctionType Type of the function to be optimized.
   * @tparam MatType Type of matrix to optimize with.
   * @tparam GradType Type of matrix to use to represent function gradients.
   * @tparam CallbackTypes Types of callback functions.
   * @param function Function to optimize; must have Evaluate() and Gradient().
   * @param iterate Starting point (will be modified).
   * @param callbacks Callback functions.
   * @return Objective value of the final point.
   */
  template<typename FunctionType,
           typename MatType,
           typename GradType,
           typename... CallbackTypes>
  typename std::enable_if<IsArmaType<GradType>::value,
      typename MatType::elem_type>::type
  Optimize(FunctionType& function,
           MatType& iterate,
           CallbackTypes&&... callbacks);

  //! Forward the MatType as GradType.
  template<typename SeparableFunctionType,
           typename MatType,
           typename... CallbackTypes>
  typename MatType::elem_type Optimize(SeparableFunctionType& function,
                                       MatType& iterate,
                                       CallbackTypes&&... callbacks)
  {
    return Optimize<SeparableFunctionType, MatType, MatType,
        CallbackTypes...>(function, iterate,
        std::forward<CallbackTypes>(callbacks)...);
  }

  //! Get the memory size.
  size_t NumBasis() const { return numBasis; }
  //! Modify the memory size.
  size_t& NumBasis() { return numBasis; }

  //! Get the maximum number of iterations.
  size_t MaxIterations() const { return maxIterations; }
  //! Modify the maximum number of iterations.
  size_t& MaxIterations() { return maxIterations; }

  //! Get the Armijo condition constant.
  double ArmijoConstant() const { return armijoConstant; }
  //! Modify the Armijo condition constant.
  double& ArmijoConstant() { return armijoConstant; }

  //! Get the Wolfe parameter.
  double Wolfe() const { return wolfe; }
  //! Modify the Wolfe parameter.
  double& Wolfe() { return wolfe; }

  //! Get the minimum gradient norm.
  double MinGradientNorm() const { return minGradientNorm; }
  //! Modify the minimum gradient norm.
  double& MinGradientNorm() { return minGradientNorm; }

  //! Get the factr value.
  double Factr() const { return factr; }
  //! Modify the factr value.
  double& Factr() { return factr; }

  //! Get the maximum number of line search trials.
  size_t MaxLineSearchTrials() const { return maxLineSearchTrials; }
  //! Modify the maximum number of line search trials.
  size_t& MaxLineSearchTrials() { return maxLineSearchTrials; }

  //! Return the minimum line search step size.
  double MinStep() const { return minStep; }
  //! Modify the minimum line search step size.
  double& MinStep() { return minStep; }

  //! Return the maximum line search step size.
  double MaxStep() const { return maxStep; }
  //! Modify the maximum line search step size.
  double& MaxStep() { return maxStep; }

 private:
  //! Size of memory for this L-BFGS optimizer.
  size_t numBasis;
  //! Maximum number of iterations.
  size_t maxIterations;
  //! Parameter for determining the Armijo condition.
  double armijoConstant;
  //! Parameter for detecting the Wolfe condition.
  double wolfe;
  //! Minimum gradient norm required to continue the optimization.
  double minGradientNorm;
  //! Minimum relative function value decrease to continue the optimization.
  double factr;
  //! Maximum number of trials for the line search.
  size_t maxLineSearchTrials;
  //! Minimum step of the line search.
  double minStep;
  //! Maximum step of the line search.
  double maxStep;
  //! Controls early termination of the optimization process.
  bool terminate;

  /**
   * Calculate the scaling factor, gamma, which is used to scale the Hessian
   * approximation matrix.  See method M3 in Section 4 of Liu and Nocedal
   * (1989).
   *
   * @return The calculated scaling factor.
   * @param gradient The gradient at the initial point.
   * @param s Differences between the iterate and old iterate matrix.
   * @param y Differences between the gradient and the old gradient matrix.
   */
  template<typename MatType, typename CubeType>
  double ChooseScalingFactor(const size_t iterationNum,
                             const MatType& gradient,
                             const CubeType& s,
                             const CubeType& y);

  /**
   * Perform a back-tracking line search along the search direction to
   * calculate a step size satisfying the Wolfe conditions.  The parameter
   * iterate will be modified if the method is successful.
   *
   * @param function Function to optimize.
   * @param functionValue Value of the function at the initial point.
   * @param iterate The initial point to begin the line search from.
   * @param gradient The gradient at the initial point.
   * @param searchDirection A vector specifying the search direction.
   * @param finalStepSize The resulting step size (0 if no step).
   * @param callbacks Callback functions.
   *
   * @return false if no step size is suitable, true otherwise.
   */
  template<typename FunctionType,
           typename ElemType,
           typename MatType,
           typename GradType,
           typename... CallbackTypes>
  bool LineSearch(FunctionType& function,
                  ElemType& functionValue,
                  MatType& iterate,
                  GradType& gradient,
                  MatType& newIterateTmp,
                  const GradType& searchDirection,
                  double& finalStepSize,
                  CallbackTypes&... callbacks);

  /**
   * Find the L-BFGS search direction.
   *
   * @param gradient The gradient at the current point.
   * @param iterationNum The iteration number.
   * @param scalingFactor Scaling factor to use (see ChooseScalingFactor_()).
   * @param s Differences between the iterate and old iterate matrix.
   * @param y Differences between the gradient and the old gradient matrix.
   * @param searchDirection Vector to store search direction in.
   */
  template<typename MatType, typename CubeType>
  void SearchDirection(const MatType& gradient,
                       const size_t iterationNum,
                       const double scalingFactor,
                       const CubeType& s,
                       const CubeType& y,
                       MatType& searchDirection);

  /**
   * Update the y and s matrices, which store the differences
   * between the iterate and old iterate and the differences between the
   * gradient and the old gradient, respectively.
   *
   * @param iterationNum Iteration number.
   * @param iterate Current point.
   * @param oldIterate Point at last iteration.
   * @param gradient Gradient at current point (iterate).
   * @param oldGradient Gradient at last iteration point (oldIterate).
   * @param s Differences between the iterate and old iterate matrix.
   * @param y Differences between the gradient and the old gradient matrix.
   */
  template<typename MatType, typename GradType, typename CubeType>
  void UpdateBasisSet(const size_t iterationNum,
                      const MatType& iterate,
                      const MatType& oldIterate,
                      const GradType& gradient,
                      const GradType& oldGradient,
                      CubeType& s,
                      CubeType& y);
};

} // namespace ens

#include "lbfgs_impl.hpp"

#endif // ENSMALLEN_LBFGS_LBFGS_HPP

/**
 * @file lbfgs_impl.hpp
 * @author Dongryeol Lee (dongryel@cc.gatech.edu)
 * @author Ryan Curtin
 *
 * The implementation of the L_BFGS optimizer.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_LBFGS_LBFGS_IMPL_HPP
#define ENSMALLEN_LBFGS_LBFGS_IMPL_HPP

// In case it hasn't been included yet.
#include "lbfgs.hpp"

#include <ensmallen_bits/function.hpp>

namespace ens {

/**
 * Initialize the L_BFGS object.
 *
 * @param numBasis Number of memory points to be stored (default 5).
 * @param maxIterations Maximum number of iterations for the optimization
 *     (0 means no limit and may run indefinitely).
 * @param armijoConstant Controls the accuracy of the line search routine for
 *     determining the Armijo condition.
 * @param wolfe Parameter for detecting the Wolfe condition.
 * @param minGradientNorm Minimum gradient norm required to continue the
 *     optimization.
 * @param factr Minimum relative function value decrease to continue
 *     the optimization.
 * @param maxLineSearchTrials The maximum number of trials for the line search
 *     (before giving up).
 * @param minStep The minimum step of the line search.
 * @param maxStep The maximum step of the line search.
 */
inline L_BFGS::L_BFGS(const size_t numBasis,
                      const size_t maxIterations,
                      const double armijoConstant,
                      const double wolfe,
                      const double minGradientNorm,
                      const double factr,
                      const size_t maxLineSearchTrials,
                      const double minStep,
                      const double maxStep) :
    numBasis(numBasis),
    maxIterations(maxIterations),
    armijoConstant(armijoConstant),
    wolfe(wolfe),
    minGradientNorm(minGradientNorm),
    factr(factr),
    maxLineSearchTrials(maxLineSearchTrials),
    minStep(minStep),
    maxStep(maxStep),
    terminate(false)
{
  // Nothing to do.
}

/**
 * Calculate the scaling factor, gamma, which is used to scale the Hessian
 * approximation matrix.  See method M3 in Section 4 of Liu and Nocedal
 * (1989).
 *
 * @return The calculated scaling factor.
 * @param gradient The gradient at the initial point.
 * @param s Differences between the iterate and old iterate matrix.
 * @param y Differences between the gradient and the old gradient matrix.
 */
template<typename MatType, typename CubeType>
double L_BFGS::ChooseScalingFactor(const size_t iterationNum,
                                   const MatType& gradient,
                                   const CubeType& s,
                                   const CubeType& y)
{
  typedef typename CubeType::elem_type CubeElemType;

  double scalingFactor;
  if (iterationNum > 0)
  {
    int previousPos = (iterationNum - 1) % numBasis;
    // Get s and y matrices once instead of multiple times.
    const arma::Mat<CubeElemType>& sMat = s.slice(previousPos);
    const arma::Mat<CubeElemType>& yMat = y.slice(previousPos);
    
    const CubeElemType tmp   = arma::dot(yMat, yMat);
    const CubeElemType denom = (tmp != CubeElemType(0)) ? tmp : CubeElemType(1);
    
    scalingFactor = arma::dot(sMat, yMat) / denom;
  }
  else
  {
    const CubeElemType tmp = arma::norm(gradient, "fro");
    
    scalingFactor = (tmp != CubeElemType(0)) ? (1.0 / tmp) : 1.0;
  }

  return scalingFactor;
}

/**
 * Find the L_BFGS search direction.
 *
 * @param gradient The gradient at the current point.
 * @param iterationNum The iteration number.
 * @param scalingFactor Scaling factor to use (see ChooseScalingFactor_()).
 * @param s Differences between the iterate and old iterate matrix.
 * @param y Differences between the gradient and the old gradient matrix.
 * @param searchDirection Vector to store search direction in.
 */
template<typename MatType, typename CubeType>
void L_BFGS::SearchDirection(const MatType& gradient,
                             const size_t iterationNum,
                             const double scalingFactor,
                             const CubeType& s,
                             const CubeType& y,
                             MatType& searchDirection)
{
  // Start from this point.
  searchDirection = gradient;

  // See "A Recursive Formula to Compute H * g" in "Updating quasi-Newton
  // matrices with limited storage" (Nocedal, 1980).
  typedef typename CubeType::elem_type CubeElemType;

  // Temporary variables.
  arma::Col<CubeElemType> rho(numBasis);
  arma::Col<CubeElemType> alpha(numBasis);

  size_t limit = (numBasis > iterationNum) ? 0 : (iterationNum - numBasis);
  for (size_t i = iterationNum; i != limit; i--)
  {
    int translatedPosition = (i + (numBasis - 1)) % numBasis;
    
    const arma::Mat<CubeElemType>& sMat = s.slice(translatedPosition);
    const arma::Mat<CubeElemType>& yMat = y.slice(translatedPosition);
    
    const CubeElemType tmp = arma::dot(yMat, sMat);
    
    rho[iterationNum - i] = (tmp != CubeElemType(0)) ? (1.0 / tmp) : CubeElemType(1);
    
    alpha[iterationNum - i] = rho[iterationNum - i] * arma::dot(sMat, searchDirection);
    
    searchDirection -= alpha[iterationNum - i] * yMat;
  }

  searchDirection *= scalingFactor;

  for (size_t i = limit; i < iterationNum; i++)
  {
    int translatedPosition = i % numBasis;
    double beta = rho[iterationNum - i - 1] *
        arma::dot(y.slice(translatedPosition), searchDirection);
    searchDirection += (alpha[iterationNum - i - 1] - beta) *
        s.slice(translatedPosition);
  }

  // Negate the search direction so that it is a descent direction.
  searchDirection *= -1;
}

/**
 * Update the y and s matrices, which store the differences between
 * the iterate and old iterate and the differences between the gradient and the
 * old gradient, respectively.
 *
 * @param iterationNum Iteration number.
 * @param iterate Current point.
 * @param oldIterate Point at last iteration.
 * @param gradient Gradient at current point (iterate).
 * @param oldGradient Gradient at last iteration point (oldIterate).
 * @param s Differences between the iterate and old iterate matrix.
 * @param y Differences between the gradient and the old gradient matrix.
 */
template<typename MatType, typename GradType, typename CubeType>
void L_BFGS::UpdateBasisSet(const size_t iterationNum,
                            const MatType& iterate,
                            const MatType& oldIterate,
                            const GradType& gradient,
                            const GradType& oldGradient,
                            CubeType& s,
                            CubeType& y)
{
  // Overwrite a certain position instead of pushing everything in the vector
  // back one position.
  int overwritePos = iterationNum % numBasis;
  s.slice(overwritePos) = iterate - oldIterate;
  y.slice(overwritePos) = gradient - oldGradient;
}

/**
 * Perform a back-tracking line search along the search direction to calculate a
 * step size satisfying the Wolfe conditions.
 *
 * @param function Function to optimize.
 * @param functionValue Value of the function at the initial point.
 * @param iterate The initial point to begin the line search from.
 * @param gradient The gradient at the initial point.
 * @param searchDirection A vector specifying the search direction.
 * @param finalStepSize The resulting step size used.
 * @param callbacks Callback functions.
 *
 * @return false if no step size is suitable, true otherwise.
 */
template<typename FunctionType,
         typename ElemType,
         typename MatType,
         typename GradType,
         typename... CallbackTypes>
bool L_BFGS::LineSearch(FunctionType& function,
                        ElemType& functionValue,
                        MatType& iterate,
                        GradType& gradient,
                        MatType& newIterateTmp,
                        const GradType& searchDirection,
                        double& finalStepSize,
                        CallbackTypes&... callbacks)
{
  // Default first step size of 1.0.
  double stepSize = 1.0;
  finalStepSize = 0.0; // Set only when we take the step.

  // The initial linear term approximation in the direction of the
  // search direction.
  ElemType initialSearchDirectionDotGradient =
      arma::dot(gradient, searchDirection);

  // If it is not a descent direction, just report failure.
  if ( (initialSearchDirectionDotGradient > 0.0)
    || (std::isfinite(initialSearchDirectionDotGradient) == false) )
  {
    Warn << "L-BFGS line search direction is not a descent direction "
        << "(terminating)!" << std::endl;
    return false;
  }

  // Save the initial function value.
  ElemType initialFunctionValue = functionValue;

  // Unit linear approximation to the decrease in function value.
  ElemType linearApproxFunctionValueDecrease = armijoConstant *
      initialSearchDirectionDotGradient;

  // The number of iteration in the search.
  size_t numIterations = 0;

  // Armijo step size scaling factor for increase and decrease.
  const double inc = 2.1;
  const double dec = 0.5;
  double width = 0;
  double bestStepSize = 1.0;
  ElemType bestObjective = std::numeric_limits<ElemType>::max();

  while (true)
  {
    // Perform a step and evaluate the gradient and the function values at that
    // point.
    newIterateTmp = iterate;
    newIterateTmp += stepSize * searchDirection;
    functionValue = function.EvaluateWithGradient(newIterateTmp, gradient);

    if (std::isnan(functionValue))
    {
      Warn << "L-BFGS objective value is NaN (terminating)!" << std::endl;
      return false;
    }

    terminate |= Callback::EvaluateWithGradient(*this, function, newIterateTmp,
        functionValue, gradient, callbacks...);

    if (functionValue < bestObjective)
    {
      bestStepSize = stepSize;
      bestObjective = functionValue;
    }
    numIterations++;

    if (functionValue > initialFunctionValue + stepSize *
        linearApproxFunctionValueDecrease)
    {
      width = dec;
    }
    else
    {
      // Check Wolfe's condition.
      ElemType searchDirectionDotGradient = arma::dot(gradient,
          searchDirection);

      if (searchDirectionDotGradient < wolfe *
          initialSearchDirectionDotGradient)
      {
        width = inc;
      }
      else
      {
        if (searchDirectionDotGradient > -wolfe *
            initialSearchDirectionDotGradient)
        {
          width = dec;
        }
        else
        {
          break;
        }
      }
    }

    // Terminate when the step size gets too small or too big or it
    // exceeds the max number of iterations.
    const bool cond1 = (stepSize < minStep);
    const bool cond2 = (stepSize > maxStep);
    const bool cond3 = (numIterations >= maxLineSearchTrials);
    if (cond1 || cond2 || cond3)
      break;

    // Scale the step size.
    stepSize *= width;
  }

  // Move to the new iterate.
  iterate += bestStepSize * searchDirection;
  finalStepSize = bestStepSize;
  return true;
}

/**
 * Use L_BFGS to optimize the given function, starting at the given iterate
 * point and performing no more than the specified number of maximum iterations.
 * The given starting point will be modified to store the finishing point of the
 * algorithm.
 *
 * @param numIterations Maximum number of iterations to perform
 * @param iterate Starting point (will be modified)
 * @param callbacks Callback functions.
 */
template<typename FunctionType,
         typename MatType,
         typename GradType,
         typename... CallbackTypes>
typename std::enable_if<IsArmaType<GradType>::value,
typename MatType::elem_type>::type
L_BFGS::Optimize(FunctionType& function,
                 MatType& iterateIn,
                 CallbackTypes&&... callbacks)
{
  // Convenience typedefs.
  typedef typename MatType::elem_type ElemType;
  typedef typename MatTypeTraits<MatType>::BaseMatType BaseMatType;
  typedef typename MatTypeTraits<GradType>::BaseMatType BaseGradType;

  // Use the Function<> wrapper to ensure the function has all of the functions
  // that we need.
  typedef Function<FunctionType, BaseMatType, BaseGradType> FullFunctionType;
  FullFunctionType& f = static_cast<FullFunctionType&>(function);

  // Check that we have all the functions we will need.
  traits::CheckFunctionTypeAPI<FullFunctionType, BaseMatType, BaseGradType>();
  RequireFloatingPointType<BaseMatType>();
  RequireFloatingPointType<BaseGradType>();
  RequireSameInternalTypes<BaseMatType, BaseGradType>();

  BaseMatType& iterate = (BaseMatType&) iterateIn;

  // Ensure that the cubes holding past iterations' information are the right
  // size.  Also set the current best point value to the maximum.
  const size_t rows = iterate.n_rows;
  const size_t cols = iterate.n_cols;

  BaseMatType newIterateTmp(rows, cols);
  arma::Cube<ElemType> s(rows, cols, numBasis);
  arma::Cube<ElemType> y(rows, cols, numBasis);

  // The old iterate to be saved.
  BaseMatType oldIterate(iterate.n_rows, iterate.n_cols);
  oldIterate.zeros();

  // Whether to optimize until convergence.
  bool optimizeUntilConvergence = (maxIterations == 0);

  // The gradient: the current and the old.
  BaseGradType gradient(iterate.n_rows, iterate.n_cols);
  gradient.zeros();
  BaseGradType oldGradient(iterate.n_rows, iterate.n_cols);
  oldGradient.zeros();

  // The search direction.
  BaseGradType searchDirection(iterate.n_rows, iterate.n_cols);
  searchDirection.zeros();

  // The initial function value and gradient.
  ElemType functionValue = f.EvaluateWithGradient(iterate, gradient);

  terminate |= Callback::EvaluateWithGradient(*this, f, iterate,
        functionValue, gradient, callbacks...);

  ElemType prevFunctionValue;

  // The main optimization loop.
  Callback::BeginOptimization(*this, f, iterate, callbacks...);
  for (size_t itNum = 0; (optimizeUntilConvergence || (itNum != maxIterations))
      && !terminate; ++itNum)
  {
    prevFunctionValue = functionValue;

    // Break when the norm of the gradient becomes too small.
    //
    // But don't do this on the first iteration to ensure we always take at
    // least one descent step.
    // TODO: to speed this up, investigate use of arma::norm2est() in Armadillo 12.4
    if (arma::norm(gradient, 2) < minGradientNorm)
    {
      Info << "L-BFGS gradient norm too small (terminating successfully)."
          << std::endl;
      break;
    }

    // Break if the objective is not a number.
    if (std::isnan(functionValue))
    {
      Warn << "L-BFGS terminated with objective " << functionValue << "; "
          << "are the objective and gradient functions implemented correctly?"
          << std::endl;
      break;
    }

    // Choose the scaling factor.
    double scalingFactor = ChooseScalingFactor(itNum, gradient, s, y);
    if (scalingFactor == 0.0)
    {
      Info << "L-BFGS scaling factor computed as 0 (terminating successfully)."
          << std::endl;
      break;
    }

    if (std::isfinite(scalingFactor) == false)
      {
      Warn << "L-BFGS scaling factor is not finite.  Stopping optimization."
           << std::endl;
      break;
      }
    
    // Build an approximation to the Hessian and choose the search
    // direction for the current iteration.
    SearchDirection(gradient, itNum, scalingFactor, s, y, searchDirection);

    // Save the old iterate and the gradient before stepping.
    oldIterate = iterate;
    oldGradient = gradient;

    double stepSize; // Set by LineSearch().
    if (!LineSearch(f, functionValue, iterate, gradient, newIterateTmp,
        searchDirection, stepSize, callbacks...))
    {
      Warn << "Line search failed.  Stopping optimization." << std::endl;
      break; // The line search failed; nothing else to try.
    }

    // It is possible that the difference between the two coordinates is zero.
    // In this case we terminate successfully.
    if (stepSize == 0.0)
    {
      Info << "L-BFGS step size of 0 (terminating successfully)."
          << std::endl;
      break;
    }

    // If we can't make progress on the gradient, then we'll also accept
    // a stable function value.
    const double denom = std::max(
        std::max(std::abs(prevFunctionValue), std::abs(functionValue)),
        (ElemType) 1.0);
    if ((prevFunctionValue - functionValue) / denom <= factr)
    {
      Info << "L-BFGS function value stable (terminating successfully)."
          << std::endl;
      break;
    }

    // Overwrite an old basis set.
    UpdateBasisSet(itNum, iterate, oldIterate, gradient, oldGradient, s, y);

    terminate |= Callback::StepTaken(*this, f, iterate, callbacks...);
  } // End of the optimization loop.

  Callback::EndOptimization(*this, f, iterate, callbacks...);
  return functionValue;
}

} // namespace ens

#endif // ENSMALLEN_LBFGS_LBFGS_IMPL_HPP

/**
 * @file log.hpp
 * @author Marcus Edel
 *
 * Definition of the Info and Warn log functions.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_LOG_HPP
#define ENSMALLEN_LOG_HPP

namespace ens {
/**
 * This class does nothing and should be optimized out entirely by the compiler.
 */
class NullOutStream
{
 public:
  /**
   * Does nothing.
   */
  NullOutStream() { }

  /**
   * Does nothing.
   */
  NullOutStream(const NullOutStream& /* other */) { }

  //! Does nothing.
  NullOutStream& operator<<(bool) { return *this; }
  //! Does nothing.
  NullOutStream& operator<<(short) { return *this; }
  //! Does nothing.
  NullOutStream& operator<<(unsigned short) { return *this; }
  //! Does nothing.
  NullOutStream& operator<<(int) { return *this; }
  //! Does nothing.
  NullOutStream& operator<<(unsigned int) { return *this; }
  //! Does nothing.
  NullOutStream& operator<<(long) { return *this; }
  //! Does nothing.
  NullOutStream& operator<<(unsigned long) { return *this; }
  //! Does nothing.
  NullOutStream& operator<<(float) { return *this; }
  //! Does nothing.
  NullOutStream& operator<<(double) { return *this; }
  //! Does nothing.
  NullOutStream& operator<<(long double) { return *this; }
  //! Does nothing.
  NullOutStream& operator<<(void*) { return *this; }
  //! Does nothing.
  NullOutStream& operator<<(const char*) { return *this; }
  //! Does nothing.
  NullOutStream& operator<<(std::string&) { return *this; }
  //! Does nothing.
  NullOutStream& operator<<(std::streambuf*) { return *this; }
  //! Does nothing.
  NullOutStream& operator<<(std::ostream& (*) (std::ostream&)) { return *this; }
  //! Does nothing.
  NullOutStream& operator<<(std::ios& (*) (std::ios&)) { return *this; }
  //! Does nothing.
  NullOutStream& operator<<(std::ios_base& (*) (std::ios_base&))
  { return *this; }

  //! Does nothing.
  template<typename T>
  NullOutStream& operator<<(const T&) { return *this; }
};

#ifdef ENS_PRINT_INFO
  static std::ostream& Info = arma::get_cout_stream();
#else
  static NullOutStream Info;
#endif

#ifdef ENS_PRINT_WARN
  static std::ostream& Warn = arma::get_cerr_stream();
#else
  static NullOutStream Warn;
#endif

} // namespace ens

#endif
/**
 * @file lookahead.hpp
 * @author Marcus Edel
 *
 * Lookahead is a stochastic gradient based optimization method which chooses a
 * search direction by looking ahead at the sequence of "fast weights" generated
 * by another optimizer.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_LOOKAHEAD_LOOKAHEAD_HPP
#define ENSMALLEN_LOOKAHEAD_LOOKAHEAD_HPP

#include <ensmallen_bits/adam/adam.hpp>
#include <ensmallen_bits/sgd/decay_policies/no_decay.hpp>

namespace ens {

/**
 * Lookahead is a stochastic gradient based optimization method which chooses a
 * search direction by looking ahead at the sequence of "fast weights" generated
 * by another optimizer.
 *
 * For more information, see the following.
 *
 * @code
 * @article{Zhang2019,
 *   author  = {Michael R. Zhang and James Lucas and Geoffrey E. Hinton and
 *              Jimmy Ba},
 *   title   = {Lookahead Optimizer: k steps forward, 1 step back},
 *   journal = {CoRR},
 *   year    = {2019},
 *   url     = {http://arxiv.org/abs/1907.08610}
 * }
 * @endcode
 *
 * Lookahead can optimize differentiable separable functions.  For more details,
 * see the documentation on function types included with this distribution or on
 * the ensmallen website.
 *
 * @tparam BaseOptimizerType Optimizer type for the forward step. By default the
 *     Adam optimizer is used.
 * @tparam DecayPolicyType Decay policy used during the iterative update
 *     process to adjust the step size. By default the step size isn't going to
 *     be adjusted (i.e. NoDecay is used).
 */
template<typename BaseOptimizerType = Adam, typename DecayPolicyType = NoDecay>
class Lookahead
{
 public:
  /**
   * Construct the Lookahead optimizer with the given function, parameters
   * and the default Adam optimizer for the forward step. The defaults here are
   * not necessarily good for the given problem, so it is suggested that the
   * values used be tailored to the task at hand.  The maximum number of
   * iterations refers to the maximum number of points that are processed
   * (i.e., one iteration equals one point; one iteration does not equal
   * one pass over the dataset).
   *
   * @param stepSize Step size for each iteration.
   * @param k The synchronization period.
   * @param maxIterations Maximum number of iterations allowed (0 means no
   *        limit).
   * @param tolerance Maximum absolute tolerance to terminate algorithm.
   * @param decayPolicy Instantiated decay policy used to adjust the step size.
   * @param resetPolicy Flag that determines whether update policy parameters
   *                    are reset before every outer Optimize call.
   * @param exactObjective Calculate the exact objective (Default: estimate the
   *        final objective obtained on the last pass over the data).
   */
  Lookahead(const double stepSize = 0.5,
            const size_t k = 5,
            const size_t maxIterations = 100000,
            const double tolerance = 1e-5,
            const DecayPolicyType& decayPolicy = DecayPolicyType(),
            const bool resetPolicy = false,
            const bool exactObjective = false);

  /**
   * Construct the Lookahead optimizer with the given function and parameters.
   * The defaults here are not necessarily good for the given problem, so it is
   * suggested that the values used be tailored to the task at hand.  The
   * maximum number of iterations refers to the maximum number of points that
   * are processed (i.e., one iteration equals one point; one iteration does not
   * equal one pass over the dataset).
   *
   * @param baseOptimizer Optimizer for the forward step.
   * @param stepSize Step size for each iteration.
   * @param k The synchronization period.
   * @param maxIterations Maximum number of iterations allowed (0 means no
   *        limit).
   * @param tolerance Maximum absolute tolerance to terminate algorithm.
   * @param decayPolicy Instantiated decay policy used to adjust the step size.
   * @param resetPolicy Flag that determines whether update policy parameters
   *                    are reset before every outer Optimize call.
   * @param exactObjective Calculate the exact objective (Default: estimate the
   *        final objective obtained on the last pass over the data).
   */
  Lookahead(const BaseOptimizerType& baseOptimizer,
            const double stepSize = 0.5,
            const size_t k = 5,
            const size_t maxIterations = 100000,
            const double tolerance = 1e-5,
            const DecayPolicyType& decayPolicy = DecayPolicyType(),
            const bool resetPolicy = false,
            const bool exactObjective = false);

  /**
   * Clean any memory associated with the Lookahead object.
   */
  ~Lookahead();

  /**
   * Optimize the given function using Lookahead. The given starting point will
   * be modified to store the finishing point of the algorithm, and the final
   * objective value is returned.
   *
   * @tparam SeparableFunctionType Type of the function to be optimized.
   * @tparam MatType Type of the parameters matrix.
   * @tparam GradType Type of the gradient matrix.
   * @tparam CallbackTypes Types of callback functions.
   * @param function Function to optimize.
   * @param iterate Starting point (will be modified).
   * @param callbacks Callback functions.
   * @return Objective value of the final point.
   */
  template<typename SeparableFunctionType,
           typename MatType,
           typename GradType,
           typename... CallbackTypes>
  typename std::enable_if<IsArmaType<GradType>::value,
      typename MatType::elem_type>::type
  Optimize(SeparableFunctionType& function,
           MatType& iterate,
           CallbackTypes&&... callbacks);

  //! Forward the MatType as GradType.
  template<typename SeparableFunctionType,
           typename MatType,
           typename... CallbackTypes>
  typename MatType::elem_type Optimize(SeparableFunctionType& function,
                                       MatType& iterate,
                                       CallbackTypes&&... callbacks)
  {
    return Optimize<SeparableFunctionType, MatType, MatType,
        CallbackTypes...>(function, iterate,
        std::forward<CallbackTypes>(callbacks)...);
  }

  //! Get the base optimizer.
  BaseOptimizerType BaseOptimizer() const { return baseOptimizer; }
  //! Modify the base optimizer.
  BaseOptimizerType& BaseOptimizer() { return baseOptimizer; }

  //! Get the step size.
  double StepSize() const { return stepSize; }
  //! Modify the step size.
  double& StepSize() { return stepSize; }

  //! Get the synchronization period.
  size_t K() const { return k; }
  //! Modify the synchronization period.
  size_t& K() { return k; }

  //! Get the maximum number of iterations (0 indicates no limit).
  size_t MaxIterations() const { return maxIterations; }
  //! Modify the maximum number of iterations (0 indicates no limit).
  size_t& MaxIterations() { return maxIterations; }

  //! Get the tolerance for termination.
  double Tolerance() const { return tolerance; }
  //! Modify the tolerance for termination.
  double& Tolerance() { return tolerance; }

  //! Get the step size decay policy.
  const DecayPolicyType& DecayPolicy() const { return decayPolicy; }
  //! Modify the step size decay policy.
  DecayPolicyType& DecayPolicy() { return decayPolicy; }

  //! Get the instantiated decay policy type.  Be sure to check its type with
  //! Has() before using!
  const Any& InstDecayPolicy() const { return instDecayPolicy; }
  //! Modify the instantiated decay policy type.  Be sure to check its type with
  //! Has() before using!
  Any& InstDecayPolicy() { return instDecayPolicy; }

  //! Get whether or not the actual objective is calculated.
  bool ExactObjective() const { return exactObjective; }
  //! Modify whether or not the actual objective is calculated.
  bool& ExactObjective() { return exactObjective; }

 private:
  /**
   * Set the maximum number of iterations if the given optimizer implements
   * MaxIterations().
   *
   * @param optimizer Optimizer to check for MaxIterations().
   * @param k The number of iterations.
   */
  template<typename OptimizerType>
  static typename std::enable_if<traits::HasMaxIterationsSignature<
      OptimizerType>::value, void>::type
  SetMaxIterations(OptimizerType& optimizer, const size_t k)
  {
    optimizer.MaxIterations() = k;
  }

  template<typename OptimizerType>
  static typename std::enable_if<!traits::HasMaxIterationsSignature<
      OptimizerType>::value, void>::type
  SetMaxIterations(const OptimizerType& /* optimizer */, const size_t /* k */)
  {
    Warn << "The base optimizer does not have a definition of "
        << "MaxIterations(), the base optimizer will have its configuration "
        << "unchanged.";
  }

  //! The base optimizer for the forward step.
  BaseOptimizerType baseOptimizer;

  //! The step size for each example.
  double stepSize;

  //! Synchronization period.
  size_t k;

  //! The maximum number of allowed iterations.
  size_t maxIterations;

  //! The tolerance for termination.
  double tolerance;

  //! The decay policy used to update the step size.
  DecayPolicyType decayPolicy;

  //! Flag indicating whether update policy
  //! should be reset before running the outer optimization.
  bool resetPolicy;

  //! Controls whether or not the actual Objective value is calculated.
  bool exactObjective;

  //! Flag indicating whether the update policy
  //! parameters have been initialized.
  bool isInitialized;

  //! The initialized decay policy.
  Any instDecayPolicy;
};

} // namespace ens

// Include implementation.
#include "lookahead_impl.hpp"

#endif
/**
 * @file lookahead_impl.hpp
 * @author Marcus Edel
 *
 * Implementation of Lookahead Optimizer: k steps forward, 1 step back.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_LOOKAHEAD_LOOKAHEAD_IMPL_HPP
#define ENSMALLEN_LOOKAHEAD_LOOKAHEAD_IMPL_HPP

// In case it hasn't been included yet.
#include "lookahead.hpp"

#include <ensmallen_bits/function.hpp>

namespace ens {

template<typename BaseOptimizerType, typename DecayPolicyType>
inline Lookahead<BaseOptimizerType, DecayPolicyType>::Lookahead(
    const double stepSize,
    const size_t k,
    const size_t maxIterations,
    const double tolerance,
    const DecayPolicyType& decayPolicy,
    const bool resetPolicy,
    const bool exactObjective) :
    baseOptimizer(BaseOptimizerType()),
    stepSize(stepSize),
    k(k),
    maxIterations(maxIterations),
    tolerance(tolerance),
    decayPolicy(decayPolicy),
    resetPolicy(resetPolicy),
    exactObjective(exactObjective),
    isInitialized(false)
{ /* Nothing to do. */ }

template<typename BaseOptimizerType, typename DecayPolicyType>
inline Lookahead<BaseOptimizerType, DecayPolicyType>::Lookahead(
    const BaseOptimizerType& baseOptimizer,
    const double stepSize,
    const size_t k,
    const size_t maxIterations,
    const double tolerance,
    const DecayPolicyType& decayPolicy,
    const bool resetPolicy,
    const bool exactObjective) :
    baseOptimizer(baseOptimizer),
    stepSize(stepSize),
    k(k),
    maxIterations(maxIterations),
    tolerance(tolerance),
    decayPolicy(decayPolicy),
    resetPolicy(resetPolicy),
    exactObjective(exactObjective),
    isInitialized(false)
{ /* Nothing to do. */ }

template<typename BaseOptimizerType, typename DecayPolicyType>
inline Lookahead<BaseOptimizerType, DecayPolicyType>::~Lookahead()
{
  instDecayPolicy.Clean();
}

//! Optimize the function (minimize).
template<typename BaseOptimizerType, typename DecayPolicyType>
template<typename SeparableFunctionType,
         typename MatType,
         typename GradType,
         typename... CallbackTypes>
typename std::enable_if<IsArmaType<GradType>::value,
typename MatType::elem_type>::type
Lookahead<BaseOptimizerType, DecayPolicyType>::Optimize(
    SeparableFunctionType& function,
    MatType& iterateIn,
    CallbackTypes&&... callbacks)
{
  // Convenience typedefs.
  typedef typename MatType::elem_type ElemType;
  typedef typename MatTypeTraits<MatType>::BaseMatType BaseMatType;
  typedef typename MatTypeTraits<GradType>::BaseMatType BaseGradType;

  typedef Function<SeparableFunctionType, BaseMatType, BaseGradType>
      FullFunctionType;
  FullFunctionType& f(static_cast<FullFunctionType&>(function));

  // The decay policy internally use a templated class so that
  // we can know MatType and GradType only when Optimize() is called.
  typedef typename DecayPolicyType::template Policy<BaseMatType, BaseGradType>
      InstDecayPolicyType;

  // Make sure we have all the methods that we need.
  traits::CheckSeparableFunctionTypeAPI<FullFunctionType, BaseMatType,
      BaseGradType>();
  RequireFloatingPointType<BaseMatType>();
  RequireFloatingPointType<BaseGradType>();
  RequireSameInternalTypes<BaseMatType, BaseGradType>();

  BaseMatType& iterate = (BaseMatType&) iterateIn;

  // Check if the optimizer implements HasMaxIterations() and override the
  // parameter with k.
  SetMaxIterations(baseOptimizer, k);

  // Check if the optimizer implements ResetPolicy() and override the reset
  // policy.
  if (traits::HasResetPolicySignature<BaseOptimizerType>::value &&
      baseOptimizer.ResetPolicy())
  {
    Warn << "Parameters are reset before every Optimize call; set "
        << "ResetPolicy() to false.";
    baseOptimizer.ResetPolicy() = resetPolicy;
  }

  // To keep track of where we are and how things are going.
  ElemType overallObjective = 0;
  ElemType lastOverallObjective = DBL_MAX;

  // Controls early termination of the optimization process.
  bool terminate = false;

  // Initialize the decay policy if needed.
  if (!isInitialized || !instDecayPolicy.Has<InstDecayPolicyType>())
  {
    instDecayPolicy.Clean();
    instDecayPolicy.Set<InstDecayPolicyType>(
        new InstDecayPolicyType(decayPolicy));
    isInitialized = true;
  }

  // Now iterate!
  Callback::BeginOptimization(*this, f, iterate, callbacks...);
  const size_t actualMaxIterations = (maxIterations == 0) ?
      std::numeric_limits<size_t>::max() : maxIterations;
  for (size_t i = 0; i < actualMaxIterations && !terminate; i++)
  {
    BaseMatType iterateModel = iterate;

    overallObjective = baseOptimizer.Optimize(f, iterateModel,
        callbacks...);

    // Now update the learning rate if requested by the user, note we pass the
    // latest inner model coordinates instead of the gradient.
    instDecayPolicy.As<InstDecayPolicyType>().Update(iterate, stepSize,
        iterateModel);

    if (std::isnan(overallObjective) || std::isinf(overallObjective))
    {
      Warn << "Lookahead: converged to " << overallObjective
          << "; terminating with failure.  Try a smaller step size?"
          << std::endl;

      iterate = iterateModel;
      Callback::EndOptimization(*this, f, iterate, callbacks...);
      return overallObjective;
    }

    if (std::abs(lastOverallObjective - overallObjective) < tolerance)
    {
      Info << "Lookahead: minimized within tolerance " << tolerance << "; "
          << "terminating optimization." << std::endl;

      iterate = iterateModel;
      Callback::EndOptimization(*this, f, iterate, callbacks...);
      return overallObjective;
    }

    iterate += stepSize * (iterateModel - iterate);
    terminate |= Callback::StepTaken(*this, f, iterate, callbacks...);

    // Save the current objective.
    lastOverallObjective = overallObjective;
  }

  Info << "Lookahead: maximum iterations (" << maxIterations << ") reached; "
      << "terminating optimization." << std::endl;

  // Calculate final objective if exactObjective is set to true.
  if (exactObjective)
  {
    // Find the number of functions to use.
    const size_t numFunctions = f.NumFunctions();

    size_t batchSize = 1;
    // Check if the optimizer implements the BatchSize() method and use the
    // parameter for the objective calculation.
    if (traits::HasBatchSizeSignature<BaseOptimizerType>::value)
      batchSize = baseOptimizer.BatchSize();

    overallObjective = 0;
    for (size_t i = 0; i < numFunctions; i += batchSize)
    {
      const size_t effectiveBatchSize = std::min(batchSize, numFunctions - i);
      const ElemType objective = f.Evaluate(iterate, i, effectiveBatchSize);
      overallObjective += objective;

      // The optimization is over, so we don't need to care about the result of
      // the callback.
      (void) Callback::Evaluate(*this, f, iterate, objective, callbacks...);
    }
  }

  Callback::EndOptimization(*this, f, iterate, callbacks...);
  return overallObjective;
}

} // namespace ens

#endif
/**
 * @file pbi_decomposition.hpp
 * @author Nanubala Gnana Sai
 *
 * The Penalty Based Boundary Intersection (PBI) decomposition policy.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_MOEAD_PBI_HPP
#define ENSMALLEN_MOEAD_PBI_HPP

namespace ens {

/**
 * Penalty Based Boundary Intersection (PBI) method is a weight decomposition method,
 * it tries to find the intersection between bottom-most boundary of the attainable
 * objective set with the reference directions.
 *
 * The goal is to minimize the distance between objective vectors with the ideal point
 * along the reference direction. To handle equality constraints, a penalty parameter
 * theta is used.
 *
 * For more information, see the following:
 * @code
 * article{zhang2007moea,
 *   title={MOEA/D: A multiobjective evolutionary algorithm based on decomposition},
 *   author={Zhang, Qingfu and Li, Hui},
 *   journal={IEEE Transactions on evolutionary computation},
 *   pages={712--731},
 *   year={2007}
 * @endcode
 */
class PenaltyBoundaryIntersection
{
 public:
  /**
   * Constructor for Penalty Based Boundary Intersection decomposition
   * policy.
   *
   * @param theta The penalty value.
   */
  PenaltyBoundaryIntersection(const double theta = 5) :
      theta(theta)
  {
    /* Nothing to do. */
  }

  /**
   * Decompose the weight vectors.
   *
   * @tparam VecType The type of the vector used in the decommposition.
   * @param weight The weight vector corresponding to a subproblem.
   * @param idealPoint The reference point in the objective space.
   * @param candidateFitness The objective vector of the candidate.
   */
  template<typename VecType>
  typename VecType::elem_type Apply(const VecType& weight,
                                    const VecType& idealPoint,
                                    const VecType& candidateFitness)
  {
    typedef typename VecType::elem_type ElemType;
    //! A unit vector in the same direction as the provided weight vector.
    const VecType referenceDirection = weight / arma::norm(weight);
    //! Distance of F(x) from the idealPoint along the reference direction.
    const ElemType d1 = arma::dot(candidateFitness - idealPoint, referenceDirection);
    //! The perpendicular distance of F(x) from reference direction.
    const ElemType d2 = arma::norm(candidateFitness - (idealPoint + d1 * referenceDirection));

    return d1 + static_cast<ElemType>(theta) * d2;
  }

  private:
    double theta;
};

} // namespace ens

#endif
/**
 * @file tchebycheff_decomposition.hpp
 * @author Nanubala Gnana Sai
 *
 * The Tchebycheff Weight decomposition policy.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_MOEAD_TCHEBYCHEFF_HPP
#define ENSMALLEN_MOEAD_TCHEBYCHEFF_HPP

namespace ens {

/**
 * The Tchebycheff method works by taking the maximum of element-wise product
 * between reference direction and the line connecting objective vector and
 * ideal point.
 *
 * Under mild conditions, for each Pareto Optimal point there exists a reference
 * direction such that the given point is also the optimal solution
 * to this scalar objective.
 *
 * For more information, see the following:
 * @code
 * article{zhang2007moea,
 *   title={MOEA/D: A multiobjective evolutionary algorithm based on decomposition},
 *   author={Zhang, Qingfu and Li, Hui},
 *   journal={IEEE Transactions on evolutionary computation},
 *   pages={712--731},
 *   year={2007}
 * @endcode
 */
class Tchebycheff
{
 public:
  /**
   * Constructor for Tchebycheff decomposition policy.
   */
  Tchebycheff()
  {
    /* Nothing to do. */
  }

  /**
   * Decompose the weight vectors.
   *
   * @tparam VecType The type of the vector used in the decommposition.
   * @param weight The weight vector corresponding to a subproblem.
   * @param idealPoint The reference point in the objective space.
   * @param candidateFitness The objective vector of the candidate.
   */
  template<typename VecType>
  typename VecType::elem_type Apply(const VecType& weight,
                                    const VecType& idealPoint,
                                    const VecType& candidateFitness)
  {
    return arma::max(weight % arma::abs(candidateFitness - idealPoint));
  }
};

} // namespace ens

#endif
/**
 * @file weighted_decomposition.hpp
 * @author Nanubala Gnana Sai
 *
 * The Weighted Average decomposition policy.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_MOEAD_WEIGHTED_HPP
#define ENSMALLEN_MOEAD_WEIGHTED_HPP

namespace ens {

/**
 * The Weighted average method of decomposition. The working principle is to
 * minimize the dot product between reference direction and the line connecting
 * objective vector and ideal point.
 *
 * For more information, see the following:
 * @code
 * article{zhang2007moea,
 *   title={MOEA/D: A multiobjective evolutionary algorithm based on decomposition},
 *   author={Zhang, Qingfu and Li, Hui},
 *   journal={IEEE Transactions on evolutionary computation},
 *   pages={712--731},
 *   year={2007}
 * @endcode
 */
class WeightedAverage
{
 public:
  /**
   * Constructor for Weighted Average decomposition policy.
   */
  WeightedAverage()
  {
    /* Nothing to do. */
  }

  /**
   * Decompose the weight vectors.
   *
   * @tparam VecType The type of the vector used in the decommposition.
   * @param weight The weight vector corresponding to a subproblem.
   * @param idealPoint The reference point in the objective space.
   * @param candidateFitness The objective vector of the candidate.
   */
  template<typename VecType>
  typename VecType::elem_type Apply(const VecType& weight,
                                    const VecType& /* idealPoint */,
                                    const VecType& candidateFitness)
  {
    return arma::dot(weight, candidateFitness);
  }
};

} // namespace ens

#endif
/**
 * @file moead.hpp
 * @author Nanubala Gnana Sai
 *
 * MOEA/D-DE is a multi objective optimization algorithm. MOEA/D-DE
 * uses genetic algorithms along with a set of reference directions
 * to drive the population towards the Optimal Front.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */

#ifndef ENSMALLEN_MOEAD_MOEAD_HPP
#define ENSMALLEN_MOEAD_MOEAD_HPP

//! Decomposition policies.
#include "decomposition_policies/tchebycheff_decomposition.hpp"
#include "decomposition_policies/weighted_decomposition.hpp"
#include "decomposition_policies/pbi_decomposition.hpp"

//! Weight initialization policies.
#include "weight_init_policies/uniform_init.hpp"
#include "weight_init_policies/bbs_init.hpp"
#include "weight_init_policies/dirichlet_init.hpp"

namespace ens {

/**
 * MOEA/D-DE (Multi Objective Evolutionary Algorithm based on Decompositon - 
 * Differential Variant) is a multiobjective optimization algorithm. This class 
 * implements the said optimizer. 
 *
 * The algorithm works by generating a candidate population from a fixed starting point. 
 * Reference directions are generated to guide the optimization process towards the Pareto Front. 
 * Further, a decomposition function is defined to decompose the problem to a scalar optimization 
 * objective. Utilizing genetic operators, offsprings are generated with better decomposition values 
 * to replace the neighboring parent solutions. 
 *
 * For more information, see the following:
 * @code
 * @article{li2008multiobjective,
 *   title={Multiobjective optimization problems with complicated Pareto sets, MOEA/D and NSGA-II},
 *   author={Li, Hui and Zhang, Qingfu},
 *   journal={IEEE transactions on evolutionary computation},
 *   pages={284--302},
 *   year={2008},
 * @endcode
 */
template<typename InitPolicyType = Uniform,
         typename DecompPolicyType = Tchebycheff>
class MOEAD {
 public:
  /**
   * Constructor for the MOEA/D optimizer.
   *
   * The default values provided here are not necessarily suitable for a
   * given function. Therefore, it is highly recommended to adjust the
   * parameters according to the problem.
   *
   * @param populationSize The number of elements in the population.
   * @param maxGenerations The maximum number of generations allowed.
   * @param crossoverProb The probability that a crossover will occur.
   * @param neighborProb The probability of sampling from neighbor.
   * @param neighborSize The number of nearest neighbours of weights
   *    to find.
   * @param distributionIndex The crowding degree of the mutation.
   * @param differentialWeight A parameter used in the mutation of candidate
   *     solutions controls amplification factor of the differentiation.
   * @param maxReplace The limit of solutions allowed to be replaced by a child.
   * @param epsilon Handle numerical stability after weight initialization.
   * @param lowerBound The lower bound on each variable of a member
   *    of the variable space.
   * @param upperBound The upper bound on each variable of a member
   *    of the variable space.
   */
  MOEAD(const size_t populationSize = 300,
        const size_t maxGenerations = 500,
        const double crossoverProb = 1.0,
        const double neighborProb = 0.9,
        const size_t neighborSize = 20,
        const double distributionIndex = 20,
        const double differentialWeight = 0.5,
        const size_t maxReplace = 2,
        const double epsilon = 1E-10,
        const arma::vec& lowerBound = arma::zeros(1, 1),
        const arma::vec& upperBound = arma::ones(1, 1),
        const InitPolicyType initPolicy = InitPolicyType(),
        const DecompPolicyType decompPolicy = DecompPolicyType());

  /**
   * Constructor for the MOEA/D optimizer. This constructor is provides an
   * overload to use lowerBound and upperBound as doubles, in case all the
   * variables in the problem have the same limits.
   *
   * The default values provided here are not necessarily suitable for a
   * given function. Therefore, it is highly recommended to adjust the
   * parameters according to the problem.
   *
   * @param populationSize The number of elements in the population.
   * @param maxGenerations The maximum number of generations allowed.
   * @param crossoverProb The probability that a crossover will occur.
   * @param neighborProb The probability of sampling from neighbor.
   * @param neighborSize The number of nearest neighbours of weights
   *    to find.
   * @param distributionIndex The crowding degree of the mutation.
   * @param differentialWeight A parameter used in the mutation of candidate
   *     solutions controls amplification factor of the differentiation.
   * @param maxReplace The limit of solutions allowed to be replaced by a child.
   * @param epsilon Handle numerical stability after weight initialization.
   * @param lowerBound The lower bound on each variable of a member
   *    of the variable space.
   * @param upperBound The upper bound on each variable of a member
   *    of the variable space.
   */
    MOEAD(const size_t populationSize = 300,
          const size_t maxGenerations = 500,
          const double crossoverProb = 1.0,
          const double neighborProb = 0.9,
          const size_t neighborSize = 20,
          const double distributionIndex = 20,
          const double differentialWeight = 0.5,
          const size_t maxReplace = 2,
          const double epsilon = 1E-10,
          const double lowerBound = 0,
          const double upperBound = 1,
          const InitPolicyType initPolicy = InitPolicyType(),
          const DecompPolicyType decompPolicy = DecompPolicyType());

  /**
   * Optimize a set of objectives. The initial population is generated
   * using the initial point. The output is the best generated front.
   *
   * @tparam MatType The type of matrix used to store coordinates.
   * @tparam ArbitraryFunctionType The type of objective function.
   * @tparam CallbackTypes Types of callback function.
   * @param objectives std::tuple of the objective functions.
   * @param iterate The initial reference point for generating population.
   * @param callbacks The callback functions.
   */
  template<typename MatType,
           typename... ArbitraryFunctionType,
           typename... CallbackTypes>
  typename MatType::elem_type Optimize(std::tuple<ArbitraryFunctionType...>& objectives,
                                       MatType& iterate,
                                       CallbackTypes&&... callbacks);

  //! Retrieve population size.
  size_t PopulationSize() const { return populationSize; }
  //! Modify the population size.
  size_t& PopulationSize() { return populationSize; }

  //! Retrieve number of generations.
  size_t MaxGenerations() const { return maxGenerations; }
  //! Modify the number of generations.
  size_t& MaxGenerations() { return maxGenerations; }

  //! Retrieve crossover rate.
  double CrossoverRate() const { return crossoverProb; }
  //! Modify the crossover rate.
  double& CrossoverRate() { return crossoverProb; }

  //! Retrieve size of the weight neighbor.
  size_t NeighborSize() const { return neighborSize; }
  //! Modify the size of the weight neighbor.
  size_t& NeighborSize() { return neighborSize; }

  //! Retrieve value of the distribution index.
  double DistributionIndex() const { return distributionIndex; }
  //! Modify the value of the distribution index.
  double& DistributionIndex() { return distributionIndex; }

  //! Retrieve value of neighbor probability.
  double NeighborProb() const { return neighborProb; }
  //! Modify the value of neigbourhood probability.
  double& NeighborProb() { return neighborProb; }

  //! Retrieve value of scaling factor.
  double DifferentialWeight() const { return differentialWeight; }
  //! Modify the value of scaling factor.
  double& DifferentialWeight() { return differentialWeight; }

  //! Retrieve value of maxReplace.
  size_t MaxReplace() const { return maxReplace; }
  //! Modify value of maxReplace.
  size_t& MaxReplace() { return maxReplace; }

   //! Retrieve value of epsilon.
  double Epsilon() const { return epsilon; }
  //! Modify value of maxReplace.
  double& Epsilon() { return epsilon; }

  //! Retrieve value of lowerBound.
  const arma::vec& LowerBound() const { return lowerBound; }
  //! Modify value of lowerBound.
  arma::vec& LowerBound() { return lowerBound; }

  //! Retrieve value of upperBound.
  const arma::vec& UpperBound() const { return upperBound; }
  //! Modify value of upperBound.
  arma::vec& UpperBound() { return upperBound; }

  //! Retrieve the Pareto optimal points in variable space. This returns an empty cube
  //! until `Optimize()` has been called.
  const arma::cube& ParetoSet() const { return paretoSet; }

  //! Retrieve the best front (the Pareto frontier). This returns an empty cube until
  //! `Optimize()` has been called.
  const arma::cube& ParetoFront() const { return paretoFront; }

  //! Get the weight initialization policy.
  const InitPolicyType& InitPolicy() const { return initPolicy; }
  //! Modify the weight initialization policy.
  InitPolicyType& InitPolicy() { return initPolicy; }

  //! Get the weight decomposition policy.
  const DecompPolicyType& DecompPolicy() const { return decompPolicy; }
  //! Modify the weight decomposition policy.
  DecompPolicyType& DecompPolicy() { return decompPolicy; }

 private:
  /**
   * @brief Randomly selects two members from the population.
   *
   * @param subProblemIdx Index of the current subproblem.
   * @param neighborSize A matrix containing indices of the neighbors.
   * @return std::tuple<size_t, size_t> The chosen pair of indices.
   */
  std::tuple<size_t, size_t> Mating(size_t subProblemIdx,
                                    const arma::umat& neighborSize,
                                    bool sampleNeighbor);

  /**
   * Mutate the child formed by the crossover of two random members of the
   * population. Uses polynomial mutation.
   *
   * @tparam MatType The type of matrix used to store coordinates.
   * @param child The candidate to be mutated.
   * @param mutationRate The probability of mutation.
   * @param lowerBound The lower bound on each variable in the matrix.
   * @param upperBound The upper bound on each variable in the matrix.
   * @return The mutated child.
   */
  template<typename MatType>
  void Mutate(MatType& child,
              double mutationRate,
              const MatType& lowerBound,
              const MatType& upperBound);

  /**
   * Evaluate objectives for the elite population.
   *
   * @tparam ArbitraryFunctionType std::tuple of multiple function types.
   * @tparam MatType Type of matrix to optimize.
   * @param population The elite population.
   * @param objectives The set of objectives.
   * @param calculatedObjectives Vector to store calculated objectives.
   */
  template<std::size_t I = 0,
           typename MatType,
           typename ...ArbitraryFunctionType>
  typename std::enable_if<I == sizeof...(ArbitraryFunctionType), void>::type
  EvaluateObjectives(
                     std::vector<MatType>&,
                     std::tuple<ArbitraryFunctionType...>&,
                     std::vector<arma::Col<typename MatType::elem_type> >&);

  template<std::size_t I = 0,
           typename MatType,
           typename ...ArbitraryFunctionType>
  typename std::enable_if<I < sizeof...(ArbitraryFunctionType), void>::type
  EvaluateObjectives(
                     std::vector<MatType>& population,
                     std::tuple<ArbitraryFunctionType...>& objectives,
                     std::vector<arma::Col<typename MatType::elem_type> >&
                     calculatedObjectives);

  //! Size of the population.
  size_t populationSize;

  //! Maximum number of generations before termination criteria is met.
  size_t maxGenerations;

  //! Probability of crossover between two members.
  double crossoverProb;

  //! The probability that two elements will be chosen from the neighbor.
  double neighborProb;

  //! Number of nearest neighbours of weights to consider.
  size_t neighborSize;

  //! The crowding degree of the mutation. Higher value produces a mutant
  //! resembling its parent.
  double distributionIndex;

  //! Amplification factor for differentiation.
  double differentialWeight;

  //! Maximum number of childs which can replace the parent. Higher value
  //! leads to a loss of diversity.
  size_t maxReplace;

  //! A small numeric value to be added to the weights after initialization.
  //! Prevents zero value inside inited weights.
  double epsilon;

  //! Lower bound on each variable in the variable space.
  arma::vec lowerBound;

  //! Upper bound on each variable in the variable space.
  arma::vec upperBound;

  //! The set of all the Pareto optimal points.
  //! Stored after Optimize() is called.
  arma::cube paretoSet;

  //! The set of all the Pareto optimal objective vectors.
  //! Stored after Optimize() is called.
  arma::cube paretoFront;

  //! Policy to initialize the reference directions (weights) matrix.
  InitPolicyType initPolicy;

  //! Policy to decompose the weights.
  DecompPolicyType decompPolicy;
};

using DefaultMOEAD = MOEAD<Uniform, Tchebycheff>;
using BBSMOEAD = MOEAD<BayesianBootstrap, Tchebycheff>;
using DirichletMOEAD = MOEAD<Dirichlet, Tchebycheff>;
} // namespace ens

// Include implementation.
#include "moead_impl.hpp"

#endif
/**
 * @file moead_impl.hpp
 * @author Nanubala Gnana Sai
 *
 * Implementation of the MOEA/D-DE algorithm. Used for multi-objective
 * optimization problems on arbitrary functions.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more Information.
 */

#ifndef ENSMALLEN_MOEAD_MOEAD_IMPL_HPP
#define ENSMALLEN_MOEAD_MOEAD_IMPL_HPP

#include "moead.hpp"
#include <assert.h>

namespace ens {
template <typename InitPolicyType, typename DecompPolicyType>
inline MOEAD<InitPolicyType, DecompPolicyType>::
MOEAD(const size_t populationSize,
      const size_t maxGenerations,
      const double crossoverProb,
      const double neighborProb,
      const size_t neighborSize,
      const double distributionIndex,
      const double differentialWeight,
      const size_t maxReplace,
      const double epsilon,
      const arma::vec& lowerBound,
      const arma::vec& upperBound,
      const InitPolicyType initPolicy,
      const DecompPolicyType decompPolicy) :
    populationSize(populationSize),
    maxGenerations(maxGenerations),
    crossoverProb(crossoverProb),
    neighborProb(neighborProb),
    neighborSize(neighborSize),
    distributionIndex(distributionIndex),
    differentialWeight(differentialWeight),
    maxReplace(maxReplace),
    epsilon(epsilon),
    lowerBound(lowerBound),
    upperBound(upperBound),
    initPolicy(initPolicy),
    decompPolicy(decompPolicy)
  { /* Nothing to do here. */ }

template <typename InitPolicyType, typename DecompPolicyType>
inline MOEAD<InitPolicyType, DecompPolicyType>::
MOEAD(const size_t populationSize,
      const size_t maxGenerations,
      const double crossoverProb,
      const double neighborProb,
      const size_t neighborSize,
      const double distributionIndex,
      const double differentialWeight,
      const size_t maxReplace,
      const double epsilon,
      const double lowerBound,
      const double upperBound,
      const InitPolicyType initPolicy,
      const DecompPolicyType decompPolicy) :
    populationSize(populationSize),
    maxGenerations(maxGenerations),
    crossoverProb(crossoverProb),
    neighborProb(neighborProb),
    neighborSize(neighborSize),
    distributionIndex(distributionIndex),
    differentialWeight(differentialWeight),
    maxReplace(maxReplace),
    epsilon(epsilon),
    lowerBound(lowerBound * arma::ones(1, 1)),
    upperBound(upperBound * arma::ones(1, 1)),
    initPolicy(initPolicy),
    decompPolicy(decompPolicy)
  { /* Nothing to do here. */ }

//! Optimize the function.
template <typename InitPolicyType, typename DecompPolicyType>
template<typename MatType,
         typename... ArbitraryFunctionType,
         typename... CallbackTypes>
typename MatType::elem_type MOEAD<InitPolicyType, DecompPolicyType>::
Optimize(std::tuple<ArbitraryFunctionType...>& objectives,
         MatType& iterateIn,
         CallbackTypes&&... callbacks)
{
  // Population Size must be at least 3 for MOEA/D-DE to work.
  if (populationSize < 3)
  {
    throw std::logic_error("MOEA/D-DE::Optimize(): population size should be at least"
        " 3!");
  }

  // Convenience typedefs.
  typedef typename MatType::elem_type ElemType;
  typedef typename MatTypeTraits<MatType>::BaseMatType BaseMatType;

  BaseMatType& iterate = (BaseMatType&) iterateIn;

  // Make sure that we have the methods that we need.  Long name...
  traits::CheckArbitraryFunctionTypeAPI<ArbitraryFunctionType...,
      BaseMatType>();
  RequireDenseFloatingPointType<BaseMatType>();

  if (neighborSize < 2)
  {
    throw std::invalid_argument(
        "neighborSize should be atleast 2, however "
        + std::to_string(neighborSize) + " was detected."
    );
  }

  if (neighborSize > populationSize - 1u)
  {
    std::ostringstream oss;
    oss << "MOEAD::Optimize(): " << "neighborSize is " << neighborSize
        << " but populationSize is " << populationSize << "(should be"
        << " atleast " << (neighborSize + 1u) << ")" << std::endl;
    throw std::logic_error(oss.str());
  }

  // Check if lower bound is a vector of a single dimension.
  if (lowerBound.n_rows == 1)
    lowerBound = lowerBound(0, 0) * arma::ones(iterate.n_rows, iterate.n_cols);

  // Check if upper bound is a vector of a single dimension.
  if (upperBound.n_rows == 1)
    upperBound = upperBound(0, 0) * arma::ones(iterate.n_rows, iterate.n_cols);

  // Check the dimensions of lowerBound and upperBound.
  assert(lowerBound.n_rows == iterate.n_rows && "The dimensions of "
      "lowerBound are not the same as the dimensions of iterate.");
  assert(upperBound.n_rows == iterate.n_rows && "The dimensions of "
      "upperBound are not the same as the dimensions of iterate.");

  const size_t numObjectives = sizeof...(ArbitraryFunctionType);
  const size_t numVariables = iterate.n_rows;

  //! Useful temporaries for float-like comparisons.
  const BaseMatType castedLowerBound = arma::conv_to<BaseMatType>::from(lowerBound);
  const BaseMatType castedUpperBound = arma::conv_to<BaseMatType>::from(upperBound);

  // Controls early termination of the optimization process.
  bool terminate = false;

  // The weight matrix. Each vector represents a decomposition subproblem (M X N).
  const BaseMatType weights = initPolicy.template Generate<BaseMatType>(
      numObjectives, populationSize, epsilon);

  // 1.1 Storing the indices of nearest neighbors of each weight vector.
  arma::umat neighborIndices(neighborSize, populationSize);
  for (size_t i = 0; i < populationSize; ++i)
  {
    // Cache the distance between weights[i] and other weights.
    const arma::Row<ElemType> distances =
        arma::sqrt(arma::sum(arma::square(weights.col(i) - weights.each_col())));
    arma::uvec sortedIndices = arma::stable_sort_index(distances);
    // Ignore distance from self.
    neighborIndices.col(i) = sortedIndices(arma::span(1, neighborSize));
  }

  // 1.2 Random generation of the initial population.
  std::vector<BaseMatType> population(populationSize);
  for (BaseMatType& individual : population)
  {
    individual = arma::randu<BaseMatType>(
        iterate.n_rows, iterate.n_cols) - 0.5 + iterate;

    // Constrain all genes to be within bounds.
    individual = arma::min(arma::max(individual, castedLowerBound), castedUpperBound);
  }

  Info << "MOEA/D-DE initialized successfully. Optimization started." << std::endl;

  std::vector<arma::Col<ElemType>> populationFitness(populationSize);
  std::fill(populationFitness.begin(), populationFitness.end(),
      arma::Col<ElemType>(numObjectives, arma::fill::zeros));
  EvaluateObjectives(population, objectives, populationFitness);

  // 1.3 Initialize the ideal point z.
  arma::Col<ElemType> idealPoint(numObjectives);
  idealPoint.fill(std::numeric_limits<ElemType>::max());

  for (const arma::Col<ElemType>& individualFitness : populationFitness)
    idealPoint = arma::min(idealPoint, individualFitness);

  Callback::BeginOptimization(*this, objectives, iterate, callbacks...);

  // 2 The main loop.
  for (size_t generation = 1; generation <= maxGenerations && !terminate; ++generation)
  {
    // Shuffle indexes of subproblems.
    const arma::uvec shuffle = arma::shuffle(
        arma::linspace<arma::uvec>(0, populationSize - 1, populationSize));
    for (size_t subProblemIdx : shuffle)
    {
      // 2.1 Randomly select two indices in neighborIndices[subProblemIdx] and use them
      // to make a child.
      size_t r1, r2, r3;
      r1 = subProblemIdx;
      // Randomly choose to sample from the population or the neighbors.
      const bool sampleNeighbor = arma::randu() < neighborProb;
      std::tie(r2, r3) =
          Mating(subProblemIdx, neighborIndices, sampleNeighbor);

      // 2.2 - 2.3 Reproduction and Repair: Differential Operator followed by
      // Polynomial Mutation.
      BaseMatType candidate(iterate.n_rows, iterate.n_cols);

      for (size_t geneIdx = 0; geneIdx < numVariables; ++geneIdx)
      {
        if (arma::randu() < crossoverProb)
        {
          candidate(geneIdx) = population[r1](geneIdx) +
              differentialWeight * (population[r2](geneIdx) -
                  population[r3](geneIdx));

          // Boundary conditions.
          if (candidate(geneIdx) < castedLowerBound(geneIdx))
          {
            candidate(geneIdx) = castedLowerBound(geneIdx) +
                arma::randu() * (population[r1](geneIdx) - castedLowerBound(geneIdx));
          }
          if (candidate(geneIdx) > castedUpperBound(geneIdx))
          {
            candidate(geneIdx) = castedUpperBound(geneIdx) -
                arma::randu() * (castedUpperBound(geneIdx) - population[r1](geneIdx));
          }
        }
        else
          candidate(geneIdx) = population[r1](geneIdx);
      }

      Mutate(candidate, 1.0 / static_cast<double>(numVariables),
          castedLowerBound, castedUpperBound);

      arma::Col<ElemType> candidateFitness(numObjectives);
      //! Creating temp vectors to pass to EvaluateObjectives.
      std::vector<BaseMatType> candidateContainer { candidate };
      std::vector<arma::Col<ElemType>> fitnessContainer { candidateFitness };
      EvaluateObjectives(candidateContainer, objectives, fitnessContainer);
      candidateFitness = std::move(fitnessContainer[0]);
      //! Flush out the dummy containers.
      fitnessContainer.clear();
      candidateContainer.clear();

      // 2.4 Update of ideal point.
      idealPoint = arma::min(idealPoint, candidateFitness);

      // 2.5 Update of the population.
      size_t replaceCounter = 0;
      const size_t sampleSize = sampleNeighbor ? neighborSize : populationSize;

      const arma::uvec idxShuffle = arma::shuffle(
          arma::linspace<arma::uvec>(0, sampleSize - 1, sampleSize));

      for (size_t idx : idxShuffle)
      {
        // Preserve diversity by controlling replacement of neighbors
        // by child solution.
        if (replaceCounter >= maxReplace)
          break;

        const size_t pick = sampleNeighbor ?
            neighborIndices(idx, subProblemIdx) : idx;

        const ElemType candidateDecomposition = decompPolicy.template
            Apply<arma::Col<ElemType>>(weights.col(pick), idealPoint, candidateFitness);
        const ElemType parentDecomposition =  decompPolicy.template
            Apply<arma::Col<ElemType>>(weights.col(pick), idealPoint, populationFitness[pick]);

        if (candidateDecomposition < parentDecomposition)
        {
          population[pick] = candidate;
          populationFitness[pick] = candidateFitness;
          ++replaceCounter;
        }
      }
    } // End of pass over all subproblems.

    //  The final population itself is the best front.
    const std::vector<arma::uvec> frontIndices { arma::shuffle(
        arma::linspace<arma::uvec>(0, populationSize - 1, populationSize)) };

    terminate |= Callback::GenerationalStepTaken(*this, objectives, iterate,
        populationFitness, frontIndices, callbacks...);
  } // End of pass over all the generations.

  // Set the candidates from the Pareto Set as the output.
  paretoSet.set_size(population[0].n_rows, population[0].n_cols, population.size());

  // The Pareto Front is stored, can be obtained via ParetoSet() getter.
  for (size_t solutionIdx = 0; solutionIdx < population.size(); ++solutionIdx)
  {
    paretoSet.slice(solutionIdx) =
        arma::conv_to<arma::mat>::from(population[solutionIdx]);
  }

  // Set the candidates from the Pareto Front as the output.
  paretoFront.set_size(populationFitness[0].n_rows, populationFitness[0].n_cols,
      populationFitness.size());

  // The Pareto Front is stored, can be obtained via ParetoFront() getter.
  for (size_t solutionIdx = 0; solutionIdx < populationFitness.size(); ++solutionIdx)
  {
    paretoFront.slice(solutionIdx) =
        arma::conv_to<arma::mat>::from(populationFitness[solutionIdx]);
  }

  // Assign iterate to first element of the Pareto Set.
  iterate = population[0];

  Callback::EndOptimization(*this, objectives, iterate, callbacks...);

  ElemType performance = std::numeric_limits<ElemType>::max();

  for (size_t geneIdx = 0; geneIdx < numObjectives; ++geneIdx)
  {
    if (arma::accu(populationFitness[geneIdx]) < performance)
      performance = arma::accu(populationFitness[geneIdx]);
  }

  return performance;
}

//! Randomly chooses to select from parents or neighbors.
template <typename InitPolicyType, typename DecompPolicyType>
inline std::tuple<size_t, size_t>
MOEAD<InitPolicyType, DecompPolicyType>::
Mating(size_t subProblemIdx,
       const arma::umat& neighborIndices,
       bool sampleNeighbor)
{
  //! Indexes of two points from the sample space.
  size_t pointA = sampleNeighbor
      ? neighborIndices(
            arma::randi(arma::distr_param(0, neighborSize - 1u)), subProblemIdx)
      : arma::randi(arma::distr_param(0, populationSize - 1u));

  size_t pointB = sampleNeighbor
      ? neighborIndices(
            arma::randi(arma::distr_param(0, neighborSize - 1u)), subProblemIdx)
      : arma::randi(arma::distr_param(0, populationSize - 1u));

  //! If the sampled points are equal, then modify one of them
  //! within reasonable bounds.
  if (pointA == pointB)
  {
    if (pointA == populationSize - 1u)
      --pointA;
    else
      ++pointA;
  }

  return std::make_tuple(pointA, pointB);
}

//! Perform Polynomial mutation of the candidate.
template <typename InitPolicyType, typename DecompPolicyType>
template<typename MatType>
inline void MOEAD<InitPolicyType, DecompPolicyType>::
Mutate(MatType& candidate,
       double mutationRate,
       const MatType& lowerBound,
       const MatType& upperBound)
{
    const size_t numVariables = candidate.n_rows;
    for (size_t geneIdx = 0; geneIdx < numVariables; ++geneIdx)
    {
      // Should this gene be mutated?
      if (arma::randu() > mutationRate)
        continue;

      const double geneRange = upperBound(geneIdx) - lowerBound(geneIdx);
      // Normalised distance from the bounds.
      const double lowerDelta = (candidate(geneIdx) - lowerBound(geneIdx)) / geneRange;
      const double upperDelta = (upperBound(geneIdx) - candidate(geneIdx)) / geneRange;
      const double mutationPower = 1. / (distributionIndex + 1.0);
      const double rand = arma::randu();
      double value, perturbationFactor;
      if (rand < 0.5)
      {
        value = 2.0 * rand + (1.0 - 2.0 * rand) *
            std::pow(upperDelta, distributionIndex + 1.0);
        perturbationFactor = std::pow(value, mutationPower) - 1.0;
      }
      else
      {
        value = 2.0 * (1.0 - rand) + 2.0 *(rand - 0.5) *
            std::pow(lowerDelta, distributionIndex + 1.0);
        perturbationFactor = 1.0 - std::pow(value, mutationPower);
      }

      candidate(geneIdx) += perturbationFactor * geneRange;
    }
    //! Enforce bounds.
    candidate = arma::min(arma::max(candidate, lowerBound), upperBound);
}

//! No objectives to evaluate.
template <typename InitPolicyType, typename DecompPolicyType>
template<std::size_t I,
         typename MatType,
         typename ...ArbitraryFunctionType>
typename std::enable_if<I == sizeof...(ArbitraryFunctionType), void>::type
MOEAD<InitPolicyType, DecompPolicyType>::
EvaluateObjectives(
    std::vector<MatType>&,
    std::tuple<ArbitraryFunctionType...>&,
    std::vector<arma::Col<typename MatType::elem_type> >&)
{
 // Nothing to do here.
}

//! Evaluate the objectives for the entire population.
template <typename InitPolicyType, typename DecompPolicyType>
template<std::size_t I,
         typename MatType,
         typename ...ArbitraryFunctionType>
typename std::enable_if<I < sizeof...(ArbitraryFunctionType), void>::type
MOEAD<InitPolicyType, DecompPolicyType>::
EvaluateObjectives(
    std::vector<MatType>& population,
    std::tuple<ArbitraryFunctionType...>& objectives,
    std::vector<arma::Col<typename MatType::elem_type> >& calculatedObjectives)
{
  for (size_t i = 0; i < population.size(); i++)
  {
    calculatedObjectives[i](I) = std::get<I>(objectives).Evaluate(population[i]);
    EvaluateObjectives<I+1, MatType, ArbitraryFunctionType...>(population, objectives,
                                                               calculatedObjectives);
  }
}

}  // namespace ens

#endif
/**
 * @file bbs_init.hpp
 * @author Nanubala Gnana Sai
 *
 * The Bayesian Bootstrap (BBS) method of Weight Initialization.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_MOEAD_BBS_HPP
#define ENSMALLEN_MOEAD_BBS_HPP

namespace ens {

/**
 * The Bayesian Bootstrap method for initializing weights. Samples are randomly picked from uniform 
 * distribution followed by sorting and finding adjacent difference. This gives you a list of 
 * numbers which is guaranteed to sum up to 1.
 *
 * @code
 * @article{rubin1981bayesian,
 *   title={The bayesian bootstrap},
 *   author={Rubin, Donald B},
 *   journal={The annals of statistics},
 *   pages={130--134},
 *   year={1981},
 * @endcode
 *
 */
class BayesianBootstrap
{
 public:
  /**
   * Constructor for Bayesian Bootstrap policy.
   */
  BayesianBootstrap()
  {
    /* Nothing to do. */
  }

  /**
   * Generate the reference direction matrix.
   *
   * @tparam MatType The type of the matrix used for constructing weights.
   * @param numObjectives The dimensionality of objective space.
   * @param numPoints The number of reference directions requested.
   * @param epsilon Handle numerical stability after weight initialization.
   */
  template<typename MatType>
  MatType Generate(const size_t numObjectives,
                   const size_t numPoints,
                   const double epsilon)
  {
      typedef typename MatType::elem_type ElemType;
      typedef typename arma::Col<ElemType> VecType;

      MatType weights(numObjectives, numPoints);
      for (size_t pointIdx = 0; pointIdx < numPoints; ++pointIdx)
      {
        VecType referenceDirection(numObjectives + 1, arma::fill::randu);
        referenceDirection(0) = 0;
        referenceDirection(numObjectives) = 1;
        referenceDirection = arma::sort(referenceDirection);
        referenceDirection = arma::diff(referenceDirection);
        weights.col(pointIdx) = std::move(referenceDirection) + epsilon;
      }

      return weights;
  }
};

} // namespace ens

#endif
/**
 * @file dirichlet_init.hpp
 * @author Nanubala Gnana Sai
 *
 * The Dirichlet method of Weight Initialization.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_MOEAD_DIRICHLET_HPP
#define ENSMALLEN_MOEAD_DIRICHLET_HPP

namespace ens {

/**
 * The Dirichlet method for initializing weights. Sampling a 
 * Dirichlet distribution with parameters set to one returns 
 * point lying on unit simplex with uniform distribution.
 */
class Dirichlet
{
 public:
  /**
   * Constructor for Dirichlet policy.
   */
  Dirichlet()
  {
    /* Nothing to do. */
  }

  /**
   * Generate the reference direction matrix.
   *
   * @tparam MatType The type of the matrix used for constructing weights.
   * @param numObjectives The dimensionality of objective space.
   * @param numPoints The number of reference directions requested.
   * @param epsilon Handle numerical stability after weight initialization.
   */
  template<typename MatType>
  MatType Generate(const size_t numObjectives,
                   const size_t numPoints,
                   const double epsilon)
  {
    MatType weights = arma::randg<MatType>(numObjectives, numPoints,
        arma::distr_param(1.0, 1.0)) + epsilon;
    // Normalize each column.
    return arma::normalise(weights, 1, 0);
  }
};

} // namespace ens

#endif
/**
 * @file uniform_init.hpp
 * @author Nanubala Gnana Sai
 *
 * The Uniform (Das Dennis) methodology of Weight Initialization.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_MOEAD_UNIFORM_HPP
#define ENSMALLEN_MOEAD_UNIFORM_HPP

namespace ens {

/**
 * The Uniform (Das Dennis) method for initializing weights. This algorithm guarantees
 * that the distance between adjacent points would be uniform.
 *
 * For more information, see the following:
 *
 * @code
 * article{zhang2007moea,
 *   title={MOEA/D: A multiobjective evolutionary algorithm based on decomposition},
 *   author={Zhang, Qingfu and Li, Hui},
 *   journal={IEEE Transactions on evolutionary computation},
 *   pages={712--731},
 *   year={2007}
 * @endcode
 */
class Uniform
{
 public:
  /**
   * Constructor for Uniform Weight Initializatoin Policy.
   */
  Uniform()
  {
    /* Nothing to do. */
  }

  /**
   * Generate the reference direction matrix.
   *
   * @tparam MatType The type of the matrix used for constructing weights.
   * @param numObjectives The dimensionality of objective space.
   * @param numPoints The number of reference directions requested.
   * @param epsilon Handle numerical stability after weight initialization.
   */
  template<typename MatType>
  MatType Generate(size_t numObjectives,
                   size_t numPoints,
                   double epsilon)
  {
    size_t numPartitions  = FindNumParitions(numObjectives, numPoints);
    size_t validNumPoints = FindNumUniformPoints(numObjectives, numPartitions);

    //! The requested number of points is not matching any partition number.
    if (numPoints != validNumPoints)
    {
      size_t nextValidNumPoints = FindNumUniformPoints(numObjectives, numPartitions + 1);
      std::ostringstream oss;
      oss << "DasDennis::Generate(): " << "The requested numPoints " << numPoints
          << " cannot be generated uniformly.\n " << "Either choose numPoints as "
          << validNumPoints << " (numPartition = " << numPartitions << ") or "
          << "numPoints as " << nextValidNumPoints << " (numPartition = "
          << numPartitions + 1 << ").";
      throw std::logic_error(oss.str());
    }

    return DasDennis<MatType>(numObjectives, numPoints,
        numPartitions, epsilon);
  }

 private:
  /**
   * Finds the number of points which can be sampled uniformly from a 
   * unit simplex given the number of partitions.
   */
  size_t FindNumUniformPoints(const size_t numObjectives,
                              const size_t numPartitions)
  {
    //! O(N) algorithm to calculate binomial coefficient.
    //! Source: https://www.geeksforgeeks.org/space-and-time-efficient-binomial-coefficient/
    auto BinomialCoefficient =
        [](size_t n, size_t k) -> size_t
        {
          size_t retval = 1;
          // Since, C(n, k) = C(n, n - k).
          if (k > n - k)
            k = n - k;

          // [n * (n - 1) * .... * (n - k + 1)] / [k * (k - 1) * .... * 1].
          for (size_t i = 0; i < k; ++i)
          {
            retval *= (n - i);
            retval /= (i + 1);
          }

          return retval;
        };
    return BinomialCoefficient(numObjectives + numPartitions - 1, numPartitions);
  }

  /**
   *  Calculates the appropriate number of partitions such that, the binomial
   *  coefficient value is closest to the number of points requested.
   */
  size_t FindNumParitions(size_t numObjectives, size_t numPoints)
  {
    if (numObjectives == 1) return 0;
    // Iteratively increase numPartitions so that the binomial coefficient
    // comes near to numPoints;
    size_t numPartitions {1};
    size_t sampledNumPoints = FindNumUniformPoints(numPartitions,
        numObjectives);
    while (sampledNumPoints <= numPoints)
    {
       ++numPartitions;
       sampledNumPoints = FindNumUniformPoints(numObjectives,
          numPartitions);
    }

    return numPartitions - 1;
  }

  /**
   * A helper function for DasDennis
   */
  template<typename AuxInfoStackType,
           typename MatType>
  void DasDennisHelper(AuxInfoStackType& progressStack,
                       MatType& weights,
                       const size_t numObjectives,
                       const size_t numPoints,
                       const size_t numPartitions,
                       const double epsilon)
  {
    typedef typename MatType::elem_type ElemType;
    typedef typename arma::Row<ElemType> RowType;

    size_t counter = 0;
    const ElemType delta = 1.0 / (ElemType)numPartitions;

    while ((counter < numPoints) && !progressStack.empty())
    {
      MatType point{};
      size_t beta{};
      std::tie(point, beta) = progressStack.back();
      progressStack.pop_back();

      if (point.size() + 1 == numObjectives)
      {
        point.insert_rows(point.n_rows, RowType(1).fill(
            delta * static_cast<ElemType>(beta)));
        weights.col(counter) = point + epsilon;
        ++counter;
      }

      else
      {
        for (size_t i = 0; i <= beta; ++i)
        {
          MatType pointClone(point);
          pointClone.insert_rows(pointClone.n_rows, RowType(1).fill(
              delta * static_cast<ElemType>(i)));
          progressStack.push_back({pointClone, beta - i});
        }
      }
    }
  }

  /**
   * Generates the weight matrix after verifying the
   * validity of the parameters.
   */
  template <typename MatType>
  MatType DasDennis(const size_t numObjectives,
                    const size_t numPoints,
                    const size_t numPartitions,
                    const double epsilon)
  {
    //! Holds auxillary information required for the helper function. 
    //! Holds the current point and beta value.
    using AuxContainer = std::pair<MatType, size_t>;

    std::vector<AuxContainer> progressStack{};
    //! Init the progress stack.
    progressStack.push_back({{}, numPartitions});
    MatType weights(numObjectives, numPoints);
    weights.fill(arma::datum::nan);
    DasDennisHelper<decltype(progressStack), MatType>(
        progressStack,
        weights,
        numObjectives,
        numPoints,
        numPartitions,
        epsilon);

    return weights;
  }

};

} // namespace ens

#endif
/**
 * @file nsga2.hpp
 * @author Sayan Goswami
 * @author Nanubala Gnana Sai
 *
 * NSGA-II is a multi-objective optimization algorithm, widely used in
 * many real-world applications. NSGA-II generates offsprings using
 * crossover and mutation and then selects the next generation according
 * to non-dominated-sorting and crowding distance comparison.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */

#ifndef ENSMALLEN_NSGA2_NSGA2_HPP
#define ENSMALLEN_NSGA2_NSGA2_HPP

namespace ens {

/**
 * NSGA-II (Non-dominated Sorting Genetic Algorithm - II) is a multi-objective
 * optimization algorithm. This class implements the NSGA-II algorithm.
 *
 * The algorithm works by generating a candidate population from a fixed
 * starting point. At each stage of optimization, a new population of children
 * is generated. This new population along with its predecessor is sorted using
 * non-domination as the metric. Following this, the population is further
 * segregated in fronts. A new population is generated from these fronts having
 * size equal to that of the starting population.
 *
 * During evolution, two parents are randomly chosen using binary tournament
 * selection. A pair of children are generated by crossing over these two
 * candidates followed by mutation.
 *
 * The best front (Pareto optimal) is returned by the Optimize() method.
 *
 * For more information, see the following:
 *
 * @code
 * @article{10.1109/4235.996017,
 *   author = {Deb, K. and Pratap, A. and Agarwal, S. and Meyarivan, T.},
 *   title = {A Fast and Elitist Multiobjective Genetic Algorithm: NSGA-II},
 *   year = {2002},
 *   url = {https://doi.org/10.1109/4235.996017},
 *   journal = {Trans. Evol. Comp}}
 * @endcode
 *
 * NSGA-II can optimize arbitrary multi-objective functions. For more details,
 * see the documentation on function types included with this distribution or
 * on the ensmallen website.
 */
class NSGA2
{
 public:
  /**
   * Constructor for the NSGA2 optimizer.
   *
   * The default values provided over here are not necessarily suitable for a
   * given function. Therefore it is highly recommended to adjust the
   * parameters according to the problem.
   *
   * @param populationSize The number of candidates in the population.
   *     This should be atleast 4 in size and a multiple of 4.
   * @param maxGenerations The maximum number of generations allowed for NSGA-II.
   * @param crossoverProb The probability that a crossover will occur.
   * @param mutationProb The probability that a mutation will occur.
   * @param mutationStrength The strength of the mutation.
   * @param epsilon The minimum difference required to distinguish between
   *     candidate solutions.
   * @param lowerBound Lower bound of the coordinates of the initial population.
   * @param upperBound Upper bound of the coordinates of the initial population.
   */
  NSGA2(const size_t populationSize = 100,
        const size_t maxGenerations = 2000,
        const double crossoverProb = 0.6,
        const double mutationProb = 0.3,
        const double mutationStrength = 1e-3,
        const double epsilon = 1e-6,
        const arma::vec& lowerBound = arma::zeros(1, 1),
        const arma::vec& upperBound = arma::ones(1, 1));

  /**
   * Constructor for the NSGA2 optimizer. This constructor provides an overload
   * to use `lowerBound` and `upperBound` of type double.
   *
   * The default values provided over here are not necessarily suitable for a
   * given function. Therefore it is highly recommended to adjust the
   * parameters according to the problem.
   *
   * @param populationSize The number of candidates in the population.
   *     This should be atleast 4 in size and a multiple of 4.
   * @param maxGenerations The maximum number of generations allowed for NSGA-II.
   * @param crossoverProb The probability that a crossover will occur.
   * @param mutationProb The probability that a mutation will occur.
   * @param mutationStrength The strength of the mutation.
   * @param epsilon The minimum difference required to distinguish between
   *     candidate solutions.
   * @param lowerBound Lower bound of the coordinates of the initial population.
   * @param upperBound Upper bound of the coordinates of the initial population.
   */
  NSGA2(const size_t populationSize = 100,
        const size_t maxGenerations = 2000,
        const double crossoverProb = 0.6,
        const double mutationProb = 0.3,
        const double mutationStrength = 1e-3,
        const double epsilon = 1e-6,
        const double lowerBound = 0,
        const double upperBound = 1);

  /**
   * Optimize a set of objectives. The initial population is generated using the
   * starting point. The output is the best generated front.
   *
   * @tparam ArbitraryFunctionType std::tuple of multiple objectives.
   * @tparam MatType Type of matrix to optimize.
   * @tparam CallbackTypes Types of callback functions.
   * @param objectives Vector of objective functions to optimize for.
   * @param iterate Starting point.
   * @param callbacks Callback functions.
   * @return MatType::elem_type The minimum of the accumulated sum over the
   *     objective values in the best front.
   */
  template<typename MatType,
           typename... ArbitraryFunctionType,
           typename... CallbackTypes>
 typename MatType::elem_type Optimize(
     std::tuple<ArbitraryFunctionType...>& objectives,
     MatType& iterate,
     CallbackTypes&&... callbacks);

  //! Get the population size.
  size_t PopulationSize() const { return populationSize; }
  //! Modify the population size.
  size_t& PopulationSize() { return populationSize; }

  //! Get the maximum number of generations.
  size_t MaxGenerations() const { return maxGenerations; }
  //! Modify the maximum number of generations.
  size_t& MaxGenerations() { return maxGenerations; }

  //! Get the crossover rate.
  double CrossoverRate() const { return crossoverProb; }
  //! Modify the crossover rate.
  double& CrossoverRate() { return crossoverProb; }

  //! Get the mutation probability.
  double MutationProbability() const { return mutationProb; }
  //! Modify the mutation probability.
  double& MutationProbability() { return mutationProb; }

  //! Get the mutation strength.
  double MutationStrength() const { return mutationStrength; }
  //! Modify the mutation strength.
  double& MutationStrength() { return mutationStrength; }

  //! Get the tolerance.
  double Epsilon() const { return epsilon; }
  //! Modify the tolerance.
  double& Epsilon() { return epsilon; }

  //! Retrieve value of lowerBound.
  const arma::vec& LowerBound() const { return lowerBound; }
  //! Modify value of lowerBound.
  arma::vec& LowerBound() { return lowerBound; }

  //! Retrieve value of upperBound.
  const arma::vec& UpperBound() const { return upperBound; }
  //! Modify value of upperBound.
  arma::vec& UpperBound() { return upperBound; }

  //! Retrieve the Pareto optimal points in variable space. This returns an empty cube
  //! until `Optimize()` has been called.
  const arma::cube& ParetoSet() const { return paretoSet; }

  //! Retrieve the best front (the Pareto frontier). This returns an empty cube until
  //! `Optimize()` has been called.
  const arma::cube& ParetoFront() const { return paretoFront; }

  /**
   * Retrieve the best front (the Pareto frontier).  This returns an empty
   * vector until `Optimize()` has been called.  Note that this function is
   * deprecated and will be removed in ensmallen 3.x!  Use `ParetoFront()`
   * instead.
   */
  ens_deprecated const std::vector<arma::mat>& Front()
  {
    if (rcFront.size() == 0)
    {
      // Match the old return format.
      for (size_t i = 0; i < paretoFront.n_slices; ++i)
      {
        rcFront.push_back(arma::mat(paretoFront.slice(i)));
      }
    }

    return rcFront;
  }

 private:
  /**
   * Evaluate objectives for the elite population.
   *
   * @tparam ArbitraryFunctionType std::tuple of multiple function types.
   * @tparam MatType Type of matrix to optimize.
   * @param population The elite population.
   * @param objectives The set of objectives.
   * @param calculatedObjectives Vector to store calculated objectives.
   */
  template<std::size_t I = 0,
           typename MatType,
           typename ...ArbitraryFunctionType>
  typename std::enable_if<I == sizeof...(ArbitraryFunctionType), void>::type
  EvaluateObjectives(std::vector<MatType>&,
                     std::tuple<ArbitraryFunctionType...>&,
                     std::vector<arma::Col<typename MatType::elem_type> >&);

  template<std::size_t I = 0,
           typename MatType,
           typename ...ArbitraryFunctionType>
  typename std::enable_if<I < sizeof...(ArbitraryFunctionType), void>::type
  EvaluateObjectives(std::vector<MatType>& population,
                     std::tuple<ArbitraryFunctionType...>& objectives,
                     std::vector<arma::Col<typename MatType::elem_type> >&
                     calculatedObjectives);

  /**
   * Reproduce candidates from the elite population to generate a new
   * population.
   *
   * @tparam MatType Type of matrix to optimize.
   * @param population The elite population.
   * @param objectives The set of objectives.
   * @param lowerBound Lower bound of the coordinates of the initial population.
   * @param upperBound Upper bound of the coordinates of the initial population.
   */
  template<typename MatType>
  void BinaryTournamentSelection(std::vector<MatType>& population,
                                 const MatType& lowerBound,
                                 const MatType& upperBound);

  /**
   * Crossover two parents to create a pair of new children.
   *
   * @tparam MatType Type of matrix to optimize.
   * @param childA A newly generated candidate.
   * @param childB Another newly generated candidate.
   * @param parentA First parent from elite population.
   * @param parentB Second parent from elite population.
   */
  template<typename MatType>
  void Crossover(MatType& childA,
                 MatType& childB,
                 const MatType& parentA,
                 const MatType& parentB);

  /**
   * Mutate the coordinates for a candidate.
   *
   * @tparam MatType Type of matrix to optimize.
   * @param child The candidate whose coordinates are being modified.
   * @param objectives The set of objectives.
   * @param lowerBound Lower bound of the coordinates of the initial population.
   * @param upperBound Upper bound of the coordinates of the initial population.
   */
  template<typename MatType>
  void Mutate(MatType& child,
              const MatType& lowerBound,
              const MatType& upperBound);

  /**
   * Sort the candidate population using their domination count and the set of
   * dominated nodes.
   *
   * @tparam MatType Type of matrix to optimize.
   * @param fronts The population is sorted into these Pareto fronts. The first
   *     front is the best, the second worse and so on.
   * @param ranks The assigned ranks, used for crowding distance based sorting.
   * @param calculatedObjectives The previously calculated objectives.
   */
  template<typename MatType>
  void FastNonDominatedSort(
      std::vector<std::vector<size_t> >& fronts,
      std::vector<size_t>& ranks,
      std::vector<arma::Col<typename MatType::elem_type> >& calculatedObjectives);

  /**
   * Operator to check if one candidate Pareto-dominates the other.
   *
   * A candidate is said to dominate the other if it is at least as good as the
   * other candidate for all the objectives and there exists at least one
   * objective for which it is strictly better than the other candidate.
   *
   * @tparam MatType Type of matrix to optimize.
   * @param calculatedObjectives The previously calculated objectives.
   * @param candidateP The candidate being compared from the elite population.
   * @param candidateQ The candidate being compared against.
   * @return true if candidateP Pareto dominates candidateQ, otherwise, false.
   */
  template<typename MatType>
  bool Dominates(
      std::vector<arma::Col<typename MatType::elem_type> >& calculatedObjectives,
      size_t candidateP,
      size_t candidateQ);

  /**
   * Assigns crowding distance metric for sorting.
   *
   * @param front The previously generated Pareto fronts.
   * @param calculatedObjectives The previously calculated objectives.
   * @param crowdingDistance The crowding distance for each individual in
   *    the population.
   */
  template <typename MatType>
  void CrowdingDistanceAssignment(
      const std::vector<size_t>& front,
      std::vector<arma::Col<typename MatType::elem_type>>& calculatedObjectives,
      std::vector<typename MatType::elem_type>& crowdingDistance);

  /**
   * The operator used in the crowding distance based sorting.
   *
   * If a candidates has a lower rank then it is preferred.
   * Otherwise, if the ranks are equal then the candidate with the larger
   * crowding distance is preferred.
   *
   * @param idxP The index of the first cadidate from the elite population being
   *     sorted.
   * @param idxQ The index of the second cadidate from the elite population
   *     being sorted.
   * @param ranks The previously calculated ranks.
   * @param crowdingDistance The crowding distance for each individual in
   *    the population.
   * @return true if the first candidate is preferred, otherwise, false.
   */
  template<typename MatType>
  bool CrowdingOperator(size_t idxP,
                        size_t idxQ,
                        const std::vector<size_t>& ranks,
                        const std::vector<typename MatType::elem_type>& crowdingDistance);

  //! The number of objectives being optimised for.
  size_t numObjectives;

  //! The numbeer of variables used per objectives.
  size_t numVariables;

  //! The number of candidates in the population.
  size_t populationSize;

  //! Maximum number of generations before termination criteria is met.
  size_t maxGenerations;

  //! Probability that crossover will occur.
  double crossoverProb;

  //! Probability that mutation will occur.
  double mutationProb;

  //! Strength of the mutation.
  double mutationStrength;

  //! The tolerance for termination.
  double epsilon;

  //! Lower bound of the initial swarm.
  arma::vec lowerBound;

  //! Upper bound of the initial swarm.
  arma::vec upperBound;

  //! The set of all the Pareto optimal points.
  //! Stored after Optimize() is called.
  arma::cube paretoSet;

  //! The set of all the Pareto optimal objective vectors.
  //! Stored after Optimize() is called.
  arma::cube paretoFront;

  //! A different representation of the Pareto front, for reverse compatibility
  //! purposes.  This can be removed when ensmallen 3.x is released!  (Along
  //! with `Front()`.)  This is only populated when `Front()` is called.
  std::vector<arma::mat> rcFront;
};

} // namespace ens

// Include implementation.
#include "nsga2_impl.hpp"

#endif
/**
 * @file nsga2_impl.hpp
 * @author Sayan Goswami
 * @author Nanubala Gnana Sai
 *
 * Implementation of the NSGA-II algorithm. Used for multi-objective
 * optimization problems on arbitrary functions.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more Information.
 */

#ifndef ENSMALLEN_NSGA2_NSGA2_IMPL_HPP
#define ENSMALLEN_NSGA2_NSGA2_IMPL_HPP

#include "nsga2.hpp"
#include <assert.h>

namespace ens {

inline NSGA2::NSGA2(const size_t populationSize,
                    const size_t maxGenerations,
                    const double crossoverProb,
                    const double mutationProb,
                    const double mutationStrength,
                    const double epsilon,
                    const arma::vec& lowerBound,
                    const arma::vec& upperBound) :
    numObjectives(0),
    numVariables(0),
    populationSize(populationSize),
    maxGenerations(maxGenerations),
    crossoverProb(crossoverProb),
    mutationProb(mutationProb),
    mutationStrength(mutationStrength),
    epsilon(epsilon),
    lowerBound(lowerBound),
    upperBound(upperBound)
{ /* Nothing to do here. */ }

inline NSGA2::NSGA2(const size_t populationSize,
                    const size_t maxGenerations,
                    const double crossoverProb,
                    const double mutationProb,
                    const double mutationStrength,
                    const double epsilon,
                    const double lowerBound,
                    const double upperBound) :
    numObjectives(0),
    numVariables(0),
    populationSize(populationSize),
    maxGenerations(maxGenerations),
    crossoverProb(crossoverProb),
    mutationProb(mutationProb),
    mutationStrength(mutationStrength),
    epsilon(epsilon),
    lowerBound(lowerBound * arma::ones(1, 1)),
    upperBound(upperBound * arma::ones(1, 1))
{ /* Nothing to do here. */ }

//! Optimize the function.
template<typename MatType,
         typename... ArbitraryFunctionType,
         typename... CallbackTypes>
typename MatType::elem_type NSGA2::Optimize(
    std::tuple<ArbitraryFunctionType...>& objectives,
    MatType& iterateIn,
    CallbackTypes&&... callbacks)
{
  // Make sure for evolution to work at least four candidates are present.
  if (populationSize < 4 && populationSize % 4 != 0)
  {
    throw std::logic_error("NSGA2::Optimize(): population size should be at"
        " least 4, and, a multiple of 4!");
  }

  // Convenience typedefs.
  typedef typename MatType::elem_type ElemType;
  typedef typename MatTypeTraits<MatType>::BaseMatType BaseMatType;

  BaseMatType& iterate = (BaseMatType&) iterateIn;

  // Make sure that we have the methods that we need.  Long name...
  traits::CheckArbitraryFunctionTypeAPI<ArbitraryFunctionType...,
      BaseMatType>();
  RequireDenseFloatingPointType<BaseMatType>();

  // Check if lower bound is a vector of a single dimension.
  if (lowerBound.n_rows == 1)
    lowerBound = lowerBound(0, 0) * arma::ones(iterate.n_rows, iterate.n_cols);

  // Check if upper bound is a vector of a single dimension.
  if (upperBound.n_rows == 1)
    upperBound = upperBound(0, 0) * arma::ones(iterate.n_rows, iterate.n_cols);

  // Check the dimensions of lowerBound and upperBound.
  assert(lowerBound.n_rows == iterate.n_rows && "The dimensions of "
      "lowerBound are not the same as the dimensions of iterate.");
  assert(upperBound.n_rows == iterate.n_rows && "The dimensions of "
      "upperBound are not the same as the dimensions of iterate.");

  numObjectives = sizeof...(ArbitraryFunctionType);
  numVariables = iterate.n_rows;

  // Cache calculated objectives.
  std::vector<arma::Col<ElemType> > calculatedObjectives(populationSize);

  // Population size reserved to 2 * populationSize + 1 to accommodate
  // for the size of intermediate candidate population.
  std::vector<BaseMatType> population;
  population.reserve(2 * populationSize + 1);

  // Pareto fronts, initialized during non-dominated sorting.
  // Stores indices of population belonging to a certain front.
  std::vector<std::vector<size_t> > fronts;
  // Initialised in CrowdingDistanceAssignment.
  std::vector<ElemType> crowdingDistance;
  // Initialised during non-dominated sorting.
  std::vector<size_t> ranks;

  //! Useful temporaries for float-like comparisons.
  const BaseMatType castedLowerBound = arma::conv_to<BaseMatType>::from(lowerBound);
  const BaseMatType castedUpperBound = arma::conv_to<BaseMatType>::from(upperBound);

  // Controls early termination of the optimization process.
  bool terminate = false;

  // Generate the population based on a uniform distribution around the given
  // starting point.
  for (size_t i = 0; i < populationSize; i++)
  {
    population.push_back(arma::randu<BaseMatType>(iterate.n_rows,
        iterate.n_cols) - 0.5 + iterate);

    // Constrain all genes to be within bounds.
    population[i] = arma::min(arma::max(population[i], castedLowerBound), castedUpperBound);
  }

  Info << "NSGA2 initialized successfully. Optimization started." << std::endl;

  // Iterate until maximum number of generations is obtained.
  Callback::BeginOptimization(*this, objectives, iterate, callbacks...);

  for (size_t generation = 1; generation <= maxGenerations && !terminate; generation++)
  {
    Info << "NSGA2: iteration " << generation << "." << std::endl;

    // Create new population of candidate from the present elite population.
    // Have P_t, generate G_t using P_t.
    BinaryTournamentSelection(population, castedLowerBound, castedUpperBound);

    // Evaluate the objectives for the new population.
    calculatedObjectives.resize(population.size());
    std::fill(calculatedObjectives.begin(), calculatedObjectives.end(),
        arma::Col<ElemType>(numObjectives, arma::fill::zeros));
    EvaluateObjectives(population, objectives, calculatedObjectives);

    // Perform fast non dominated sort on P_t ‚à™ G_t.
    ranks.resize(population.size());
    FastNonDominatedSort<BaseMatType>(fronts, ranks, calculatedObjectives);

    // Perform crowding distance assignment.
    crowdingDistance.resize(population.size());
    std::fill(crowdingDistance.begin(), crowdingDistance.end(), 0.);
    for (size_t fNum = 0; fNum < fronts.size(); fNum++)
    {
      CrowdingDistanceAssignment<BaseMatType>(
          fronts[fNum], calculatedObjectives, crowdingDistance);
    }

    // Sort based on crowding distance.
    std::sort(population.begin(), population.end(),
      [this, ranks, crowdingDistance, population]
        (BaseMatType candidateP, BaseMatType candidateQ)
          {
            size_t idxP{}, idxQ{};
            for (size_t i = 0; i < population.size(); i++)
            {
              if (arma::approx_equal(population[i], candidateP, "absdiff", epsilon))
                idxP = i;

              if (arma::approx_equal(population[i], candidateQ, "absdiff", epsilon))
                idxQ = i;
            }

            return CrowdingOperator<BaseMatType>(idxP, idxQ, ranks, crowdingDistance);
          }
    );

    // Yield a new population P_{t+1} of size populationSize.
    // Discards unfit population from the R_{t} to yield P_{t+1}.
    population.resize(populationSize);

    terminate |= Callback::GenerationalStepTaken(*this, objectives, iterate,
        calculatedObjectives, fronts, callbacks...);
  }

  // Set the candidates from the Pareto Set as the output.
  paretoSet.set_size(population[0].n_rows, population[0].n_cols, fronts[0].size());
  // The Pareto Set is stored, can be obtained via ParetoSet() getter.
  for (size_t solutionIdx = 0; solutionIdx < fronts[0].size(); ++solutionIdx)
  {
    paretoSet.slice(solutionIdx) =
      arma::conv_to<arma::mat>::from(population[fronts[0][solutionIdx]]);
  }

  // Set the candidates from the Pareto Front as the output.
  paretoFront.set_size(calculatedObjectives[0].n_rows, calculatedObjectives[0].n_cols,
      fronts[0].size());
  // The Pareto Front is stored, can be obtained via ParetoFront() getter.
  for (size_t solutionIdx = 0; solutionIdx < fronts[0].size(); ++solutionIdx)
  {
    paretoFront.slice(solutionIdx) =
      arma::conv_to<arma::mat>::from(calculatedObjectives[fronts[0][solutionIdx]]);
  }

  // Clear rcFront, in case it is later requested by the user for reverse
  // compatibility reasons.
  rcFront.clear();

  // Assign iterate to first element of the Pareto Set.
  iterate = population[fronts[0][0]];

  Callback::EndOptimization(*this, objectives, iterate, callbacks...);

  ElemType performance = std::numeric_limits<ElemType>::max();

  for (const arma::Col<ElemType>& objective: calculatedObjectives)
    if (arma::accu(objective) < performance)
      performance = arma::accu(objective);

  return performance;
}

//! No objectives to evaluate.
template<std::size_t I,
         typename MatType,
         typename ...ArbitraryFunctionType>
typename std::enable_if<I == sizeof...(ArbitraryFunctionType), void>::type
NSGA2::EvaluateObjectives(
    std::vector<MatType>&,
    std::tuple<ArbitraryFunctionType...>&,
    std::vector<arma::Col<typename MatType::elem_type> >&)
{
  // Nothing to do here.
}

//! Evaluate the objectives for the entire population.
template<std::size_t I,
         typename MatType,
         typename ...ArbitraryFunctionType>
typename std::enable_if<I < sizeof...(ArbitraryFunctionType), void>::type
NSGA2::EvaluateObjectives(
    std::vector<MatType>& population,
    std::tuple<ArbitraryFunctionType...>& objectives,
    std::vector<arma::Col<typename MatType::elem_type> >& calculatedObjectives)
{
  for (size_t i = 0; i < populationSize; i++)
  {
    calculatedObjectives[i](I) = std::get<I>(objectives).Evaluate(population[i]);
    EvaluateObjectives<I+1, MatType, ArbitraryFunctionType...>(population, objectives,
                                                               calculatedObjectives);
  }
}

//! Reproduce and generate new candidates.
template<typename MatType>
inline void NSGA2::BinaryTournamentSelection(std::vector<MatType>& population,
                                             const MatType& lowerBound,
                                             const MatType& upperBound)
{
  std::vector<MatType> children;

  while (children.size() < population.size())
  {
    // Choose two random parents for reproduction from the elite population.
    size_t indexA = arma::randi<size_t>(arma::distr_param(0, populationSize - 1));
    size_t indexB = arma::randi<size_t>(arma::distr_param(0, populationSize - 1));

    // Make sure that the parents differ.
    if (indexA == indexB)
    {
      if (indexB < populationSize - 1)
        indexB++;
      else
        indexB--;
    }

    // Initialize the children to the respective parents.
    MatType childA = population[indexA], childB = population[indexB];

    Crossover(childA, childB, population[indexA], population[indexB]);

    Mutate(childA, lowerBound, upperBound);
    Mutate(childB, lowerBound, upperBound);

    // Add the children to the candidate population.
    children.push_back(childA);
    children.push_back(childB);
  }

  // Add the candidates to the elite population.
  population.insert(std::end(population), std::begin(children), std::end(children));
}

//! Perform crossover of genes for the children.
template<typename MatType>
inline void NSGA2::Crossover(MatType& childA,
                             MatType& childB,
                             const MatType& parentA,
                             const MatType& parentB)
{
  // Indices at which crossover is to occur.
  const arma::umat idx = arma::randu<MatType>(childA.n_rows, childA.n_cols) < crossoverProb;

  // Use traits from parentA for indices where idx is 1 and parentB otherwise.
  childA = parentA % idx + parentB % (1 - idx);
  // Use traits from parentB for indices where idx is 1 and parentA otherwise.
  childB = parentA % (1 - idx) + parentA % idx;
}

//! Perform mutation of the candidates weights with some noise.
template<typename MatType>
inline void NSGA2::Mutate(MatType& child,
                          const MatType& lowerBound,
                          const MatType& upperBound)
{
  child += (arma::randu<MatType>(child.n_rows, child.n_cols) < mutationProb) %
      (mutationStrength * arma::randn<MatType>(child.n_rows, child.n_cols));

  // Constrain all genes to be between bounds.
  child = arma::min(arma::max(child, lowerBound), upperBound);
}

//! Sort population into Pareto fronts.
template<typename MatType>
inline void NSGA2::FastNonDominatedSort(
    std::vector<std::vector<size_t> >& fronts,
    std::vector<size_t>& ranks,
    std::vector<arma::Col<typename MatType::elem_type> >& calculatedObjectives)
{
  std::map<size_t, size_t> dominationCount;
  std::map<size_t, std::set<size_t> > dominated;

  // Reset and initialize fronts.
  fronts.clear();
  fronts.push_back(std::vector<size_t>());

  for (size_t p = 0; p < populationSize; p++)
  {
    dominated[p] = std::set<size_t>();
    dominationCount[p] = 0;

    for (size_t q = 0; q < populationSize; q++)
    {
      if (Dominates<MatType>(calculatedObjectives, p, q))
        dominated[p].insert(q);
      else if (Dominates<MatType>(calculatedObjectives, q, p))
        dominationCount[p] += 1;
    }

    if (dominationCount[p] == 0)
    {
      ranks[p] = 0;
      fronts[0].push_back(p);
    }
  }

  size_t i = 0;

  while (!fronts[i].empty())
  {
    std::vector<size_t> nextFront;

    for (size_t p: fronts[i])
    {
      for (size_t q: dominated[p])
      {
        dominationCount[q]--;

        if (dominationCount[q] == 0)
        {
          ranks[q] = i + 1;
          nextFront.push_back(q);
        }
      }
    }

    i++;
    fronts.push_back(nextFront);
  }
  // Remove the empty final set.
  fronts.pop_back();
}

//! Check if a candidate Pareto dominates another candidate.
template<typename MatType>
inline bool NSGA2::Dominates(
    std::vector<arma::Col<typename MatType::elem_type> >& calculatedObjectives,
    size_t candidateP,
    size_t candidateQ)
{
  bool allBetterOrEqual = true;
  bool atleastOneBetter = false;
  size_t n_objectives = calculatedObjectives[0].n_elem;

  for (size_t i = 0; i < n_objectives; i++)
  {
    // P is worse than Q for the i-th objective function.
    if (calculatedObjectives[candidateP](i) > calculatedObjectives[candidateQ](i))
      allBetterOrEqual = false;

    // P is better than Q for the i-th objective function.
    else if (calculatedObjectives[candidateP](i) < calculatedObjectives[candidateQ](i))
      atleastOneBetter = true;
  }

  return allBetterOrEqual && atleastOneBetter;
}

//! Assign crowding distance to the population.
template <typename MatType>
inline void NSGA2::CrowdingDistanceAssignment(
    const std::vector<size_t>& front,
    std::vector<arma::Col<typename MatType::elem_type>>& calculatedObjectives,
    std::vector<typename MatType::elem_type>& crowdingDistance)
{
  // Convenience typedefs.
  typedef typename MatType::elem_type ElemType;

  size_t fSize = front.size();
  // Stores the sorted indices of the fronts.
  arma::uvec sortedIdx  = arma::regspace<arma::uvec>(0, 1, fSize - 1);

  for (size_t m = 0; m < numObjectives; m++)
  {
    // Cache fValues of individuals for current objective.
    arma::Col<ElemType> fValues(fSize);
    std::transform(front.begin(), front.end(), fValues.begin(),
      [&](const size_t& individual)
        {
          return calculatedObjectives[individual](m);
        });

    // Sort front indices by ascending fValues for current objective.
    std::sort(sortedIdx.begin(), sortedIdx.end(),
      [&](const size_t& frontIdxA, const size_t& frontIdxB)
        {
          return (fValues(frontIdxA) < fValues(frontIdxB));
        });

    crowdingDistance[front[sortedIdx(0)]] =
        std::numeric_limits<ElemType>::max();
    crowdingDistance[front[sortedIdx(fSize - 1)]] =
        std::numeric_limits<ElemType>::max();
    ElemType minFval = fValues(sortedIdx(0));
    ElemType maxFval = fValues(sortedIdx(fSize - 1));
    ElemType scale =
        std::abs(maxFval - minFval) == 0. ? 1. : std::abs(maxFval - minFval);

    for (size_t i = 1; i < fSize - 1; i++)
    {
      crowdingDistance[front[sortedIdx(i)]] +=
          (fValues(sortedIdx(i + 1)) - fValues(sortedIdx(i - 1))) / scale;
    }
  }
}

//! Comparator for crowding distance based sorting.
template<typename MatType>
inline bool NSGA2::CrowdingOperator(size_t idxP,
                                    size_t idxQ,
                                    const std::vector<size_t>& ranks,
                                    const std::vector<typename MatType::elem_type>& crowdingDistance)
{
  if (ranks[idxP] < ranks[idxQ])
    return true;
  else if (ranks[idxP] == ranks[idxQ] && crowdingDistance[idxP] > crowdingDistance[idxQ])
    return true;

  return false;
}

} // namespace ens

#endif
/**
 * @file padam.hpp
 * @author Marcus Edel
 *
 * Definition of Partially adaptive momentum estimation method (Padam).
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PADAM_PADAM_HPP
#define ENSMALLEN_PADAM_PADAM_HPP

#include <ensmallen_bits/sgd/sgd.hpp>
#include "padam_update.hpp"

namespace ens {

/**
 * Partially adaptive momentum estimation method (Padam),
 * adopts historical gradient information to automatically adjust the
 * learning rate.
 *
 * For more information, see the following.
 *
 * @code
 * @article{
 *   title   = {Closing the Generalization Gap of Adaptive Gradient Methods in
 *              Training Deep Neural Networks},
 *   author  = {{Chen}, J. and {Gu}, Q.},
 *   journal = {ArXiv e-prints},
 *   url     = {https://arxiv.org/abs/1806.06763}
 *   year    = {2018}
 * }
 * @endcode
 *
 * Padam can optimize differentiable separable functions.  For more details, see
 * the documentation on function types include with this distribution or on the
 * ensmallen website.
 */
class Padam
{
 public:
  /**
   * Construct the Padam optimizer with the given function and parameters. The
   * defaults here are not necessarily good for the given problem, so it is
   * suggested that the values used be tailored to the task at hand.  The
   * maximum number of iterations refers to the maximum number of points that
   * are processed (i.e., one iteration equals one point; one iteration does not
   * equal one pass over the dataset).
   *
   * @param stepSize Step size for each iteration.
   * @param batchSize Number of points to process in a single step.
   * @param beta1 Exponential decay rate for the first moment estimates.
   * @param beta2 Exponential decay rate for the weighted infinity norm
   *        estimates.
   * @param partial Partially adaptive parameter.
   * @param epsilon Epsilon is the minimum allowed gradient.
   * @param maxIterations Maximum number of iterations allowed (0 means no
   *        limit).
   * @param tolerance Maximum absolute tolerance to terminate algorithm.
   * @param shuffle If true, the function order is shuffled; otherwise, each
   *        function is visited in linear order.
   * @param resetPolicy If true, parameters are reset before every Optimize
   *        call; otherwise, their values are retained.
   * @param exactObjective Calculate the exact objective (Default: estimate the
   *        final objective obtained on the last pass over the data).
   */
  Padam(const double stepSize = 0.001,
        const size_t batchSize = 32,
        const double beta1 = 0.9,
        const double beta2 = 0.999,
        const double partial = 0.25,
        const double epsilon = 1e-8,
        const size_t maxIterations = 100000,
        const double tolerance = 1e-5,
        const bool shuffle = true,
        const bool resetPolicy = true,
        const bool exactObjective = false) :
      optimizer(stepSize,
                batchSize,
                maxIterations,
                tolerance,
                shuffle,
                PadamUpdate(epsilon, beta1, beta2, partial),
                NoDecay(),
                resetPolicy,
                exactObjective)
  { /* Nothing to do here. */ }

  /**
   * Optimize the given function using Padam. The given starting point will be
   * modified to store the finishing point of the algorithm, and the final
   * objective value is returned.
   *
   * @tparam SeparableFunctionType Type of the function to optimize.
   * @tparam MatType Type of matrix to optimize with.
   * @tparam GradType Type of matrix to use to represent function gradients.
   * @tparam CallbackTypes Types of callback functions.
   * @param function Function to optimize.
   * @param iterate Starting point (will be modified).
   * @param callbacks Callback functions.
   * @return Objective value of the final point.
   */
  template<typename SeparableFunctionType,
           typename MatType,
           typename GradType,
           typename... CallbackTypes>
  typename MatType::elem_type Optimize(SeparableFunctionType& function,
                                       MatType& iterate,
                                       CallbackTypes&&... callbacks)
  {
    return optimizer.template Optimize<
        SeparableFunctionType, MatType, GradType, CallbackTypes...>(
        function, iterate, std::forward<CallbackTypes>(callbacks)...);
  }

  //! Forward the MatType as GradType.
  template<typename SeparableFunctionType,
           typename MatType,
           typename... CallbackTypes>
  typename MatType::elem_type Optimize(SeparableFunctionType& function,
                                       MatType& iterate,
                                       CallbackTypes&&... callbacks)
  {
    return Optimize<SeparableFunctionType, MatType, MatType,
        CallbackTypes...>(function, iterate,
        std::forward<CallbackTypes>(callbacks)...);
  }

  //! Get the step size.
  double StepSize() const { return optimizer.StepSize(); }
  //! Modify the step size.
  double& StepSize() { return optimizer.StepSize(); }

  //! Get the batch size.
  size_t BatchSize() const { return optimizer.BatchSize(); }
  //! Modify the batch size.
  size_t& BatchSize() { return optimizer.BatchSize(); }

  //! Get the smoothing parameter.
  double Beta1() const { return optimizer.UpdatePolicy().Beta1(); }
  //! Modify the smoothing parameter.
  double& Beta1() { return optimizer.UpdatePolicy().Beta1(); }

  //! Get the second moment coefficient.
  double Beta2() const { return optimizer.UpdatePolicy().Beta2(); }
  //! Modify the second moment coefficient.
  double& Beta2() { return optimizer.UpdatePolicy().Beta2(); }

  //! Get the partial adaptive parameter.
  double Partial() const { return optimizer.UpdatePolicy().Partial(); }
  //! Modify the partial adaptive parameter.
  double& Partial() { return optimizer.UpdatePolicy().Partial(); }

  //! Get the value used to initialise the mean squared gradient parameter.
  double Epsilon() const { return optimizer.UpdatePolicy().Epsilon(); }
  //! Modify the value used to initialise the mean squared gradient parameter.
  double& Epsilon() { return optimizer.UpdatePolicy().Epsilon(); }

  //! Get the maximum number of iterations (0 indicates no limit).
  size_t MaxIterations() const { return optimizer.MaxIterations(); }
  //! Modify the maximum number of iterations (0 indicates no limit).
  size_t& MaxIterations() { return optimizer.MaxIterations(); }

  //! Get the tolerance for termination.
  double Tolerance() const { return optimizer.Tolerance(); }
  //! Modify the tolerance for termination.
  double& Tolerance() { return optimizer.Tolerance(); }

  //! Get whether or not the individual functions are shuffled.
  bool Shuffle() const { return optimizer.Shuffle(); }
  //! Modify whether or not the individual functions are shuffled.
  bool& Shuffle() { return optimizer.Shuffle(); }

  //! Get whether or not the actual objective is calculated.
  bool ExactObjective() const { return optimizer.ExactObjective(); }
  //! Modify whether or not the actual objective is calculated.
  bool& ExactObjective() { return optimizer.ExactObjective(); }

  //! Get whether or not the update policy parameters
  //! are reset before Optimize call.
  bool ResetPolicy() const { return optimizer.ResetPolicy(); }
  //! Modify whether or not the update policy parameters
  //! are reset before Optimize call.
  bool& ResetPolicy() { return optimizer.ResetPolicy(); }

 private:
  //! The Stochastic Gradient Descent object with Padam policy.
  SGD<PadamUpdate> optimizer;
};

} // namespace ens

#endif
/**
 * @file padam_update.hpp
 * @author Marcus Edel
 *
 * Implementation of Partially adaptive momentum estimation method (Padam).
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PADAM_PADAM_UPDATE_HPP
#define ENSMALLEN_PADAM_PADAM_UPDATE_HPP

namespace ens {

/**
 * Partially adaptive momentum estimation method (Padam),
 * adopts historical gradient information to automatically adjust the
 * learning rate.
 *
 * For more information, see the following.
 *
 * @code
 * @article{
 *   title   = {Closing the Generalization Gap of Adaptive Gradient Methods in
 *              Training Deep Neural Networks},
 *   author  = {{Chen}, J. and {Gu}, Q.},
 *   journal = {ArXiv e-prints},
 *   url     = {https://arxiv.org/abs/1806.06763}
 *   year    = {2018}
 * }
 * @endcode
 */
class PadamUpdate
{
 public:
  /**
   * Construct the Padam update policy with the given parameters.
   *
   * @param epsilon Epsilon is the minimum allowed gradient.
   * @param beta1 The smoothing parameter.
   * @param beta2 The second moment coefficient.
   * @param partial Partially adaptive parameter.
   */
  PadamUpdate(const double epsilon = 1e-8,
              const double beta1 = 0.9,
              const double beta2 = 0.999,
              const double partial = 0.25) :
      epsilon(epsilon),
      beta1(beta1),
      beta2(beta2),
      partial(partial)
  {
    // Nothing to do.
  }

  //! Get the value used to initialise the squared gradient parameter.
  double Epsilon() const { return epsilon; }
  //! Modify the value used to initialise the squared gradient parameter.
  double& Epsilon() { return epsilon; }

  //! Get the smoothing parameter.
  double Beta1() const { return beta1; }
  //! Modify the smoothing parameter.
  double& Beta1() { return beta1; }

  //! Get the second moment coefficient.
  double Beta2() const { return beta2; }
  //! Modify the second moment coefficient.
  double& Beta2() { return beta2; }

  //! Get the partial adaptive parameter.
  double Partial() const { return partial; }
  //! Modify the partial adaptive parameter.
  double& Partial() { return partial; }

  /**
   * The UpdatePolicyType policy classes must contain an internal 'Policy'
   * template class with two template arguments: MatType and GradType.  This is
   * instantiated at the start of the optimization, and holds parameters
   * specific to an individual optimization.
   */
  template<typename MatType, typename GradType>
  class Policy
  {
   public:
    /**
     * This constructor is called by the SGD Optimize() method before the start
     * of the iteration update process.
     *
     * @param parent Instantiated PadamUpdate parent object.
     * @param rows Number of rows in the gradient matrix.
     * @param cols Number of columns in the gradient matrix.
     */
    Policy(PadamUpdate& parent, const size_t rows, const size_t cols) :
        parent(parent),
        iteration(0)
    {
      m.zeros(rows, cols);
      v.zeros(rows, cols);
      vImproved.zeros(rows, cols);
    }

    /**
     * Update step for Padam.
     *
     * @param iterate Parameters that minimize the function.
     * @param stepSize Step size to be used for the given iteration.
     * @param gradient The gradient matrix.
     */
    void Update(MatType& iterate,
                const double stepSize,
                const GradType& gradient)
    {
      // Increment the iteration counter variable.
      ++iteration;

      // And update the iterate.
      m *= parent.beta1;
      m += (1 - parent.beta1) * gradient;

      v *= parent.beta2;
      v += (1 - parent.beta2) * (gradient % gradient);

      const double biasCorrection1 = 1.0 - std::pow(parent.beta1, iteration);
      const double biasCorrection2 = 1.0 - std::pow(parent.beta2, iteration);

      // Element wise maximum of past and present squared gradients.
      vImproved = arma::max(vImproved, v);

      iterate -= (stepSize * std::sqrt(biasCorrection2) / biasCorrection1) *
          m / arma::pow(vImproved + parent.epsilon, parent.partial);
    }

   private:
    //! Instantiated parent object.
    PadamUpdate& parent;

    //! The exponential moving average of gradient values.
    GradType m;

    //! The exponential moving average of squared gradient values.
    GradType v;

    //! The optimal sqaured gradient value.
    GradType vImproved;

    //! The number of iterations.
    size_t iteration;
  };

 private:
  //! The epsilon value used to initialise the squared gradient parameter.
  double epsilon;

  //! The smoothing parameter.
  double beta1;

  //! The second moment coefficient.
  double beta2;

  //! Partial adaptive parameter.
  double partial;
};

} // namespace ens

#endif
/**
 * @file constant_step.hpp
 * @author Shikhar Bhardwaj
 *
 * Constant step size policy for parallel Stochastic Gradient Descent.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PARALLEL_SGD_CONSTANT_STEP_HPP
#define ENSMALLEN_PARALLEL_SGD_CONSTANT_STEP_HPP

namespace ens {

/**
 * Implementation of the ConstantStep stepsize decay policy for parallel SGD.
 */
class ConstantStep
{
 public:
  /**
   * Member initialization constructor.
   *
   * The defaults here are not necessarily good for the given problem, so it is
   * suggested that the values used be tailored to the task at hand.
   *
   * @param step The intial stepsize to use.
   */
  ConstantStep(const double step = 0.01) : step(step) { /* Nothing to do */ }

  /**
   * This function is called in each iteration before the gradient update.
   *
   * @param numEpoch The iteration number for which the stepsize is to be
   *    calculated.
   * @return The step size for the current iteration.
   */
  double StepSize(const size_t /* numEpoch */)
  {
    return step;
  }

 private:
  //! The initial stepsize, which remains unchanged.
  double step;
};

} // namespace ens

#endif
/**
 * @file exponential_backoff.hpp
 * @author Shikhar Bhardwaj
 *
 * Exponential backoff step size decay policy for parallel Stochastic Gradient
 * Descent.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PARALLEL_SGD_EXP_BACKOFF_HPP
#define ENSMALLEN_PARALLEL_SGD_EXP_BACKOFF_HPP

namespace ens {

/**
 * Exponential backoff stepsize reduction policy for parallel SGD.
 *
 * For more information, see the following.
 *
 * @misc{1106.5730,
 *   Author = {Feng Niu and Benjamin Recht and Christopher Re and Stephen J.
 *             Wright},
 *   Title = {HOGWILD!: A Lock-Free Approach to Parallelizing Stochastic
 *            Gradient Descent},
 *   Year = {2011},
 *   Eprint = {arXiv:1106.5730},
 * }
 *
 * This stepsize update scheme gives robust 1/k convergence rates to the
 * implementation of parallel SGD.
 */
class ExponentialBackoff
{
 public:
  /**
   * Member initializer constructor to construct the exponential backoff policy
   * with the required parameters.
   *
   * @param firstBackoffEpoch The number of updates to run before the first
   * stepsize backoff.
   * @param step The initial stepsize(gamma).
   * @param beta The reduction factor. This should be a value in range (0, 1).
   */
  ExponentialBackoff(const size_t firstBackoffEpoch,
                     const double step,
                     const double beta) :
    firstBackoffEpoch(firstBackoffEpoch),
    cutoffEpoch(firstBackoffEpoch),
    step(step),
    beta(beta)
  { /* Nothing to do. */ }

  /**
   * Get the step size for the current gradient update.
   *
   * @param numEpoch The iteration number of the current update.
   * @return The stepsize for the current iteration.
   */
  double StepSize(const size_t numEpoch)
  {
    if (numEpoch >= cutoffEpoch)
    {
      step *= beta;
      cutoffEpoch += firstBackoffEpoch / beta;
    }
    return step;
  }

 private:
  //! The first iteration at which the stepsize should be reduced.
  size_t firstBackoffEpoch;

  //! The iteration at which the next decay will be performed.
  size_t cutoffEpoch;

  //! The initial stepsize.
  double step;

  //! The reduction factor, should be in range (0, 1).
  double beta;
};

} // namespace ens

#endif
/**
 * @file parallel_sgd.hpp
 * @author Shikhar Bhardwaj
 *
 * Parallel Stochastic Gradient Descent.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PARALLEL_SGD_HPP
#define ENSMALLEN_PARALLEL_SGD_HPP

#include "decay_policies/constant_step.hpp"
#include "decay_policies/exponential_backoff.hpp"

namespace ens {

/**
 * An implementation of parallel stochastic gradient descent using the lock-free
 * HOGWILD! approach.
 *
 * For more information, see the following.
 *
 * @code
 * @misc{1106.5730,
 *   Author = {Feng Niu and Benjamin Recht and Christopher Re and Stephen J.
 *             Wright},
 *   Title  = {HOGWILD!: A Lock-Free Approach to Parallelizing Stochastic
 *             Gradient Descent},
 *   Year   = {2011},
 *   Eprint = {arXiv:1106.5730},
 * }
 * @endcode
 *
 * ParallelSGD can optimize sparse differentiable separable functions.  For more
 * details, see the documentation on function types included with this
 * distribution or on the ensmallen website.
 *
 * @tparam DecayPolicyType Step size update policy used by parallel SGD
 *     to update the stepsize after each iteration.
 */
template <typename DecayPolicyType = ConstantStep>
class ParallelSGD
{
 public:
  /**
   * Construct the parallel SGD optimizer to optimize the given function with
   * the given parameters. One iteration means one batch of datapoints processed
   * by each thread.
   *
   * The defaults here are not necessarily good for the given problem, so it is
   * suggested that the values used be tailored to the task at hand.
   *
   * @param maxIterations Maximum number of iterations allowed (0 means no
   *     limit).
   * @param threadShareSize Number of datapoints to be processed in one
   *     iteration by each thread.
   * @param tolerance Maximum absolute tolerance to terminate the algorithm.
   * @param shuffle If true, the function order is shuffled; otherwise, each
   *     function is visited in linear order.
   * @param decayPolicy The step size update policy to use.
  */
  ParallelSGD(const size_t maxIterations,
              const size_t threadShareSize,
              const double tolerance = 1e-5,
              const bool shuffle = true,
              const DecayPolicyType& decayPolicy = DecayPolicyType());

  /**
   * Optimize the given function using the parallel SGD algorithm. The given
   * starting point will be modified to store the finishing point of the
   * algorithm, and the value of the loss function at the final point is
   * returned.
   *
   * @tparam SparseFunctionType Type of function to be optimized.
   * @tparam MatType Type of the objective function.
   * @tparam GradType Type of gradient (it is strongly suggested that this be a
   *     sparse matrix of some sort!).
   * @tparam CallbackTypes Types of callback functions.
   * @param function Function to be optimized(minimized).
   * @param iterate Starting point(will be modified).
   * @param callbacks Callback functions.
   * @return Objective value at the final point.
   */
  template <typename SparseFunctionType,
            typename MatType,
            typename GradType,
            typename... CallbackTypes>
  typename std::enable_if<IsArmaType<GradType>::value,
      typename MatType::elem_type>::type
  Optimize(SparseFunctionType& function,
           MatType& iterate,
           CallbackTypes&&... callbacks);

  //! Forward arma::SpMat<typename MatType::elem_type> as GradType.
  template<typename SeparableFunctionType,
           typename MatType,
           typename... CallbackTypes>
  typename MatType::elem_type Optimize(SeparableFunctionType& function,
                                       MatType& iterate,
                                       CallbackTypes&&... callbacks)
  {
    return Optimize<SeparableFunctionType, MatType,
        arma::SpMat<typename MatType::elem_type>, CallbackTypes...>(
        function, iterate, std::forward<CallbackTypes>(callbacks)...);
  }

  //! Get the maximum number of iterations (0 indicates no limits).
  size_t MaxIterations() const { return maxIterations; }
  //! Modify the maximum number of iterations (0 indicates no limits).
  size_t& MaxIterations() { return maxIterations; }

  //! Get the number of datapoints to be processed in one iteration by each
  //! thread.
  size_t ThreadShareSize() const { return threadShareSize; }
  //! Modify the number of datapoints to be processed in one iteration by each
  //! thread.
  size_t& ThreadShareSize() { return threadShareSize; }

  //! Get the tolerance for termination.
  double Tolerance() const { return tolerance; }
  //! Modify the tolerance for termination.
  double& Tolerance() { return tolerance; }

  //! Get whether or not the individual functions are shuffled.
  bool Shuffle() const { return shuffle; }
  //! Modify whether or not the individual functions are shuffled.
  bool& Shuffle() { return shuffle; }

  //! Get the step size decay policy.
  DecayPolicyType& DecayPolicy() const { return decayPolicy; }
  //! Modify the step size decay policy.
  DecayPolicyType& DecayPolicy() { return decayPolicy; }

 private:
  //! The maximum number of allowed iterations.
  size_t maxIterations;

  //! The number of datapoints to be processed in one iteration by each thread.
  size_t threadShareSize;

  //! The tolerance for termination.
  double tolerance;

  //! Controls whether or not the individual functions are shuffled when
  //! iterating.
  bool shuffle;

  //! The step size decay policy.
  DecayPolicyType decayPolicy;
};

} // namespace ens

// Include implementation.
#include "parallel_sgd_impl.hpp"

#endif
/**
 * @file parallel_sgd_impl.hpp
 * @author Shikhar Bhardwaj
 *
 * Implementation of Parallel Stochastic Gradient Descent.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PARALLEL_SGD_IMPL_HPP
#define ENSMALLEN_PARALLEL_SGD_IMPL_HPP

// In case it hasn't been included yet.
#include "parallel_sgd.hpp"

#include <ensmallen_bits/function.hpp>

namespace ens {

// Utility function to update a location of a dense matrix or other type using
// an atomic section.
template<typename MatType>
inline void UpdateLocation(MatType& iterate,
                           const size_t row,
                           const size_t col,
                           const typename MatType::elem_type value)
{
  ENS_PRAGMA_OMP_ATOMIC
  iterate(row, col) -= value;
}

// Utility function to update a location of a sparse matrix using a critical
// section.
template<typename eT>
inline void UpdateLocation(arma::SpMat<eT>& iterate,
                           const size_t row,
                           const size_t col,
                           const eT value)
{
  ENS_PRAGMA_OMP_CRITICAL_NAMED
  {
    iterate(row, col) -= value;
  }
}

template <typename DecayPolicyType>
ParallelSGD<DecayPolicyType>::ParallelSGD(
    const size_t maxIterations,
    const size_t threadShareSize,
    const double tolerance,
    const bool shuffle,
    const DecayPolicyType& decayPolicy) :
    maxIterations(maxIterations),
    threadShareSize(threadShareSize),
    tolerance(tolerance),
    shuffle(shuffle),
    decayPolicy(decayPolicy)
{ /* Nothing to do. */ }

template <typename DecayPolicyType>
template <typename SparseFunctionType,
          typename MatType,
          typename GradType,
          typename... CallbackTypes>
typename std::enable_if<IsArmaType<GradType>::value,
typename MatType::elem_type>::type ParallelSGD<DecayPolicyType>::Optimize(
    SparseFunctionType& function,
    MatType& iterateIn,
    CallbackTypes&&... callbacks)
{
  // Convenience typedefs.
  typedef typename MatType::elem_type ElemType;
  typedef typename MatTypeTraits<MatType>::BaseMatType BaseMatType;
  typedef typename MatTypeTraits<GradType>::BaseMatType BaseGradType;

  // Check that we have all the functions that we need.
  traits::CheckSparseFunctionTypeAPI<SparseFunctionType, BaseMatType,
      BaseGradType>();
  RequireFloatingPointType<BaseMatType>();
  RequireFloatingPointType<BaseGradType>();
  RequireSameInternalTypes<BaseMatType, BaseGradType>();

  BaseMatType& iterate = (BaseMatType&) iterateIn;

  ElemType overallObjective = DBL_MAX;
  ElemType lastObjective;

  // Controls early termination of the optimization process.
  bool terminate = false;

  // The order in which the functions will be visited.
  // TODO: maybe use function.Shuffle() instead?
  arma::Col<size_t> visitationOrder = arma::linspace<arma::Col<size_t>>(0,
      (function.NumFunctions() - 1), function.NumFunctions());

  // Iterate till the objective is within tolerance or the maximum number of
  // allowed iterations is reached. If maxIterations is 0, this will iterate
  // till convergence.
  Callback::BeginOptimization(*this, function, iterate, callbacks...);
  for (size_t i = 1; i != maxIterations && !terminate; ++i)
  {
    // Calculate the overall objective.
    lastObjective = overallObjective;

    overallObjective = function.Evaluate(iterate);

    terminate |= Callback::Evaluate(*this, function, iterate, overallObjective,
        callbacks...);

    // Output current objective function.
    Info << "Parallel SGD: iteration " << i << ", objective "
      << overallObjective << "." << std::endl;

    if (std::isnan(overallObjective) || std::isinf(overallObjective))
    {
      Warn << "Parallel SGD: converged to " << overallObjective
        << "; terminating with failure. Try a smaller step size?"
        << std::endl;

      Callback::EndOptimization(*this, function, iterate, callbacks...);
      return overallObjective;
    }

    if (std::abs(lastObjective - overallObjective) < tolerance)
    {
      Info << "SGD: minimized within tolerance " << tolerance << "; "
        << "terminating optimization." << std::endl;

      Callback::EndOptimization(*this, function, iterate, callbacks...);
      return overallObjective;
    }

    // Get the stepsize for this iteration
    double stepSize = decayPolicy.StepSize(i);

    // Shuffle for uniform sampling of functions by each thread.
    if (shuffle)
    {
      // Determine order of visitation.
      visitationOrder = arma::shuffle(visitationOrder);
    }

    ENS_PRAGMA_OMP_PARALLEL
    {
      // Each processor gets a subset of the instances.
      // Each subset is of size threadShareSize
      size_t threadId = 0;
      #ifdef ENS_USE_OPENMP
        threadId = omp_get_thread_num();
      #endif

      for (size_t j = threadId * threadShareSize;
          j < (threadId + 1) * threadShareSize && j < visitationOrder.n_elem;
          ++j)
      {
        // Each instance affects only some components of the decision variable.
        // So the gradient is sparse.
        BaseGradType gradient;

        // Evaluate the sparse gradient.
        // TODO: support for batch size > 1 could be really useful.
        function.Gradient(iterate, visitationOrder[j], gradient, 1);

        terminate |= Callback::Gradient(*this, function, iterate, gradient,
            callbacks...);

        // Update the decision variable with non-zero components of the
        // gradient.
        for (size_t i = 0; i < gradient.n_cols; ++i)
        {
          // Iterate over the non-zero elements.
          const typename GradType::iterator curEnd = gradient.end_col(i);
          for (typename GradType::iterator cur = gradient.begin_col(i);
              cur != curEnd; ++cur)
          {
            const ElemType value = (*cur);
            const arma::uword row = cur.row();

            // Call out to utility function to use the right type of OpenMP
            // lock.
            UpdateLocation(iterate, row, i, stepSize * value);
          }
        }
        terminate |= Callback::StepTaken(*this, function, iterate,
            callbacks...);
      }
    }
  }

  Info << "\nParallel SGD terminated with objective : " << overallObjective
      << "." << std::endl;

  Callback::EndOptimization(*this, function, iterate, callbacks...);
  return overallObjective;
}

} // namespace ens

#endif
/**
 * @file ackley_function.hpp
 * @author Suryoday Basak
 *
 * Definition of the Ackley function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_ACKLEY_FUNCTION_HPP
#define ENSMALLEN_PROBLEMS_ACKLEY_FUNCTION_HPP

namespace ens {
namespace test {

/**
 * The Ackley function, defined by
 *
 * \f[
 * f(x_1,x_2) = -20 * e^(-0.2 * sqrt(0.5 * (x_1^2 + x_2^2))) -
 *    e * (0.5(cos(2 * pi * x_1) + cos(2 * pi * x_2))) + e + 20
 * \f]
 *
 * This should optimize to f(x) = 0, at x = [0, 0].
 *
 * For more information, please refer to:
 *
 * @code
 * @book{Ackley1987,
 *   doi       = {10.1007/978-1-4613-1997-9},
 *   url       = {https://doi.org/10.1007/978-1-4613-1997-9},
 *   year      = {1987},
 *   publisher = {Springer {US}},
 *   author    = {David H. Ackley},
 *   title     = {A Connectionist Machine for Genetic Hillclimbing}
 * }
 * @endcode
 */
class AckleyFunction
{
 public:
  /**
   * Initialize the AckleyFunction.
   *
   * @param c Multiplicative constant with a default value of 2 * pi.
   * @param epsilon Coefficient to avoid division by zero (numerical stability).
   */
  AckleyFunction(const double c = 2 * arma::datum::pi,
                 const double epsilon = 1e-8);

  /**
   * Shuffle the order of function visitation. This may be called by the
   * optimizer.
   */
  void Shuffle();

  //! Return 1 (the number of functions).
  size_t NumFunctions() const { return 1; }

  /**
   * Evaluate a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param batchSize Number of points to process.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates,
                                       const size_t begin,
                                       const size_t batchSize) const;

  /**
   * Evaluate a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates) const;

  /**
   * Evaluate the gradient of a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param gradient The function gradient.
   * @param batchSize Number of points to process.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates,
                const size_t begin,
                GradType& gradient,
                const size_t batchSize) const;

  /**
   * Evaluate the gradient of a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   * @param gradient The function gradient.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates, GradType& gradient);

  //! Get the value used for c.
  double MultiplicativeConstant() const { return c; }
  //! Modify the value used for c.
  double& MultiplicativeConstant() { return c; }

  //! Get the value used for numerical stability.
  double Epsilon() const { return epsilon; }
  //! Modify the value used for numerical stability.
  double& Epsilon() { return epsilon; }

  // Note: GetInitialPoint(), GetFinalPoint(), and GetFinalObjective() are not
  // required for using ensmallen to optimize this function!  They are
  // specifically used as a convenience just for ensmallen's testing
  // infrastructure.

  //! Get the starting point.
  template<typename MatType = arma::mat>
  MatType GetInitialPoint() const { return MatType("0.02; 0.02"); }

  //! Get the final point.
  template<typename MatType = arma::mat>
  MatType GetFinalPoint() const { return MatType("0.0; 0.0"); }

  //! Get the final objective.
  double GetFinalObjective() const { return 0.0; }

 private:
  //! The value of the multiplicative constant.
  double c;
  //! The value used for numerical stability.
  double epsilon;
};

} // namespace test
} // namespace ens

// Include implementation.
#include "ackley_function_impl.hpp"

#endif // ENSMALLEN_PROBLEMS_ACKLEY_FUNCTION_HPP
/**
 * @file ackley_function_impl.hpp
 * @author Suryoday Basak
 *
 * Implementation of the Ackley function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_ACKLEY_FUNCTION_IMPL_HPP
#define ENSMALLEN_PROBLEMS_ACKLEY_FUNCTION_IMPL_HPP

// In case it hasn't been included yet.
#include "ackley_function.hpp"

namespace ens {
namespace test {

inline AckleyFunction::AckleyFunction(const double c, const double epsilon) :
    c(c), epsilon(epsilon)
{ /* Nothing to do here */}

inline void AckleyFunction::Shuffle() { /* Nothing to do here */ }

template<typename MatType>
typename MatType::elem_type AckleyFunction::Evaluate(
    const MatType& coordinates,
    const size_t /* begin */,
    const size_t /* batchSize */) const
{
  // Convenience typedef.
  typedef typename MatType::elem_type ElemType;

  // For convenience; we assume these temporaries will be optimized out.
  const ElemType x1 = coordinates(0);
  const ElemType x2 = coordinates(1);

  const ElemType objective = -20 * std::exp(
      -0.2 * std::sqrt(0.5 * (x1 * x1 + x2 * x2))) -
      std::exp(0.5 * (std::cos(c * x1) + std::cos(c * x2))) + std::exp(1) + 20;

  return objective;
}

template<typename MatType>
typename MatType::elem_type AckleyFunction::Evaluate(
    const MatType& coordinates) const
{
  return Evaluate(coordinates, 0, NumFunctions());
}

template<typename MatType, typename GradType>
inline void AckleyFunction::Gradient(const MatType& coordinates,
                                     const size_t /* begin */,
                                     GradType& gradient,
                                     const size_t /* batchSize */) const
{
  // Convenience typedef.
  typedef typename MatType::elem_type ElemType;

  // For convenience; we assume these temporaries will be optimized out.
  const ElemType x1 = coordinates(0);
  const ElemType x2 = coordinates(1);

  // Aliases for different terms in the expression of the gradient.
  const ElemType t0 = std::sqrt(0.5 * (x1 * x1 + x2 * x2));
  const ElemType t1 = 2.0 * std::exp(- 0.2 * t0) / (t0 + epsilon);
  const ElemType t2 = 0.5 * c *
      std::exp(0.5 * (std::cos(c * x1) + std::cos(c * x2)));

  gradient.set_size(2, 1);
  gradient(0) = (x1 * t1) + (t2 * std::sin(c * x1));
  gradient(1) = (x2 * t1) + (t2 * std::sin(c * x2));
}

template<typename MatType, typename GradType>
inline void AckleyFunction::Gradient(const MatType& coordinates,
                                     GradType& gradient)
{
  Gradient(coordinates, 0, gradient, 1);
}

} // namespace test
} // namespace ens

#endif
/**
 * @file aug_lagrangian_test_functions.hpp
 * @author Ryan Curtin
 *
 * Define test functions for the augmented Lagrangian method.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_AUG_LAGRANGIAN_TEST_FUNCTIONS_HPP
#define ENSMALLEN_AUG_LAGRANGIAN_TEST_FUNCTIONS_HPP

namespace ens {
namespace test {

/**
 * This function is taken from "Practical Mathematical Optimization" (Snyman),
 * section 5.3.8 ("Application of the Augmented Lagrangian Method").  It has
 * only one constraint.
 *
 * The minimum that satisfies the constraint is x = [1, 4], with an objective
 * value of 70.
 */
class AugLagrangianTestFunction
{
 public:
  AugLagrangianTestFunction();
  AugLagrangianTestFunction(const arma::mat& initial_point);

  double Evaluate(const arma::mat& coordinates);
  void Gradient(const arma::mat& coordinates, arma::mat& gradient);

  size_t NumConstraints() const { return 1; }

  double EvaluateConstraint(const size_t index, const arma::mat& coordinates);
  void GradientConstraint(const size_t index,
                          const arma::mat& coordinates,
                          arma::mat& gradient);

  const arma::mat& GetInitialPoint() const { return initialPoint; }

 private:
  arma::mat initialPoint;
};

/**
 * This function is taken from M. Gockenbach's lectures on general nonlinear
 * programs, found at:
 * http://www.math.mtu.edu/~msgocken/ma5630spring2003/lectures/nlp/nlp.pdf
 *
 * The program we are using is example 2.5 from this document.
 * I have arbitrarily decided that this will be called the Gockenbach function.
 *
 * The minimum that satisfies the two constraints is given as
 *   x = [0.12288, -1.1078, 0.015100], with an objective value of about 29.634.
 */
class GockenbachFunction
{
 public:
  GockenbachFunction();
  GockenbachFunction(const arma::mat& initialPoint);

  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates);

  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates, GradType& gradient);

  size_t NumConstraints() const { return 2; }

  template<typename MatType>
  typename MatType::elem_type EvaluateConstraint(
      const size_t index,
      const MatType& coordinates);

  template<typename MatType, typename GradType>
  void GradientConstraint(const size_t index,
                          const MatType& coordinates,
                          GradType& gradient);

  template<typename MatType>
  MatType GetInitialPoint() const
  {
    return arma::conv_to<MatType>::from(initialPoint);
  }

 private:
  arma::mat initialPoint;
};

/**
 * This function is the Lovasz-Theta semidefinite program, as implemented in the
 * following paper:
 *
 * S. Burer, R. Monteiro
 * "A nonlinear programming algorithm for solving semidefinite programs via
 * low-rank factorization."
 * Journal of Mathematical Programming, 2004
 *
 * Given a simple, undirected graph G = (V, E), the Lovasz-Theta SDP is defined
 * by:
 *
 * min_X{Tr(-(e e^T)^T X) : Tr(X) = 1, X_ij = 0 for all (i, j) in E, X >= 0}
 *
 * where e is the vector of all ones and X has dimension |V| x |V|.
 *
 * In the Monteiro-Burer formulation, we take X = R * R^T, where R is the
 * coordinates given to the Evaluate(), Gradient(), EvaluateConstraint(), and
 * GradientConstraint() functions.
 */
class LovaszThetaSDP
{
 public:
  LovaszThetaSDP();

  /**
   * Initialize the Lovasz-Theta SDP with the given set of edges.  The edge
   * matrix should consist of rows of two dimensions, where dimension 0 is the
   * first vertex of the edge and dimension 1 is the second edge (or vice versa,
   * as it doesn't make a difference).
   *
   * @param edges Matrix of edges.
   */
  LovaszThetaSDP(const arma::mat& edges);

  double Evaluate(const arma::mat& coordinates);
  void Gradient(const arma::mat& coordinates, arma::mat& gradient);

  size_t NumConstraints() const;

  double EvaluateConstraint(const size_t index, const arma::mat& coordinates);
  void GradientConstraint(const size_t index,
                          const arma::mat& coordinates,
                          arma::mat& gradient);

  const arma::mat& GetInitialPoint();

  const arma::mat& Edges() const { return edges; }
  arma::mat&       Edges()       { return edges; }

 private:
  arma::mat edges;
  size_t vertices;

  arma::mat initialPoint;
};

} // namespace test
} // namespace ens

// Include implementation.
#include "aug_lagrangian_test_functions_impl.hpp"

#endif // ENSMALLEN_AUG_LAGRANGIAN_TEST_FUNCTIONS_HPP
/**
 * @file aug_lagrangian_test_functions_impl.hpp
 * @author Ryan Curtin
 *
 * Implementation of AugLagrangianTestFunction class.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_AUG_LAGRANGIAN_TEST_FUNCTIONS_IMPL_HPP
#define ENSMALLEN_PROBLEMS_AUG_LAGRANGIAN_TEST_FUNCTIONS_IMPL_HPP

#include "aug_lagrangian_test_functions.hpp"

namespace ens {
namespace test {

//
// AugLagrangianTestFunction
//
inline AugLagrangianTestFunction::AugLagrangianTestFunction()
{
  // Set the initial point to be (0, 0).
  initialPoint.zeros(2, 1);
}

inline AugLagrangianTestFunction::AugLagrangianTestFunction(
      const arma::mat& initialPoint) :
    initialPoint(initialPoint)
{
  // Nothing to do.
}

inline double AugLagrangianTestFunction::Evaluate(const arma::mat& coordinates)
{
  // f(x) = 6 x_1^2 + 4 x_1 x_2 + 3 x_2^2
  return ((6 * std::pow(coordinates[0], 2)) +
          (4 * (coordinates[0] * coordinates[1])) +
          (3 * std::pow(coordinates[1], 2)));
}

inline void AugLagrangianTestFunction::Gradient(const arma::mat& coordinates,
                                                arma::mat& gradient)
{
  // f'_x1(x) = 12 x_1 + 4 x_2
  // f'_x2(x) = 4 x_1 + 6 x_2
  gradient.set_size(2, 1);

  gradient[0] = 12 * coordinates[0] + 4 * coordinates[1];
  gradient[1] = 4 * coordinates[0] + 6 * coordinates[1];
}

inline double AugLagrangianTestFunction::EvaluateConstraint(const size_t index,
    const arma::mat& coordinates)
{
  // We return 0 if the index is wrong (not 0).
  if (index != 0)
    return 0;

  // c(x) = x_1 + x_2 - 5
  return (coordinates[0] + coordinates[1] - 5);
}

inline void AugLagrangianTestFunction::GradientConstraint(const size_t index,
    const arma::mat& /* coordinates */,
    arma::mat& gradient)
{
  // If the user passed an invalid index (not 0), we will return a zero
  // gradient.
  gradient.zeros(2, 1);

  if (index == 0)
  {
    // c'_x1(x) = 1
    // c'_x2(x) = 1
    gradient.ones(2, 1); // Use a shortcut instead of assigning individually.
  }
}

//
// GockenbachFunction
//
inline GockenbachFunction::GockenbachFunction()
{
  // Set the initial point to (0, 0, 1).
  initialPoint.zeros(3, 1);
  initialPoint[2] = 1;
}

inline GockenbachFunction::GockenbachFunction(const arma::mat& initialPoint) :
    initialPoint(initialPoint)
{
  // Nothing to do.
}

template<typename MatType>
inline typename MatType::elem_type GockenbachFunction::Evaluate(
    const MatType& coordinates)
{
  // f(x) = (x_1 - 1)^2 + 2 (x_2 + 2)^2 + 3(x_3 + 3)^2
  return ((std::pow(coordinates[0] - 1, 2)) +
          (2 * std::pow(coordinates[1] + 2, 2)) +
          (3 * std::pow(coordinates[2] + 3, 2)));
}

template<typename MatType, typename GradType>
inline void GockenbachFunction::Gradient(const MatType& coordinates,
                                         GradType& gradient)
{
  // f'_x1(x) = 2 (x_1 - 1)
  // f'_x2(x) = 4 (x_2 + 2)
  // f'_x3(x) = 6 (x_3 + 3)
  gradient.set_size(3, 1);

  gradient[0] = 2 * (coordinates[0] - 1);
  gradient[1] = 4 * (coordinates[1] + 2);
  gradient[2] = 6 * (coordinates[2] + 3);
}

template<typename MatType>
inline typename MatType::elem_type GockenbachFunction::EvaluateConstraint(
    const size_t index,
    const MatType& coordinates)
{
  typename MatType::elem_type constraint = 0;

  switch (index)
  {
    case 0: // g(x) = (x_3 - x_2 - x_1 - 1) = 0
      constraint = (coordinates[2] - coordinates[1] - coordinates[0] -
          typename MatType::elem_type(1));
      break;

    case 1: // h(x) = (x_3 - x_1^2) >= 0
      // To deal with the inequality, the constraint will simply evaluate to 0
      // when h(x) >= 0.
      constraint = std::min(typename MatType::elem_type(0), (coordinates[2] -
          std::pow(coordinates[0], typename MatType::elem_type(2))));
      break;
  }

  // 0 will be returned for an invalid index (but this is okay).
  return constraint;
}

template<typename MatType, typename GradType>
inline void GockenbachFunction::GradientConstraint(const size_t index,
                                                   const MatType& coordinates,
                                                   GradType& gradient)
{
  gradient.zeros(3, 1);

  switch (index)
  {
    case 0:
      // g'_x1(x) = -1
      // g'_x2(x) = -1
      // g'_x3(x) = 1
      gradient[0] = -1;
      gradient[1] = -1;
      gradient[2] = 1;
      break;

    case 1:
      // h'_x1(x) = -2 x_1
      // h'_x2(x) = 0
      // h'_x3(x) = 1
      gradient[0] = -2 * coordinates[0];
      gradient[2] = 1;
      break;
  }
}

//
// LovaszThetaSDP
//
inline LovaszThetaSDP::LovaszThetaSDP() :
    edges(0),
    vertices(0),
    initialPoint(0, 0)
{ }

inline LovaszThetaSDP::LovaszThetaSDP(const arma::mat& edges) :
    edges(edges),
    initialPoint(0, 0)
{
  // Calculate V by finding the maximum index in the edges matrix.
  vertices = max(max(edges)) + 1;
}

inline double LovaszThetaSDP::Evaluate(const arma::mat& coordinates)
{
  // The objective is equal to -Tr(ones * X) = -Tr(ones * (R^T * R)).
  // This can be simplified into the negative sum of (R^T * R).
  arma::mat x = trans(coordinates) * coordinates;
  double obj = -accu(x);

  return obj;
}

inline void LovaszThetaSDP::Gradient(const arma::mat& coordinates,
                                     arma::mat& gradient)
{
  // The gradient is equal to (2 S' R^T)^T, with R being coordinates.
  // S' = C - sum_{i = 1}^{m} [ y_i - sigma (Tr(A_i * (R^T R)) - b_i)] * A_i
  // We will calculate it in a not very smart way, but it should work.

  // Initialize S' piece by piece.  It is of size n x n.
  const size_t n = coordinates.n_cols;
  arma::mat s(n, n);
  s.ones();
  s *= -1; // C = -ones().

  for (size_t i = 0; i < NumConstraints(); ++i)
  {
    // Calculate [ y_i - sigma (Tr(A_i * (R^T R)) - b_i) ] * A_i.
    // Result will be a matrix; inner result is a scalar.
    if (i == 0)
    {
      // A_0 = I_n.  Hooray!  That's easy!  b_0 = 1.
      double inner = -1 * double(n) - 0.5 *
          (accu(trans(coordinates) % coordinates) - 1);

      arma::mat zz = (inner * arma::eye<arma::mat>(n, n));
      s -= zz;
    }
    else
    {
      // Get edge so we can construct constraint A_i matrix.  b_i = 0.
      arma::vec edge = edges.col(i - 1);

      arma::mat a;
      a.zeros(n, n);

      // Only two nonzero entries.
      a(edge[0], edge[1]) = 1;
      a(edge[1], edge[0]) = 1;

      double inner = (-1) - 0.5 *
          (accu(a % (trans(coordinates) * coordinates)));

      arma::mat zz = (inner * a);
      s -= zz;
    }
  }

  // The gradient of -Tr(ones * X) is equal to -2 * ones * R.
  gradient = trans(2 * s * trans(coordinates));
}

inline size_t LovaszThetaSDP::NumConstraints() const
{
  // Each edge is a constraint, and we have the constraint Tr(X) = 1.
  return edges.n_cols + 1;
}

inline double LovaszThetaSDP::EvaluateConstraint(const size_t index,
                                                 const arma::mat& coordinates)
{
  if (index == 0) // This is the constraint Tr(X) = 1.
  {
    double sum = -1; // Tr(X) - 1 = 0, so we prefix the subtraction.
    for (size_t i = 0; i < coordinates.n_cols; i++)
      sum += std::abs(dot(coordinates.col(i), coordinates.col(i)));

    return sum;
  }

  size_t i = edges(0, index - 1);
  size_t j = edges(1, index - 1);

  // The constraint itself is X_ij, or (R^T R)_ij.
  return std::abs(dot(coordinates.col(i), coordinates.col(j)));
}

inline void LovaszThetaSDP::GradientConstraint(const size_t index,
                                               const arma::mat& coordinates,
                                               arma::mat& gradient)
{
  if (index == 0) // This is the constraint Tr(X) = 1.
  {
    gradient = 2 * coordinates; // d/dR (Tr(R R^T)) = 2 R.
    return;
  }

  size_t i = edges(0, index - 1);
  size_t j = edges(1, index - 1);

  // Since the constraint is (R^T R)_ij, the gradient for (x, y) will be (I
  // derived this for one of the MVU constraints):
  //   0     , y != i, y != j
  //   2 R_xj, y  = i, y != j
  //   2 R_xi, y != i, y  = j
  //   4 R_xy, y  = i, y  = j
  // This results in the gradient matrix having two nonzero rows; for row
  // i, the elements are R_nj, where n is the row; for column j, the elements
  // are R_ni.
  gradient.zeros(coordinates.n_rows, coordinates.n_cols);

  gradient.col(i) = coordinates.col(j);
  gradient.col(j) += coordinates.col(i); // In case j = i (shouldn't happen).
}

inline const arma::mat& LovaszThetaSDP::GetInitialPoint()
{
  if (initialPoint.n_rows != 0 && initialPoint.n_cols != 0)
    return initialPoint; // It has already been calculated.

  // First, we must calculate the correct value of r.  The matrix we return, R,
  // will be r x V, because X = R^T R is of dimension V x V.
  // The rule for calculating r (from Monteiro and Burer, eq. 5) is
  //    r = max(r >= 0 : r (r + 1) / 2 <= m }
  // where m is equal to the number of constraints plus one.
  //
  // Solved, this is
  //   0.5 r^2 + 0.5 r - m = 0
  // which becomes
  //   r = (-0.5 [+/-] sqrt((-0.5)^2 - 4 * -0.5 * m)) / -1
  //   r = 0.5 [+/-] sqrt(0.25 + 2 m)
  // and because m is always positive,
  //   r = 0.5 + sqrt(0.25 + 2m)
  float m = NumConstraints();
  float r = 0.5 + sqrt(0.25 + 2 * m);
  if (ceil(r) > vertices)
    r = vertices; // An upper bound on the dimension.

  initialPoint.set_size(ceil(r), vertices);

  // Now we set the entries of the initial matrix according to the formula given
  // in Section 4 of Monteiro and Burer.
  for (size_t i = 0; i < r; i++)
  {
    for (size_t j = 0; j < (size_t) vertices; j++)
    {
      if (i == j)
        initialPoint(i, j) = sqrt(1.0 / r) + sqrt(1.0 / (vertices * m));
      else
        initialPoint(i, j) = sqrt(1.0 / (vertices * m));
    }
  }

  return initialPoint;
}

} // namespace test
} // namespace ens

#endif
/**
 * @file beale_function.hpp
 * @author Suryoday Basak
 *
 * Definition of the Beale function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_BEALE_FUNCTION_HPP
#define ENSMALLEN_PROBLEMS_BEALE_FUNCTION_HPP

namespace ens {
namespace test {

/**
 * The Beale function, defined by
 *
 * \f[
 * f(x_1,x_2) = (1.5 - x_1 + x_1 * x_2)^2 +
 *              (2.25 - x_1 + x_1 * x_2^2)^2 +
 *              (2.625 - x_1 + x_1 * x_2^3)^2
 * \f]
 *
 * This should optimize to f(x) = 0, at x = [3, 0.5].
 *
 * For more information, please refer to:
 *
 * @code
 * @misc{1307.5838,
 *   Author = {Masoumeh Vali},
 *   Title  = {Rotational Mutation Genetic Algorithm on optimizationProblems},
 *   Year   = {2013},
 *   Eprint = {arXiv:1307.5838},
 * }
 * @endcode
 */
class BealeFunction
{
 public:
  //! Initialize the BealeFunction.
  BealeFunction();

  /**
   * Shuffle the order of function visitation. This may be called by the
   * optimizer.
   */
  void Shuffle();

  //! Return 1 (the number of functions).
  size_t NumFunctions() const { return 1; }

  /**
   * Evaluate a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param batchSize Number of points to process.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates,
                                       const size_t begin,
                                       const size_t batchSize) const;

  /**
   * Evaluate a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates) const;

  /**
   * Evaluate the gradient of a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param gradient The function gradient.
   * @param batchSize Number of points to process.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates,
                const size_t begin,
                GradType& gradient,
                const size_t batchSize) const;

  /**
   * Evaluate the gradient of a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   * @param gradient The function gradient.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates, GradType& gradient);

  // Note: GetInitialPoint(), GetFinalPoint(), and GetFinalObjective() are not
  // required for using ensmallen to optimize this function!  They are
  // specifically used as a convenience just for ensmallen's testing
  // infrastructure.

  //! Get the starting point.
  template<typename MatType = arma::mat>
  MatType GetInitialPoint() const { return MatType("2.8; 0.35"); }

  //! Get the final point.
  template<typename MatType = arma::mat>
  MatType GetFinalPoint() const { return MatType("3.0; 0.5"); }

  //! Get the final objective.
  double GetFinalObjective() const { return 0.0; }
};

} // namespace test
} // namespace ens

// Include implementation.
#include "beale_function_impl.hpp"

#endif // ENSMALLEN_PROBLEMS_BEALE_FUNCTION_HPP
/**
 * @file beale_function_impl.hpp
 * @author Suryoday Basak
 *
 * Implementation of the Beale function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_BEALE_FUNCTION_IMPL_HPP
#define ENSMALLEN_PROBLEMS_BEALE_FUNCTION_IMPL_HPP

// In case it hasn't been included yet.
#include "beale_function.hpp"

namespace ens {
namespace test {

inline BealeFunction::BealeFunction() { /* Nothing to do here */ }

inline void BealeFunction::Shuffle() { /* Nothing to do here */ }

template<typename MatType>
typename MatType::elem_type BealeFunction::Evaluate(
    const MatType& coordinates,
    const size_t /* begin */,
    const size_t /* batchSize */) const
{
  // Convenience typedef.
  typedef typename MatType::elem_type ElemType;

  // For convenience; we assume these temporaries will be optimized out.
  const ElemType x1 = coordinates(0);
  const ElemType x2 = coordinates(1);

  const ElemType objective = std::pow(1.5 - x1 + x1 * x2, 2) +
      std::pow(2.25 - x1 + x1 * x2 * x2, 2) +
      std::pow(2.625 - x1 + x1 * pow(x2, 3), 2);

  return objective;
}

template<typename MatType>
typename MatType::elem_type BealeFunction::Evaluate(
    const MatType& coordinates) const
{
  return Evaluate(coordinates, 0, NumFunctions());
}

template<typename MatType, typename GradType>
inline void BealeFunction::Gradient(const MatType& coordinates,
                                    const size_t /* begin */,
                                    GradType& gradient,
                                    const size_t /* batchSize */) const
{
  // Convenience typedef.
  typedef typename MatType::elem_type ElemType;

  // For convenience; we assume these temporaries will be optimized out.
  const ElemType x1 = coordinates(0);
  const ElemType x2 = coordinates(1);

  // Aliases for different terms in the expression of the gradient.
  const ElemType x2Sq = x2 * x2;
  const ElemType x2Cub = pow(x2, 3);

  gradient.set_size(2, 1);
  gradient(0) = ((2 * x2 - 2) * (x1 * x2 - x1 + 1.5)) +
      ((2 * x2Sq - 2) * (x1 * x2Sq - x1 + 2.25)) +
      ((2 * x2Cub - 2) * (x1 * x2Cub - x1 + 2.625));
  gradient(1) = (6 * x1 * x2Sq * (x1 * x2Cub - x1 + 2.625)) +
      (4 * x1 * x2 * (x1 * x2Sq - x1 + 2.25)) +
      (2 * x1 * (x1 * x2 - x1 + 1.5));
}

template<typename MatType, typename GradType>
inline void BealeFunction::Gradient(const MatType& coordinates,
                                    GradType& gradient)
{
  Gradient(coordinates, 0, gradient, 1);
}

} // namespace test
} // namespace ens

#endif
/**
 * @file booth_function.hpp
 * @author Marcus Edel
 *
 * Definition of the Booth function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_BOOTH_FUNCTION_HPP
#define ENSMALLEN_PROBLEMS_BOOTH_FUNCTION_HPP

namespace ens {
namespace test {

/**
 * The Booth function, defined by
 *
 * \f[
 * f(x) = (x_1 + 2x_2 - 7)^2 + (2x_1 + x_2 - 5)^2
 * \f]
 *
 * This should optimize to f(x) = 0, at x = [1, 3].
 *
 * For more information, please refer to:
 *
 * @code
 * @article{Jamil2013,
 *   title   = {A Literature Survey of Benchmark Functions For Global
 *              Optimization Problems},
 *   author  = {Momin Jamil and Xin{-}She Yang},
 *   journal = {CoRR},
 *   year    = {2013},
 *   url     = {http://arxiv.org/abs/1308.4008}
 * }
 * @endcode
 */
class BoothFunction
{
 public:
  //! Initialize the BoothFunction.
  BoothFunction();

  /**
   * Shuffle the order of function visitation. This may be called by the
   * optimizer.
   */
  void Shuffle();

  //! Return 1 (the number of functions).
  size_t NumFunctions() const { return 1; }

  /**
   * Evaluate a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param batchSize Number of points to process.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates,
                                       const size_t begin,
                                       const size_t batchSize) const;

  /**
   * Evaluate a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates) const;

  /**
   * Evaluate the gradient of a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param gradient The function gradient.
   * @param batchSize Number of points to process.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates,
                const size_t begin,
                GradType& gradient,
                const size_t batchSize) const;

  /**
   * Evaluate the gradient of a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   * @param gradient The function gradient.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates, GradType& gradient);

  // Note: GetInitialPoint(), GetFinalPoint(), and GetFinalObjective() are not
  // required for using ensmallen to optimize this function!  They are
  // specifically used as a convenience just for ensmallen's testing
  // infrastructure.

  //! Get the starting point.
  template<typename MatType = arma::mat>
  MatType GetInitialPoint() const { return MatType("-9; -9"); }

  //! Get the final point.
  template<typename MatType = arma::mat>
  MatType GetFinalPoint() const { return MatType("1.0; 3.0"); }

  //! Get the final objective.
  double GetFinalObjective() const { return 0.0; }
};

} // namespace test
} // namespace ens

// Include implementation.
#include "booth_function_impl.hpp"

#endif // ENSMALLEN_PROBLEMS_BOOTH_FUNCTION_HPP
/**
 * @file booth_function_impl.hpp
 * @author Marcus Edel
 *
 * Implementation of the Booth function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_BOOTH_FUNCTION_IMPL_HPP
#define ENSMALLEN_PROBLEMS_BOOTH_FUNCTION_IMPL_HPP

// In case it hasn't been included yet.
#include "booth_function.hpp"

namespace ens {
namespace test {

inline BoothFunction::BoothFunction() { /* Nothing to do here */ }

inline void BoothFunction::Shuffle() { /* Nothing to do here */ }

template<typename MatType>
typename MatType::elem_type BoothFunction::Evaluate(
    const MatType& coordinates,
    const size_t /* begin */,
    const size_t /* batchSize */) const
{
  // Convenience typedef.
  typedef typename MatType::elem_type ElemType;

  // For convenience; we assume these temporaries will be optimized out.
  const ElemType x1 = coordinates(0);
  const ElemType x2 = coordinates(1);

  const ElemType objective = std::pow(x1 + 2 * x2 - 7, 2) +
      std::pow(2 * x1 + x2 - 5, 2);

  return objective;
}

template<typename MatType>
typename MatType::elem_type BoothFunction::Evaluate(
    const MatType& coordinates) const
{
  return Evaluate(coordinates, 0, NumFunctions());
}

template<typename MatType, typename GradType>
inline void BoothFunction::Gradient(const MatType& coordinates,
                                    const size_t /* begin */,
                                    GradType& gradient,
                                    const size_t /* batchSize */) const
{
  // Convenience typedef.
  typedef typename MatType::elem_type ElemType;

  // For convenience; we assume these temporaries will be optimized out.
  const ElemType x1 = coordinates(0);
  const ElemType x2 = coordinates(1);

  gradient.set_size(2, 1);
  gradient(0) = 10 * x1 + 8 * x2 - 34;
  gradient(1) = 8 * x1 + 10 * x2 - 38;
}

template<typename MatType, typename GradType>
inline void BoothFunction::Gradient(const MatType& coordinates,
                                    GradType& gradient)
{
  Gradient(coordinates, 0, gradient, 1);
}

} // namespace test
} // namespace ens

#endif
/**
 * @file bukin_function.hpp
 * @author Marcus Edel
 *
 * Definition of the Booth function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_BUKIN_FUNCTION_HPP
#define ENSMALLEN_PROBLEMS_BUKIN_FUNCTION_HPP

namespace ens {
namespace test {

/**
 * The Bukin function, defined by
 *
 * \f[
 * f(x) = 100 * \sqrt(\left|x_2 - 0.01 * x_1^2 \right|) +
 *    0.01 * \left|x_1 + 10 \right|
 * \f]
 *
 * This should optimize to f(x) = 0, at x = [-10, 1].
 *
 * For more information, please refer to:
 *
 * @code
 * @article{Jamil2013,
 *   title   = {A Literature Survey of Benchmark Functions For Global
 *              Optimization Problems},
 *   author  = {Momin Jamil and Xin{-}She Yang},
 *   journal = {CoRR},
 *   year    = {2013},
 *   url     = {http://arxiv.org/abs/1308.4008}
 * }
 * @endcode
 */
class BukinFunction
{
 public:
  /**
   * Initialize the BukinFunction.
   *
   * @param epsilon Coefficient to avoid division by zero (numerical stability).
   */
  BukinFunction(const double epsilon = 1e-8);

  /**
   * Shuffle the order of function visitation. This may be called by the
   * optimizer.
   */
  void Shuffle();

  //! Return 1 (the number of functions).
  size_t NumFunctions() const { return 1; }

  /**
   * Evaluate a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param batchSize Number of points to process.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates,
                                       const size_t begin,
                                       const size_t batchSize) const;

  /**
   * Evaluate a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates) const;

  /**
   * Evaluate the gradient of a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param gradient The function gradient.
   * @param batchSize Number of points to process.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates,
                const size_t begin,
                GradType& gradient,
                const size_t batchSize) const;

  /**
   * Evaluate the gradient of a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   * @param gradient The function gradient.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates, GradType& gradient);

  //! Get the value used for numerical stability.
  double Epsilon() const { return epsilon; }
  //! Modify the value used for numerical stability.
  double& Epsilon() { return epsilon; }

  // Note: GetInitialPoint(), GetFinalPoint(), and GetFinalObjective() are not
  // required for using ensmallen to optimize this function!  They are
  // specifically used as a convenience just for ensmallen's testing
  // infrastructure.

  //! Get the starting point.
  template<typename MatType = arma::mat>
  MatType GetInitialPoint() const { return MatType("-10; -2.0"); }

  //! Get the final point.
  template<typename MatType = arma::mat>
  MatType GetFinalPoint() const { return MatType("-10.0; 1.0"); }

  //! Get the final objective.
  double GetFinalObjective() const { return 0.0; }

 private:
  //! The value used for numerical stability.
  double epsilon;
};

} // namespace test
} // namespace ens

// Include implementation.
#include "bukin_function_impl.hpp"

#endif // ENSMALLEN_PROBLEMS_BUKIN_FUNCTION_HPP
/**
 * @file bukin_function_impl.hpp
 * @author Marcus Edel
 *
 * Implementation of the Bukin function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_BUKIN_FUNCTION_IMPL_HPP
#define ENSMALLEN_PROBLEMS_BUKIN_FUNCTION_IMPL_HPP

// In case it hasn't been included yet.
#include "bukin_function.hpp"

namespace ens {
namespace test {

inline BukinFunction::BukinFunction(const double epsilon) : epsilon(epsilon)
{ /* Nothing to do here */ }

inline void BukinFunction::Shuffle() { /* Nothing to do here */ }

template<typename MatType>
typename MatType::elem_type BukinFunction::Evaluate(
    const MatType& coordinates,
    const size_t /* begin */,
    const size_t /* batchSize */) const
{
  // Convenience typedef.
  typedef typename MatType::elem_type ElemType;

  // For convenience; we assume these temporaries will be optimized out.
  const ElemType x1 = coordinates(0);
  const ElemType x2 = coordinates(1);

  const ElemType objective = 100 * std::sqrt(std::abs(x2 - 0.01 *
      std::pow(x1, 2))) + 0.01 * std::abs(x1 + 10);

  return objective;
}

template<typename MatType>
typename MatType::elem_type BukinFunction::Evaluate(
    const MatType& coordinates) const
{
  return Evaluate(coordinates, 0, NumFunctions());
}

template<typename MatType, typename GradType>
inline void BukinFunction::Gradient(const MatType& coordinates,
                                    const size_t /* begin */,
                                    GradType& gradient,
                                    const size_t /* batchSize */) const
{
  // Convenience typedef.
  typedef typename MatType::elem_type ElemType;

  // For convenience; we assume these temporaries will be optimized out.
  const ElemType x1 = coordinates(0);
  const ElemType x2 = coordinates(1);

  gradient.set_size(2, 1);
  gradient(0) = (0.01 * (x1 + 10.0)) / (std::abs(x1 + 10.0) + epsilon) -
      (x1 * (x2 - 0.01 * std::pow(x1, 2))) / std::pow(std::abs(x2 - 0.01 *
      std::pow(x1, 2)), 1.5);
  gradient(1) = (50 * (x2 - 0.01 * std::pow(x1, 2))) /
      std::pow(std::abs(x2 - 0.01 * std::pow(x1, 2)), 1.5);
}

template<typename MatType, typename GradType>
inline void BukinFunction::Gradient(const MatType& coordinates,
                                    GradType& gradient)
{
  Gradient(coordinates, 0, gradient, NumFunctions());
}

} // namespace test
} // namespace ens

#endif
/**
 * @file colville_function.hpp
 * @author Marcus Edel
 *
 * Definition of the Colville function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_COLVILLE_FUNCTION_HPP
#define ENSMALLEN_PROBLEMS_COLVILLE_FUNCTION_HPP

namespace ens {
namespace test {

/**
 * The Colville function, defined by
 *
 * \f[
 * f(x) = 100(x_1^2 - x_2)^2 + (x_1 - 1)^2 + (x_3 - 1)^2 + 90 * (x_3^2 - x_4)^2
 *    + 10.1 * ((x_2-1)^2 + (x_4 - 1)^2) + 19.8 * (x_2 - 1) * (x_4 - 1)
 * \f]
 *
 * This should optimize to f(x) = 0, at x = [1, 1, 1, 1].
 *
 * For more information, please refer to:
 *
 * @code
 * @article{Jamil2013,
 *   title   = {A Literature Survey of Benchmark Functions For Global
 *              Optimization Problems},
 *   author  = {Momin Jamil and Xin{-}She Yang},
 *   journal = {CoRR},
 *   year    = {2013},
 *   url     = {http://arxiv.org/abs/1308.4008}
 * }
 * @endcode
 */
class ColvilleFunction
{
 public:
  //! Initialize the ColvilleFunction.
  ColvilleFunction();

  /**
   * Shuffle the order of function visitation. This may be called by the
   * optimizer.
   */
  void Shuffle();

  //! Return 1 (the number of functions).
  size_t NumFunctions() const { return 1; }

  /**
   * Evaluate a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param batchSize Number of points to process.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates,
                                       const size_t begin,
                                       const size_t batchSize) const;

  /**
   * Evaluate a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates) const;

  /**
   * Evaluate the gradient of a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param gradient The function gradient.
   * @param batchSize Number of points to process.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates,
                const size_t begin,
                GradType& gradient,
                const size_t batchSize) const;

  /**
   * Evaluate the gradient of a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   * @param gradient The function gradient.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates, GradType& gradient) const;

  // Note: GetInitialPoint(), GetFinalPoint(), and GetFinalObjective() are not
  // required for using ensmallen to optimize this function!  They are
  // specifically used as a convenience just for ensmallen's testing
  // infrastructure.

  //! Get the starting point.
  template<typename MatType = arma::mat>
  MatType GetInitialPoint() const { return MatType("-5; 3; 1; -9"); }

  //! Get the final point.
  template<typename MatType = arma::mat>
  MatType GetFinalPoint() const { return MatType("1; 1; 1; 1"); }

  //! Get the final objective.
  double GetFinalObjective() const { return 0.0; }
};

} // namespace test
} // namespace ens

// Include implementation.
#include "colville_function_impl.hpp"

#endif // ENSMALLEN_PROBLEMS_COLVILLE_FUNCTION_HPP
/**
 * @file colville_function_impl.hpp
 * @author Marcus Edel
 *
 * Implementation of the Coville function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_COLVILLE_FUNCTION_IMPL_HPP
#define ENSMALLEN_PROBLEMS_COLVILLE_FUNCTION_IMPL_HPP

// In case it hasn't been included yet.
#include "colville_function.hpp"

namespace ens {
namespace test {

inline ColvilleFunction::ColvilleFunction() { /* Nothing to do here */ }

inline void ColvilleFunction::Shuffle() { /* Nothing to do here */ }

template<typename MatType>
typename MatType::elem_type ColvilleFunction::Evaluate(
    const MatType& coordinates,
    const size_t /* begin */,
    const size_t /* batchSize */) const
{
  // Convenience typedef.
  typedef typename MatType::elem_type ElemType;

  // For convenience; we assume these temporaries will be optimized out.
  const ElemType x1 = coordinates(0);
  const ElemType x2 = coordinates(1);
  const ElemType x3 = coordinates(2);
  const ElemType x4 = coordinates(3);

  const ElemType objective = 100 * std::pow(std::pow(x1, 2) - x2, 2) +
      std::pow(x1 - 1, 2) + std::pow(x3 - 1, 2) + 90 *
      std::pow(std::pow(x3, 2) - x4, 2) + 10.1 * (std::pow(x2 - 1, 2) +
      std::pow(x4 - 1, 2)) + 19.8 * (x2 - 1) * (x4 - 1);

  return objective;
}

template<typename MatType>
typename MatType::elem_type ColvilleFunction::Evaluate(
    const MatType& coordinates) const
{
  return Evaluate(coordinates, 0, NumFunctions());
}

template<typename MatType, typename GradType>
inline void ColvilleFunction::Gradient(const MatType& coordinates,
                                       const size_t /* begin */,
                                       GradType& gradient,
                                       const size_t /* batchSize */) const
{
  // Convenience typedef.
  typedef typename MatType::elem_type ElemType;

  // For convenience; we assume these temporaries will be optimized out.
  const ElemType x1 = coordinates(0);
  const ElemType x2 = coordinates(1);
  const ElemType x3 = coordinates(2);
  const ElemType x4 = coordinates(3);

  gradient.set_size(4, 1);
  gradient(0) = 2 * (200 * x1 * (std::pow(x1, 2) - x2) + x1 - 1);
  gradient(1) = 19.8 * x4 - 200 * std::pow(x1, 2) + 220.2 * x2 - 40;
  gradient(2) = 2 * (180 * x3 * (std::pow(x3, 2) - x4) + x3 - 1);
  gradient(3) = 200.2 * x4 + 19.8 * x2 - 180 * std::pow(x3, 2) - 40;
}

template<typename MatType, typename GradType>
inline void ColvilleFunction::Gradient(const MatType& coordinates,
                                       GradType& gradient) const
{
  Gradient(coordinates, 0, gradient, NumFunctions());
}

} // namespace test
} // namespace ens

#endif
/**
 * @file cross_in_tray_function.hpp
 * @author Suryoday Basak
 *
 * Definition of the Cross-in-Tray function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_CROSS_IN_TRAY_FUNCTION_HPP
#define ENSMALLEN_PROBLEMS_CROSS_IN_TRAY_FUNCTION_HPP

namespace ens {
namespace test {

/**
 * The Cross-in-Tray function, defined by
 *
 * \f[
 * f(x1, x2) = - 0.0001 * (|sin(x1) * sin(x2) *
 *               exp(|100 - (sqrt(x1^2 + x2^2) / pi)|)| + 1)^0.1
 * \f]
 *
 * This should optimize to f(x1, x2) = -2.06261, at
 *                                (x1, x2) = [1.34941, -1.34941], or
 *                                (x1, x2) = [1.34941, 1.34941],  or
 *                                (x1, x2) = [-1.34941, 1.34941], or
 *                                (x1, x2) = [-1.34941, -1.34941]
 *
 * For more information, please refer to:
 *
 * @code
 * @article{1308.4008,
 *   Author = {Momin Jamil and Xin-She Yang},
 *   Title  = {A Literature Survey of Benchmark Functions For Global
 *             Optimization Problems},
 *   Year   = {2013},
 *   Eprint = {arXiv:1308.4008},
 *   Doi    = {10.1504/IJMMNO.2013.055204},
 * }
 * @endcode
 */
class CrossInTrayFunction
{
 public:
  //! Initialize the CrossInTrayFunction.
  CrossInTrayFunction();

  /**
   * Shuffle the order of function visitation. This may be called by the
   * optimizer.
   */
  void Shuffle();

  //! Return 1 (the number of functions).
  size_t NumFunctions() const { return 1; }

  /*
   * Evaluate a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param batchSize Number of points to process.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates,
                                       const size_t begin,
                                       const size_t batchSize) const;

  /*
   * Evaluate a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates) const;

  // Note: GetInitialPoint() is not required for using ensmallen to optimize
  // this function!  It is specifically used as a convenience just for
  // ensmallen's testing infrastructure.

  //! Get the starting point.
  template<typename MatType = arma::mat>
  MatType GetInitialPoint() const { return MatType("0; 0"); }
};

} // namespace test
} // namespace ens

// Include implementation.
#include "cross_in_tray_function_impl.hpp"

#endif // ENSMALLEN_PROBLEMS_CROSS_IN_TRAY_FUNCTION_HPP
/**
 * @file cross_in_tray_function_impl.hpp
 * @author Suryoday Basak
 *
 * Implementation of the Cross-in-Tray function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_CROSS_IN_TRAY_FUNCTION_IMPL_HPP
#define ENSMALLEN_PROBLEMS_CROSS_IN_TRAY_FUNCTION_IMPL_HPP

// In case it hasn't been included yet.
#include "cross_in_tray_function.hpp"

namespace ens {
namespace test {

inline CrossInTrayFunction::CrossInTrayFunction() { /* Nothing to do here */ }

inline void CrossInTrayFunction::Shuffle() { /* Nothing to do here */ }

template<typename MatType>
typename MatType::elem_type CrossInTrayFunction::Evaluate(
    const MatType& coordinates,
    const size_t /* begin */,
    const size_t /* batchSize */) const
{
  // Convenience typedef.
  typedef typename MatType::elem_type ElemType;

  // For convenience; we assume these temporaries will be optimized out.
  const ElemType x1 = coordinates(0);
  const ElemType x2 = coordinates(1);

  const ElemType objective = -0.0001 * std::pow(std::abs(std::sin(x1) *
      std::sin(x2) * std::exp(std::abs(100 - (std::sqrt(std::pow(x1, 2) +
      std::pow(x2, 2)) / arma::datum::pi))) + 1), 0.1);
  return objective;
}

template<typename MatType>
typename MatType::elem_type CrossInTrayFunction::Evaluate(
    const MatType& coordinates) const
{
  return Evaluate(coordinates, 0, NumFunctions());
}

} // namespace test
} // namespace ens

#endif
/**
 * @file drop_wave_function.hpp
 * @author Marcus Edel
 *
 * Definition of the Drop-Wave function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_DROP_WAVE_FUNCTION_HPP
#define ENSMALLEN_PROBLEMS_DROP_WAVE_FUNCTION_HPP

namespace ens {
namespace test {

/**
 * The Drop-Wave function, defined by
 *
 * \f[
 * f(x) = - (1 + \cos(12 * \sqrt(x_1^2 + x_2^2))) / (0.5 * (x_1^2 + x_2^2) + 2)
 * \f]
 *
 * This should optimize to f(x) = 0, at x = [0, 0].
 *
 * For more information, please refer to:
 *
 * @code
 * @article{Jamil2013,
 *   title   = {A Literature Survey of Benchmark Functions For Global
 *              Optimization Problems},
 *   author  = {Momin Jamil and Xin{-}She Yang},
 *   journal = {CoRR},
 *   year    = {2013},
 *   url     = {http://arxiv.org/abs/1308.4008}
 * }
 * @endcode
 */
class DropWaveFunction
{
 public:
  //! Initialize the DropWaveFunction.
  DropWaveFunction();

  /**
   * Shuffle the order of function visitation. This may be called by the
   * optimizer.
   */
  void Shuffle();

  //! Return 1 (the number of functions).
  size_t NumFunctions() const { return 1; }

  /**
   * Evaluate a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param batchSize Number of points to process.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates,
                                       const size_t begin,
                                       const size_t batchSize) const;

  /**
   * Evaluate a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates) const;

  /**
   * Evaluate the gradient of a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param gradient The function gradient.
   * @param batchSize Number of points to process.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates,
                const size_t begin,
                GradType& gradient,
                const size_t batchSize) const;

  /**
   * Evaluate the gradient of a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   * @param gradient The function gradient.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates, GradType& gradient);

  // Note: GetInitialPoint(), GetFinalPoint(), and GetFinalObjective() are not
  // required for using ensmallen to optimize this function!  They are
  // specifically used as a convenience just for ensmallen's testing
  // infrastructure.

  //! Get the starting point.
  template<typename MatType = arma::mat>
  MatType GetInitialPoint() const { return MatType("0.5; 0.5"); }

  //! Get the final point.
  template<typename MatType = arma::mat>
  MatType GetFinalPoint() const { return MatType("0.0; 0.0"); }

  //! Get the final objective.
  double GetFinalObjective() const { return 0.0; }
};

} // namespace test
} // namespace ens

// Include implementation.
#include "drop_wave_function_impl.hpp"

#endif // ENSMALLEN_PROBLEMS_DROP_WAVE_FUNCTION_HPP
/**
 * @file drop_wave_function_impl.hpp
 * @author Marcus Edel
 *
 * Implementation of the Drop-Wave function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_DROP_WAVE_FUNCTION_IMPL_HPP
#define ENSMALLEN_PROBLEMS_DROP_WAVE_FUNCTION_IMPL_HPP

// In case it hasn't been included yet.
#include "drop_wave_function.hpp"

namespace ens {
namespace test {

inline DropWaveFunction::DropWaveFunction() { /* Nothing to do here */ }

inline void DropWaveFunction::Shuffle() { /* Nothing to do here */ }

template<typename MatType>
typename MatType::elem_type DropWaveFunction::Evaluate(
    const MatType& coordinates,
    const size_t /* begin */,
    const size_t /* batchSize */) const
{
  // Convenience typedef.
  typedef typename MatType::elem_type ElemType;

  // For convenience; we assume these temporaries will be optimized out.
  const ElemType x1 = coordinates(0);
  const ElemType x2 = coordinates(1);

  const ElemType objective = -1.0 * (1.0 + std::cos(12.0 *
      std::sqrt(std::pow(x1, 2) + std::pow(x2, 2)))) /
      (0.5 * (std::pow(x1, 2) + std::pow(x2, 2)) + 2.0);

  return objective;
}

template<typename MatType>
typename MatType::elem_type DropWaveFunction::Evaluate(
    const MatType& coordinates) const
{
  return Evaluate(coordinates, 0, 1);
}

template<typename MatType, typename GradType>
inline void DropWaveFunction::Gradient(const MatType& coordinates,
                                       const size_t /* begin */,
                                       GradType& gradient,
                                       const size_t /* batchSize */) const
{
  // Convenience typedef.
  typedef typename MatType::elem_type ElemType;

  // For convenience; we assume these temporaries will be optimized out.
  const ElemType x1 = coordinates(0);
  const ElemType x2 = coordinates(1);

  gradient.set_size(2, 1);
  gradient(0) = (12.0 * x1 * std::sin(12.0 * std::sqrt(std::pow(x1, 2) +
      std::pow(x2, 2)))) / (std::sqrt(std::pow(x1, 2) + std::pow(x2, 2)) *
      (0.5 * (std::pow(x1, 2) + std::pow(x2, 2)) + 2)) -
      (x1 * (-1.0 * std::cos(12.0 * std::sqrt(std::pow(x1, 2) +
      std::pow(x2, 2))) -1.0)) / std::pow(0.5 *
      (std::pow(x1, 2) + std::pow(x2, 2)) + 2, 2);

  gradient(1) = (12.0 * x2 * std::sin(12.0 * std::sqrt(std::pow(x1, 2) +
      std::pow(x2, 2)))) / (std::sqrt(std::pow(x1, 2) + std::pow(x2, 2)) *
      (0.5 * (std::pow(x1, 2) + std::pow(x2, 2)) + 2)) -
      (x2 * (-1.0 * std::cos(12.0 * std::sqrt(std::pow(x1, 2) +
      std::pow(x2, 2))) -1.0)) / std::pow(0.5 *
      (std::pow(x1, 2) + std::pow(x2, 2)) + 2, 2);
}

template<typename MatType, typename GradType>
inline void DropWaveFunction::Gradient(const MatType& coordinates,
                                       GradType& gradient)
{
  Gradient(coordinates, 0, gradient, 1);
}

} // namespace test
} // namespace ens

#endif
/**
 * @file easom_function.hpp
 * @author Marcus Edel
 *
 * Definition of the Booth function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_EASOM_FUNCTION_HPP
#define ENSMALLEN_PROBLEMS_EASOM_FUNCTION_HPP

namespace ens {
namespace test {

/**
 * The Easom function, defined by
 *
 * \f[
 * f(x) = -1.0 * \cos(x_1) * \cos(x_2) * \exp(-(x_1 - \pi)^2 - (x_2 - \pi)^2)
 * \f]
 *
 * This should optimize to f(x) = -1, at x = [3.14, 3.14].
 *
 * For more information, please refer to:
 *
 * @code
 * @article{Jamil2013,
 *   title   = {A Literature Survey of Benchmark Functions For Global
 *              Optimization Problems},
 *   author  = {Momin Jamil and Xin{-}She Yang},
 *   journal = {CoRR},
 *   year    = {2013},
 *   url     = {http://arxiv.org/abs/1308.4008}
 * }
 * @endcode
 */
class EasomFunction
{
 public:
  //! Initialize the EasomFunction.
  EasomFunction();

  /**
   * Shuffle the order of function visitation. This may be called by the
   * optimizer.
   */
  void Shuffle();

  //! Return 1 (the number of functions).
  size_t NumFunctions() const { return 1; }

  /**
   * Evaluate a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param batchSize Number of points to process.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates,
                                       const size_t begin,
                                       const size_t batchSize) const;

  /**
   * Evaluate a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates) const;

  /**
   * Evaluate the gradient of a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param gradient The function gradient.
   * @param batchSize Number of points to process.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates,
                const size_t begin,
                GradType& gradient,
                const size_t batchSize) const;

  /**
   * Evaluate the gradient of a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   * @param gradient The function gradient.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates, GradType& gradient);

  // Note: GetInitialPoint(), GetFinalPoint(), and GetFinalObjective() are not
  // required for using ensmallen to optimize this function!  They are
  // specifically used as a convenience just for ensmallen's testing
  // infrastructure.

  //! Get the starting point.
  template<typename MatType = arma::mat>
  MatType GetInitialPoint() const { return MatType("2.9; 2.9"); }

  //! Get the final point.
  template<typename MatType = arma::mat>
  MatType GetFinalPoint() const { return MatType("3.14; 3.14"); }

  //! Get the final objective.
  double GetFinalObjective() const { return -1.0; }
};

} // namespace test
} // namespace ens

// Include implementation.
#include "easom_function_impl.hpp"

#endif // ENSMALLEN_PROBLEMS_EASOM_FUNCTION_HPP
/**
 * @file easom_function_impl.hpp
 * @author Marcus Edel
 *
 * Implementation of the Easom function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_EASOM_FUNCTION_IMPL_HPP
#define ENSMALLEN_PROBLEMS_EASOM_FUNCTION_IMPL_HPP

// In case it hasn't been included yet.
#include "easom_function.hpp"

namespace ens {
namespace test {

inline EasomFunction::EasomFunction() { /* Nothing to do here */ }

inline void EasomFunction::Shuffle() { /* Nothing to do here */ }

template<typename MatType>
typename MatType::elem_type EasomFunction::Evaluate(
    const MatType& coordinates,
    const size_t /* begin */,
    const size_t /* batchSize */) const
{
  // Convenience typedef.
  typedef typename MatType::elem_type ElemType;

  // For convenience; we assume these temporaries will be optimized out.
  const ElemType x1 = coordinates(0);
  const ElemType x2 = coordinates(1);

  const ElemType objective = -std::cos(x1) * std::cos(x2) *
      std::exp(-1.0 * std::pow(x1 - arma::datum::pi, 2) -
                      std::pow(x2 - arma::datum::pi, 2));

  return objective;
}

template<typename MatType>
typename MatType::elem_type EasomFunction::Evaluate(
    const MatType& coordinates) const
{
  return Evaluate(coordinates, 0, NumFunctions());
}

template<typename MatType, typename GradType>
inline void EasomFunction::Gradient(const MatType& coordinates,
                                    const size_t /* begin */,
                                    GradType& gradient,
                                    const size_t /* batchSize */) const
{
  // Convenience typedef.
  typedef typename MatType::elem_type ElemType;

  // For convenience; we assume these temporaries will be optimized out.
  const ElemType x1 = coordinates(0);
  const ElemType x2 = coordinates(1);

  gradient.set_size(2, 1);
  gradient(0) = 2 * (x1 - arma::datum::pi) *
      std::exp(-1.0 * std::pow(x1 - arma::datum::pi, 2) -
                      std::pow(x2 - arma::datum::pi, 2)) *
      std::cos(x1) * std::cos(x2) +
      std::exp(-1.0 * std::pow(x1 - arma::datum::pi, 2) -
                      std::pow(x2 -  arma::datum::pi, 2)) *
      std::sin(x1) * std::cos(x2);

  gradient(1) = 2 * (x2 - arma::datum::pi) *
      std::exp(-1.0 * std::pow(x1 - arma::datum::pi, 2) -
                      std::pow(x2 - arma::datum::pi, 2)) *
      std::cos(x1) * std::cos(x2) +
      std::exp(-1.0 * std::pow(x1 - arma::datum::pi, 2) -
                      std::pow(x2 - arma::datum::pi, 2)) *
      std::cos(x1) * std::sin(x2);
}

template<typename MatType, typename GradType>
inline void EasomFunction::Gradient(const MatType& coordinates,
                                    GradType& gradient)
{
  Gradient(coordinates, 0, gradient, NumFunctions());
}

} // namespace test
} // namespace ens

#endif
/**
 * @file eggholder_function.hpp
 * @author Marcus Edel
 *
 * Definition of the Eggholder function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_EGGHOLDER_FUNCTION_HPP
#define ENSMALLEN_PROBLEMS_EGGHOLDER_FUNCTION_HPP

namespace ens {
namespace test {

/**
 * The Eggholder function, defined by
 *
 * \f[
 * f(x) = -(x_2 + 47) * \sin(\sqrt(\left|x_2 + x_1 / 2 + 47\right|)) - x_1 *
 *    \sin(\sqrt(\left|x_1-(x_2 + 47)\right|))
 * \f]
 *
 * This should optimize to f(x) = -959.6407, at x = [512, 404.2319].
 *
 * For more information, please refer to:
 *
 * @code
 * @article{Jamil2013,
 *   title   = {A Literature Survey of Benchmark Functions For Global
 *              Optimization Problems},
 *   author  = {Momin Jamil and Xin{-}She Yang},
 *   journal = {CoRR},
 *   year    = {2013},
 *   url     = {http://arxiv.org/abs/1308.4008}
 * }
 * @endcode
 */
class EggholderFunction
{
 public:
  //! Initialize the EggholderFunction.
  EggholderFunction();

  /**
   * Shuffle the order of function visitation. This may be called by the
   * optimizer.
   */
  void Shuffle();

  //! Return 1 (the number of functions).
  size_t NumFunctions() const { return 1; }

  /**
   * Evaluate a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param batchSize Number of points to process.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates,
                                       const size_t begin,
                                       const size_t batchSize) const;

  /**
   * Evaluate a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates) const;

  /**
   * Evaluate the gradient of a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param gradient The function gradient.
   * @param batchSize Number of points to process.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates,
                const size_t begin,
                GradType& gradient,
                const size_t batchSize) const;

  /**
   * Evaluate the gradient of a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   * @param gradient The function gradient.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates, GradType& gradient);

  // Note: GetInitialPoint(), GetFinalPoint(), and GetFinalObjective() are not
  // required for using ensmallen to optimize this function!  They are
  // specifically used as a convenience just for ensmallen's testing
  // infrastructure.

  //! Get the starting point.
  template<typename MatType = arma::mat>
  MatType GetInitialPoint() const { return MatType("-333; -333"); }

  //! Get the final point.
  template<typename MatType = arma::mat>
  MatType GetFinalPoint() const { return MatType("512; 404.2319"); }

  //! Get the final objective.
  double GetFinalObjective() const { return -959.6407; }
};

} // namespace test
} // namespace ens

// Include implementation.
#include "eggholder_function_impl.hpp"

#endif // ENSMALLEN_PROBLEMS_EGGHOLDER_FUNCTION_HPP
/**
 * @file eggholder_function_impl.hpp
 * @author Marcus Edel
 *
 * Implementation of the Eggholder function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_EGGHOLDER_FUNCTION_IMPL_HPP
#define ENSMALLEN_PROBLEMS_EGGHOLDER_FUNCTION_IMPL_HPP

// In case it hasn't been included yet.
#include "eggholder_function.hpp"

namespace ens {
namespace test {

inline EggholderFunction::EggholderFunction() { /* Nothing to do here */ }

inline void EggholderFunction::Shuffle() { /* Nothing to do here */ }

template<typename MatType>
typename MatType::elem_type EggholderFunction::Evaluate(
    const MatType& coordinates,
    const size_t /* begin */,
    const size_t /* batchSize */) const
{
  // Convenience typedef.
  typedef typename MatType::elem_type ElemType;

  // For convenience; we assume these temporaries will be optimized out.
  const ElemType x1 = coordinates(0);
  const ElemType x2 = coordinates(1);

  const ElemType objective = -1.0 * (x2 + 47) * std::sin(std::sqrt(
      std::abs(x2 + x1 / 2 + 47))) - x1 * std::sin(std::sqrt(
      std::abs(x1 - (x2 + 47))));

  return objective;
}

template<typename MatType>
typename MatType::elem_type EggholderFunction::Evaluate(
    const MatType& coordinates) const
{
  return Evaluate(coordinates, 0, NumFunctions());
}

template<typename MatType, typename GradType>
inline void EggholderFunction::Gradient(const MatType& coordinates,
                                        const size_t /* begin */,
                                        GradType& gradient,
                                        const size_t /* batchSize */) const
{
  // Convenience typedef.
  typedef typename MatType::elem_type ElemType;

  // For convenience; we assume these temporaries will be optimized out.
  const ElemType x1 = coordinates(0);
  const ElemType x2 = coordinates(1);

  gradient.set_size(2, 1);
  gradient(0) = -1.0 * std::sin(std::sqrt(std::abs(x1 - x2 - 47))) -
      (x1 * (x1 - x2 - 47) * std::cos(std::sqrt(std::abs(x1 - x2 - 47)))) /
      std::pow(2 * std::abs(x1 - x2 - 47), 1.5) -
      ((x1 + 47) * (x1 / 2 + x2 + 47) *
      std::cos(std::sqrt(std::abs(x1 / 2 + x2  + 47)))) /
      (4 * std::pow(std::abs(x1 / 2 + x2  + 47), 1.5));

  gradient(1) = -1.0 * std::sin(std::sqrt(std::abs(x1 / 2 + x2 + 47))) -
      (x1 * (x1 - x2 - 47) * std::cos(std::sqrt(std::abs(x1 - x2 - 47)))) /
      std::pow(2 * std::abs(x1 - x2 - 47), 1.5) -
      ((x1 + 47) * (x1 / 2 + x2 + 47) *
      std::cos(std::sqrt(std::abs(x1 / 2 + x2  + 47)))) /
      (4 * std::pow(std::abs(x1 / 2 + x2  + 47), 1.5));
}

template<typename MatType, typename GradType>
inline void EggholderFunction::Gradient(const MatType& coordinates,
                                        GradType& gradient)
{
  Gradient(coordinates, 0, gradient, NumFunctions());
}

} // namespace test
} // namespace ens

#endif
/**
 * @file fonseca_fleming_function_n1.hpp
 * @author Sayan Goswami
 *
 * Implementation of Fonseca Fleming function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */

#ifndef ENSMALLEN_PROBLEMS_FONSECA_FLEEMING_FUNCTION_HPP
#define ENSMALLEN_PROBLEMS_FONSECA_FLEEMING_FUNCTION_HPP

#include <tuple>

namespace ens {
namespace test {

/**
 * The Fonseca Fleming function N.1 is defined by
 *
 * \f[
 * f_{1}\left(\boldsymbol{x}\right) = 1 - \exp \left[-\sum_{i=1}^{3} \left(x_{i} - \frac{1}{\sqrt{n}} \right)^{2} \right] \\
 * f_{2}\left(\boldsymbol{x}\right) = 1 - \exp \left[-\sum_{i=1}^{3} \left(x_{i} + \frac{1}{\sqrt{n}} \right)^{2} \right] \\
 * \f]
 *
 * The optimal solutions to this multi-objective function lie in the
 * range [-1/sqrt(3), 1/sqrt(3)].
 *
 * @tparam arma::mat Type of matrix to optimize.
 */
template<typename MatType = arma::mat>
class FonsecaFlemingFunction
{
 private:
  size_t numObjectives;
  size_t numVariables;

 public:
  FonsecaFlemingFunction() : numObjectives(2), numVariables(3)
  {/* Nothing to do here. */}

  /**
   * Evaluate the objectives with the given coordinate.
   *
   * @param coords The function coordinates.
   * @return arma::Col<typename MatType::elem_type>
   */
  arma::Col<typename MatType::elem_type> Evaluate(const MatType& coords)
  {
    // Convenience typedef.
    typedef typename MatType::elem_type ElemType;

    arma::Col<ElemType> objectives(numObjectives);

    objectives(0) = objectiveA.Evaluate(coords);
    objectives(1) = objectiveB.Evaluate(coords);

    return objectives;
  }

  //! Get the starting point.
  MatType GetInitialPoint()
  {
    // Convenience typedef.
    typedef typename MatType::elem_type ElemType;

    return arma::Col<ElemType>(numVariables, 1, arma::fill::zeros);
  }

  struct ObjectiveA
  {
    typename MatType::elem_type Evaluate(const MatType& coords)
    {
        return 1.0 - exp(
             -pow(static_cast<double>(coords[0]) - 1.0 / sqrt(3.0), 2.0)
             -pow(static_cast<double>(coords[1]) - 1.0 / sqrt(3.0), 2.0)
             -pow(static_cast<double>(coords[2]) - 1.0 / sqrt(3.0), 2.0)
        );
    }
  } objectiveA;

  struct ObjectiveB
  {
    typename MatType::elem_type Evaluate(const MatType& coords)
    {
        return 1.0 - exp(
            -pow(static_cast<double>(coords[0]) + 1.0 / sqrt(3.0), 2.0)
            -pow(static_cast<double>(coords[1]) + 1.0 / sqrt(3.0), 2.0)
            -pow(static_cast<double>(coords[2]) + 1.0 / sqrt(3.0), 2.0)
        );
    }
  } objectiveB;

  //! Get objective functions.
  std::tuple<ObjectiveA, ObjectiveB> GetObjectives()
  {
    return std::make_tuple(objectiveA, objectiveB);
  }
};
} // namespace test
} // namespace ens

#endif
/**
 * @file fw_test_function.hpp
 * @author Chenzhe Diao
 *
 * Simple test function for classic Frank Wolfe Algorithm:
 *
 * \f$ f(x) = (x1 - 0.1)^2 + (x2 - 0.2)^2 + (x3 - 0.3)^2 \f$
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_FW_TEST_FUNCTION_HPP
#define ENSMALLEN_PROBLEMS_FW_TEST_FUNCTION_HPP

namespace ens {

/**
 * Simple test function for classic Frank Wolfe Algorithm:
 *
 * \f$ f(x) = (x1 - 0.1)^2 + (x2 - 0.2)^2 + (x3 - 0.3)^2 \f$.
 */
template<typename MatType = arma::mat, typename GradType = MatType>
class TestFuncFW
{
 public:
  TestFuncFW() {/* Nothing to do. */}

  /**
   * Evaluation of the function.
   *
   * @param coords input vector x.
   */
  typename MatType::elem_type Evaluate(const MatType& coords)
  {
    typename MatType::elem_type f = std::pow(coords[0] - 0.1, 2);
    f += std::pow(coords[1] - 0.2, 2);
    f += std::pow(coords[2] - 0.3, 2);
    return f;
  }

  /**
   * Gradient of the function.
   *
   * @param coords input vector x.
   * @param gradient output gradient vector.
   */
  void Gradient(const MatType& coords, GradType& gradient)
  {
    gradient.set_size(3, 1);
    gradient[0] = coords[0] - 0.1;
    gradient[1] = coords[1] - 0.2;
    gradient[2] = coords[2] - 0.3;
  }
};

} // namespace ens

#endif
/**
 * @file generalized_rosenbrock_function.hpp
 * @author Ryan Curtin
 * @author Marcus Edel
 *
 * Definition of the Generalized Rosenbrock function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_GENERALIZED_ROSENBROCK_FUNCTION_HPP
#define ENSMALLEN_PROBLEMS_GENERALIZED_ROSENBROCK_FUNCTION_HPP

namespace ens {
namespace test {

/**
 * The Generalized Rosenbrock function in n dimensions, defined by
 *  f(x) = sum_i^{n - 1} (f(i)(x))
 *  f_i(x) = 100 * (x_i^2 - x_{i + 1})^2 + (1 - x_i)^2
 *  x_0 = [-1.2, 1, -1.2, 1, ...]
 *
 * This should optimize to f(x) = 0, at x = [1, 1, 1, 1, ...].
 *
 * This function can also be used for stochastic gradient descent (SGD) as a
 * decomposable function (SeparableFunctionType), so there are other
 * overloads of Evaluate() and Gradient() implemented, as well as
 * NumFunctions().
 *
 * For more information, please refer to:
 *
 * @code
 * @phdthesis{Jong1975,
 *   title  = {Analysis of the behavior of a class of genetic adaptive
 *             systems},
 *   author = {De Jong, Kenneth Alan},
 *   school = {Queensland University of Technology},
 *   year   = {1975},
 *   type   = {{PhD} dissertation},
 * }
 * @endcode
 */
class GeneralizedRosenbrockFunction
{
 public:
  /*
   * Initialize the GeneralizedRosenbrockFunction.
   *
   * @param n Number of dimensions for the function.
   */
  GeneralizedRosenbrockFunction(const size_t n);

  /**
   * Shuffle the order of function visitation. This may be called by the
   * optimizer.
   */
 void Shuffle();

  //! Return 1 (the number of functions).
  size_t NumFunctions() const { return n - 1; }

  /**
   * Evaluate a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param batchSize Number of points to process.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates,
                                       const size_t begin,
                                       const size_t batchSize = 1) const;

  /**
   * Evaluate a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates) const;

  /**
   * Evaluate the gradient of a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param gradient The function gradient.
   * @param batchSize Number of points to process.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates,
                const size_t begin,
                GradType& gradient,
                const size_t batchSize = 1) const;

  /**
   * Evaluate the gradient of a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   * @param gradient The function gradient.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates, GradType& gradient) const;

  // Note: GetInitialPoint(), GetFinalPoint(), and GetFinalObjective() are not
  // required for using ensmallen to optimize this function!  They are
  // specifically used as a convenience just for ensmallen's testing
  // infrastructure.

  //! Get the starting point.
  template<typename MatType = arma::mat>
  const MatType GetInitialPoint() const
  {
    return arma::conv_to<MatType>::from(initialPoint);
  }

  //! Get the final point.
  template<typename MatType = arma::mat>
  const MatType GetFinalPoint() const
  {
    return arma::ones<MatType>(initialPoint.n_rows, initialPoint.n_cols);
  }

  //! Get the final objective.
  double GetFinalObjective() const { return 0.0; }

 private:
  //! Locally-stored Initial point.
  arma::mat initialPoint;

  //! //! Number of dimensions for the function.
  size_t n;

  //! For shuffling.
  arma::Row<size_t> visitationOrder;
};

} // namespace test
} // namespace ens

// Include implementation.
#include "generalized_rosenbrock_function_impl.hpp"

#endif // ENSMALLEN_PROBLEMS_GENERALIZED_ROSENBROCK_FUNCTION_HPP
/**
 * @file generalized_rosenbrock_function_impl.hpp
 * @author Ryan Curtin
 * @author Marcus Edel
 *
 * Implementation of the Generalized-Rosenbrock function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_GENERALIZED_ROSENBROC_FUNCTION_IMPL_HPP
#define ENSMALLEN_PROBLEMS_GENERALIZED_ROSENBROC_FUNCTION_IMPL_HPP

// In case it hasn't been included yet.
#include "generalized_rosenbrock_function.hpp"

namespace ens {
namespace test {

inline GeneralizedRosenbrockFunction::GeneralizedRosenbrockFunction(
    const size_t n) :
    n(n),
    visitationOrder(arma::linspace<arma::Row<size_t> >(0, n - 1, n))

{
  initialPoint.set_size(n, 1);
  for (size_t i = 0; i < n; i++) // Set to [-1.2 1 -1.2 1 ...].
  {
    if (i % 2 == 1)
    {
      initialPoint(i) = -1.2;
    }
    else
    {
      initialPoint(i) = 1;
    }
  }
}

inline void GeneralizedRosenbrockFunction::Shuffle()
{
  visitationOrder = arma::shuffle(arma::linspace<arma::Row<size_t>>(0, n - 2,
      n - 1));
}

template<typename MatType>
typename MatType::elem_type GeneralizedRosenbrockFunction::Evaluate(
    const MatType& coordinates,
    const size_t begin,
    const size_t batchSize) const
{
  typename MatType::elem_type objective = 0.0;
  for (size_t j = begin; j < begin + batchSize; ++j)
  {
    const size_t p = visitationOrder[j];
    objective += 100 * std::pow((std::pow(coordinates[p], 2)
        - coordinates[p + 1]), 2) + std::pow(1 - coordinates[p], 2);
  }

  return objective;
}

template<typename MatType>
typename MatType::elem_type GeneralizedRosenbrockFunction::Evaluate(
    const MatType& coordinates) const
{
  typename MatType::elem_type fval = 0;
  for (size_t i = 0; i < (n - 1); i++)
  {
    fval += 100 * std::pow(std::pow(coordinates[i], 2) -
        coordinates[i + 1], 2) + std::pow(1 - coordinates[i], 2);
  }

  return fval;
}

template<typename MatType, typename GradType>
inline void GeneralizedRosenbrockFunction::Gradient(
    const MatType& coordinates,
    const size_t begin,
    GradType& gradient,
    const size_t batchSize) const
{
  gradient.zeros(n);
  for (size_t j = begin; j < begin + batchSize; ++j)
  {
    const size_t p = visitationOrder[j];
    gradient[p] = 400 * (std::pow(coordinates[p], 3) - coordinates[p] *
        coordinates[p + 1]) + 2 * (coordinates[p] - 1);
    gradient[p + 1] = 200 * (coordinates[p + 1] - std::pow(coordinates[p], 2));
  }
}

template<typename MatType, typename GradType>
inline void GeneralizedRosenbrockFunction::Gradient(
    const MatType& coordinates,
    GradType& gradient) const
{
  gradient.zeros(n);
  for (size_t i = 0; i < (n - 1); i++)
  {
    gradient[i] = 400 * (std::pow(coordinates[i], 3) - coordinates[i] *
        coordinates[i + 1]) + 2 * (coordinates[i] - 1);

    if (i > 0)
      gradient[i] += 200 * (coordinates[i] - std::pow(coordinates[i - 1], 2));
  }

  gradient[n - 1] = 200 * (coordinates[n - 1] -
      std::pow(coordinates[n - 2], 2));
}

} // namespace test
} // namespace ens

#endif
/**
 * @file goldstein_price_function.hpp
 * @author Suryoday Basak
 *
 * Definition of the Goldstein-Price function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_GOLDSTEIN_PRICE_FUNCTION_HPP
#define ENSMALLEN_PROBLEMS_GOLDSTEIN_PRICE_FUNCTION_HPP

namespace ens {
namespace test {

/**
 * The Goldstein-Price function, defined by
 * \f[
 * f(x_1, x_2) = (1 + (x_1 + x_2 + 1)^2 * (19 - 14 * x_1 + 3 * x_1^2 - 14 *
 *               x_2 + 6 * x_1 * x_2 + 3 * x_2^2)) *
 *               (30 + (2 * x_1 - 3 * x_2)^2 * (18 - 32 * x_1 + 12 * x^2 +
 *               48 * x_2 - 36 * x_1 * x_2 + 27 * x_2^2))
 * \f]
 *
 * This should optimize to f(x) = 3, at x = [0, -1].
 *
 * For more information, please refer to:
 *
 * @code
 * @article{Picheny:2013:BKI:2579829.2579986,
 *   author     = {Picheny, Victor and Wagner, Tobias and Ginsbourger, David},
 *   title      = {A Benchmark of Kriging-based Infill Criteria for Noisy
 *                 Optimization},
 *   journal    = {Struct. Multidiscip. Optim.},
 *   issue_date = {September 2013},
 *   volume     = {48},
 *   number     = {3},
 *   month      = sep,
 *   year       = {2013},
 *   issn       = {1615-147X},
 *   pages      = {607--626},
 *   numpages   = {20},
 *   doi        = {10.1007/s00158-013-0919-4},
 * }
 * @endcode
 */
class GoldsteinPriceFunction
{
 public:
  //! Initialize the GoldsteinPriceFunction.
  GoldsteinPriceFunction();

  /**
   * Shuffle the order of function visitation. This may be called by the
   * optimizer.
   */
  void Shuffle();

  //! Return 1 (the number of functions).
  size_t NumFunctions() const { return 1; }

  /**
   * Evaluate a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param batchSize Number of points to process.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates,
                                       const size_t begin,
                                       const size_t batchSize) const;

  /**
   * Evaluate a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates) const;

  /**
   * Evaluate the gradient of a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param gradient The function gradient.
   * @param batchSize Number of points to process.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates,
                const size_t begin,
                GradType& gradient,
                const size_t batchSize) const;

  /**
   * Evaluate the gradient of a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   * @param gradient The function gradient.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates, GradType& gradient);

  // Note: GetInitialPoint(), GetFinalPoint(), and GetFinalObjective() are not
  // required for using ensmallen to optimize this function!  They are
  // specifically used as a convenience just for ensmallen's testing
  // infrastructure.

  //! Get the starting point.
  template<typename MatType = arma::mat>
  MatType GetInitialPoint() const { return MatType("0.2; -0.5"); }

  //! Get the final point.
  template<typename MatType = arma::mat>
  MatType GetFinalPoint() const { return MatType("0.0; -1.0"); }

  //! Get the final objective.
  double GetFinalObjective() const { return 3.0; }
};

} // namespace test
} // namespace ens

// Include implementation.
#include "goldstein_price_function_impl.hpp"

#endif // ENSMALLEN_PROBLEMS_GOLDSTEIN_PRICE_FUNCTION_HPP
/**
 * @file goldstein_price_function_impl.hpp
 * @author Suryoday Basak
 *
 * Implementation of the Goldstein-Price function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_GOLDSTEIN_PRICE_FUNCTION_IMPL_HPP
#define ENSMALLEN_PROBLEMS_GOLDSTEIN_PRICE_FUNCTION_IMPL_HPP

// In case it hasn't been included yet.
#include "goldstein_price_function.hpp"

namespace ens {
namespace test {

inline GoldsteinPriceFunction::GoldsteinPriceFunction()
{ /* Nothing to do here */ }

inline void GoldsteinPriceFunction::Shuffle() { /* Nothing to do here */ }

template<typename MatType>
typename MatType::elem_type GoldsteinPriceFunction::Evaluate(
    const MatType& coordinates,
    const size_t /* begin */,
    const size_t /* batchSize */) const
{
  // Convenience typedef.
  typedef typename MatType::elem_type ElemType;

  // For convenience; we assume these temporaries will be optimized out.
  const ElemType x1 = coordinates(0);
  const ElemType x2 = coordinates(1);

  const ElemType x1Sq = std::pow(x1, 2);
  const ElemType x2Sq = std::pow(x2, 2);
  const ElemType x1x2 = x1 * x2;
  const ElemType objective = (1 + std::pow(x1 + x2 + 1, 2) * (19 - 14 * x1 + 3 *
      x1Sq - 14 * x2 + 6 * x1x2 + 3 * x2Sq)) * (30 + std::pow(2 * x1 - 3 * x2,
      2) * (18 - 32 * x1 + 12 * x1Sq + 48 * x2 - 36 * x1x2 + 27 * x2Sq));

  return objective;
}

template<typename MatType>
typename MatType::elem_type GoldsteinPriceFunction::Evaluate(
    const MatType& coordinates) const
{
  return Evaluate(coordinates, 0, NumFunctions());
}

template<typename MatType, typename GradType>
inline void GoldsteinPriceFunction::Gradient(const MatType& coordinates,
                                             const size_t /* begin */,
                                             GradType& gradient,
                                             const size_t /* batchSize */) const
{
  // Convenience typedef.
  typedef typename MatType::elem_type ElemType;

  // For convenience; we assume these temporaries will be optimized out.
  const ElemType x1 = coordinates(0);
  const ElemType x2 = coordinates(1);

  gradient.set_size(2, 1);
  gradient(0) = (std::pow(2 * x1 - 3 * x2, 2) * (24 * x1 - 36 * x2 - 32) + (8 *
      x1 - 12 * x2) * (12 * x1 * x1 - 36 * x1 * x2 - 32 * x1 + 27 * x2 * x2 +
      48 * x2 + 18)) * (std::pow(x1 + x2 + 1, 2) * (3 * x1 * x1 + 6 * x1 * x2 -
      14 * x1 + 3 * x2 * x2 - 14 * x2 + 19) + 1) + (std::pow(2 * x1 - 3 * x2,
      2) * (12 * x1 * x1 - 36 * x1 * x2 - 32 * x1 + 27 * x2 * x2 + 48 * x2 +
      18) + 30) * (std::pow(x1 + x2 + 1, 2) * (6 * x1 + 6 * x2 - 14) + (2 * x1 +
      2 * x2 + 2) * (3 * x1 * x1 + 6 * x1 * x2 - 14 * x1 + 3 * x2 * x2 - 14 *
      x2 + 19));
  gradient(1) = ((- 12 * x1 + 18 * x2) * (12 * x1 * x1 - 36 * x1 * x2 - 32 *
      x1 + 27 * x2 * x2 + 48 * x2 + 18) + std::pow(2 * x1 - 3 * x2, 2) * (-36 *
      x1 + 54 * x2 + 48)) * (std::pow(x1 + x2 + 1, 2) * (3 * x1 * x1 + 6 * x1 *
      x2 - 14 * x1 + 3 * x2 * x2 - 14 * x2 + 19) + 1) + (std::pow(2 * x1 - 3 *
      x2, 2) * (12 * x1 * x1 - 36 * x1 * x2 - 32 * x1 + 27 * x2 * x2 + 48 * x2 +
      18) + 30) * (std::pow(x1 + x2 + 1, 2) * (6 * x1 + 6 * x2 - 14) + (2 * x1 +
      2 * x2 + 2) * (3 * x1 * x1 + 6 * x1 * x2 - 14 * x1 + 3 * x2 * x2 - 14 *
      x2 + 19));
}

template<typename MatType, typename GradType>
inline void GoldsteinPriceFunction::Gradient(const MatType& coordinates,
                                             GradType& gradient)
{
  Gradient(coordinates, 0, gradient, 1);
}

} // namespace test
} // namespace ens

#endif
/**
 * @file gradient_descent_test_function.hpp
 * @author Sumedh Ghaisas
 *
 * Very simple test function for SGD.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_GRADIENT_DESCENT_TEST_FUNCTION_HPP
#define ENSMALLEN_PROBLEMS_GRADIENT_DESCENT_TEST_FUNCTION_HPP

namespace ens {
namespace test {

//! Very, very simple test function which is the composite of three other
//! functions.  The gradient is not very steep far away from the optimum, so a
//! larger step size may be required to optimize it in a reasonable number of
//! iterations.
class GDTestFunction
{
 public:
  //! Nothing to do for the constructor.
  GDTestFunction() { }

  //! Evaluate a function.
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates) const;

  //! Evaluate the gradient of a function.
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates, GradType& gradient) const;

  // Note: GetInitialPoint(), GetFinalPoint(), and GetFinalObjective() are not
  // required for using ensmallen to optimize this function!  They are
  // specifically used as a convenience just for ensmallen's testing
  // infrastructure.

  //! Get the starting point.
  template<typename MatType>
  MatType GetInitialPoint() const { return MatType("1; 3; 2"); }

  //! Get the final point.
  template<typename MatType = arma::mat>
  MatType GetFinalPoint() const { return MatType("0; 0; 0"); }

  //! Get the final objective.
  double GetFinalObjective() const { return 0.0; }
};

} // namespace test
} // namespace ens

#include "gradient_descent_test_function_impl.hpp"

#endif
/**
 * @file gradient_descent_test_function_impl.hpp
 * @author Sumedh Ghaisas
 *
 * Implementation of very simple test function for gradient descent.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_GRADIENT_DESCENT_TEST_FUNCTION_IMPL_HPP
#define ENSMALLEN_PROBLEMS_GRADIENT_DESCENT_TEST_FUNCTION_IMPL_HPP

#include "gradient_descent_test_function.hpp"

namespace ens {
namespace test {

template<typename MatType>
inline typename MatType::elem_type GDTestFunction::Evaluate(
    const MatType& coordinates) const
{
  MatType temp = arma::trans(coordinates) * coordinates;
  return temp(0, 0);
}

template<typename MatType, typename GradType>
inline void GDTestFunction::Gradient(const MatType& coordinates,
                                     GradType& gradient) const
{
  gradient = 2 * coordinates;
}

} // namespace test
} // namespace ens

#endif
/**
 * @file himmelblau_function.hpp
 * @author Suryoday Basak
 *
 * Definition of the Himmelblau function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_HIMMELBLAU_FUNCTION_HPP
#define ENSMALLEN_PROBLEMS_HIMMELBLAU_FUNCTION_HPP

namespace ens {
namespace test {

/**
 * The Himmelblau function, defined by
 *
 * \f[
 * f(x_1,x_2) = (x_1^2 + y - 11)^2 + (x_1 + x_2^2 - 7)^2
 * \f]
 *
 * This should optimize to f(x) = 0, at x = [3.0,  2.0], or
 *          x = [-2.805118, 3.131312], or
 *          x = [-3.779310, -3.283186], or
 *          x = [3.584428, -1.848126].
 *
 * For more information, please refer to:
 *
 * @code
 * @book{davidmautnerhimmelblau1972,
 *   Author      = {David Mautner Himmelblau},
 *   title       = {Applied Nonlinear Programming},
 *   description = {Applied Nonlinear Programming (Book, 1972)},
 *   publisher   = {McGraw-Hill},
 *   year        = {1972},
 *   month       = {jun},
 *   isbn        = {0070289212},
 * }
 * @endcode
 */
class HimmelblauFunction
{
 public:
  //! Initialize the HimmelblauFunction.
  HimmelblauFunction();

  /**
   * Shuffle the order of function visitation. This may be called by the
   * optimizer.
   */
  void Shuffle();

  //! Return 1 (the number of functions).
  size_t NumFunctions() const { return 1; }

  //! Get the starting point.
  template<typename MatType = arma::mat>
  MatType GetInitialPoint() const { return MatType("5; -5"); }

  /**
   * Evaluate a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param batchSize Number of points to process.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates,
                                       const size_t begin,
                                       const size_t batchSize) const;

  /**
   * Evaluate a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates) const;

  /**
   * Evaluate the gradient of a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param gradient The function gradient.
   * @param batchSize Number of points to process.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates,
                const size_t begin,
                GradType& gradient,
                const size_t batchSize) const;

  /**
   * Evaluate the gradient of a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   * @param gradient The function gradient.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates, GradType& gradient);
};

} // namespace test
} // namespace ens

// Include implementation.
#include "himmelblau_function_impl.hpp"

#endif // ENSMALLEN_PROBLEMS_HIMMELBLAU_FUNCTION_HPP
/**
 * @file himmelblau_function_impl.hpp
 * @author Suryoday Basak
 *
 * Implementation of the Beale function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_HIMMELBLAU_FUNCTION_IMPL_HPP
#define ENSMALLEN_PROBLEMS_HIMMELBLAU_FUNCTION_IMPL_HPP

// In case it hasn't been included yet.
#include "himmelblau_function.hpp"

namespace ens {
namespace test {

inline HimmelblauFunction::HimmelblauFunction() { /* Nothing to do here */ }

inline void HimmelblauFunction::Shuffle() { /* Nothing to do here */ }

template<typename MatType>
typename MatType::elem_type HimmelblauFunction::Evaluate(
    const MatType& coordinates,
    const size_t /* begin */,
    const size_t /* batchSize */) const
{
  // Convenience typedef.
  typedef typename MatType::elem_type ElemType;

  // For convenience; we assume these temporaries will be optimized out.
  const ElemType x1 = coordinates(0);
  const ElemType x2 = coordinates(1);

  const ElemType objective = std::pow(x1 * x1 + x2  - 11 , 2) +
      std::pow(x1 + x2 * x2 - 7, 2);
  return objective;
}

template<typename MatType>
typename MatType::elem_type HimmelblauFunction::Evaluate(
    const MatType& coordinates) const
{
  return Evaluate(coordinates, 0, NumFunctions());
}

template<typename MatType, typename GradType>
inline void HimmelblauFunction::Gradient(const MatType& coordinates,
                                         const size_t /* begin */,
                                         GradType& gradient,
                                         const size_t /* batchSize */) const
{
  // Convenience typedef.
  typedef typename MatType::elem_type ElemType;

  // For convenience; we assume these temporaries will be optimized out.
  const ElemType x1 = coordinates(0);
  const ElemType x2 = coordinates(1);

  // Aliases for different terms in the expression of the gradient
  const ElemType x1Sq = x1 * x1;
  const ElemType x2Sq = x2 * x2;

  gradient.set_size(2, 1);
  gradient(0) = (4 * x1 * (x1Sq + x2 - 11)) + (2 * (x1 + x2Sq - 7));
  gradient(1) = (2 * (x1Sq + x2 - 11)) + (4 * x2 * (x1 + x2Sq - 7));
}

template<typename MatType, typename GradType>
inline void HimmelblauFunction::Gradient(const MatType& coordinates,
                                         GradType& gradient)
{
  Gradient(coordinates, 0, gradient, 1);
}

} // namespace test
} // namespace ens

#endif
/**
 * @file holder_table_function.hpp
 * @author Suryoday Basak
 *
 * Definition of the Holder table function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_HOLDER_TABLE_FUNCTION_HPP
#define ENSMALLEN_PROBLEMS_HOLDER_TABLE_FUNCTION_HPP

namespace ens {
namespace test {

/**
 * The Holder table function, defined by
 *
 * \f[
 * f(x1, x2) = - |sin(x1) * cos(x2) * exp(|1 - (sqrt(x1^2 + x2^2) / pi)|)|
 * \f]
 *
 * This should optimize to f(x1, x2) = -19.2085, at
 *                                     (x1, x2) = [-8.05502, -9.66459], or
 *                                     (x1, x2) = [8.05502, -9.66459],  or
 *                                     (x1, x2) = [-8.05502, 9.66459],  or
 *                                     (x1, x2) = [8.05502, 9.66459]
 *
 * For more information, please refer to:
 *
 * @code
 * @article{Mishra2006,
 *   author    = {S. K. Mishra},
 *   title     = {Some New Test Functions for Global Optimization and
 *                Performance of Repulsive Particle Swarm Method},
 *   year      = {2006},
 *   publisher = {Elsevier {BV}},
 *   journal = {{SSRN} Electronic Journal}
 * }
 * @endcode
 */
class HolderTableFunction
{
 public:
  //! Initialize the HolderTableFunction.
  HolderTableFunction();

  /**
   * Shuffle the order of function visitation. This may be called by the
   * optimizer.
   */
  void Shuffle();

  //! Return 1 (the number of functions).
  size_t NumFunctions() const { return 1; }

  //! Get the starting point.
  template<typename MatType = arma::mat>
  MatType GetInitialPoint() const { return MatType("7; 7"); }

  /**
   * Evaluate a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param batchSize Number of points to process.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates,
                                       const size_t begin,
                                       const size_t batchSize) const;

  /**
   * Evaluate a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates) const;
};

} // namespace test
} // namespace ens

// Include implementation.
#include "holder_table_function_impl.hpp"

#endif // ENSMALLEN_PROBLEMS_HOLDER_TABLE_FUNCTION_HPP
/**
 * @file holder_table_function_impl.hpp
 * @author Suryoday Basak
 *
 * Implementation of the Holder table function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_HOLDER_TABLE_FUNCTION_IMPL_HPP
#define ENSMALLEN_PROBLEMS_HOLDER_TABLE_FUNCTION_IMPL_HPP

// In case it hasn't been included yet.
#include "holder_table_function.hpp"

namespace ens {
namespace test {

inline HolderTableFunction::HolderTableFunction() { /* Nothing to do here */ }

inline void HolderTableFunction::Shuffle() { /* Nothing to do here */ }

template<typename MatType>
typename MatType::elem_type HolderTableFunction::Evaluate(
    const MatType& coordinates,
    const size_t /* begin */,
    const size_t /* batchSize */) const
{
  // Convenience typedef.
  typedef typename MatType::elem_type ElemType;

  // For convenience; we assume these temporaries will be optimized out.
  const ElemType x1 = coordinates(0);
  const ElemType x2 = coordinates(1);

  const ElemType objective = -std::abs(std::sin(x1) * std::cos(x2) *
      std::exp(std::abs(1 - (std::sqrt(x1 * x1 + x2 * x2) / arma::datum::pi))));

  return objective;
}

template<typename MatType>
typename MatType::elem_type HolderTableFunction::Evaluate(
    const MatType& coordinates) const
{
  return Evaluate(coordinates, 0, NumFunctions());
}

} // namespace test
} // namespace ens

#endif
/**
 * @file levy_function_n13.hpp
 * @author Suryoday Basak
 *
 * Definition of the Levy function N.13.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_LEVY_FUNCTION_N13_HPP
#define ENSMALLEN_PROBLEMS_LEVY_FUNCTION_N13_HPP

namespace ens {
namespace test {

/**
 * The Levy function N.13, defined by
 *
 * \f[
 * f(x_1, x_2) = sin(3 * pi * x_1)^2 + (x_1 - 1)^2 *
 *               (1 + (sin(3 * pi * x_2)^2)) +
 *               (x_2 - 1)^2 * (1 + sin(2 * pi * x_2)^2)
 * \f]
 * This should optimize to f(x_1, x_2) = 0, at x = [1, 1].
 *
 * For more information, please refer to:
 *
 * @code
 * @misc{LevyFunction,
 *   URL = {http://www.sfu.ca/~ssurjano/levy13.html},
 * }
 * @endcode
 */
class LevyFunctionN13
{
 public:
  //! Initialize the BealeFunction.
  LevyFunctionN13();

  /**
   * Shuffle the order of function visitation. This may be called by the
   * optimizer.
   */
  void Shuffle();

  //! Return 1 (the number of functions).
  size_t NumFunctions() const { return 1; }

  /**
   * Evaluate a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param batchSize Number of points to process.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates,
                                       const size_t begin,
                                       const size_t batchSize) const;

  /**
   * Evaluate a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates) const;

  /**
   * Evaluate the gradient of a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param gradient The function gradient.
   * @param batchSize Number of points to process.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates,
                const size_t begin,
                GradType& gradient,
                const size_t batchSize) const;

  /**
   * Evaluate the gradient of a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   * @param gradient The function gradient.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates, GradType& gradient);

  // Note: GetInitialPoint(), GetFinalPoint(), and GetFinalObjective() are not
  // required for using ensmallen to optimize this function!  They are
  // specifically used as a convenience just for ensmallen's testing
  // infrastructure.

  //! Get the starting point.
  template<typename MatType = arma::mat>
  MatType GetInitialPoint() const { return MatType("0.9; 1.1"); }

  //! Get the final point.
  template<typename MatType = arma::mat>
  MatType GetFinalPoint() const { return MatType("1.0; 1.0"); }

  //! Get the final objective.
  double GetFinalObjective() const { return 0.0; }
};

} // namespace test
} // namespace ens

// Include implementation.
#include "levy_function_n13_impl.hpp"

#endif // ENSMALLEN_PROBLEMS_LEVY_FUNCTION_N13_HPP
/**
 * @file levy_function_n13_impl.hpp
 * @author Suryoday Basak
 *
 * Implementation of the Levy function N.13.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_LEVY_FUNCTION_N13_IMPL_HPP
#define ENSMALLEN_PROBLEMS_LEVY_FUNCTION_N13_IMPL_HPP

// In case it hasn't been included yet.
#include "levy_function_n13.hpp"

namespace ens {
namespace test {

inline LevyFunctionN13::LevyFunctionN13() { /* Nothing to do here */ }

inline void LevyFunctionN13::Shuffle() { /* Nothing to do here */ }

template<typename MatType>
typename MatType::elem_type LevyFunctionN13::Evaluate(
    const MatType& coordinates,
    const size_t /* begin */,
    const size_t /* batchSize */) const
{
  // Convenience typedef.
  typedef typename MatType::elem_type ElemType;

  // For convenience; we assume these temporaries will be optimized out.
  const ElemType x1 = coordinates(0);
  const ElemType x2 = coordinates(1);

  const ElemType objective = std::pow(std::sin(3 * arma::datum::pi * x1), 2) +
      (std::pow(x1 - 1, 2) * (1 + std::pow(
          std::sin(3 * arma::datum::pi * x2), 2))) +
      (std::pow(x2 - 1, 2) * (1 + std::pow(
          std::sin(2 * arma::datum::pi * x2), 2)));

  return objective;
}

template<typename MatType>
typename MatType::elem_type LevyFunctionN13::Evaluate(
    const MatType& coordinates) const
{
  return Evaluate(coordinates, 0, NumFunctions());
}

template<typename MatType, typename GradType>
inline void LevyFunctionN13::Gradient(const MatType& coordinates,
                                      const size_t /* begin */,
                                      GradType& gradient,
                                      const size_t /* batchSize */) const
{
  // Convenience typedef.
  typedef typename MatType::elem_type ElemType;

  // For convenience; we assume these temporaries will be optimized out.
  const ElemType x1 = coordinates(0);
  const ElemType x2 = coordinates(1);
  gradient.set_size(2, 1);

  gradient(0) = (2 * x1 - 2) * (std::pow(std::sin(3 * arma::datum::pi * x2),
      2) + 1) + 6 * arma::datum::pi * std::sin(3 * arma::datum::pi * x1) *
      std::cos(3 * arma::datum::pi * x1);

  gradient(1) = 6 * arma::datum::pi * std::pow(x1 - 1, 2) * std::sin(3 *
      arma::datum::pi * x2) * std::cos(3 * arma::datum::pi * x2) +
      4 * arma::datum::pi * std::pow(x2 - 1, 2) * std::sin(2 *
      arma::datum::pi * x2) * std::cos(2 * arma::datum::pi * x2) +
      (2 * x2 - 2) * (std::pow(std::sin(2 * arma::datum::pi * x2), 2) + 1);
}

template<typename MatType, typename GradType>
inline void LevyFunctionN13::Gradient(const MatType& coordinates,
                                      GradType& gradient)
{
  Gradient(coordinates, 0, gradient, 1);
}

} // namespace test
} // namespace ens

#endif
/**
 * @file logistic_regression_function.hpp
 * @author Sumedh Ghaisas
 *
 * Implementation of the logistic regression function, which is meant to be
 * optimized by a separate optimizer class that takes LogisticRegressionFunction
 * as its FunctionType class.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_LOGISTIC_REGRESSION_FUNCTION_HPP
#define ENSMALLEN_PROBLEMS_LOGISTIC_REGRESSION_FUNCTION_HPP

namespace ens {
namespace test {

/**
 * The log-likelihood function for the logistic regression objective function.
 * This is used by various ensmallen optimizers to train a logistic regression
 * model.
 */
template<typename MatType = arma::mat>
class LogisticRegressionFunction
{
 public:
  LogisticRegressionFunction(MatType& predictors,
                             arma::Row<size_t>& responses,
                             const double lambda = 0);

  LogisticRegressionFunction(MatType& predictors,
                             arma::Row<size_t>& responses,
                             MatType& initialPoint,
                             const double lambda = 0);

  //! Return the initial point for the optimization.
  const MatType& InitialPoint() const { return initialPoint; }
  //! Modify the initial point for the optimization.
  MatType& InitialPoint() { return initialPoint; }

  //! Return the regularization parameter (lambda).
  const double& Lambda() const { return lambda; }
  //! Modify the regularization parameter (lambda).
  double& Lambda() { return lambda; }

  //! Return the matrix of predictors.
  const MatType& Predictors() const { return predictors; }
  //! Return the vector of responses.
  const arma::Row<size_t>& Responses() const { return responses; }

  /**
   * Shuffle the order of function visitation.  This may be called by the
   * optimizer.
   */
  void Shuffle();

  /**
   * Evaluate the logistic regression log-likelihood function with the given
   * parameters.  Note that if a point has 0 probability of being classified
   * directly with the given parameters, then Evaluate() will return nan (this
   * is kind of a corner case and should not happen for reasonable models).
   *
   * The optimum (minimum) of this function is 0.0, and occurs when each point
   * is classified correctly with very high probability.
   *
   * @param parameters Vector of logistic regression parameters.
   */
  typename MatType::elem_type Evaluate(const MatType& parameters) const;

  /**
   * Evaluate the logistic regression log-likelihood function with the given
   * parameters using the given batch size from the given point index.  This is
   * useful for optimizers such as SGD, which require a separable objective
   * function.  Note that if the points have 0 probability of being classified
   * correctly with the given parameters, then Evaluate() will return nan (this
   * is kind of a corner case and should not happen for reasonable models).
   *
   * The optimum (minimum) of this function is 0.0, and occurs when the points
   * are classified correctly with very high probability.
   *
   * @param parameters Vector of logistic regression parameters.
   * @param begin Index of the starting point to use for objective function
   *     evaluation.
   * @param batchSize Number of points to be passed at a time to use for
   *     objective function evaluation.
   */
  typename MatType::elem_type Evaluate(const MatType& parameters,
                                       const size_t begin,
                                       const size_t batchSize = 1) const;

  /**
   * Evaluate the gradient of the logistic regression log-likelihood function
   * with the given parameters.
   *
   * @param parameters Vector of logistic regression parameters.
   * @param gradient Vector to output gradient into.
   */
  template<typename GradType>
  void Gradient(const MatType& parameters, GradType& gradient) const;

  /**
   * Evaluate the gradient of the logistic regression log-likelihood function
   * with the given parameters, for the given batch size from a given point the
   * in dataset. This is useful for optimizers such as SGD, which require a
   * separable objective function.
   *
   * @param parameters Vector of logistic regression parameters.
   * @param begin Index of the starting point to use for objective function
   *     gradient evaluation.
   * @param gradient Vector to output gradient into.
   * @param batchSize Number of points to be processed as a batch for objective
   *     function gradient evaluation.
   */
  template<typename GradType>
  void Gradient(const MatType& parameters,
                const size_t begin,
                GradType& gradient,
                const size_t batchSize = 1) const;

  /**
   * Evaluate the gradient of the logistic regression log-likelihood function
   * with the given parameters, and with respect to only one feature in the
   * dataset.  This is useful for optimizers such as SCD, which require
   * partial gradients.
   *
   * @param parameters Vector of logistic regression parameters.
   * @param j Index of the feature with respect to which the gradient is to
   *    be computed.
   * @param gradient Sparse matrix to output gradient into.
   */
  void PartialGradient(const MatType& parameters,
                       const size_t j,
                       arma::sp_mat& gradient) const;

  /**
   * Evaluate the objective function and gradient of the logistic regression
   * log-likelihood function simultaneously with the given parameters.
   */
  template<typename GradType>
  typename MatType::elem_type EvaluateWithGradient(
      const MatType& parameters,
      GradType& gradient) const;

  template<typename GradType>
  typename MatType::elem_type EvaluateWithGradient(
      const MatType& parameters,
      const size_t begin,
      GradType& gradient,
      const size_t batchSize = 1) const;

  //! Return the initial point for the optimization.
  const MatType& GetInitialPoint() const { return initialPoint; }

  //! Return the number of separable functions (the number of predictor points).
  size_t NumFunctions() const { return predictors.n_cols; }

  //! Return the number of features(add 1 for the intercept term).
  size_t NumFeatures() const { return predictors.n_rows + 1; }

  /**
   * Compute the accuracy of the model on the given predictors and responses,
   * optionally using the given decision boundary.  The responses should be
   * either 0 or 1.  Logistic regression returns a value between 0 and 1.  If
   * the value is greater than the decision boundary, the response is taken to
   * be 1; otherwise, it is 0.  By default, the decision boundary is 0.5.
   *
   * The accuracy is returned as a percentage, between 0 and 100.
   *
   * @param predictors Input predictors.
   * @param responses Vector of responses.
   * @param parameters Vector of logistic regression parameters.
   * @param decisionBoundary Decision boundary (default 0.5).
   * @return Percentage of responses that are predicted correctly.
   */
  double ComputeAccuracy(const MatType& predictors,
                         const arma::Row<size_t>& responses,
                         const MatType& parameters,
                         const double decisionBoundary = 0.5) const;

  /**
   * Classify the given points, returning the predicted labels for each point.
   * Optionally, specify the decision boundary; logistic regression returns a
   * value between 0 and 1.  If the value is greater than the decision boundary,
   * the response is taken to be 1; otherwise, it is 0.  By default the decision
   * boundary is 0.5.
   *
   * @param dataset Set of points to classify.
   * @param labels Predicted labels for each point.
   * @param parameters Vector of logistic regression parameters.
   * @param decisionBoundary Decision boundary (default 0.5).
   */
  void Classify(const MatType& dataset,
                arma::Row<size_t>& labels,
                const MatType& parameters,
                const double decisionBoundary = 0.5) const;

 private:
  //! The initial point, from which to start the optimization.
  MatType initialPoint;
  //! The matrix of data points (predictors).  This is an alias until shuffling
  //! is done.
  MatType& predictors;
  //! The vector of responses to the input data points.  This is an alias until
  //! shuffling is done.
  arma::Row<size_t>& responses;
  //! The regularization parameter for L2-regularization.
  double lambda;
};

// Convenience typedefs.
template<typename MatType = arma::mat>
using LogisticRegression = LogisticRegressionFunction<MatType>;

} // namespace test
} // namespace ens

// Include implementation.
#include "logistic_regression_function_impl.hpp"

#endif // ENSMALLEN_PROBLEMS_LOGISTIC_REGRESSION_FUNCTION_HPP
/**
 * @file logistic_regression_function.cpp
 * @author Sumedh Ghaisas
 *
 * Implementation of the LogisticRegressionFunction class.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_LOGISTIC_REGRESSION_FUNCTION_IMPL_HPP
#define ENSMALLEN_PROBLEMS_LOGISTIC_REGRESSION_FUNCTION_IMPL_HPP

// In case it hasn't been included yet.
#include "logistic_regression_function.hpp"

namespace ens {
namespace test {

template<typename MatType>
LogisticRegressionFunction<MatType>::LogisticRegressionFunction(
    MatType& predictors,
    arma::Row<size_t>& responses,
    const double lambda) :
    // We promise to be well-behaved... the elements won't be modified.
    predictors(predictors),
    responses(responses),
    lambda(lambda)
{
  initialPoint = arma::Row<typename MatType::elem_type>(predictors.n_rows + 1,
      arma::fill::zeros);

  // Sanity check.
  if (responses.n_elem != predictors.n_cols)
  {
    std::ostringstream oss;
    oss << "LogisticRegressionFunction::LogisticRegressionFunction(): "
        << "predictors matrix has " << predictors.n_cols << " points, but "
        << "responses vector has " << responses.n_elem << " elements (should be"
        << " " << predictors.n_cols << ")!" << std::endl;
    throw std::logic_error(oss.str());
  }
}

template<typename MatType>
LogisticRegressionFunction<MatType>::LogisticRegressionFunction(
    MatType& predictors,
    arma::Row<size_t>& responses,
    MatType& initialPoint,
    const double lambda) :
    initialPoint(initialPoint),
    predictors(predictors),
    responses(responses),
    lambda(lambda)
{
  // To check if initialPoint is compatible with predictors.
  if (initialPoint.n_rows != (predictors.n_rows + 1) ||
      initialPoint.n_cols != 1)
    this->initialPoint = arma::Row<typename MatType::elem_type>(
        predictors.n_rows + 1, arma::fill::zeros);
}

/**
 * Shuffle the datapoints.
 */
template<typename MatType>
void LogisticRegressionFunction<MatType>::Shuffle()
{
  MatType newPredictors;
  arma::Row<size_t> newResponses;

  arma::uvec ordering = arma::shuffle(arma::linspace<arma::uvec>(0,
      predictors.n_cols - 1, predictors.n_cols));

  newPredictors.set_size(predictors.n_rows, predictors.n_cols);
  for (size_t i = 0; i < predictors.n_cols; ++i)
    newPredictors.col(i) = predictors.col(ordering[i]);
  newResponses = responses.cols(ordering);

  // Take ownership of the new data.
  predictors = std::move(newPredictors);
  responses = std::move(newResponses);
}

/**
 * Evaluate the logistic regression objective function given the estimated
 * parameters.
 */
template<typename MatType>
typename MatType::elem_type LogisticRegressionFunction<MatType>::Evaluate(
    const MatType& parameters) const
{
  // The objective function is the log-likelihood function (w is the parameters
  // vector for the model; y is the responses; x is the predictors; sig() is the
  // sigmoid function):
  //   f(w) = sum(y log(sig(w'x)) + (1 - y) log(sig(1 - w'x))).
  // We want to minimize this function.  L2-regularization is just lambda
  // multiplied by the squared l2-norm of the parameters then divided by two.
  typedef typename MatType::elem_type ElemType;

  // For the regularization, we ignore the first term, which is the intercept
  // term and take every term except the last one in the decision variable.
  const ElemType regularization = 0.5 * lambda *
      arma::dot(parameters.tail_cols(parameters.n_elem - 1),
      parameters.tail_cols(parameters.n_elem - 1));

  // Calculate vectors of sigmoids.  The intercept term is parameters(0, 0) and
  // does not need to be multiplied by any of the predictors.
  const arma::Row<ElemType> sigmoid = 1.0 / (1.0 +
      arma::exp(-(parameters(0, 0) +
                parameters.tail_cols(parameters.n_elem - 1) * predictors)));

  // Assemble full objective function.  Often the objective function and the
  // regularization as given are divided by the number of features, but this
  // doesn't actually affect the optimization result, so we'll just ignore those
  // terms for computational efficiency.  Note that the conversion causes some
  // copy and slowdown, but this is so negligible compared to the rest of the
  // calculation it is not worth optimizing for.
  const ElemType result = arma::accu(arma::log(1.0 -
      arma::conv_to<arma::Row<ElemType>>::from(responses) + sigmoid %
      (2 * arma::conv_to<arma::Row<ElemType>>::from(responses) - 1.0)));

  // Invert the result, because it's a minimization.
  return regularization - result;
}

/**
 * Evaluate the logistic regression objective function given the estimated
 * parameters for a given batch from a given point.
 */
template<typename MatType>
typename MatType::elem_type LogisticRegressionFunction<MatType>::Evaluate(
    const MatType& parameters,
    const size_t begin,
    const size_t batchSize) const
{
  typedef typename MatType::elem_type ElemType;

  // Calculate the regularization term.
  const ElemType regularization = lambda *
      (batchSize / (2.0 * predictors.n_cols)) *
      arma::dot(parameters.tail_cols(parameters.n_elem - 1),
                parameters.tail_cols(parameters.n_elem - 1));

  // Calculate the sigmoid function values.
  const arma::Row<ElemType> sigmoid = 1.0 / (1.0 +
      arma::exp(-(parameters(0, 0) +
                  parameters.tail_cols(parameters.n_elem - 1) *
                      predictors.cols(begin, begin + batchSize - 1))));

  // Compute the objective for the given batch size from a given point.
  arma::Row<ElemType> respD = arma::conv_to<arma::Row<ElemType>>::from(
      responses.subvec(begin, begin + batchSize - 1));
  const ElemType result = arma::accu(arma::log(1.0 - respD + sigmoid %
      (2 * respD - 1.0)));

  // Invert the result, because it's a minimization.
  return regularization - result;
}

//! Evaluate the gradient of the logistic regression objective function.
template<typename MatType>
template<typename GradType>
void LogisticRegressionFunction<MatType>::Gradient(
    const MatType& parameters,
    GradType& gradient) const
{
  typedef typename MatType::elem_type ElemType;
  // Regularization term.
  MatType regularization;
  regularization = lambda * parameters.tail_cols(parameters.n_elem - 1);

  const arma::Row<ElemType> sigmoids = (1 / (1 + arma::exp(-parameters(0, 0)
      - parameters.tail_cols(parameters.n_elem - 1) * predictors)));

  gradient.set_size(arma::size(parameters));
  gradient[0] = -arma::accu(responses - sigmoids);
  gradient.tail_cols(parameters.n_elem - 1) = (sigmoids - responses) *
      predictors.t() + regularization;
}

//! Evaluate the gradient of the logistic regression objective function for a
//! given batch size.
template<typename MatType>
template<typename GradType>
void LogisticRegressionFunction<MatType>::Gradient(
                const MatType& parameters,
                const size_t begin,
                GradType& gradient,
                const size_t batchSize) const
{
  typedef typename MatType::elem_type ElemType;

  // Regularization term.
  MatType regularization;
  regularization = lambda * parameters.tail_cols(parameters.n_elem - 1)
      / predictors.n_cols * batchSize;

  const arma::Row<ElemType> exponents = parameters(0, 0) +
      parameters.tail_cols(parameters.n_elem - 1) *
      predictors.cols(begin, begin + batchSize - 1);
  // Calculating the sigmoid function values.
  const arma::Row<ElemType> sigmoids = 1.0 / (1.0 + arma::exp(-exponents));

  gradient.set_size(parameters.n_rows, parameters.n_cols);
  gradient[0] = -arma::accu(responses.subvec(begin, begin + batchSize - 1) -
      sigmoids);
  gradient.tail_cols(parameters.n_elem - 1) = (sigmoids -
      responses.subvec(begin, begin + batchSize - 1)) *
      predictors.cols(begin, begin + batchSize - 1).t() + regularization;
}

/**
 * Evaluate the partial gradient of the logistic regression objective
 * function with respect to the individual features in the parameter.
 */
template <typename MatType>
void LogisticRegressionFunction<MatType>::PartialGradient(
    const MatType& parameters,
    const size_t j,
    arma::sp_mat& gradient) const
{
  const arma::Row<typename MatType::elem_type> diffs = responses -
      (1 / (1 + arma::exp(-parameters(0, 0) -
                          parameters.tail_cols(parameters.n_elem - 1) *
                              predictors)));

  gradient.set_size(arma::size(parameters));

  if (j == 0)
  {
    gradient[j] = -arma::accu(diffs);
  }
  else
  {
    gradient[j] = arma::dot(-predictors.row(j - 1), diffs) + lambda *
      parameters(0, j);
  }
}

template<typename MatType>
template<typename GradType>
typename MatType::elem_type
LogisticRegressionFunction<MatType>::EvaluateWithGradient(
    const MatType& parameters,
    GradType& gradient) const
{
  typedef typename MatType::elem_type ElemType;

  // Regularization term.
  MatType regularization = lambda *
      parameters.tail_cols(parameters.n_elem - 1);

  const ElemType objectiveRegularization = lambda / 2.0 *
      arma::dot(parameters.tail_cols(parameters.n_elem - 1),
                parameters.tail_cols(parameters.n_elem - 1));

  // Calculate the sigmoid function values.
  const arma::Row<ElemType> sigmoids = 1.0 / (1.0 +
      arma::exp(-(parameters(0, 0) +
                  parameters.tail_cols(parameters.n_elem - 1) * predictors)));

  gradient.set_size(arma::size(parameters));
  gradient[0] = -arma::accu(responses - sigmoids);
  gradient.tail_cols(parameters.n_elem - 1) = (sigmoids - responses) *
      predictors.t() + regularization;

  // Now compute the objective function using the sigmoids.
  ElemType result = arma::accu(arma::log(1.0 -
      arma::conv_to<arma::Row<ElemType>>::from(responses) + sigmoids %
      (2 * arma::conv_to<arma::Row<ElemType>>::from(responses) - 1.0)));

  // Invert the result, because it's a minimization.
  return objectiveRegularization - result;
}

template<typename MatType>
template<typename GradType>
typename MatType::elem_type
LogisticRegressionFunction<MatType>::EvaluateWithGradient(
    const MatType& parameters,
    const size_t begin,
    GradType& gradient,
    const size_t batchSize) const
{
  typedef typename MatType::elem_type ElemType;

  // Regularization term.
  MatType regularization =
      lambda * parameters.tail_cols(parameters.n_elem - 1) / predictors.n_cols *
      batchSize;

  const ElemType objectiveRegularization = lambda *
      (batchSize / (2.0 * predictors.n_cols)) *
      arma::dot(parameters.tail_cols(parameters.n_elem - 1),
                parameters.tail_cols(parameters.n_elem - 1));

  // Calculate the sigmoid function values.
  const arma::Row<ElemType> sigmoids = 1.0 / (1.0 +
      arma::exp(-(parameters(0, 0) +
                  parameters.tail_cols(parameters.n_elem - 1) *
                      predictors.cols(begin, begin + batchSize - 1))));

  gradient.set_size(parameters.n_rows, parameters.n_cols);
  gradient[0] = -arma::accu(responses.subvec(begin, begin + batchSize - 1) -
      sigmoids);
  gradient.tail_cols(parameters.n_elem - 1) = (sigmoids -
      responses.subvec(begin, begin + batchSize - 1)) *
      predictors.cols(begin, begin + batchSize - 1).t() + regularization;

  // Now compute the objective function using the sigmoids.
  arma::Row<ElemType> respD = arma::conv_to<arma::Row<ElemType>>::from(
      responses.subvec(begin, begin + batchSize - 1));
  const ElemType result = arma::accu(arma::log(1.0 - respD + sigmoids %
      (2 * respD - 1.0)));

  // Invert the result, because it's a minimization.
  return objectiveRegularization - result;
}

template<typename MatType>
void LogisticRegressionFunction<MatType>::Classify(
    const MatType& dataset,
    arma::Row<size_t>& labels,
    const MatType& parameters,
    const double decisionBoundary) const
{
  // Calculate sigmoid function for each point.  The (1.0 - decisionBoundary)
  // term correctly sets an offset so that floor() returns 0 or 1 correctly.
  labels = arma::conv_to<arma::Row<size_t>>::from((1.0 /
      (1.0 + arma::exp(-parameters(0) -
      parameters.tail_cols(parameters.n_elem - 1) * dataset))) +
      (1.0 - decisionBoundary));
}

template<typename MatType>
double LogisticRegressionFunction<MatType>::ComputeAccuracy(
    const MatType& predictors,
    const arma::Row<size_t>& responses,
    const MatType& parameters,
    const double decisionBoundary) const
{
  // Predict responses using the current model.
  arma::Row<size_t> tempResponses;
  Classify(predictors, tempResponses, parameters, decisionBoundary);

  // Count the number of responses that were correct.
  size_t count = 0;
  for (size_t i = 0; i < responses.n_elem; i++)
  {
    if (responses(i) == tempResponses(i))
      count++;
  }

  return (double) (count * 100) / responses.n_elem;
}

} // namespace test
} // namespace ens

#endif
/**
 * @file matyas_function.hpp
 * @author Marcus Edel
 *
 * Definition of the Matyas function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_MATYAS_FUNCTION_HPP
#define ENSMALLEN_PROBLEMS_MATYAS_FUNCTION_HPP

namespace ens {
namespace test {

/**
 * The Matyas function, defined by
 *
 * \f[
 * f(x) = 0.26 * (x_1^2 + x_2^2) - 0.48 * x_1 * x_2
 * \f]
 *
 * This should optimize to f(x) = 0, at x = [0, 0].
 *
 * For more information, please refer to:
 *
 * @code
 * @article{Jamil2013,
 *   title   = {A Literature Survey of Benchmark Functions For Global
 *              Optimization Problems},
 *   author  = {Momin Jamil and Xin{-}She Yang},
 *   journal = {CoRR},
 *   year    = {2013},
 *   url     = {http://arxiv.org/abs/1308.4008}
 * }
 * @endcode
 */
class MatyasFunction
{
 public:
  //! Initialize the MatyasFunction.
  MatyasFunction();

  /**
   * Shuffle the order of function visitation. This may be called by the
   * optimizer.
   */
  void Shuffle();

  //! Return 1 (the number of functions).
  size_t NumFunctions() const { return 1; }

  /**
   * Evaluate a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param batchSize Number of points to process.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates,
                                       const size_t begin,
                                       const size_t batchSize) const;

  /**
   * Evaluate a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates) const;

  /**
   * Evaluate the gradient of a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param gradient The function gradient.
   * @param batchSize Number of points to process.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates,
                const size_t begin,
                GradType& gradient,
                const size_t batchSize) const;

  /**
   * Evaluate the gradient of a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   * @param gradient The function gradient.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates, GradType& gradient);

  // Note: GetInitialPoint(), GetFinalPoint(), and GetFinalObjective() are not
  // required for using ensmallen to optimize this function!  They are
  // specifically used as a convenience just for ensmallen's testing
  // infrastructure.

  //! Get the starting point.
  template<typename MatType = arma::mat>
  MatType GetInitialPoint() const { return MatType("-3; 3"); }

  //! Get the final point.
  template<typename MatType = arma::mat>
  MatType GetFinalPoint() const { return MatType("0.0; 0.0"); }

  //! Get the final objective.
  double GetFinalObjective() const { return 0.0; }
};

} // namespace test
} // namespace ens

// Include implementation.
#include "matyas_function_impl.hpp"

#endif // ENSMALLEN_PROBLEMS_MATYAS_FUNCTION_HPP
/**
 * @file matyas_function_impl.hpp
 * @author Marcus Edel
 *
 * Implementation of the Matyas function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_MATYAS_FUNCTION_IMPL_HPP
#define ENSMALLEN_PROBLEMS_MATYAS_FUNCTION_IMPL_HPP

// In case it hasn't been included yet.
#include "matyas_function.hpp"

namespace ens {
namespace test {

inline MatyasFunction::MatyasFunction() { /* Nothing to do here */ }

inline void MatyasFunction::Shuffle() { /* Nothing to do here */ }

template<typename MatType>
typename MatType::elem_type MatyasFunction::Evaluate(
    const MatType& coordinates,
    const size_t /* begin */,
    const size_t /* batchSize */) const
{
  // Convenience typedef.
  typedef typename MatType::elem_type ElemType;

  // For convenience; we assume these temporaries will be optimized out.
  const ElemType x1 = coordinates(0);
  const ElemType x2 = coordinates(1);

  const double objective = 0.26 * (pow(x1, 2) + std::pow(x2, 2)) -
      0.48 * x1 * x2;

  return objective;
}

template<typename MatType>
typename MatType::elem_type MatyasFunction::Evaluate(
    const MatType& coordinates) const
{
  return Evaluate(coordinates, 0, NumFunctions());
}

template<typename MatType, typename GradType>
inline void MatyasFunction::Gradient(const MatType& coordinates,
                                     const size_t /* begin */,
                                     GradType& gradient,
                                     const size_t /* batchSize */) const
{
  // Convenience typedef.
  typedef typename MatType::elem_type ElemType;

  // For convenience; we assume these temporaries will be optimized out.
  const ElemType x1 = coordinates(0);
  const ElemType x2 = coordinates(1);

  gradient.set_size(2, 1);
  gradient(0) = 0.52 * x1 - 48 * x2;
  gradient(1) = 0.52 * x2 - 0.48 * x1;
}

template<typename MatType, typename GradType>
inline void MatyasFunction::Gradient(const MatType& coordinates,
                                     GradType& gradient)
{
  Gradient(coordinates, 0, gradient, NumFunctions());
}

} // namespace test
} // namespace ens

#endif
/**
 * @file mc_cormick_function.hpp
 * @author Marcus Edel
 *
 * Definition of the McCormick function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_MC_CORMICK_FUNCTION_HPP
#define ENSMALLEN_PROBLEMS_MC_CORMICK_FUNCTION_HPP

namespace ens {
namespace test {

/**
 * The McCormick function, defined by
 *
 * \f[
 * f(x) = \sin(x_1 + x_2) + (x_1 - x_2)^2 - 1.5 * x_1 + 2.5 * x_2 + 1
 * \f]
 *
 * This should optimize to f(x) = -1.9133, at x = [-0.54719, -1.54719].
 *
 * For more information, please refer to:
 *
 * @code
 * @article{Jamil2013,
 *   title   = {A Literature Survey of Benchmark Functions For Global
 *              Optimization Problems},
 *   author  = {Momin Jamil and Xin{-}She Yang},
 *   journal = {CoRR},
 *   year    = {2013},
 *   url     = {http://arxiv.org/abs/1308.4008}
 * }
 * @endcode
 */
class McCormickFunction
{
 public:
  //! Initialize the McCormickFunction.
  McCormickFunction();

  /**
   * Shuffle the order of function visitation. This may be called by the
   * optimizer.
   */
  void Shuffle();

  //! Return 1 (the number of functions).
  size_t NumFunctions() const { return 1; }

  /**
   * Evaluate a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param batchSize Number of points to process.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates,
                                       const size_t begin,
                                       const size_t batchSize) const;

  /**
   * Evaluate a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates) const;

  /**
   * Evaluate the gradient of a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param gradient The function gradient.
   * @param batchSize Number of points to process.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates,
                const size_t begin,
                GradType& gradient,
                const size_t batchSize) const;

  /**
   * Evaluate the gradient of a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   * @param gradient The function gradient.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates, GradType& gradient);

  // Note: GetInitialPoint(), GetFinalPoint(), and GetFinalObjective() are not
  // required for using ensmallen to optimize this function!  They are
  // specifically used as a convenience just for ensmallen's testing
  // infrastructure.

  //! Get the starting point.
  template<typename MatType = arma::mat>
  MatType GetInitialPoint() const { return MatType("-2; 4"); }

  //! Get the final point.
  template<typename MatType = arma::mat>
  MatType GetFinalPoint() const { return MatType("-0.54719; -1.54719"); }

  //! Get the final objective.
  double GetFinalObjective() const { return -1.9133; }
};

} // namespace test
} // namespace ens

// Include implementation.
#include "mc_cormick_function_impl.hpp"

#endif // ENSMALLEN_PROBLEMS_MC_CORMICK_FUNCTION_HPP
/**
 * @file mc_cormick_function_impl.hpp
 * @author Marcus Edel
 *
 * Implementation of the McCormick function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_MC_CORMICK_FUNCTION_IMPL_HPP
#define ENSMALLEN_PROBLEMS_MC_CORMICK_FUNCTION_IMPL_HPP

// In case it hasn't been included yet.
#include "mc_cormick_function.hpp"

namespace ens {
namespace test {

inline McCormickFunction::McCormickFunction() { /* Nothing to do here */ }

inline void McCormickFunction::Shuffle() { /* Nothing to do here */ }

template<typename MatType>
typename MatType::elem_type McCormickFunction::Evaluate(
    const MatType& coordinates,
    const size_t /* begin */,
    const size_t /* batchSize */) const
{
  // For convenience; we assume these temporaries will be optimized out.
  const typename MatType::elem_type x1 = coordinates(0);
  const typename MatType::elem_type x2 = coordinates(1);

  const typename MatType::elem_type objective = std::sin(x1 + x2) +
      std::pow(x1 - x2, 2) - 1.5 * x1 + 2.5 * x2 + 1;

  return objective;
}

template<typename MatType>
typename MatType::elem_type McCormickFunction::Evaluate(
    const MatType& coordinates) const
{
  return Evaluate(coordinates, 0, NumFunctions());
}

template<typename MatType, typename GradType>
inline void McCormickFunction::Gradient(const MatType& coordinates,
                                        const size_t /* begin */,
                                        GradType& gradient,
                                        const size_t /* batchSize */) const
{
  // For convenience; we assume these temporaries will be optimized out.
  const typename MatType::elem_type x1 = coordinates(0);
  const typename MatType::elem_type x2 = coordinates(1);

  gradient.set_size(2, 1);
  gradient(0) = std::cos(x1 + x2) + 2 * x1 - 2 * x2 - 1.5;
  gradient(1) = std::cos(x1 + x2) - 2 * x1 + 2 * x2 + 2.5;
}

template<typename MatType, typename GradType>
inline void McCormickFunction::Gradient(const MatType& coordinates,
                                        GradType& gradient)
{
  Gradient(coordinates, 0, gradient, NumFunctions());
}

} // namespace test
} // namespace ens

#endif
/**
 * @file problems.hpp
 * @author Ryan Curtin
 *
 * Include each of the test problems for ensmallen.
 */
#ifndef ENSMALLEN_PROBLEMS_PROBLEMS_HPP
#define ENSMALLEN_PROBLEMS_PROBLEMS_HPP

#include "ackley_function.hpp"
#include "aug_lagrangian_test_functions.hpp"
#include "beale_function.hpp"
#include "booth_function.hpp"
#include "bukin_function.hpp"
#include "colville_function.hpp"
#include "cross_in_tray_function.hpp"
#include "drop_wave_function.hpp"
#include "easom_function.hpp"
#include "eggholder_function.hpp"
#include "fonseca_fleming_function.hpp"
#include "fw_test_function.hpp"
#include "generalized_rosenbrock_function.hpp"
#include "goldstein_price_function.hpp"
#include "gradient_descent_test_function.hpp"
#include "himmelblau_function.hpp"
#include "holder_table_function.hpp"
#include "levy_function_n13.hpp"
#include "logistic_regression_function.hpp"
#include "matyas_function.hpp"
#include "mc_cormick_function.hpp"
#include "rastrigin_function.hpp"
#include "rosenbrock_function.hpp"
#include "rosenbrock_wood_function.hpp"
#include "schaffer_function_n1.hpp"
#include "schaffer_function_n2.hpp"
#include "schaffer_function_n4.hpp"
#include "schwefel_function.hpp"
#include "sgd_test_function.hpp"
#include "softmax_regression_function.hpp"
#include "sparse_test_function.hpp"
#include "sphere_function.hpp"
#include "styblinski_tang_function.hpp"
#include "three_hump_camel_function.hpp"
#include "wood_function.hpp"
#include "zdt/zdt1_function.hpp"
#include "zdt/zdt2_function.hpp"
#include "zdt/zdt3_function.hpp"
#include "zdt/zdt4_function.hpp"
#include "zdt/zdt6_function.hpp"

#endif
/**
 * @file rastrigin_function.hpp
 * @author Marcus Edel
 *
 * Definition of the Rastrigin function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_RASTRIGIN_FUNCTION_HPP
#define ENSMALLEN_PROBLEMS_RASTRIGIN_FUNCTION_HPP

namespace ens {
namespace test {

/**
 * The Rastrigin function, defined by
 *
 * \f[
 * f(x) = 10 * d * \sum_{i=1}^{d} x_i^2 - 10 * \cos(2 * \pi * x_i)
 * \f]
 *
 * This should optimize to f(x) = 0
 * at x = [0, ..., 0].
 *
 * For more information, please refer to:
 *
 * @code
 * @article{Jamil2013,
 *   title   = {Systems of extremal control},
 *   author  = {Rastrigin, L. A.},
 *   journal = {Mir},
 *   year    = {1974}
 * }
 * @endcode
 */
class RastriginFunction
{
 public:
  /*
   * Initialize the RastriginFunction.
   *
   * @param n Number of dimensions for the function.
   */
  RastriginFunction(const size_t n = 2);

  /**
   * Shuffle the order of function visitation. This may be called by the
   * optimizer.
   */
  void Shuffle();

  //! Return 1 (the number of functions).
  size_t NumFunctions() const { return n; }

  /**
   * Evaluate a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param batchSize Number of points to process.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates,
                                       const size_t begin,
                                       const size_t batchSize) const;

  /**
   * Evaluate a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates) const;

  /**
   * Evaluate the gradient of a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param gradient The function gradient.
   * @param batchSize Number of points to process.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates,
                const size_t begin,
                GradType& gradient,
                const size_t batchSize) const;

  /**
   * Evaluate the gradient of a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   * @param gradient The function gradient.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates, GradType& gradient);

  // Note: GetInitialPoint(), GetFinalPoint(), and GetFinalObjective() are not
  // required for using ensmallen to optimize this function!  They are
  // specifically used as a convenience just for ensmallen's testing
  // infrastructure.

  //! Get the starting point.
  template<typename MatType = arma::mat>
  MatType GetInitialPoint() const
  {
    return arma::conv_to<MatType>::from(initialPoint);
  }

  //! Get the final point.
  template<typename MatType = arma::mat>
  MatType GetFinalPoint() const
  {
    return arma::zeros<MatType>(initialPoint.n_rows, initialPoint.n_cols);
  }

  //! Get the final objective.
  double GetFinalObjective() const { return 0.0; }

 private:
  //! Number of dimensions for the function.
  size_t n;

  //! For shuffling.
  arma::Row<size_t> visitationOrder;

  //! Initial starting point.
  arma::mat initialPoint;
};

} // namespace test
} // namespace ens

// Include implementation.
#include "rastrigin_function_impl.hpp"

#endif // ENSMALLEN_PROBLEMS_RASTRIGIN_FUNCTION_HPP
/**
 * @file rastrigin_function_impl.hpp
 * @author Marcus Edel
 *
 * Implementation of the Rastrigin function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_RASTRIGIN_FUNCTION_IMPL_HPP
#define ENSMALLEN_PROBLEMS_RASTRIGIN_FUNCTION_IMPL_HPP

// In case it hasn't been included yet.
#include "rastrigin_function.hpp"

namespace ens {
namespace test {

inline RastriginFunction::RastriginFunction(const size_t n) :
    n(n),
    visitationOrder(arma::linspace<arma::Row<size_t> >(0, n - 1, n))

{
  initialPoint.set_size(n, 1);
  initialPoint.fill(-3);
}

inline void RastriginFunction::Shuffle()
{
  visitationOrder = arma::shuffle(
      arma::linspace<arma::Row<size_t> >(0, n - 1, n));
}

template<typename MatType>
typename MatType::elem_type RastriginFunction::Evaluate(
    const MatType& coordinates,
    const size_t begin,
    const size_t batchSize) const
{
  // Convenience typedef.
  typedef typename MatType::elem_type ElemType;

  ElemType objective = 0.0;
  for (size_t j = begin; j < begin + batchSize; ++j)
  {
    const size_t p = visitationOrder[j];
    objective += std::pow(coordinates(p), 2) - 10.0 *
        std::cos(2.0 * arma::datum::pi * coordinates(p));
  }
  objective += 10.0 * n;

  return objective;
}

template<typename MatType>
typename MatType::elem_type RastriginFunction::Evaluate(
    const MatType& coordinates) const
{
  return Evaluate(coordinates, 0, NumFunctions());
}

template<typename MatType, typename GradType>
inline void RastriginFunction::Gradient(const MatType& coordinates,
                                        const size_t begin,
                                        GradType& gradient,
                                        const size_t batchSize) const
{
  gradient.zeros(n, 1);

  for (size_t j = begin; j < begin + batchSize; ++j)
  {
    const size_t p = visitationOrder[j];
    gradient(p) += (10.0 * n) * (2 * (coordinates(p) + 10.0 * arma::datum::pi *
        std::sin(2.0 * arma::datum::pi * coordinates(p))));
  }
}

template<typename MatType, typename GradType>
inline void RastriginFunction::Gradient(const MatType& coordinates,
                                        GradType& gradient)
{
  Gradient(coordinates, 0, gradient, NumFunctions());
}

} // namespace test
} // namespace ens

#endif
/**
 * @file rosenbrock_function.hpp
 * @author Ryan Curtin
 * @author Marcus Edel
 *
 * Definition of the Rosenbrock function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_ROSENBROCK_FUNCTION_HPP
#define ENSMALLEN_PROBLEMS_ROSENBROCK_FUNCTION_HPP

namespace ens {
namespace test {

/**
 * The Rosenbrock function, defined by:
 *
 *  f(x) = f1(x) + f2(x)
 *  f1(x) = 100 (x2 - x1^2)^2
 *  f2(x) = (1 - x1)^2
 *  x_0 = [-1.2, 1]
 *
 * This should optimize to f(x) = 0, at x = [1, 1].
 *
 * For more information, please refer to:
 *
 * @code
 * @article{Rosenbrock1960,
 *    title  = {An Automatic Method for Finding the Greatest or Least Value of a
 *              Function},
 *   author  = {Rosenbrock, H. H.},
 *   journal = {The Computer Journal},
 *   number  = {3},
 *   pages   = {175--184},
 *   year    = {1960},
 * }
 * @endcode
 */
class RosenbrockFunction
{
 public:
  //! Initialize the RosenbrockFunction.
  RosenbrockFunction();

  /**
   * Shuffle the order of function visitation. This may be called by the
   * optimizer.
   */
  void Shuffle();

  //! Return 1 (the number of functions).
  size_t NumFunctions() const { return 1; }

  /**
   * Evaluate a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param batchSize Number of points to process.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates,
                                       const size_t begin,
                                       const size_t batchSize) const;

  /**
   * Evaluate a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates) const;

  /**
   * Evaluate the gradient of a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param gradient The function gradient.
   * @param batchSize Number of points to process.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates,
                const size_t begin,
                GradType& gradient,
                const size_t batchSize) const;

  /**
   * Evaluate the gradient of a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   * @param gradient The function gradient.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates, GradType& gradient) const;

  /**
   * Evaluate the function and gradient at the given coordinates.
   */
  template<typename MatType, typename GradType>
  typename MatType::elem_type EvaluateWithGradient(const MatType& coordinates,
                                                   GradType& gradient) const;

  // Note: GetInitialPoint(), GetFinalPoint(), and GetFinalObjective() are not
  // required for using ensmallen to optimize this function!  They are
  // specifically used as a convenience just for ensmallen's testing
  // infrastructure.

  //! Get the starting point.
  template<typename MatType = arma::mat>
  MatType GetInitialPoint() const { return MatType("-1.2; 1.0"); }

  //! Get the final point.
  template<typename MatType = arma::mat>
  MatType GetFinalPoint() const { return MatType("1.0; 1.0"); }

  //! Get the final objective.
  double GetFinalObjective() const { return 0.0; }
};

} // namespace test
} // namespace ens

// Include implementation.
#include "rosenbrock_function_impl.hpp"

#endif // ENSMALLEN_PROBLEMS_ROSENBROCK_FUNCTION_HPP
/**
 * @file rosenbrock_function_impl.hpp
 * @author Ryan Curtin
 * @author Marcus Edel
 *
 * Implementation of the Rosenbrock function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_ROSENBROCK_FUNCTION_IMPL_HPP
#define ENSMALLEN_PROBLEMS_ROSENBROCK_FUNCTION_IMPL_HPP

// In case it hasn't been included yet.
#include "rosenbrock_function.hpp"

namespace ens {
namespace test {

inline RosenbrockFunction::RosenbrockFunction() { /* Nothing to do here */ }

inline void RosenbrockFunction::Shuffle() { /* Nothing to do here */ }

template<typename MatType>
typename MatType::elem_type RosenbrockFunction::Evaluate(
    const MatType& coordinates,
    const size_t /* begin */,
    const size_t /* batchSize */) const
{
  // Convenience typedef.
  typedef typename MatType::elem_type ElemType;

  // For convenience; we assume these temporaries will be optimized out.
  const ElemType x1 = coordinates(0);
  const ElemType x2 = coordinates(1);

  const ElemType objective =
      /* f1(x) */ 100 * std::pow(x2 - std::pow(x1, 2), 2) +
      /* f2(x) */ std::pow(1 - x1, 2);

  return objective;
}

template<typename MatType>
typename MatType::elem_type RosenbrockFunction::Evaluate(
    const MatType& coordinates) const
{
  return Evaluate(coordinates, 0, NumFunctions());
}

template<typename MatType, typename GradType>
void RosenbrockFunction::Gradient(const MatType& coordinates,
                                  const size_t /* begin */,
                                  GradType& gradient,
                                  const size_t /* batchSize */) const
{
  // Convenience typedef.
  typedef typename MatType::elem_type ElemType;

  // For convenience; we assume these temporaries will be optimized out.
  const ElemType x1 = coordinates(0);
  const ElemType x2 = coordinates(1);

  gradient.set_size(2, 1);
  gradient(0) = -2 * (1 - x1) + 400 * (std::pow(x1, 3) - x2 * x1);
  gradient(1) = 200 * (x2 - std::pow(x1, 2));
}

template<typename MatType, typename GradType>
void RosenbrockFunction::Gradient(const MatType& coordinates,
                                  GradType& gradient) const
{
  Gradient(coordinates, 0, gradient, 1);
}

/**
 * Evaluate the function and gradient at the given coordinates.
 */
template<typename MatType, typename GradType>
typename MatType::elem_type RosenbrockFunction::EvaluateWithGradient(
    const MatType& coordinates,
    GradType& gradient) const
{
  Gradient(coordinates, gradient);
  return Evaluate(coordinates);
}

} // namespace test
} // namespace ens

#endif
/**
 * @file rosenbrock_wood_function.hpp
 * @author Ryan Curtin
 * @author Marcus Edel
 *
 * Definition of the Rosenbrock-Wood function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_ROSENBROCK_WOOD_FUNCTION_HPP
#define ENSMALLEN_PROBLEMS_ROSENBROCK_WOOD_FUNCTION_HPP

#include "generalized_rosenbrock_function.hpp"
#include "wood_function.hpp"

namespace ens {
namespace test {

/**
 * The Generalized Rosenbrock function in 4 dimensions with the Wood Function in
 * four dimensions.  In this function we are actually optimizing a 2x4 matrix of
 * coordinates, not a vector.
 */
class RosenbrockWoodFunction
{
 public:
  //! Initialize the RosenbrockWoodFunction.
  RosenbrockWoodFunction();

  /**
   * Shuffle the order of function visitation. This may be called by the
   * optimizer.
   */
  void Shuffle();

  //! Return 1 (the number of functions).
  size_t NumFunctions() const { return 1; }

  /**
   * Evaluate a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param batchSize Number of points to process.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates,
                                       const size_t begin,
                                       const size_t batchSize) const;

  /**
   * Evaluate a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates) const;

  /**
   * Evaluate the gradient of a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param gradient The function gradient.
   * @param batchSize Number of points to process.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates,
                const size_t begin,
                GradType& gradient,
                const size_t batchSize) const;

  /**
   * Evaluate the gradient of a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   * @param gradient The function gradient.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates, GradType& gradient) const;

  // Note: GetInitialPoint(), GetFinalPoint(), and GetFinalObjective() are not
  // required for using ensmallen to optimize this function!  They are
  // specifically used as a convenience just for ensmallen's testing
  // infrastructure.

  //! Get the starting point.
  template<typename MatType = arma::mat>
  const MatType GetInitialPoint() const
  {
    return arma::conv_to<MatType>::from(initialPoint);
  }

  //! Get the final point.
  template<typename MatType = arma::mat>
  MatType GetFinalPoint() const
  {
    return arma::ones<MatType>(initialPoint.n_rows, initialPoint.n_cols);
  }

  //! Get the final objective.
  double GetFinalObjective() const { return 0.0; }

 private:
  //! Locally-stored initial point.
  arma::mat initialPoint;

  //! Locally-stored Generalized-Rosenbrock function.
  GeneralizedRosenbrockFunction rf;

  //! Locally-stored Wood function.
  WoodFunction wf;
};

} // namespace test
} // namespace ens

// Include implementation.
#include "rosenbrock_wood_function_impl.hpp"

#endif // ENSMALLEN_PROBLEMS_ROSENBROCK_WOOD_FUNCTION_HPP
/**
 * @file rosenbrock_wood_function_impl.hpp
 * @author Ryan Curtin
 * @author Marcus Edel
 *
 * Implementation of the Rosenbrock-Wood function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */

#ifndef ENSMALLEN_PROBLEMS_ROSENBROCK_WOOD_FUNCTION_IMPL_HPP
#define ENSMALLEN_PROBLEMS_ROSENBROCK_WOOD_FUNCTION_IMPL_HPP

// In case it hasn't been included yet.
#include "rosenbrock_wood_function.hpp"

namespace ens {
namespace test {

inline RosenbrockWoodFunction::RosenbrockWoodFunction() : rf(4), wf()
{
  initialPoint.set_size(4, 2);
  initialPoint.col(0) = rf.GetInitialPoint();
  initialPoint.col(1) = wf.GetInitialPoint();
}

inline void RosenbrockWoodFunction::Shuffle() { /* Nothing to do here */ }

template<typename MatType>
typename MatType::elem_type RosenbrockWoodFunction::Evaluate(
    const MatType& coordinates,
    const size_t /* begin */,
    const size_t /* batchSize */) const
{
  return rf.Evaluate(coordinates.col(0)) + wf.Evaluate(coordinates.col(1));
}

template<typename MatType>
typename MatType::elem_type RosenbrockWoodFunction::Evaluate(
    const MatType& coordinates) const
{
  return Evaluate(coordinates, 0, NumFunctions());
}

template<typename MatType, typename GradType>
inline void RosenbrockWoodFunction::Gradient(const MatType& coordinates,
                                             const size_t /* begin */,
                                             GradType& gradient,
                                             const size_t /* batchSize */) const
{
  // Convenience typedef.
  typedef typename MatType::elem_type ElemType;

  gradient.set_size(4, 2);

  arma::Col<ElemType> grf(4);
  arma::Col<ElemType> gwf(4);

  rf.Gradient(coordinates.col(0), grf);
  wf.Gradient(coordinates.col(1), gwf);

  gradient.col(0) = grf;
  gradient.col(1) = gwf;
}

template<typename MatType, typename GradType>
inline void RosenbrockWoodFunction::Gradient(const MatType& coordinates,
                                             GradType& gradient) const
{
  Gradient(coordinates, 0, gradient, 1);
}

} // namespace test
} // namespace ens

#endif
/**
 * @file schaffer_function_n1.hpp
 * @author Sayan Goswami
 *
 * Implementation of Schaffer function N.1.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */

#ifndef ENSMALLEN_PROBLEMS_SCHAFFER_FUNCTION_N1_HPP
#define ENSMALLEN_PROBLEMS_SCHAFFER_FUNCTION_N1_HPP

namespace ens {
namespace test {

/**
 * The Schaffer function N.1 is defined by
 *
 * \f[
 * f_1(x) = x^2
 * f_2(x) = (x-2)^2
 * \f]
 *
 * The optimal solutions to this multi-objective function lie in the
 * range [0, 2].
 *
 * @tparam arma::mat Type of matrix to optimize.
 */
template<typename MatType = arma::mat>
class SchafferFunctionN1
{
 private:
  size_t numObjectives;
  size_t numVariables;

 public:
 //! Initialize the SchafferFunctionN1
  SchafferFunctionN1() : numObjectives(2), numVariables(1)
  {/* Nothing to do here. */}

  /**
   * Evaluate the objectives with the given coordinate.
   *
   * @param coords The function coordinates.
   * @return arma::Col<typename MatType::elem_type>
   */
  arma::Col<typename MatType::elem_type> Evaluate(const MatType& coords)
  {
    // Convenience typedef.
    typedef typename MatType::elem_type ElemType;

    arma::Col<ElemType> objectives(numObjectives);

    objectives(0) = std::pow(coords[0], 2);
    objectives(1) = std::pow(coords[0] - 2, 2);

    return objectives;
  }

  //! Get the starting point.
  MatType GetInitialPoint()
  {
    // Convenience typedef.
    typedef typename MatType::elem_type ElemType;

    return arma::Col<ElemType>(numVariables, 1, arma::fill::zeros);
  }

  struct ObjectiveA
  {
    typename MatType::elem_type Evaluate(const MatType& coords)
    {
        return std::pow(coords[0], 2);
    }
  } objectiveA;

  struct ObjectiveB
  {
    typename MatType::elem_type Evaluate(const MatType& coords)
    {
        return std::pow(coords[0] - 2, 2);
    }
  } objectiveB;

  //! Get objective functions.
  std::tuple<ObjectiveA, ObjectiveB> GetObjectives()
  {
    return std::make_tuple(objectiveA, objectiveB);
  }
};
} // namespace test
} // namespace ens

#endif
/**
 * @file schaffer_function_n2.hpp
 * @author Suryoday Basak
 *
 * Definition of Schaffer function N.2.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_SCHAFFER_FUNCTION_N2_HPP
#define ENSMALLEN_PROBLEMS_SCHAFFER_FUNCTION_N2_HPP

namespace ens {
namespace test {

/**
 * The Schaffer function N.2, defined by
 *
 * \f[
 * f(x1, x2) = 0.5 + ((sin^2(x1^2 - x2^2) - 0.5) /
 *             (1 + 0.001 * (x1^2 + x2^2))^2)
 * \f]
 *
 * This should optimize to f(x1, x2) = 0, at (x1, x2) = [0, 0].
 *
 * For more information, please refer to:
 *
 * @code
 * @article{1308.4008,
 *   Author = {Momin Jamil and Xin-She Yang},
 *   Title  = {A Literature Survey of Benchmark Functions For Global
 *             Optimization Problems},
 *   Year   = {2013},
 *   Eprint = {arXiv:1308.4008},
 *   Doi    = {10.1504/IJMMNO.2013.055204},
 * }
 * @endcode
 */
class SchafferFunctionN2
{
 public:
  //! Initialize the SchafferFunctionN2.
  SchafferFunctionN2();

  /**
   * Shuffle the order of function visitation. This may be called by the
   * optimizer.
   */
  void Shuffle();

  //! Return 1 (the number of functions).
  size_t NumFunctions() const { return 1; }

  /**
   * Evaluate a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param batchSize Number of points to process.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates,
                                       const size_t begin,
                                       const size_t batchSize) const;

  /**
   * Evaluate a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates) const;

  /**
   * Evaluate the gradient of a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param gradient The function gradient.
   * @param batchSize Number of points to process.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates,
                const size_t begin,
                GradType& gradient,
                const size_t batchSize) const;

  /**
   * Evaluate the gradient of a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   * @param gradient The function gradient.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates, GradType& gradient);

  // Note: GetInitialPoint(), GetFinalPoint(), and GetFinalObjective() are not
  // required for using ensmallen to optimize this function!  They are
  // specifically used as a convenience just for ensmallen's testing
  // infrastructure.

  //! Get the starting point.
  template<typename MatType = arma::mat>
  MatType GetInitialPoint() const { return MatType("-100; 100"); }

  //! Get the final point.
  template<typename MatType = arma::mat>
  MatType GetFinalPoint() const { return MatType("0.0; 0.0"); }

  //! Get the final objective.
  double GetFinalObjective() const { return 0.0; }
};

} // namespace test
} // namespace ens

// Include implementation.
#include "schaffer_function_n2_impl.hpp"

#endif // ENSMALLEN_PROBLEMS_SCHAFFER_FUNCTION_N2_HPP
/**
 * @file schaffer_function_n2_impl.hpp
 * @author Suryoday Basak
 *
 * Implementation of Schaffer function N.2.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_SCHAFFER_FUNCTION_N2_IMPL_HPP
#define ENSMALLEN_PROBLEMS_SCHAFFER_FUNCTION_N2_IMPL_HPP

// In case it hasn't been included yet.
#include "schaffer_function_n2.hpp"

namespace ens {
namespace test {

inline SchafferFunctionN2::SchafferFunctionN2() { /* Nothing to do here */ }

inline void SchafferFunctionN2::Shuffle() { /* Nothing to do here */ }

template<typename MatType>
typename MatType::elem_type SchafferFunctionN2::Evaluate(
    const MatType& coordinates,
    const size_t /* begin */,
    const size_t /* batchSize */) const
{
  // Convenience typedef.
  typedef typename MatType::elem_type ElemType;

  // For convenience; we assume these temporaries will be optimized out.
  const ElemType x1 = coordinates(0);
  const ElemType x2 = coordinates(1);

  const ElemType objective = 0.5 + (std::pow(std::sin(std::pow(x1, 2) -
      std::pow(x2, 2)), 2) - 0.5) / std::pow(1 + 0.001 *
      (std::pow(x1, 2) + std::pow(x2, 2)), 2);

  return objective;
}

template<typename MatType>
typename MatType::elem_type SchafferFunctionN2::Evaluate(
    const MatType& coordinates) const
{
  return Evaluate(coordinates, 0, NumFunctions());
}

template<typename MatType, typename GradType>
inline void SchafferFunctionN2::Gradient(const MatType& coordinates,
                                         const size_t /* begin */,
                                         GradType& gradient,
                                         const size_t /* batchSize */) const
{
  // Convenience typedef.
  typedef typename MatType::elem_type ElemType;

  // For convenience; we assume these temporaries will be optimized out.
  const ElemType x1 = coordinates(0);
  const ElemType x2 = coordinates(1);

  // Aliases for different terms in the expression of the gradient
  const ElemType x1Sq = x1 * x1;
  const ElemType x2Sq = x2 * x2;
  const ElemType sum1 = x1Sq - x2Sq;
  const ElemType sinSum1 = sin(sum1);
  const ElemType sum2 = 0.001 * (x1Sq + x2Sq) + 1;
  const ElemType trigExpression = 4 * sinSum1 * cos(sum1);
  const ElemType numerator1 = - 0.004 * (pow(sinSum1, 2) - 0.5);
  const ElemType expr1 = numerator1 / pow(sum2, 3);
  const ElemType expr2 = trigExpression / pow(sum2, 2);

  gradient.set_size(2, 1);
  gradient(0) = x1 * (expr1 + expr2);
  gradient(1) = x2 * (expr1 - expr2);
}

template<typename MatType, typename GradType>
inline void SchafferFunctionN2::Gradient(const MatType& coordinates,
                                         GradType& gradient)
{
  Gradient(coordinates, 0, gradient, 1);
}

} // namespace test
} // namespace ens

#endif
/**
 * @file schaffer_function_n4.hpp
 * @author Suryoday Basak
 *
 * Definition of Schaffer function N.4.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_SCHAFFER_FUNCTION_N4_HPP
#define ENSMALLEN_PROBLEMS_SCHAFFER_FUNCTION_N4_HPP

namespace ens {
namespace test {

/**
 * The Schaffer function N.4, defined by
 *
 * \f[
 * f(x1, x2) = 0.5 + (cos^2(sin(|x1^2 - x2^2|)) - 0.5) /
 *     (1 + 0.001 * (x1^2 + x2^2))^2
 * \f]
 *
 * This should optimize to f(x1, x2) = 0.292579, at (x1, x2) = [0, 1.25313], or
 *                                                  (x1, x2) = [0, -1.25313].
 *
 * For more information, please refer to:
 *
 * @code
 * @misc{LevyFunction,
 *   URL = {http://benchmarkfcns.xyz/benchmarkfcns/schaffern4fcn.html}
 * }
 * @endcode
 */
class SchafferFunctionN4
{
 public:
  //! Initialize the SchafferFunctionN4.
  SchafferFunctionN4();

  /**
   * Shuffle the order of function visitation. This may be called by the
   * optimizer.
   */
  void Shuffle();

  //! Return 1 (the number of functions).
  size_t NumFunctions() const { return 1; }

  //! Get the starting point.
  template<typename MatType = arma::mat>
  MatType GetInitialPoint() const { return MatType("-5; 5"); }

  /**
   * Evaluate a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param batchSize Number of points to process.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates,
                                       const size_t begin,
                                       const size_t batchSize) const;

  /**
   * Evaluate a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates) const;
};

} // namespace test
} // namespace ens

// Include implementation.
#include "schaffer_function_n4_impl.hpp"

#endif // ENSMALLEN_PROBLEMS_SCHAFFER_FUNCTION_N4_HPP
/**
 * @file schaffer_function_n4_impl.hpp
 * @author Suryoday Basak
 *
 * Implementation of Schaffer function N.4.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_SCHAFFER_FUNCTION_N4_IMPL_HPP
#define ENSMALLEN_PROBLEMS_SCHAFFER_FUNCTION_N4_IMPL_HPP

// In case it hasn't been included yet.
#include "schaffer_function_n4.hpp"

namespace ens {
namespace test {

inline SchafferFunctionN4::SchafferFunctionN4() { /* Nothing to do here */ }

inline void SchafferFunctionN4::Shuffle() { /* Nothing to do here */ }

template<typename MatType>
typename MatType::elem_type SchafferFunctionN4::Evaluate(
    const MatType& coordinates,
    const size_t /* begin */,
    const size_t /* batchSize */) const
{
  // Convenience typedef.
  typedef typename MatType::elem_type ElemType;

  // For convenience; we assume these temporaries will be optimized out.
  const ElemType x1 = coordinates(0);
  const ElemType x2 = coordinates(1);

  const ElemType objective = 0.5 + (std::pow(std::cos(std::sin(std::abs(
      std::pow(x1, 2) - std::pow(x2, 2)))), 2) - 0.5) / std::pow(1 + 0.001 *
      (std::pow(x1, 2) + std::pow(x2, 2)), 2);

  return objective;
}

template<typename MatType>
typename MatType::elem_type SchafferFunctionN4::Evaluate(
    const MatType& coordinates) const
{
  return Evaluate(coordinates, 0, NumFunctions());
}

} // namespace test
} // namespace ens

#endif
/**
 * @file schwefel_function.hpp
 * @author Marcus Edel
 *
 * Definition of the Schwefel function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_SCHWEFEL_FUNCTION_HPP
#define ENSMALLEN_PROBLEMS_SCHWEFEL_FUNCTION_HPP

namespace ens {
namespace test {

/**
 * The Schwefel function, defined by
 *
 * \f[
 * f(x) = 418.9829 * d * \sum_{i=1}^{d} x_i * \sin(\sqrt(\left|x\right|))
 * \f]
 *
 * This should optimize to f(x) = 0
 * at x = [420.9687, ..., 420.9687].
 *
 * For more information, please refer to:
 *
 * @code
 * @article{Jamil2013,
 *   title   = {Systems of extremal control},
 *   author  = {Rastrigin, L. A.},
 *   journal = {Mir},
 *   year    = {1974}
 * }
 * @endcode
 */
class SchwefelFunction
{
 public:
  /*
   * Initialize the SchwefelFunction.
   *
   * @param n Number of dimensions for the function.
   */
  SchwefelFunction(const size_t n);

  /**
   * Shuffle the order of function visitation. This may be called by the
   * optimizer.
   */
  void Shuffle();

  //! Return 1 (the number of functions).
  size_t NumFunctions() const { return n; }

  /**
   * Evaluate a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param batchSize Number of points to process.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates,
                                       const size_t begin,
                                       const size_t batchSize) const;

  /**
   * Evaluate a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates) const;

  /**
   * Evaluate the gradient of a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param gradient The function gradient.
   * @param batchSize Number of points to process.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates,
                const size_t begin,
                GradType& gradient,
                const size_t batchSize) const;

  /**
   * Evaluate the gradient of a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   * @param gradient The function gradient.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates, GradType& gradient);

  // Note: GetInitialPoint(), GetFinalPoint(), and GetFinalObjective() are not
  // required for using ensmallen to optimize this function!  They are
  // specifically used as a convenience just for ensmallen's testing
  // infrastructure.

  //! Get the starting point.
  template<typename MatType = arma::mat>
  MatType GetInitialPoint() const
  {
    return arma::conv_to<MatType>::from(initialPoint);
  }

  //! Get the final point.
  template<typename MatType = arma::mat>
  MatType GetFinalPoint() const
  {
    MatType result(initialPoint.n_rows, initialPoint.n_cols, arma::fill::none);
    result.fill(420.9687);
    return result;
  }

  //! Get the final objective.
  double GetFinalObjective() const { return 0.0; }

 private:
  //! Number of dimensions for the function.
  size_t n;

  //! For shuffling.
  arma::Row<size_t> visitationOrder;

  //! Initial starting point.
  arma::mat initialPoint;
};

} // namespace test
} // namespace ens

// Include implementation.
#include "schwefel_function_impl.hpp"

#endif // ENSMALLEN_PROBLEMS_SCHWEFEL_FUNCTION_HPP
/**
 * @file schwefel_function_impl.hpp
 * @author Marcus Edel
 *
 * Implementation of the Schwefel function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_SCHWEFEL_FUNCTION_IMPL_HPP
#define ENSMALLEN_PROBLEMS_SCHWEFEL_FUNCTION_IMPL_HPP

// In case it hasn't been included yet.
#include "schwefel_function.hpp"

namespace ens {
namespace test {

inline SchwefelFunction::SchwefelFunction(const size_t n) :
    n(n),
    visitationOrder(arma::linspace<arma::Row<size_t> >(0, n - 1, n))

{
  initialPoint.set_size(n, 1);
  initialPoint.fill(-300);
}

inline void SchwefelFunction::Shuffle()
{
  visitationOrder = arma::shuffle(
      arma::linspace<arma::Row<size_t> >(0, n - 1, n));
}

template<typename MatType>
typename MatType::elem_type SchwefelFunction::Evaluate(
    const MatType& coordinates,
    const size_t begin,
    const size_t batchSize) const
{
  typename MatType::elem_type objective = 0;
  for (size_t j = begin; j < begin + batchSize; ++j)
  {
    const size_t p = visitationOrder[j];
    objective += coordinates(p) * std::sin(std::sqrt(std::abs(coordinates(p))));
  }
  objective -= 418.9829 * batchSize;

  return objective;
}

template<typename MatType>
typename MatType::elem_type SchwefelFunction::Evaluate(
    const MatType& coordinates) const
{
  return Evaluate(coordinates, 0, NumFunctions());
}

template<typename MatType, typename GradType>
inline void SchwefelFunction::Gradient(const MatType& coordinates,
                                       const size_t begin,
                                       GradType& gradient,
                                       const size_t batchSize) const
{
  gradient.zeros(n, 1);

  for (size_t j = begin; j < begin + batchSize; ++j)
  {
    const size_t p = visitationOrder[j];
    gradient(p) += (std::pow(coordinates(p), 2) *
        std::cos(std::sqrt(std::abs(coordinates(p)))) /
        (2 * std::pow(std::abs(coordinates(p)), 1.5)) +
        std::sin(std::sqrt(std::abs(coordinates(p)))));
  }
}

template<typename MatType, typename GradType>
inline void SchwefelFunction::Gradient(const MatType& coordinates,
                                       GradType& gradient)
{
  Gradient(coordinates, 0, gradient, NumFunctions());
}

} // namespace test
} // namespace ens

#endif
/**
 * @file sgd_test_function.hpp
 * @author Ryan Curtin
 *
 * Very simple test function for SGD.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_SGD_TEST_FUNCTION_HPP
#define ENSMALLEN_PROBLEMS_SGD_TEST_FUNCTION_HPP

namespace ens {
namespace test {

//! Very, very simple test function which is the composite of three other
//! functions.  The gradient is not very steep far away from the optimum, so a
//! larger step size may be required to optimize it in a reasonable number of
//! iterations.
class SGDTestFunction
{
 private:
  arma::Col<size_t> visitationOrder;

 public:
  //! Initialize the SGDTestFunction.
  SGDTestFunction();

  /**
   * Shuffle the order of function visitation. This may be called by the
   * optimizer.
   */
  void Shuffle();

  //! Return 3 (the number of functions).
  size_t NumFunctions() const { return 3; }

  //! Evaluate a function for a particular batch-size.
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates,
                                       const size_t begin,
                                       const size_t batchSize) const;

  //! Evaluate the gradient of a function for a particular batch-size
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates,
                const size_t begin,
                GradType& gradient,
                const size_t batchSize) const;

  // Note: GetInitialPoint(), GetFinalPoint(), and GetFinalObjective() are not
  // required for using ensmallen to optimize this function!  They are
  // specifically used as a convenience just for ensmallen's testing
  // infrastructure.

  //! Get the starting point.
  template<typename MatType = arma::mat>
  MatType GetInitialPoint() const { return MatType("6; -45.6; 6.2"); }

  //! Get the final point.
  template<typename MatType = arma::mat>
  MatType GetFinalPoint() const { return MatType("0.0; 0.0; 0.0"); }

  //! Get the final objective.
  double GetFinalObjective() const { return -1.0; }
};

} // namespace test
} // namespace ens

// Include implementation.
#include "sgd_test_function_impl.hpp"

#endif
/**
 * @file sgd_test_function_impl.hpp
 * @author Ryan Curtin
 *
 * Implementation of very simple test function for stochastic gradient descent
 * (SGD).
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_SGD_TEST_FUNCTION_IMPL_HPP
#define ENSMALLEN_PROBLEMS_SGD_TEST_FUNCTION_IMPL_HPP

// In case it hasn't been included yet.
#include "sgd_test_function.hpp"

namespace ens {
namespace test {

inline SGDTestFunction::SGDTestFunction() :
    visitationOrder(arma::linspace<arma::Col<size_t>>(0, NumFunctions() - 1,
        NumFunctions()))
{ }

inline void SGDTestFunction::Shuffle()
{
  visitationOrder = arma::shuffle(arma::linspace<arma::Col<size_t> >(0,
      (NumFunctions() - 1), NumFunctions()));
}

template<typename MatType>
typename MatType::elem_type SGDTestFunction::Evaluate(
    const MatType& coordinates,
    const size_t begin,
    const size_t batchSize) const
{
  typename MatType::elem_type objective = 0;

  for (size_t i = begin; i < begin + batchSize; i++)
  {
    switch (visitationOrder(i))
    {
      case 0:
        objective -= std::exp(-std::abs(coordinates[0]));
        break;

      case 1:
        objective += std::pow(coordinates[1], 2);
        break;

      case 2:
        objective += std::pow(coordinates[2], 4) + \
                     3 * std::pow(coordinates[2], 2);
        break;
    }
  }

  return objective;
}

template<typename MatType, typename GradType>
void SGDTestFunction::Gradient(const MatType& coordinates,
                               const size_t begin,
                               GradType& gradient,
                               const size_t batchSize) const
{
  gradient.zeros(3);

  for (size_t i = begin; i < begin + batchSize; ++i)
  {
    switch (visitationOrder(i))
    {
      case 0:
        if (coordinates[0] >= 0)
          gradient[0] += std::exp(-coordinates[0]);
        else
          gradient[0] += -std::exp(coordinates[0]);
        break;

      case 1:
        gradient[1] += 2 * coordinates[1];
        break;

      case 2:
        gradient[2] += 4 * std::pow(coordinates[2], 3) + 6 * coordinates[2];
        break;
    }
  }
}

} // namespace test
} // namespace ens

#endif
/**
 * @file softmax_regression_function.hpp
 * @author Siddharth Agrawal
 *
 * The function to be optimized for softmax regression. Any ensmallen optimizer
 * can be used.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_SOFTMAX_REGRESSION_FUNCTION_HPP
#define ENSMALLEN_PROBLEMS_SOFTMAX_REGRESSION_FUNCTION_HPP

namespace ens {
namespace test {

class SoftmaxRegressionFunction
{
 public:
  /**
   * Construct the Softmax Regression objective function with the given
   * parameters.
   *
   * @param data Input training data, each column associate with one sample
   * @param labels Labels associated with the feature data.
   * @param inputSize Size of the input feature vector.
   * @param numClasses Number of classes for classification.
   * @param lambda L2-regularization constant.
   * @param fitIntercept Intercept term flag.
   */
  SoftmaxRegressionFunction(const arma::mat& data,
                            const arma::Row<size_t>& labels,
                            const size_t numClasses,
                            const double lambda = 0.0001,
                            const bool fitIntercept = false);

  //! Initializes the parameters of the model to suitable values.
  const arma::mat InitializeWeights();

  /**
   * Shuffle the dataset.
   */
  void Shuffle();

  /**
   * Initialize Softmax Regression weights (trainable parameters) with the given
   * parameters.
   *
   * @param featureSize The number of features in the training set.
   * @param numClasses Number of classes for classification.
   * @param fitIntercept If true, an intercept is fitted.
   * @return Initialized model weights.
   */
  const arma::mat InitializeWeights(const size_t featureSize,
                                    const size_t numClasses,
                                    const bool fitIntercept = false);

  /**
   * Initialize Softmax Regression weights (trainable parameters) with the given
   * parameters.
   *
   * @param weights This will be filled with the initialized model weights.
   * @param featureSize The number of features in the training set.
   * @param numClasses Number of classes for classification.
   * @param fitIntercept Intercept term flag.
   */
  void InitializeWeights(arma::mat &weights,
                         const size_t featureSize,
                         const size_t numClasses,
                         const bool fitIntercept = false);

  /**
   * Constructs the ground truth label matrix with the passed labels.
   *
   * @param labels Labels associated with the training data.
   * @param groundTruth Pointer to arma::mat which stores the computed matrix.
   */
  void GetGroundTruthMatrix(const arma::Row<size_t>& labels,
                            arma::sp_mat& groundTruth);

  /**
   * Evaluate the probabilities matrix with the passed parameters.
   * probabilities(i, j) =
   *     exp(\theta_i * data_j) / sum_k(exp(\theta_k * data_j)).
   * It represents the probability of data_j belongs to class i.
   *
   * @param parameters Current values of the model parameters.
   * @param probabilities Pointer to arma::mat which stores the probabilities.
   * @param start Index of point to start at.
   * @param batchSize Number of points to calculate probabilities for.
   */
  void GetProbabilitiesMatrix(const arma::mat& parameters,
                              arma::mat& probabilities,
                              const size_t start,
                              const size_t batchSize) const;

  /**
   * Evaluates the objective function of the softmax regression model using the
   * given parameters. The cost function has terms for the log likelihood error
   * and the regularization cost. The objective function takes a low value when
   * the model generalizes well for the given training data, while having small
   * parameter values.
   *
   * @param parameters Current values of the model parameters.
   */
  double Evaluate(const arma::mat& parameters) const;

  /**
   * Evaluate the objective function of the softmax regression model for a
   * subset of the data points using the given parameters. The cost function has
   * terms for the log likelihood error and the regularization cost. The
   * objective function takes a low value when the model generalizes well for
   * the given training data, while having small parameter values.
   *
   * @param parameters Current values of the model parameters.
   * @param start First index of the data points to use.
   * @param batchSize Number of data points to evaluate objective for.
   */
  double Evaluate(const arma::mat& parameters,
                  const size_t start,
                  const size_t batchSize = 1) const;

  /**
   * Evaluates the gradient values of the objective function given the current
   * set of parameters. The function calculates the probabilities for each class
   * given the parameters, and computes the gradients based on the difference
   * from the ground truth.
   *
   * @param parameters Current values of the model parameters.
   * @param gradient Matrix where gradient values will be stored.
   */
  void Gradient(const arma::mat& parameters, arma::mat& gradient) const;

  /**
   * Evaluate the gradient of the objective function given the current set of
   * parameters, on a subset of the data. The function calculates the
   * probabilities for each class given the parameters, and computes the
   * gradients based on the difference from the ground truth.
   *
   * @param parameters Current values of the model parameters.
   * @param start First index of the data points to use.
   * @param gradient Matrix to store gradient into.
   * @param batchSize Number of data points to evaluate gradient for.
   */
  void Gradient(const arma::mat& parameters,
                const size_t start,
                arma::mat& gradient,
                const size_t batchSize = 1) const;

  /**
   * Evaluates the gradient values of the objective function given the current
   * set of parameters for a single feature indexed by j.
   *
   * @param parameters Current values of the model parameters.
   * @param j The index of the feature with respect to which the partial
   *    gradient is to be computed.
   * @param gradient Out param for the gradient value.
   */
  void PartialGradient(const arma::mat& parameters,
                       size_t j,
                       arma::sp_mat& gradient) const;

  //! Return the initial point for the optimization.
  const arma::mat& GetInitialPoint() const { return initialPoint; }

  //! Gets the number of classes.
  size_t NumClasses() const { return numClasses; }

  //! Gets the features size of the training data.
  size_t NumFeatures() const
  {
    return initialPoint.n_cols;
  }

  //! Sets the regularization parameter.
  double& Lambda() { return lambda; }
  //! Gets the regularization parameter.
  double Lambda() const { return lambda; }

  //! Gets the intercept flag.
  bool FitIntercept() const { return fitIntercept; }

 private:
  //! Training data matrix.  This is an alias until the data is shuffled.
  arma::mat data;
  //! Label matrix for the provided data.
  arma::sp_mat groundTruth;
  //! Initial parameter point.
  arma::mat initialPoint;
  //! Number of classes.
  size_t numClasses;
  //! L2-regularization constant.
  double lambda;
  //! Intercept term flag.
  bool fitIntercept;
};

} // namespace test
} // namespace ens

// Include implementation.
#include "softmax_regression_function_impl.hpp"

#endif // ENSMALLEN_PROBLEMS_SOFTMAX_REGRESSION_FUNCTION_HPP
/**
 * @file softmax_regression_function_impl.hpp
 * @author Siddharth Agrawal
 *
 * Implementation of function to be optimized for softmax regression.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_SOFTMAX_REGRESSION_FUNCTION_IMPL_HPP
#define ENSMALLEN_PROBLEMS_SOFTMAX_REGRESSION_FUNCTION_IMPL_HPP

// In case it hasn't been included yet.
#include "softmax_regression_function.hpp"

namespace ens {
namespace test {

inline SoftmaxRegressionFunction::SoftmaxRegressionFunction(
    const arma::mat& data,
    const arma::Row<size_t>& labels,
    const size_t numClasses,
    const double lambda,
    const bool fitIntercept) :
    data(arma::mat(const_cast<arma::mat&>(data).memptr(), data.n_rows,
      data.n_cols, false, false)),
    numClasses(numClasses),
    lambda(lambda),
    fitIntercept(fitIntercept)
{
  // Initialize the parameters to suitable values.
  initialPoint = InitializeWeights();

  // Calculate the label matrix.
  GetGroundTruthMatrix(labels, groundTruth);
}

/**
 * Shuffle the data.
 */
inline void SoftmaxRegressionFunction::Shuffle()
{
  // Determine new ordering.
  arma::uvec ordering = arma::shuffle(arma::linspace<arma::uvec>(0,
      data.n_cols - 1, data.n_cols));

  // Re-sort data.
  arma::mat newData = data.cols(ordering);
  if (data.mem_state >= 1)
    data.reset();
  data = std::move(newData);

  // Assemble data for batch constructor.  We need reverse orderings though...
  arma::uvec reverseOrdering(ordering.n_elem);
  for (size_t i = 0; i < ordering.n_elem; ++i)
    reverseOrdering[ordering[i]] = i;

  arma::umat newLocations(2, groundTruth.n_nonzero);
  arma::vec values(groundTruth.n_nonzero);
  arma::sp_mat::const_iterator it = groundTruth.begin();
  size_t loc = 0;
  while (it != groundTruth.end())
  {
    newLocations(0, loc) = reverseOrdering(it.col());
    newLocations(1, loc) = it.row();
    values(loc) = (*it);

    ++it;
    ++loc;
  }

  groundTruth = arma::sp_mat(newLocations, values, groundTruth.n_rows,
      groundTruth.n_cols);
}

/**
 * Initializes parameter weights to random values taken from a scaled standard
 * normal distribution. The weights cannot be initialized to zero, as that will
 * lead to each class output being the same.
 */
inline const arma::mat SoftmaxRegressionFunction::InitializeWeights()
{
  return InitializeWeights(data.n_rows, numClasses, fitIntercept);
}

inline const arma::mat SoftmaxRegressionFunction::InitializeWeights(
    const size_t featureSize,
    const size_t numClasses,
    const bool fitIntercept)
{
    arma::mat parameters;
    InitializeWeights(parameters, featureSize, numClasses, fitIntercept);
    return parameters;
}

inline void SoftmaxRegressionFunction::InitializeWeights(
    arma::mat &weights,
    const size_t featureSize,
    const size_t numClasses,
    const bool fitIntercept)
{
  // Initialize values to 0.005 * r. 'r' is a matrix of random values taken from
  // a Gaussian distribution with mean zero and variance one.
  // If the fitIntercept flag is true, parameters.col(0) is the intercept.
  if (fitIntercept)
    weights.randn(numClasses, featureSize + 1);
  else
    weights.randn(numClasses, featureSize);
  weights *= 0.005;
}

/**
 * This is equivalent to applying the indicator function to the training
 * labels. The output is in the form of a matrix, which leads to simpler
 * calculations in the Evaluate() and Gradient() methods.
 */
inline void SoftmaxRegressionFunction::GetGroundTruthMatrix(
    const arma::Row<size_t>& labels, arma::sp_mat& groundTruth)
{
  // Calculate the ground truth matrix according to the labels passed. The
  // ground truth matrix is a matrix of dimensions 'numClasses * numExamples',
  // where each column contains a single entry of '1', marking the label
  // corresponding to that example.

  // Row pointers and column pointers corresponding to the entries.
  arma::uvec rowPointers(labels.n_elem);
  arma::uvec colPointers(labels.n_elem + 1);

  // Row pointers are the labels of the examples, and column pointers are the
  // number of cumulative entries made uptil that column.
  for (size_t i = 0; i < labels.n_elem; i++)
  {
    rowPointers(i) = labels(i);
    colPointers(i + 1) = i + 1;
  }

  // All entries are '1'.
  arma::vec values;
  values.ones(labels.n_elem);

  // Calculate the matrix.
  groundTruth = arma::sp_mat(rowPointers, colPointers, values, numClasses,
                             labels.n_elem);
}

/**
 * Evaluate the probabilities matrix. If fitIntercept flag is true,
 * it should consider the parameters.cols(0) intercept term.
 */
inline void SoftmaxRegressionFunction::GetProbabilitiesMatrix(
    const arma::mat& parameters,
    arma::mat& probabilities,
    const size_t start,
    const size_t batchSize) const
{
  arma::mat hypothesis;

  if (fitIntercept)
  {
    // In order to add the intercept term, we should compute following matrix:
    //     [1; data] = arma::join_cols(ones(1, data.n_cols), data)
    //     hypothesis = arma::exp(parameters * [1; data]).
    //
    // Since the cost of join may be high due to the copy of original data,
    // split the hypothesis computation to two components.
    hypothesis = arma::exp(
        arma::repmat(parameters.col(0), 1, batchSize) +
        parameters.cols(1, parameters.n_cols - 1) *
        data.cols(start, start + batchSize - 1));
  }
  else
  {
    hypothesis = arma::exp(parameters *
        data.cols(start, start + batchSize - 1));
  }

  probabilities = hypothesis / arma::repmat(arma::sum(hypothesis, 0),
                                            numClasses, 1);
}

/**
 * Evaluates the objective function given the parameters.
 */
inline double SoftmaxRegressionFunction::Evaluate(
    const arma::mat& parameters) const
{
  // The objective function is the negative log likelihood of the model
  // calculated over all the training examples. Mathematically it is as follows:
  // log likelihood = sum(1{y_i = j} * log(probability(j))) / m
  // The sum is over all 'i's and 'j's, where 'i' points to a training example
  // and 'j' points to a particular class. 1{x} is an indicator function whose
  // value is 1 only when 'x' is satisfied, otherwise it is 0.
  // 'm' is the number of training examples.
  // The cost also takes into account the regularization to control the
  // parameter weights.

  // Calculate the class probabilities for each training example. The
  // probabilities for each of the classes are given by:
  // p_j = exp(theta_j' * x_i) / sum(exp(theta_k' * x_i))
  // The sum is calculated over all the classes.
  // x_i is the input vector for a particular training example.
  // theta_j is the parameter vector associated with a particular class.
  arma::mat probabilities;
  GetProbabilitiesMatrix(parameters, probabilities, 0, data.n_cols);

  // Calculate the log likelihood and regularization terms.
  double logLikelihood, weightDecay, cost;

  logLikelihood = arma::accu(groundTruth % arma::log(probabilities)) /
                  data.n_cols;
  weightDecay = 0.5 * lambda * arma::accu(parameters % parameters);

  // The cost is the sum of the negative log likelihood and the regularization
  // terms.
  cost = -logLikelihood + weightDecay;

  return cost;
}

/**
 * Evaluate the objective function for the given points given the parameters.
 */
inline double SoftmaxRegressionFunction::Evaluate(
    const arma::mat& parameters,
    const size_t start,
    const size_t batchSize) const
{
  arma::mat probabilities;
  GetProbabilitiesMatrix(parameters, probabilities, start, batchSize);

  // Calculate the log likelihood and regularization terms.
  double logLikelihood, weightDecay;

  logLikelihood = arma::accu(groundTruth.cols(start, start + batchSize - 1) %
      arma::log(probabilities)) / batchSize;
  weightDecay = 0.5 * lambda * arma::accu(parameters * parameters);

  return -logLikelihood + weightDecay;
}

/**
 * Calculates and stores the gradient values given a set of parameters.
 */
inline void SoftmaxRegressionFunction::Gradient(
    const arma::mat& parameters, arma::mat& gradient) const
{
  // Calculate the class probabilities for each training example. The
  // probabilities for each of the classes are given by:
  // p_j = exp(theta_j' * x_i) / sum(exp(theta_k' * x_i))
  // The sum is calculated over all the classes.
  // x_i is the input vector for a particular training example.
  // theta_j is the parameter vector associated with a particular class.
  arma::mat probabilities;
  GetProbabilitiesMatrix(parameters, probabilities, 0, data.n_cols);

  // Calculate the parameter gradients.
  gradient.set_size(parameters.n_rows, parameters.n_cols);
  if (fitIntercept)
  {
    // Treating the intercept term parameters.col(0) seperately to avoid
    // the cost of building matrix [1; data].
    arma::mat inner = probabilities - groundTruth;
    gradient.col(0) =
      inner * arma::ones<arma::mat>(data.n_cols, 1) / data.n_cols +
      lambda * parameters.col(0);
    gradient.cols(1, parameters.n_cols - 1) =
      inner * data.t() / data.n_cols +
      lambda * parameters.cols(1, parameters.n_cols - 1);
  }
  else
  {
    gradient = (probabilities - groundTruth) * data.t() / data.n_cols +
               lambda * parameters;
  }
}

inline void SoftmaxRegressionFunction::Gradient(
    const arma::mat& parameters,
    const size_t start,
    arma::mat& gradient,
    const size_t batchSize) const
{
  arma::mat probabilities;
  GetProbabilitiesMatrix(parameters, probabilities, start, batchSize);

  // Calculate the parameter gradients.
  gradient.set_size(parameters.n_rows, parameters.n_cols);
  if (fitIntercept)
  {
    arma::mat inner = probabilities - groundTruth.cols(start, start +
        batchSize - 1);
    gradient.col(0) =
        inner * arma::ones<arma::mat>(batchSize, 1) / batchSize +
        lambda * parameters.col(0);
    gradient.cols(1, parameters.n_cols - 1) =
        inner * data.cols(start, start + batchSize - 1).t() / batchSize +
        lambda * parameters.cols(1, parameters.n_cols - 1);
  }
  else
  {
    gradient = (probabilities - groundTruth.cols(start, start + batchSize - 1))
        * data.cols(start, start + batchSize - 1).t() / batchSize
        + lambda * parameters;
  }
}

inline void SoftmaxRegressionFunction::PartialGradient(
    const arma::mat& parameters,
    const size_t j,
    arma::sp_mat& gradient) const
{
  gradient.zeros(arma::size(parameters));

  arma::mat probabilities;
  GetProbabilitiesMatrix(parameters, probabilities, 0, data.n_cols);

  // Calculate the required part of the gradient.
  arma::mat inner = probabilities - groundTruth;
  if (fitIntercept)
  {
    if (j == 0)
    {
      gradient.col(j) =
          inner * arma::ones<arma::mat>(data.n_cols, 1) / data.n_cols +
          lambda * parameters.col(0);
    }
    else
    {
      gradient.col(j) = inner * data.row(j).t() / data.n_cols + lambda *
          parameters.col(j);
    }
  }
  else
  {
    gradient.col(j) = inner * data.row(j).t() / data.n_cols + lambda *
        parameters.col(j);
  }
}

} // namespace test
} // namespace ens

#endif
/**
 * @file sparse_test_function.hpp
 * @author Shikhar Bhardwaj
 *
 * Sparse test function for Parallel SGD.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_SPARSE_TEST_FUNCTION_HPP
#define ENSMALLEN_PROBLEMS_SPARSE_TEST_FUNCTION_HPP

namespace ens {
namespace test {

// A simple test function. Each dimension has a parabola with a
// distinct minimum. Each update is guaranteed to be sparse(only a single
// dimension is updated in the decision variable by each thread). At the end of
// a reasonable number of iterations, each value in the decision variable should
// be at the vertex of the parabola in that dimension.
class SparseTestFunction
{
 public:
  //! Set members in the default constructor.
  SparseTestFunction();

  //! Return 4 (the number of functions).
  size_t NumFunctions() const { return 4; }

  //! Return 4 (the number of features).
  size_t NumFeatures() const { return 4; }

  //! Evaluate a function.
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates,
                                       const size_t i,
                                       const size_t batchSize = 1) const;

  //! Evaluate all the functions.
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates) const;

  //! Evaluate the gradient of a function.
  template<typename MatType,
           typename GradType = arma::SpMat<typename MatType::elem_type>>
  void Gradient(const MatType& coordinates,
                const size_t i,
                GradType& gradient,
                const size_t batchSize = 1) const;

  //! Evaluate the gradient of a feature function.
  template<typename MatType,
           typename GradType = arma::SpMat<typename MatType::elem_type>>
  void PartialGradient(const MatType& coordinates,
                       const size_t j,
                       GradType& gradient) const;

  // Note: GetInitialPoint(), GetFinalPoint(), and GetFinalObjective() are not
  // required for using ensmallen to optimize this function!  They are
  // specifically used as a convenience just for ensmallen's testing
  // infrastructure.

  //! Get the starting point.
  template<typename MatType>
  MatType GetInitialPoint() const { return MatType("0 0 0 0;"); }

  //! Get the final point.
  template<typename MatType = arma::mat>
  MatType GetFinalPoint() const { return MatType("2.0 1.0 1.5 4.0"); }

  //! Get the final objective.
  double GetFinalObjective() const { return 123.75; }

 private:
  // Each quadratic polynomial is monic. The intercept and coefficient of the
  // first order term is stored.

  //! The vector storing the intercepts
  arma::vec intercepts;

  //! The vector having coefficients of the first order term
  arma::vec bi;
};

} // namespace test
} // namespace ens

// Include implementation.
#include "sparse_test_function_impl.hpp"

#endif // ENSMALLEN_PROBLEMS_SPARSE_TEST_FUNCTION_HPP
/**
 * @file sparse_test_function_impl.hpp
 * @author Shikhar Bhardwaj
 *
 * Sparse test function for Parallel SGD.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_SPARSE_TEST_FUNCTION_IMPL_HPP
#define ENSMALLEN_PROBLEMS_SPARSE_TEST_FUNCTION_IMPL_HPP

// In case it hasn't been included yet.
#include "sparse_test_function.hpp"

namespace ens {
namespace test {

inline SparseTestFunction::SparseTestFunction()
{
  intercepts = arma::vec("20 12 15 100");
  bi = arma::vec("-4 -2 -3 -8");
}

//! Evaluate a function.
template<typename MatType>
inline typename MatType::elem_type SparseTestFunction::Evaluate(
    const MatType& coordinates,
    const size_t i,
    const size_t batchSize) const
{
  typename MatType::elem_type result = 0.0;
  for (size_t j = i; j < i + batchSize; ++j)
  {
    result += coordinates[j] * coordinates[j] + bi[j] * coordinates[j] +
        intercepts[j];
  }

  return result;
}

//! Evaluate all the functions.
template<typename MatType>
inline typename MatType::elem_type SparseTestFunction::Evaluate(
    const MatType& coordinates) const
{
  typename MatType::elem_type objective = 0.0;
  for (size_t i = 0; i < NumFunctions(); ++i)
  {
    objective += coordinates[i] * coordinates[i] + bi[i] * coordinates[i] +
      intercepts[i];
  }

  return objective;
}

//! Evaluate the gradient of a function.
template<typename MatType, typename GradType>
inline void SparseTestFunction::Gradient(const MatType& coordinates,
                                         const size_t i,
                                         GradType& gradient,
                                         const size_t batchSize) const
{
  gradient.zeros(arma::size(coordinates));
  for (size_t j = i; j < i + batchSize; ++j)
    gradient[j] = 2 * coordinates[j] + bi[j];
}

//! Evaluate the gradient of a feature function.
template<typename MatType, typename GradType>
inline void SparseTestFunction::PartialGradient(const MatType& coordinates,
                                                const size_t j,
                                                GradType& gradient) const
{
  gradient.zeros(arma::size(coordinates));
  gradient[j] = 2 * coordinates[j] + bi[j];
}

} // namespace test
} // namespace ens

#endif
/**
 * @file sphere_function.hpp
 * @author Marcus Edel
 *
 * Definition of the Sphere function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_SPHERE_FUNCTION_HPP
#define ENSMALLEN_PROBLEMS_SPHERE_FUNCTION_HPP

namespace ens {
namespace test {

/**
 * The Sphere function, defined by
 *
 * \f[
 * f(x) = \sum_{i=1}^{d} x_i^2
 * \f]
 *
 * This should optimize to f(x) = 0, at x = [0, ..., 0].
 *
 * For more information, please refer to:
 *
 * @code
 * @article{Jamil2013,
 *   title   = {A Literature Survey of Benchmark Functions For Global
 *              Optimization Problems},
 *   author  = {Momin Jamil and Xin{-}She Yang},
 *   journal = {CoRR},
 *   year    = {2013},
 *   url     = {http://arxiv.org/abs/1308.4008}
 * }
 * @endcode
 */
class SphereFunction
{
 public:
  /*
   * Initialize the SphereFunction.
   *
   * @param n Number of dimensions for the function.
   */
  SphereFunction(const size_t n = 2);

  /**
   * Shuffle the order of function visitation. This may be called by the
   * optimizer.
   */
  void Shuffle();

  //! Return 1 (the number of functions).
  size_t NumFunctions() const { return n; }

  /**
   * Evaluate a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param batchSize Number of points to process.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates,
                                       const size_t begin,
                                       const size_t batchSize) const;

  /**
   * Evaluate a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates) const;

  /**
   * Evaluate the gradient of a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param gradient The function gradient.
   * @param batchSize Number of points to process.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates,
                const size_t begin,
                GradType& gradient,
                const size_t batchSize) const;

  /**
   * Evaluate the gradient of a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   * @param gradient The function gradient.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates, GradType& gradient);

  // Note: GetInitialPoint(), GetFinalPoint(), and GetFinalObjective() are not
  // required for using ensmallen to optimize this function!  They are
  // specifically used as a convenience just for ensmallen's testing
  // infrastructure.

  //! Get the starting point.
  template<typename MatType = arma::mat>
  MatType GetInitialPoint() const
  {
    return arma::conv_to<MatType>::from(initialPoint);
  }

  //! Get the final point.
  template<typename MatType = arma::mat>
  MatType GetFinalPoint() const
  {
    return arma::zeros<MatType>(initialPoint.n_rows, initialPoint.n_cols);
  }

  //! Get the final objective.
  double GetFinalObjective() const { return 0.0; }

 private:
  //! Number of dimensions for the function.
  size_t n;

  //! For shuffling.
  arma::Row<size_t> visitationOrder;

  //! Initial starting point.
  arma::mat initialPoint;
};

} // namespace test
} // namespace ens

// Include implementation.
#include "sphere_function_impl.hpp"

#endif // ENSMALLEN_PROBLEMS_SPHERE_FUNCTION_HPP
/**
 * @file sphere_function_impl.hpp
 * @author Marcus Edel
 *
 * Implementation of the Sphere function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_SPHERE_FUNCTION_IMPL_HPP
#define ENSMALLEN_PROBLEMS_SPHERE_FUNCTION_IMPL_HPP

// In case it hasn't been included yet.
#include "sphere_function.hpp"

namespace ens {
namespace test {

inline SphereFunction::SphereFunction(const size_t n) :
    n(n),
    visitationOrder(arma::linspace<arma::Row<size_t> >(0, n - 1, n))
{
  initialPoint.set_size(n, 1);

  for (size_t i = 0; i < n; ++i) // Set to [-5 5 -5 5 -5 5...].
  {
    if (i % 2 == 1)
      initialPoint(i) = 5;
    else
      initialPoint(i) = -5;
  }
}

inline void SphereFunction::Shuffle()
{
  visitationOrder = arma::shuffle(
      arma::linspace<arma::Row<size_t> >(0, n - 1, n));
}

template<typename MatType>
typename MatType::elem_type SphereFunction::Evaluate(
    const MatType& coordinates,
    const size_t begin,
    const size_t batchSize) const
{
  typename MatType::elem_type objective = 0.0;
  for (size_t j = begin; j < begin + batchSize; ++j)
  {
    const size_t p = visitationOrder[j];
    objective += std::pow(coordinates(p), 2);
  }

  return objective;
}

template<typename MatType>
typename MatType::elem_type SphereFunction::Evaluate(
    const MatType& coordinates) const
{
  return Evaluate(coordinates, 0, NumFunctions());
}

template<typename MatType, typename GradType>
void SphereFunction::Gradient(const MatType& coordinates,
                              const size_t begin,
                              GradType& gradient,
                              const size_t batchSize) const
{
  gradient.zeros(n, 1);

  for (size_t j = begin; j < begin + batchSize; ++j)
  {
    const size_t p = visitationOrder[j];
    gradient(p) += 2.0 * coordinates[p];
  }
}

template<typename MatType, typename GradType>
void SphereFunction::Gradient(const MatType& coordinates,
                              GradType& gradient)
{
  Gradient(coordinates, 0, gradient, NumFunctions());
}

} // namespace test
} // namespace ens

#endif
/**
 * @file styblinski_tang_function.hpp
 * @author Marcus Edel
 *
 * Definition of the Styblinski-Tang function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_STYBLINSKI_TANG_FUNCTION_HPP
#define ENSMALLEN_PROBLEMS_STYBLINSKI_TANG_FUNCTION_HPP

namespace ens {
namespace test {

/**
 * The Styblinski-Tang function, defined by
 *
 * \f[
 * f(x) = 0.5 * \sum_{i=1}^{d} x_i^4 - 16_i^2+5x_i
 * \f]
 *
 * This should optimize to f(x) = -39.16599 * d
 * at x = [-2.903534, ..., -2.903534].
 *
 * For more information, please refer to:
 *
 * @code
 * @article{Jamil2013,
 *   title   = {A Literature Survey of Benchmark Functions For Global
 *              Optimization Problems},
 *   author  = {Momin Jamil and Xin{-}She Yang},
 *   journal = {CoRR},
 *   year    = {2013},
 *   url     = {http://arxiv.org/abs/1308.4008}
 * }
 * @endcode
 */
class StyblinskiTangFunction
{
 public:
  /*
   * Initialize the StyblinskiTangFunction.
   *
   * @param n Number of dimensions for the function.
   */
  StyblinskiTangFunction(const size_t n = 2);

  /**
   * Shuffle the order of function visitation. This may be called by the
   * optimizer.
   */
  void Shuffle();

  //! Return 1 (the number of functions).
  size_t NumFunctions() const { return n; }

  /**
   * Evaluate a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param batchSize Number of points to process.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates,
                                       const size_t begin,
                                       const size_t batchSize) const;

  /**
   * Evaluate a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates) const;

  /**
   * Evaluate the gradient of a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param gradient The function gradient.
   * @param batchSize Number of points to process.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates,
                const size_t begin,
                GradType& gradient,
                const size_t batchSize) const;

  /**
   * Evaluate the gradient of a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   * @param gradient The function gradient.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates, GradType& gradient);

  // Note: GetInitialPoint(), GetFinalPoint(), and GetFinalObjective() are not
  // required for using ensmallen to optimize this function!  They are
  // specifically used as a convenience just for ensmallen's testing
  // infrastructure.

  //! Get the starting point.
  template<typename MatType = arma::mat>
  MatType GetInitialPoint() const
  {
    return arma::conv_to<MatType>::from(initialPoint);
  }

  //! Get the final point.
  template<typename MatType = arma::mat>
  MatType GetFinalPoint() const
  {
    MatType result(initialPoint.n_rows, initialPoint.n_cols);
    for (size_t i = 0; i < result.n_elem; ++i)
      result[i] = -2.903534;
    return result;
  }

  //! Get the final objective.
  double GetFinalObjective() const { return -39.16599 * n; }

 private:
  //! Number of dimensions for the function.
  size_t n;

  //! For shuffling.
  arma::Row<size_t> visitationOrder;

  //! Initial starting point.
  arma::mat initialPoint;
};

} // namespace test
} // namespace ens

// Include implementation.
#include "styblinski_tang_function_impl.hpp"

#endif // ENSMALLEN_PROBLEMS_STYBLINSKI_TANG_FUNCTION_HPP
/**
 * @file styblinski_tang_function_impl.hpp
 * @author Marcus Edel
 *
 * Implementation of the Styblinski-Tang function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_STYBLINSKI_TANG_FUNCTION_IMPL_HPP
#define ENSMALLEN_PROBLEMS_STYBLINSKI_TANG_FUNCTION_IMPL_HPP

// In case it hasn't been included yet.
#include "styblinski_tang_function.hpp"

namespace ens {
namespace test {

inline StyblinskiTangFunction::StyblinskiTangFunction(const size_t n) :
    n(n),
    visitationOrder(arma::linspace<arma::Row<size_t> >(0, n - 1, n))

{
  initialPoint.set_size(n, 1);
  initialPoint.fill(-5);
}

inline void StyblinskiTangFunction::Shuffle()
{
  visitationOrder = arma::shuffle(
      arma::linspace<arma::Row<size_t> >(0, n - 1, n));
}

template<typename MatType>
typename MatType::elem_type StyblinskiTangFunction::Evaluate(
    const MatType& coordinates,
    const size_t begin,
    const size_t batchSize) const
{
  typename MatType::elem_type objective = 0.0;
  for (size_t j = begin; j < begin + batchSize; ++j)
  {
    const size_t p = visitationOrder[j];
    objective += std::pow(coordinates(p), 4) - 16 *
        std::pow(coordinates(p), 2) + 5 * coordinates(p);
  }
  objective /= 2;

  return objective;
}

template<typename MatType>
typename MatType::elem_type StyblinskiTangFunction::Evaluate(
    const MatType& coordinates) const
{
  return Evaluate(coordinates, 0, NumFunctions());
}

template<typename MatType, typename GradType>
void StyblinskiTangFunction::Gradient(const MatType& coordinates,
                                      const size_t begin,
                                      GradType& gradient,
                                      const size_t batchSize) const
{
  gradient.zeros(n, 1);

  for (size_t j = begin; j < begin + batchSize; ++j)
  {
    const size_t p = visitationOrder[j];
    gradient(p) += 0.5 * (4 * std::pow(coordinates(p), 3) -
        32.0 * coordinates(p) + 5.0);
  }
}

template<typename MatType, typename GradType>
void StyblinskiTangFunction::Gradient(const MatType& coordinates,
                                      GradType& gradient)
{
  Gradient(coordinates, 0, gradient, NumFunctions());
}

} // namespace test
} // namespace ens

#endif
/**
 * @file three_hump_camel_function.hpp
 * @author Suryoday Basak
 *
 * Definition of the Three-hump camel function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_THREE_HUMP_CAMEL_FUNCTION_HPP
#define ENSMALLEN_PROBLEMS_THREE_HUMP_CAMEL_FUNCTION_HPP

namespace ens {
namespace test {

/**
 * The Three-hump camel function, defined by
 *
 * \f[
 * f(x_1,x_2) = 2 * x_1^2 - 1.05 * x_1^4 + (x_1^6)/6 + x_1 * x_2 + x_2^2
 * \f]
 *
 * This should optimize to f(x) = 0, at x = [0, 0].
 *
 * For more information, please refer to:
 *
 * @code
 * @article{Ali2005,
 *   doi       = {10.1007/s10898-004-9972-2},
 *   year      = {2005},
 *   month     = apr,
 *   publisher = {Springer Nature},
 *   volume    = {31},
 *   number    = {4},
 *   pages     = {635--672},
 *   author    = {M. Montaz Ali and Charoenchai Khompatraporn and
 *                Zelda B. Zabinsky},
 *   title     = {A Numerical Evaluation of Several Stochastic Algorithms
 *                on Selected Continuous Global Optimization Test Problems},
 *   journal   = {Journal of Global Optimization}
 * }
 * @endcode
 */
class ThreeHumpCamelFunction
{
 public:
  //! Initialize the ThreeHumpCamelFunction.
  ThreeHumpCamelFunction();

  /**
   * Shuffle the order of function visitation. This may be called by the
   * optimizer.
   */
  void Shuffle();

  //! Return 1 (the number of functions).
  size_t NumFunctions() const { return 1; }

  /**
   * Evaluate a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param batchSize Number of points to process.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates,
                                       const size_t begin,
                                       const size_t batchSize) const;

  /**
   * Evaluate a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates) const;

  /**
   * Evaluate the gradient of a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param gradient The function gradient.
   * @param batchSize Number of points to process.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates,
                const size_t begin,
                GradType& gradient,
                const size_t batchSize) const;

  /**
   * Evaluate the gradient of a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   * @param gradient The function gradient.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates, GradType& gradient);

  // Note: GetInitialPoint(), GetFinalPoint(), and GetFinalObjective() are not
  // required for using ensmallen to optimize this function!  They are
  // specifically used as a convenience just for ensmallen's testing
  // infrastructure.

  //! Get the starting point.
  template<typename MatType = arma::mat>
  MatType GetInitialPoint() const { return MatType("1; 1"); }

  //! Get the final point.
  template<typename MatType = arma::mat>
  MatType GetFinalPoint() const { return MatType("0.0; 0.0"); }

  //! Get the final objective.
  double GetFinalObjective() const { return 0.0; }
};

} // namespace test
} // namespace ens

// Include implementation.
#include "three_hump_camel_function_impl.hpp"

#endif // ENSMALLEN_PROBLEMS_THREE_HUMP_CAMEL_FUNCTION_HPP
/**
 * @file three_hump_camel_function_impl.hpp
 * @author Suryoday Basak
 *
 * Implementation of the Three-hump camel function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_THREE_HUMP_CAMEL_FUNCTION_IMPL_HPP
#define ENSMALLEN_PROBLEMS_THREE_HUMP_CAMEL_FUNCTION_IMPL_HPP

// In case it hasn't been included yet.
#include "three_hump_camel_function.hpp"

namespace ens {
namespace test {

inline ThreeHumpCamelFunction::ThreeHumpCamelFunction()
{ /* Nothing to do here */ }

inline void ThreeHumpCamelFunction::Shuffle() { /* Nothing to do here */ }

template<typename MatType>
typename MatType::elem_type ThreeHumpCamelFunction::Evaluate(
    const MatType& coordinates,
    const size_t /* begin */,
    const size_t /* batchSize */) const
{
  // Convenience typedef.
  typedef typename MatType::elem_type ElemType;

  // For convenience; we assume these temporaries will be optimized out.
  const ElemType x1 = coordinates(0);
  const ElemType x2 = coordinates(1);

  const ElemType objective = (2 * std::pow(x1, 2)) - (1.05 * std::pow(x1, 4)) +
      (std::pow(x1, 6) / 6) + (x1 * x2) + std::pow(x2, 2);
  return objective;
}

template<typename MatType>
typename MatType::elem_type ThreeHumpCamelFunction::Evaluate(
    const MatType& coordinates) const
{
  return Evaluate(coordinates, 0, NumFunctions());
}

template<typename MatType, typename GradType>
inline void ThreeHumpCamelFunction::Gradient(const MatType& coordinates,
                                             const size_t /* begin */,
                                             GradType& gradient,
                                             const size_t /* batchSize */) const
{
  // Convenience typedef.
  typedef typename MatType::elem_type ElemType;

  // For convenience; we assume these temporaries will be optimized out.
  const ElemType x1 = coordinates(0);
  const ElemType x2 = coordinates(1);

  gradient.set_size(2, 1);
  gradient(0) = std::pow(x1, 5) - (4.2 * std::pow(x1, 3)) + (4 * x1) + x2;
  gradient(1) = x1 + (2 * x2);
}

template<typename MatType, typename GradType>
inline void ThreeHumpCamelFunction::Gradient(const MatType& coordinates,
                                             GradType& gradient)
{
  Gradient(coordinates, 0, gradient, 1);
}

} // namespace test
} // namespace ens

#endif
/**
 * @file wood_function.hpp
 * @author Ryan Curtin
 * @author Marcus Edel
 *
 * Definition of the Wood function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_WOOD_FUNCTION_HPP
#define ENSMALLEN_PROBLEMS_WOOD_FUNCTION_HPP

namespace ens {
namespace test {

/**
 * The Wood function, defined by
 *  f(x) = f1(x) + f2(x) + f3(x) + f4(x) + f5(x) + f6(x)
 *  f1(x) = 100 (x2 - x1^2)^2
 *  f2(x) = (1 - x1)^2
 *  f3(x) = 90 (x4 - x3^2)^2
 *  f4(x) = (1 - x3)^2
 *  f5(x) = 10 (x2 + x4 - 2)^2
 *  f6(x) = (1 / 10) (x2 - x4)^2
 *  x_0 = [-3, -1, -3, -1]
 *
 * This should optimize to f(x) = 0, at x = [1, 1, 1, 1].
 *
 * For more information, please refer to:
 *
 * @code
 * @article{Grippo1989,
 *   title   = {A truncated Newton method with nonmonotone line search for
 *              unconstrained optimization},
 *   author  = {Grippo, L. and Lampariello, F. and Lucidi, S.},
 *   journal = {Journal of Optimization Theory and Applications},
 *   year    = {1989},
 *   volume  = {60},
 *   number  = {3},
 *   pages   = {401--419},
 * }
 * @endcode
 */
class WoodFunction
{
 public:
  //! Initialize the WoodFunction.
  WoodFunction();

  /**
   * Shuffle the order of function visitation. This may be called by the
   * optimizer.
   */
  void Shuffle();

  //! Return 1 (the number of functions).
  size_t NumFunctions() const { return 1; }

  /**
   * Evaluate a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param batchSize Number of points to process.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates,
                                       const size_t begin,
                                       const size_t batchSize) const;

  /**
   * Evaluate a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates) const;

  /**
   * Evaluate the gradient of a function for a particular batch-size.
   *
   * @param coordinates The function coordinates.
   * @param begin The first function.
   * @param gradient The function gradient.
   * @param batchSize Number of points to process.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates,
                const size_t begin,
                GradType& gradient,
                const size_t batchSize) const;

  /**
   * Evaluate the gradient of a function with the given coordinates.
   *
   * @param coordinates The function coordinates.
   * @param gradient The function gradient.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates, GradType& gradient) const;

  // Note: GetInitialPoint(), GetFinalPoint(), and GetFinalObjective() are not
  // required for using ensmallen to optimize this function!  They are
  // specifically used as a convenience just for ensmallen's testing
  // infrastructure.

  //! Get the starting point.
  template<typename MatType = arma::mat>
  MatType GetInitialPoint() const { return MatType("-3; -1; -3; -1"); }

  //! Get the final point.
  template<typename MatType = arma::mat>
  MatType GetFinalPoint() const { return MatType("1; 1; 1; 1"); }

  //! Get the final objective.
  double GetFinalObjective() const { return 0.0; }
};

} // namespace test
} // namespace ens

// Include implementation.
#include "wood_function_impl.hpp"

#endif // ENSMALLEN_PROBLEMS_WOOD_FUNCTION_HPP
/**
 * @file wood_function_impl.hpp
 * @author Ryan Curtin
 * @author Marcus Edel
 *
 * Implementation of the Wood function.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PROBLEMS_WOOD_FUNCTION_IMPL_HPP
#define ENSMALLEN_PROBLEMS_WOOD_FUNCTION_IMPL_HPP

// In case it hasn't been included yet.
#include "wood_function.hpp"

namespace ens {
namespace test {

inline WoodFunction::WoodFunction() { /* Nothing to do here */ }

inline void WoodFunction::Shuffle() { /* Nothing to do here */ }

template<typename MatType>
typename MatType::elem_type WoodFunction::Evaluate(
    const MatType& coordinates,
    const size_t /* begin */,
    const size_t /* batchSize */) const
{
  // Convenience typedef.
  typedef typename MatType::elem_type ElemType;

  // For convenience; we assume these temporaries will be optimized out.
  const ElemType x1 = coordinates(0);
  const ElemType x2 = coordinates(1);
  const ElemType x3 = coordinates(2);
  const ElemType x4 = coordinates(3);

  const ElemType objective =
      /* f1(x) */ 100 * std::pow(x2 - std::pow(x1, 2), 2) +
      /* f2(x) */ std::pow(1 - x1, 2) +
      /* f3(x) */ 90 * std::pow(x4 - std::pow(x3, 2), 2) +
      /* f4(x) */ std::pow(1 - x3, 2) +
      /* f5(x) */ 10 * std::pow(x2 + x4 - 2, 2) +
      /* f6(x) */ (1.0 / 10.0) * std::pow(x2 - x4, 2);

  return objective;
}

template<typename MatType>
typename MatType::elem_type WoodFunction::Evaluate(
    const MatType& coordinates) const
{
  return Evaluate(coordinates, 0, NumFunctions());
}

template<typename MatType, typename GradType>
inline void WoodFunction::Gradient(const MatType& coordinates,
                                   const size_t /* begin */,
                                   GradType& gradient,
                                   const size_t /* batchSize */) const
{
  // Convenience typedef.
  typedef typename MatType::elem_type ElemType;

  // For convenience; we assume these temporaries will be optimized out.
  const ElemType x1 = coordinates(0);
  const ElemType x2 = coordinates(1);
  const ElemType x3 = coordinates(2);
  const ElemType x4 = coordinates(3);

  gradient.set_size(4, 1);
  gradient(0) = 400 * (std::pow(x1, 3) - x2 * x1) - 2 * (1 - x1);
  gradient(1) = 200 * (x2 - std::pow(x1, 2)) + 20 * (x2 + x4 - 2) +
      (1.0 / 5.0) * (x2 - x4);
  gradient(2) = 360 * (std::pow(x3, 3) - x4 * x3) - 2 * (1 - x3);
  gradient(3) = 180 * (x4 - std::pow(x3, 2)) + 20 * (x2 + x4 - 2) -
      (1.0 / 5.0) * (x2 - x4);
}

template<typename MatType, typename GradType>
inline void WoodFunction::Gradient(const MatType& coordinates,
                                   GradType& gradient) const
{
  Gradient(coordinates, 0, gradient, 1);
}

} // namespace test
} // namespace ens

#endif
/**
 * @file zdt1_function.hpp
 * @author Nanubala Gnana Sai
 *
 * Implementation of the first ZDT(Zitzler, Deb and Thiele) test.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */

#ifndef ENSMALLEN_PROBLEMS_ZDT_ONE_FUNCTION_HPP
#define ENSMALLEN_PROBLEMS_ZDT_ONE_FUNCTION_HPP

namespace ens {
namespace test {

/**
 * The ZDT1 function, defined by:
 * \f[
 * g(x) = 1 + 9(\sum_{i=2}^{n} x_i )/(n-1)
 * f_1(x) = x_1
 * h(f_1, g) = g(x)[1-\sqrt{f_1/g}\ ]
 * f_2(x) = g(x) * h(f_1, g)
 * \f]
 *
 * This is a 30-variable problem (n = 30) with a convex optimal set.
 *
 * Bounds of the variable space is:
 * 0 <= x_i <= 1 for i = 1,...,n.
 *
 * This should be optimized to g(x) = 1.0, at:
 * x_1* in [0, 1] ; x_i* = 0 for i = 2,...,n
 *
 * For more information, please refer to:
 *
 * @code
 * @article{Zitzler2000,
 *   title   = {Comparison of multiobjective evolutionary algorithms:
 *              Empirical results},
 *   author  = {Zitzler, Eckart and Deb, Kalyanmoy and Thiele, Lothar},
 *   journal = {Evolutionary computation},
 *   year    = {2000},
 *   doi     = {10.1162/106365600568202}
 * }
 * @endcode
 *
 * @tparam MatType Type of matrix to optimize.
 */
  template<typename MatType = arma::mat>
  class ZDT1
  {
   private:
    size_t numParetoPoints {100};
    size_t numObjectives {2};
    size_t numVariables {30};

   public:
     //! Initialize the ZDT1
    ZDT1(size_t numParetoPoints = 100) :
        numParetoPoints(numParetoPoints),
        objectiveF1(*this),
        objectiveF2(*this)
    {/* Nothing to do here. */}

    /**
     * Evaluate the objectives with the given coordinate.
     *
     * @param coords The function coordinates.
     * @return arma::Col<typename MatType::elem_type>
     */
    arma::Col<typename MatType::elem_type> Evaluate(const MatType& coords)
    {
      // Convenience typedef.
      typedef typename MatType::elem_type ElemType;

      arma::Col<ElemType> objectives(numObjectives);
      objectives(0) = coords[0];
      ElemType sum = arma::accu(coords(arma::span(1, numVariables - 1), 0));
      ElemType g = 1. + 9. * sum / (static_cast<ElemType>(numVariables) - 1.);
      ElemType objectiveRatio = objectives(0) / g;
      objectives(1) = g * (1. - std::sqrt(objectiveRatio));

      return objectives;
    }

    //! Get the starting point.
    MatType GetInitialPoint()
    {
      // Convenience typedef.
      typedef typename MatType::elem_type ElemType;

      return arma::Col<ElemType>(numVariables, 1, arma::fill::zeros);
    }

    struct ObjectiveF1
    {
      ObjectiveF1(ZDT1& zdtClass) : zdtClass(zdtClass)
      {/*Nothing to do here */}

      typename MatType::elem_type Evaluate(const MatType& coords)
      {
        return coords[0];
      }

      ZDT1& zdtClass;
    };

    struct ObjectiveF2
    {
      ObjectiveF2(ZDT1& zdtClass) : zdtClass(zdtClass)
      {/*Nothing to do here */}

      typename MatType::elem_type Evaluate(const MatType& coords)
      {
        // Convenience typedef.
        typedef typename MatType::elem_type ElemType;

        size_t numVariables = zdtClass.numVariables;
        ElemType sum = arma::accu(coords(arma::span(1, numVariables - 1), 0));
        ElemType g = 1. + 9. * sum / (static_cast<ElemType>(numVariables - 1));
        ElemType objectiveRatio = zdtClass.objectiveF1.Evaluate(coords) / g;

        return g * (1. - std::sqrt(objectiveRatio));
      }

      ZDT1& zdtClass;
    };

    //! Get objective functions.
    std::tuple<ObjectiveF1, ObjectiveF2> GetObjectives()
    {
      return std::make_tuple(objectiveF1, objectiveF2);
    }

    //! Get the Reference Front.
    //! Refer PR #273 Ipynb notebook to see the plot of Reference
    //! Front. The implementation has been taken from pymoo.
    arma::cube GetReferenceFront()
    {
      arma::cube front(2, 1, numParetoPoints);
      arma::vec x = arma::linspace(0, 1, numParetoPoints);
      arma::vec y = 1 - arma::sqrt(x);
      for (size_t idx = 0; idx < numParetoPoints; ++idx)
        front.slice(idx) = arma::vec{ x(idx), y(idx) };

      return front;
    }

    ObjectiveF1 objectiveF1;
    ObjectiveF2 objectiveF2;
  };
  } //namespace test
  } //namespace ens

#endif
/**
 * @file zdt2_function.hpp
 * @author Nanubala Gnana Sai
 *
 * Implementation of the second ZDT(Zitzler, Deb and Thiele) test.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */

#ifndef ENSMALLEN_PROBLEMS_ZDT_TWO_FUNCTION_HPP
#define ENSMALLEN_PROBLEMS_ZDT_TWO_FUNCTION_HPP

namespace ens {
namespace test {

/**
 * The ZDT2 function, defined by:
 * \f[
 * g(x) = 1 + 9(\sum_{i=2}^{n} x_i )/(n-1)
 * f_1(x) = x_1
 * h(f_1, g) = 1 - (f_1/g)^2
 * f_2(x) = g(x) * h(f_1, g)
 * \f]
 *
 * This is a 30-variable problem(n = 30) with a
 * non convex optimal set.
 *
 * Bounds of the variable space is:
 * 0 <= x_i <= 1 for i = 1,..,n.
 *
 * This should be optimized to g(x) = 1.0, at:
 * x_1* in [0, 1] ; x_i* = 0 for i = 2,...,n
 *
 * For more information, please refer to:
 *
 * @code
 * @article{Zitzler2000,
 *   title   = {Comparison of multiobjective evolutionary algorithms:
 *              Empirical results},
 *   author  = {Zitzler, Eckart and Deb, Kalyanmoy and Thiele, Lothar},
 *   journal = {Evolutionary computation},
 *   year    = {2000},
 *   doi     = {10.1162/106365600568202}
 * }
 * @endcode
 *
 * @tparam MatType Type of matrix to optimize.
 */
  template<typename MatType = arma::mat>
  class ZDT2
  {
   private:
    size_t numParetoPoints {100};
    size_t numObjectives {2};
    size_t numVariables {30};

   public:
     //! Initialize the ZDT2
    ZDT2(size_t numParetoPoints = 100) :
        numParetoPoints(numParetoPoints),
        objectiveF1(*this),
        objectiveF2(*this)
    {/* Nothing to do here. */}

    /**
     * Evaluate the objectives with the given coordinate.
     *
     * @param coords The function coordinates.
     * @return arma::Col<typename MatType::elem_type>
     */
    arma::Col<typename MatType::elem_type> Evaluate(const MatType& coords)
    {
      // Convenience typedef.
      typedef typename MatType::elem_type ElemType;

      arma::Col<ElemType> objectives(numObjectives);
      objectives(0) = coords[0];
      ElemType sum = arma::accu(coords(arma::span(1, numVariables - 1), 0));
      ElemType g = 1. + 9. * sum / (static_cast<ElemType>(numVariables) - 1.);
      ElemType objectiveRatio = objectives(0) / g;
      objectives(1) = g * (1. - std::pow(objectiveRatio, 2));

      return objectives;
    }

    //! Get the starting point.
    MatType GetInitialPoint()
    {
      // Convenience typedef.
      typedef typename MatType::elem_type ElemType;

      return arma::Col<ElemType>(numVariables, 1, arma::fill::zeros);
    }

    struct ObjectiveF1
    {
      ObjectiveF1(ZDT2& zdtClass) : zdtClass(zdtClass)
      {/*Nothing to do here */}

      typename MatType::elem_type Evaluate(const MatType& coords)
      {
        return coords[0];
      }

      ZDT2& zdtClass;
    };

    struct ObjectiveF2
    {
      ObjectiveF2(ZDT2& zdtClass) : zdtClass(zdtClass)
      {/*Nothing to do here */}

      typename MatType::elem_type Evaluate(const MatType& coords)
      {
        // Convenience typedef.
        typedef typename MatType::elem_type ElemType;

        size_t numVariables = zdtClass.numVariables;
        ElemType sum = arma::accu(coords(arma::span(1, numVariables - 1), 0));
        ElemType g = 1. + 9. * sum / (static_cast<ElemType>(numVariables - 1));
        ElemType objectiveRatio = zdtClass.objectiveF1.Evaluate(coords) / g;

        return g * (1. - std::pow(objectiveRatio, 2));
      }

      ZDT2& zdtClass;
    };

    //! Get objective functions.
    std::tuple<ObjectiveF1, ObjectiveF2> GetObjectives()
    {
      return std::make_tuple(objectiveF1, objectiveF2);
    }

    //! Get the Reference Front.
    //! Refer PR #273 Ipynb notebook to see the plot of Reference
    //! Front. The implementation has been taken from pymoo.
    arma::cube GetReferenceFront()
    {
      arma::cube front(2, 1, numParetoPoints);
      arma::vec x = arma::linspace(0, 1, numParetoPoints);
      arma::vec y = 1 - arma::square(x);
      for (size_t idx = 0; idx < numParetoPoints; ++idx)
        front.slice(idx) = arma::vec{ x(idx), y(idx) };

      return front;
    }

    ObjectiveF1 objectiveF1;
    ObjectiveF2 objectiveF2;
  };
  } //namespace test
  } //namespace ens

#endif
/**
 * @file zdt3_function.hpp
 * @author Nanubala Gnana Sai
 *
 * Implementation of the third ZDT(Zitzler, Deb and Thiele) test.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */

#ifndef ENSMALLEN_PROBLEMS_ZDT_THREE_FUNCTION_HPP
#define ENSMALLEN_PROBLEMS_ZDT_THREE_FUNCTION_HPP

namespace ens {
namespace test {

/**
 * The ZDT3 function, defined by:
 * \f[
 * g(x) = 1 + 9(\sum_{i=2}^{n} x_i )/(n-1)
 * f_1(x) = x_1
 * h(f_1,g) = 1 - \sqrt{f_1/g}  - (f_1/g)sin(10\pi f_1)
 * f_2(x) = g(x) * h(f_1, g)
 * \f]
 *
 * This is a 30-variable problem(n = 30) with a number
 * of disconnected optimal fronts.
 *
 * Bounds of the variable space is:
 * 0 <= x_i <= 1 for i = 1,...,n.
 *
 * This should be optimized to g(x) = 1.0, at:
 *
 * x_1* in [0.0000, 0.0830] OR
 * x_1* in [0.1822, 0.2577] OR
 * x_1* in [0.4093, 0.4538] OR
 * x_1* in [0.6183, 0.6525] OR
 * x_1* in [0.8233, 0.8518].
 *
 * x_i* = 0 for i = 2,...,n.
 *
 * For more information, please refer to:
 *
 * @code
 * @article{Zitzler2000,
 *   title   = {Comparison of multiobjective evolutionary algorithms:
 *              Empirical results},
 *   author  = {Zitzler, Eckart and Deb, Kalyanmoy and Thiele, Lothar},
 *   journal = {Evolutionary computation},
 *   year    = {2000},
 *   doi     = {10.1162/106365600568202}
 * }
 * @endcode
 *
 * @tparam MatType Type of matrix to optimize.
 */
  template<typename MatType = arma::mat>
  class ZDT3
  {
   private:
    size_t numParetoPoints {100};
    size_t numObjectives {2};
    size_t numVariables {30};

   public:
     //! Initialize the ZDT3
    ZDT3(size_t numParetoPoints = 100) :
        numParetoPoints(numParetoPoints),
        objectiveF1(*this),
        objectiveF2(*this)
    {/* Nothing to do here. */}

    /**
     * Evaluate the objectives with the given coordinate.
     *
     * @param coords The function coordinates.
     * @return arma::Col<typename MatType::elem_type>
     */
    arma::Col<typename MatType::elem_type> Evaluate(const MatType& coords)
    {
      typedef typename MatType::elem_type ElemType;

      arma::Col<ElemType> objectives(numObjectives);
      objectives(0) = coords[0];
      ElemType sum = arma::accu(coords(arma::span(1, numVariables - 1), 0));
      ElemType g = 1. + 9. * sum / (static_cast<ElemType>(numVariables) - 1.);
      ElemType objectiveRatio = objectives(0) / g;
      objectives(1) = g * (1. - std::sqrt(objectiveRatio) -
          (objectiveRatio) * std::sin(10. * arma::datum::pi * coords[0]));

      return objectives;
    }

    //! Get the starting point.
    MatType GetInitialPoint()
    {
      // Convenience typedef.
      typedef typename MatType::elem_type ElemType;

      return arma::Col<ElemType>(numVariables, 1, arma::fill::zeros);
    }

    struct ObjectiveF1
    {
      ObjectiveF1(ZDT3& zdtClass) : zdtClass(zdtClass)
      {/*Nothing to do here */}

      typename MatType::elem_type Evaluate(const MatType& coords)
      {
        return coords[0];
      }

      ZDT3& zdtClass;
    };

    struct ObjectiveF2
    {
      ObjectiveF2(ZDT3& zdtClass) : zdtClass(zdtClass)
      {/*Nothing to do here */}

      typename MatType::elem_type Evaluate(const MatType& coords)
      {
        typedef typename MatType::elem_type ElemType;

        size_t numVariables = zdtClass.numVariables;
        ElemType sum = arma::accu(coords(arma::span(1, numVariables - 1), 0));
        ElemType g = 1. + 9. * sum / (static_cast<ElemType>(numVariables - 1));
        ElemType objectiveRatio = zdtClass.objectiveF1.Evaluate(coords) / g;

        return g * (1. - std::sqrt(objectiveRatio) -
            (objectiveRatio) * std::sin(10. * arma::datum::pi * coords[0]));
      }

      ZDT3& zdtClass;
    };

    //! Get objective functions.
    std::tuple<ObjectiveF1, ObjectiveF2> GetObjectives()
    {
      return std::make_tuple(objectiveF1, objectiveF2);
    }

    //! Get the Reference Front.
    //! Refer PR #273 Ipynb notebook to see the plot of Reference
    //! Front. The implementation has been taken from pymoo.
    arma::cube GetReferenceFront()
    {
      size_t numRegions = 5;
      size_t regionDensity = std::floor(numParetoPoints / numRegions);
      size_t apparentParetoPoints = numRegions * regionDensity;
      arma::cube front(2, 1, apparentParetoPoints);

      arma::mat regions{
        {0.0, 0.182228780, 0.4093136748,
         0.6183967944, 0.8233317983},
        {0.0830015349, 0.2577623634, 0.4538821041,
         0.6525117038, 0.8518328654}
      };

      for (size_t regionIdx = 0; regionIdx < numRegions; ++regionIdx)
      {
        arma::vec region = regions.col(regionIdx);
        //! Generate x and y coordinates for the region.
        arma::vec x = arma::linspace(
            region(0), region(1), regionDensity);
        arma::vec y = 1 - arma::sqrt(x) - x
            % arma::sin(10 * arma::datum::pi * x);

        //! Fill the front with the generated points.
        for (size_t pointIdx = 0; pointIdx < regionDensity; ++pointIdx)
        {
          size_t sliceIdx = regionIdx * regionDensity + pointIdx;
          front.slice(sliceIdx) = arma::vec{ x(pointIdx), y(pointIdx) };
        }
      }

      return front;
    }

    ObjectiveF1 objectiveF1;
    ObjectiveF2 objectiveF2;
  };
  } //namespace test
  } //namespace ens

#endif
/**
 * @file zdt4_function.hpp
 * @author Nanubala Gnana Sai
 *
 * Implementation of the fourth ZDT(Zitzler, Deb and Thiele) test.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */

#ifndef ENSMALLEN_PROBLEMS_ZDT_FOUR_FUNCTION_HPP
#define ENSMALLEN_PROBLEMS_ZDT_FOUR_FUNCTION_HPP

namespace ens {
namespace test {
/**
 * The ZDT4 function, defined by:
 * \f[
 * g(x) = 1 + 10(n-1) + \sum_{i=2}^{n}(x_i^2 - 10cos(4\pi x_i))
 * f_1(x) = x_i
 * h(f_1,g) = 1 - \sqrt{f_i/g}
 * f_2(x) = g(x) * h(f_1, g)
 * \f]
 *
 * This is a 10-variable problem(n = 10) with a convex
 * optimal front. This problem contains several local
 * optimum, making it difficult to reach the global optimum.
 *
 * Bounds of the variable space is:
 *  0 <= x_1 <= 1;
 * -10 <= x_i <= 10 for i = 2,...,n.
 *
 * This should be optimized to g(x) = 1.0, at:
 * x_1* in [0, 1] ; x_i* = 0 for i = 2,...,n
 *
 * For more information, please refer to:
 *
 * @code
 * @article{Zitzler2000,
 *   title   = {Comparison of multiobjective evolutionary algorithms:
 *              Empirical results},
 *   author  = {Zitzler, Eckart and Deb, Kalyanmoy and Thiele, Lothar},
 *   journal = {Evolutionary computation},
 *   year    = {2000},
 *   doi     = {10.1162/106365600568202}
 * }
 * @endcode
 *
 * @tparam MatType Type of matrix to optimize.
 */
  template<typename MatType = arma::mat>
  class ZDT4
  {
   private:
    size_t numParetoPoints {100};
    size_t numObjectives {2};
    size_t numVariables {10};

   public:
     //! Initialize the ZDT4
    ZDT4(size_t numParetoPoints = 100) :
        numParetoPoints(numParetoPoints),
        objectiveF1(*this),
        objectiveF2(*this)
    {/* Nothing to do here. */}

    /**
     * Evaluate the objectives with the given coordinate.
     *
     * @param coords The function coordinates.
     * @return arma::Col<typename MatType::elem_type>
     */
    arma::Col<typename MatType::elem_type> Evaluate(const MatType& coords)
    {
      typedef typename MatType::elem_type ElemType;

      arma::Col<ElemType> objectives(numObjectives);
      objectives(0) = coords[0];
      MatType truncatedCoords = coords(arma::span(1, numVariables - 1), 0);
      ElemType sum = arma::accu(arma::square(truncatedCoords) -
          10. * arma::cos(4 * arma::datum::pi * truncatedCoords));
      ElemType g = 1. + 10. * static_cast<ElemType>(numVariables - 1) + sum;
      ElemType objectiveRatio = objectives(0) / g;
          objectives(1) = g * (1. - std::sqrt(objectiveRatio));

      return objectives;
    }

    //! Get the starting point.
    MatType GetInitialPoint()
    {
      // Convenience typedef.
      typedef typename MatType::elem_type ElemType;

      return arma::Col<ElemType>(numVariables, 1, arma::fill::zeros);
    }

    struct ObjectiveF1
    {
      ObjectiveF1(ZDT4& zdtClass) : zdtClass(zdtClass)
      {/*Nothing to do here */}

      typename MatType::elem_type Evaluate(const MatType& coords)
      {
        return coords[0];
      }

      ZDT4& zdtClass;
    };

    struct ObjectiveF2
    {
      ObjectiveF2(ZDT4& zdtClass) : zdtClass(zdtClass)
      {/*Nothing to do here */}

      typename MatType::elem_type Evaluate(const MatType& coords)
      {
        typedef typename MatType::elem_type ElemType;

        size_t numVariables = zdtClass.numVariables;
        MatType truncatedCoords = coords(arma::span(1, numVariables - 1), 0);
        ElemType sum = arma::accu(arma::square(truncatedCoords) -
            10. * arma::cos(4 * arma::datum::pi * truncatedCoords));
        ElemType g = 1. + 10 * static_cast<ElemType>(numVariables - 1) + sum;
        ElemType objectiveRatio = zdtClass.objectiveF1.Evaluate(coords) / g;

        return  g * (1. - std::sqrt(objectiveRatio));
      }

      ZDT4& zdtClass;
    };

    //! Get objective functions.
    std::tuple<ObjectiveF1, ObjectiveF2> GetObjectives()
    {
      return std::make_tuple(objectiveF1, objectiveF2);
    }

    //! Get the Reference Front.
    //! Refer PR #273 Ipynb notebook to see the plot of Reference
    //! Front. The implementation has been taken from pymoo.
    arma::cube GetReferenceFront()
    {
      arma::cube front(2, 1, numParetoPoints);
      arma::vec x = arma::linspace(0, 1, numParetoPoints);
      arma::vec y = 1 - arma::sqrt(x);
      for (size_t idx = 0; idx < numParetoPoints; ++idx)
        front.slice(idx) = arma::vec{ x(idx), y(idx) };

      return front;
    }

    ObjectiveF1 objectiveF1;
    ObjectiveF2 objectiveF2;
  };
  } //namespace test
  } //namespace ens
#endif
/**
 * @file zdt6_function.hpp
 * @author Nanubala Gnana Sai
 *
 * Implementation of the sixth ZDT(Zitzler, Deb and Thiele) test.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */

#ifndef ENSMALLEN_PROBLEMS_ZDT_SIX_FUNCTION_HPP
#define ENSMALLEN_PROBLEMS_ZDT_SIX_FUNCTION_HPP

namespace ens {
namespace test {
/**
 * The ZDT6 function, defined by:
 * \f[
 * g(x) = 1 + 9[ \sum_{i=2}^{n}(x_i^2)/9]^{0.25}
 * f_1(x) = 1 - e^{-4x_1}sin^{6}(6\pi x_1)
 * h(f1, g) = 1 - (f_1/g)^{2}
 * f_2(x) = g(x) * h(f_1, g)
 * \f]
 *
 * This is a 10-variable problem(n = 10) with a
 * non-convex optimal front. The density of the
 * solutions across optimal region is non-uniform.
 *
 * Bounds of the variable space is:
 * 0 <= x_i <= 1 for i = 1,...,n
 *
 * This should be optimized to g(x) = 1.0, at:
 * x_1* in [0, 1] ; x_i* = 0 for i = 2,...,n
 *
 *
 * For more information, please refer to:
 *
 * @code
 * @article{Zitzler2000,
 *   title   = {Comparison of multiobjective evolutionary algorithms:
 *              Empirical results},
 *   author  = {Zitzler, Eckart and Deb, Kalyanmoy and Thiele, Lothar},
 *   journal = {Evolutionary computation},
 *   year    = {2000},
 *   doi     = {10.1162/106365600568202}
 * }
 * @endcode
 *
 * @tparam MatType Type of matrix to optimize.
 */
  template<typename MatType = arma::mat>
  class ZDT6
  {
   private:
    size_t numParetoPoints {100};
    size_t numObjectives {2};
    size_t numVariables {10};

   public:
     //! Initialize the ZDT6
    ZDT6(size_t numParetoPoints = 100) :
        numParetoPoints(numParetoPoints),
        objectiveF1(*this),
        objectiveF2(*this)
    {/* Nothing to do here. */}

    /**
     * Evaluate the objectives with the given coordinate.
     *
     * @param coords The function coordinates.
     * @return arma::Col<typename MatType::elem_type>
     */
    arma::Col<typename MatType::elem_type> Evaluate(const MatType& coords)
    {
      // Convenience typedef.
      typedef typename MatType::elem_type ElemType;

      arma::Col<ElemType> objectives(numObjectives);
      objectives(0) = 1. - std::exp(-4 * coords[0]) *
          std::pow(std::sin(6 * arma::datum::pi * coords[0]), 6);
      ElemType sum = std::pow(
          arma::accu(coords(arma::span(1, numVariables - 1), 0)) / 9, 0.25);
      ElemType g = 1. + 9. * sum;
      ElemType objectiveRatio = objectives(0) / g;
      objectives(1) = g * (1. - std::pow(objectiveRatio, 2));

      return objectives;
    }

    //! Get the starting point.
    MatType GetInitialPoint()
    {
      // Convenience typedef.
      typedef typename MatType::elem_type ElemType;

      return arma::Col<ElemType>(numVariables, 1, arma::fill::zeros);
    }

    struct ObjectiveF1
    {
      ObjectiveF1(ZDT6& zdtClass) : zdtClass(zdtClass)
      {/*Nothing to do here */}

      typename MatType::elem_type Evaluate(const MatType& coords)
      {
        return 1. - std::exp(-4. * coords[0]) *
            std::pow(std::sin(6. * arma::datum::pi * coords[0]), 6.);
      }

      ZDT6& zdtClass;
    };

    struct ObjectiveF2
    {
      ObjectiveF2(ZDT6& zdtClass) : zdtClass(zdtClass)
      {/*Nothing to do here */}

      typename MatType::elem_type Evaluate(const MatType& coords)
      {
        typedef typename MatType::elem_type ElemType;

        size_t numVariables = zdtClass.numVariables;

        ElemType sum = std::pow(
            arma::accu(coords(arma::span(1, numVariables - 1), 0)) / 9, 0.25);
        ElemType g = 1. + 9. * sum;
        ElemType objectiveRatio = zdtClass.objectiveF1.Evaluate(coords) / g;

        return  g * (1. - std::pow(objectiveRatio, 2));
    }

      ZDT6& zdtClass;
    };

    //! Get objective functions.
    std::tuple<ObjectiveF1, ObjectiveF2> GetObjectives()
    {
      return std::make_tuple(objectiveF1, objectiveF2);
    }

    //! Get the Reference Front.
    //! Refer PR #273 Ipynb notebook to see the plot of Reference
    //! Front. The implementation has been taken from pymoo.
    arma::cube GetReferenceFront()
    {
      arma::cube front(2, 1, numParetoPoints);
      arma::vec x = arma::linspace(0.2807753191, 1, numParetoPoints);
      arma::vec y = 1 - arma::square(x);
      for (size_t idx = 0; idx < numParetoPoints; ++idx)
        front.slice(idx) = arma::vec{ x(idx), y(idx) };

      return front;
    }

    ObjectiveF1 objectiveF1;
    ObjectiveF2 objectiveF2;
  };
  } //namespace test
  } //namespace ens
#endif
/**
 * @file default_init.hpp
 * @author Chintan Soni
 * @author Suryoday Basak
 *
 * The default initialization policy used by the PSO optimizer.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PSO_INIT_POLICIES_DEFAULT_INIT_HPP
#define ENSMALLEN_PSO_INIT_POLICIES_DEFAULT_INIT_HPP
#include <assert.h>

namespace ens {

/**
 * The default initialization policy used by the PSO optimizer. It initializes
 * particle positions uniformly in [-1, 1], the velocities in [0, 1] personal
 * bests of the particles to the initial positions, and all fitness values to
 * std::numeric_limits<double>::max().
 */
class DefaultInit
{
 public:
  /**
   * Constructor for the DefaultInit policy. The policy initializes particle
   * posiitons in the range [lowerBound, upperBound]. Defaults to [-1, 1].
   */
  DefaultInit()
  {
    /* Nothing to do.*/
  }

  /**
   * The InitializeParticles method of the init policy. Any class that is used
   * in place of this default must implement this method which is used by the
   * optimizer.
   *
   * @param iterate Coordinates of the initial point for training.
   * @param numParticles The number of particles in the swarm.
   * @param lowerBound Lower bound of the position initialization range.
   * @param upperBound Upper bound of the position initialization range.
   * @param particlePositions Current positions of particles.
   * @param particleVelocities Current velocities of particles.
   * @param particleFitnesses Current fitness values of particles.
   * @param particleBestPositions Best positions attained by each particle.
   * @param particleBestFitnesses Best fitness values attained by each particle.
   */
  template<typename MatType,
           typename BoundMatType,
           typename VecType,
           typename CubeType>
  void Initialize(const MatType& iterate,
                  const size_t numParticles,
                  BoundMatType& lowerBound,
                  BoundMatType& upperBound,
                  CubeType& particlePositions,
                  CubeType& particleVelocities,
                  VecType& particleFitnesses,
                  CubeType& particleBestPositions,
                  VecType& particleBestFitnesses)
  {
    // Convenience typedef.
    typedef typename MatType::elem_type ElemType;
    typedef typename CubeType::elem_type CubeElemType;

    // Randomly initialize the particle positions.
    particlePositions.randu(iterate.n_rows, iterate.n_cols, numParticles);

    // Check if lowerBound is equal to upperBound. If equal, reinitialize.
    arma::umat lbEquality = (lowerBound == upperBound);
    if (lbEquality.n_rows == 1 && lbEquality(0, 0) == 1)
    {
      lowerBound.set_size(iterate.n_rows, iterate.n_cols);
      lowerBound.fill(-1.0);

      upperBound.set_size(iterate.n_rows, iterate.n_cols);
      upperBound.fill(1.0);
    }
    // Check if lowerBound and upperBound are vectors of a single dimension.
    else if (lbEquality.n_rows == 1 && lbEquality(0, 0) == 0)
    {
      lowerBound = -lowerBound(0) * arma::ones(iterate.n_rows, iterate.n_cols);
      upperBound = upperBound(0) * arma::ones(iterate.n_rows, iterate.n_cols);
    }

    // Check the dimensions of lowerBound and upperBound.
    assert(lowerBound.n_rows == iterate.n_rows && "The dimensions of "
        "lowerBound are not the same as the dimensions of iterate.");
    assert(upperBound.n_rows == iterate.n_rows && "The dimensions of "
        "upperBound are not the same as the dimensions of iterate.");

    // Distribute particles in [lowerBound, upperBound].
    for (size_t i = 0; i < numParticles; i++)
    {
      particlePositions.slice(i) = particlePositions.slice(i) %
          arma::conv_to<arma::Mat<CubeElemType> >::from(upperBound - lowerBound)
          + arma::conv_to<arma::Mat<CubeElemType> >::from(lowerBound);
    }

    // Randomly initialize particle velocities.
    particleVelocities.randu(iterate.n_rows, iterate.n_cols, numParticles);

    // Initialize current fitness values to infinity.
    particleFitnesses.set_size(numParticles);
    particleFitnesses.fill(std::numeric_limits<ElemType>::max());

    // Copy to personal best values for first iteration.
    particleBestPositions = particlePositions;
    // Initialize personal best fitness values to infinity.
    particleBestFitnesses.set_size(numParticles);
    particleBestFitnesses.fill(std::numeric_limits<ElemType>::max());
  }

};

} // ens

#endif
/**
 * @file pso.hpp
 * @author Chintan Soni
 * @author Suryoday Basak
 *
 * Particle swarm optimization.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PSO_PSO_HPP
#define ENSMALLEN_PSO_PSO_HPP

#include "update_policies/lbest_update.hpp"
#include "init_policies/default_init.hpp"

namespace ens {

/**
 * Particle Swarm Optimization (PSO) is an evolutionary approach to optimization
 * that is inspired by flocks or birds or fishes. The fundamental analogy is
 * that every creature (particle in a swarm) is at a measurable position of
 * `goodness' (in the context of PSO, called `fitness') in terms of being able
 * to find food, and this information can be shared amongst the creatures in the
 * flock, so that iteratively, the entire flock can get close to the optimal
 * food source. In a more technical respect, the means by which the fitness
 * information is shared determines the way in which the global optimum is
 * approached.
 *
 * When this information is shared among particles whose fitness is close to
 * each other (in a sense, the `nearest' neighbors in the fitness space), the
 * variant of the approach is called the `local-best' or `lbest' PSO
 * (consequently, it follows a ring-topology in an information-communication
 * sense); and when this information is globally shared, the variant is called
 * the `global-best' or `gbest' PSO (consequently, it follows a star-topology in
 * an information-communication sense).
 *
 * For more information, refer to:
 *
 * @code
 * @inproceedings{Kennedy1995,
 *   author    = {Kennedy, James and Eberhart, Russell C.},
 *   booktitle = {Proceedings of the IEEE International Conference on
 *                Neural Networks},
 *   pages     = {1942--1948},
 *   title     = {Particle swarm optimization},
 *   year      = 1995
 * }
 * @endcode
 *
 * PSO can optimize arbitrary functions. For more details, see the documentation
 * on function types included with this distribution or on the ensmallen
 * website.
 *
 * For PSO to work, the function being optimized must implement an
 * ArbitraryFunctionType template parameter. The respective class must implement
 * the following function:
 *
 *    double Evaluate(const arma::mat& x);
 *
 * @tparam VelocityUpdatePolicy Velocity update policy. By default LBest update
 *     policy (see ens::LBestUpdate) is used.
 * @tparam InitPolicy Particle initialization policy. By default DefaultInit
 *     policy (see ens::DefaultInit) is used.
 */
template<typename VelocityUpdatePolicy = LBestUpdate,
         typename InitPolicy = DefaultInit>
class PSOType
{
 public:
  /**
   * Construct the particle swarm optimizer with the given function and
   * parameters. The defaults here are not necessarily good for the given
   * problem, so it is suggested that the values used be tailored to the task
   * at hand.
   *
   * @param numParticles Number of particles in the swarm.
   * @param lowerBound Lower bound of the coordinates of the initial population.
   * @param upperBound Upper bound of the coordinates of the initial population.
   * @param maxIterations Number of iterations allowed.
   * @param horizonSize Size of the lookback-horizon for computing improvement.
   * @param impTolerance Improvement threshold for termination.
   * @param exploitationFactor Influence of the personal best of the particle.
   * @param explorationFactor Influence of the neighbours of the particle.
   * @param velocityUpdatePolicy Velocity update policy.
   * @param initPolicy Particle initialization policy.
   */
  PSOType(const size_t numParticles = 64,
          const arma::mat& lowerBound = arma::ones(1, 1),
          const arma::mat& upperBound = arma::ones(1, 1),
          const size_t maxIterations = 3000,
          const size_t horizonSize = 350,
          const double impTolerance = 1e-10,
          const double exploitationFactor = 2.05,
          const double explorationFactor = 2.05,
          const VelocityUpdatePolicy& velocityUpdatePolicy =
              VelocityUpdatePolicy(),
          const InitPolicy& initPolicy = InitPolicy()) :
          numParticles(numParticles),
          lowerBound(lowerBound),
          upperBound(upperBound),
          maxIterations(maxIterations),
          horizonSize(horizonSize),
          impTolerance(impTolerance),
          exploitationFactor(exploitationFactor),
          explorationFactor(explorationFactor),
          velocityUpdatePolicy(velocityUpdatePolicy),
          initPolicy(initPolicy)
  { /* Nothing to do. */ }

  /**
   * Clean memory associated with the PSO object.
   */
  ~PSOType()
  {
    instUpdatePolicy.Clean();
  }

  /**
   * Construct the particle swarm optimizer with the given function and
   * parameters. The defaults here are not necessarily good for the given
   * problem, so it is suggested that the values used be tailored to the task
   * at hand.
   *
   * @param numParticles Number of particles in the swarm.
   * @param lowerBound Lower bound of the coordinates of the initial population.
   * @param upperBound Upper bound of the coordinates of the initial population.
   * @param maxIterations Number of iterations allowed.
   * @param horizonSize Size of the lookback-horizon for computing improvement.
   * @param impTolerance Improvement threshold for termination.
   * @param exploitationFactor Influence of the personal best of the particle.
   * @param explorationFactor Influence of the neighbours of the particle.
   */
  PSOType(const size_t numParticles,
          const double lowerBound,
          const double upperBound,
          const size_t maxIterations = 3000,
          const size_t horizonSize = 350,
          const double impTolerance = 1e-10,
          const double exploitationFactor = 2.05,
          const double explorationFactor = 2.05,
          const VelocityUpdatePolicy& velocityUpdatePolicy =
              VelocityUpdatePolicy(),
          const InitPolicy& initPolicy = InitPolicy()) :
          numParticles(numParticles),
          lowerBound(lowerBound * arma::ones(1, 1)),
          upperBound(upperBound * arma::ones(1, 1)),
          maxIterations(maxIterations),
          horizonSize(horizonSize),
          impTolerance(impTolerance),
          exploitationFactor(exploitationFactor),
          explorationFactor(explorationFactor),
          velocityUpdatePolicy(velocityUpdatePolicy),
          initPolicy(initPolicy)
  { /* Nothing to do. */ }

  /**
   * Optimize the input function using PSO. The given variable that holds the
   * initial point will be modified to store the value of the optimum, or the
   * point where the PSO method stops, and the final objective value is
   * returned.
   *
   * @tparam ArbitraryFunctionType Type of the function to be optimized.
   * @tparam MatType Type of matrix to optimize.
   * @tparam CallbackTypes Types of callback functions.
   * @param function Function to be optimized.
   * @param iterate Initial point (will be modified).
   * @param callbacks Callback functions.
   * @return Objective value of the final point.
   */
  template<typename ArbitraryFunctionType,
           typename MatType,
           typename... CallbackTypes>
  typename MatType::elem_type Optimize(ArbitraryFunctionType& function,
                                       MatType& iterate,
                                       CallbackTypes&&... callbacks);

  //! Retrieve value of numParticles.
  size_t NumParticles() const { return numParticles; }
  //! Modify value of numParticles.
  size_t& NumParticles() { return numParticles; }

  //! Retrieve value of lowerBound.
  const arma::mat& LowerBound() const { return lowerBound; }
  //! Modify value of lowerBound.
  arma::mat& LowerBound() { return lowerBound; }

  //! Retrieve value of upperBound.
  const arma::mat& UpperBound() const { return upperBound; }
  //! Modify value of upperBound.
  arma::mat& UpperBound() { return upperBound; }

  //! Retrieve value of maxIterations.
  size_t MaxIterations() const { return maxIterations; }
  //! Modify value of maxIterations.
  size_t& MaxIterations() { return maxIterations; }

  //! Retrieve value of horizonSize.
  size_t HorizonSize() const { return horizonSize; }
  //! Modify value of horizonSize.
  size_t& HorizonSize() { return horizonSize; }

  //! Retrieve value of impTolerance.
  double ImpTolerance() const { return impTolerance; }
  //! Modify value of impTolerance.
  double& ImpTolerance() { return impTolerance; }

  //! Retrieve value of exploitationFactor.
  double ExploitationFactor() const { return exploitationFactor; }
  //! Modify value of exploitationFactor.
  double& ExploitationFactor() { return exploitationFactor; }

  //! Retrieve value of explorationFactor.
  double ExplorationFactor() const { return explorationFactor; }
  //! Modify value of explorationFactor.
  double& ExplorationFactor() { return explorationFactor; }

  //! Get the update policy.
  const VelocityUpdatePolicy& UpdatePolicy() const
  {
    return velocityUpdatePolicy;
  }
  //! Modify the update policy.
  VelocityUpdatePolicy& UpdatePolicy() { return velocityUpdatePolicy; }

  //! Get the instantiated update policy type.  Be sure to check its type with
  //! Has() before using!
  const Any& InstUpdatePolicy() const { return instUpdatePolicy; }
  //! Modify the instantiated update policy type.  Be sure to check its type
  //! with Has() before using!
  Any& InstUpdatePolicy() { return instUpdatePolicy; }

 private:
  //! Number of particles in the swarm.
  size_t numParticles;

  //! Lower bound of the initial swarm.
  arma::mat lowerBound;

  //! Upper bound of the initial swarm.
  arma::mat upperBound;

  //! Maximum number of iterations for which the optimizer will run.
  size_t maxIterations;

  //! The number of iterations looked back at for improvement analysis.
  size_t horizonSize;

  //! The tolerance for improvement over the horizon.
  double impTolerance;

  //! Exploitation factor for lbest version.
  double exploitationFactor;

  //! Exploration factor for lbest version.
  double explorationFactor;

  //! Velocity update policy used.
  VelocityUpdatePolicy velocityUpdatePolicy;
  //! Particle initialization policy used.
  InitPolicy initPolicy;

  //! The initialized update policy.
  Any instUpdatePolicy;
};

using LBestPSO = PSOType<LBestUpdate>;
} // ens

#include "pso_impl.hpp"

#endif
/**
 * @file pso_impl.hpp
 * @author Chintan Soni
 * @author Suryoday Basak
 *
 * Implementation of the particle swarm optimization algorithm.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PSO_PSO_IMPL_HPP
#define ENSMALLEN_PSO_PSO_IMPL_HPP

#include "pso.hpp"
#include <ensmallen_bits/function.hpp>
#include <queue>

namespace ens {

/**
 * After the velocity of each particle is updated at the end of each iteration
 * in PSO, the position of particle i (in iteration j) is updated as:
 *
 * \f[
 *     p_{i, j + 1} = p_{i, j} + v_{i, j}
 * \f]
 *
 * pso_impl.hpp implements the position-updating procedure. The velocity update
 * may be done using either the lbest or gbest methods, by using the
 * appropriate templates.
 */

//! Optimize the function (minimize).
template<typename VelocityUpdatePolicy,
         typename InitPolicy>
template<typename ArbitraryFunctionType,
         typename MatType,
         typename... CallbackTypes>
typename MatType::elem_type PSOType<VelocityUpdatePolicy, InitPolicy>::Optimize(
    ArbitraryFunctionType& function,
    MatType& iterateIn,
    CallbackTypes&&... callbacks)
{
  // Convenience typedefs.
  typedef typename MatType::elem_type ElemType;
  typedef typename MatTypeTraits<MatType>::BaseMatType BaseMatType;

  // The update policy internally use a templated class so that
  // we can know MatType only when Optimize() is called.
  typedef typename VelocityUpdatePolicy::template Policy<BaseMatType>
      InstUpdatePolicyType;

  // Make sure that we have the methods that we need.  Long name...
  traits::CheckArbitraryFunctionTypeAPI<ArbitraryFunctionType,
      BaseMatType>();
  RequireDenseFloatingPointType<BaseMatType>();

  // The number of iterations must be greater than the horizon size.
  if (maxIterations < horizonSize)
  {
    std::ostringstream oss;
    oss << "PSO::Optimize(): maxIterations (" << maxIterations << ") must be "
        << "greater than or equal to horizonSize (" << horizonSize << ")!";
    throw std::runtime_error(oss.str());
  }

  BaseMatType& iterate = (BaseMatType&) iterateIn;

  // Controls early termination of the optimization process.
  bool terminate = false;

  if (!instUpdatePolicy.Has<InstUpdatePolicyType>())
  {
    instUpdatePolicy.Clean();
    instUpdatePolicy.Set<InstUpdatePolicyType>(
        new InstUpdatePolicyType(velocityUpdatePolicy));
  }

  // Initialize helper variables.
  arma::Cube<ElemType> particlePositions;
  arma::Cube<ElemType> particleVelocities;
  arma::Col<ElemType> particleFitnesses;
  arma::Col<ElemType> particleBestFitnesses;
  arma::Cube<ElemType> particleBestPositions;

  // Initialize particles using the init policy.
  initPolicy.Initialize(iterate,
      numParticles,
      lowerBound,
      upperBound,
      particlePositions,
      particleVelocities,
      particleFitnesses,
      particleBestPositions,
      particleBestFitnesses);

  // Initialize the update policy.
  instUpdatePolicy.As<InstUpdatePolicyType>().Initialize(exploitationFactor,
      explorationFactor, numParticles, iterate);

  Callback::BeginOptimization(*this, function, iterate, callbacks...);

  // Calculate initial fitness of population.
  for (size_t i = 0; (i < numParticles) && !terminate; i++)
  {
    // Calculate fitness value.
    particleFitnesses(i) = function.Evaluate(particlePositions.slice(i));
    terminate |= Callback::Evaluate(*this, function,
        particlePositions.slice(i), particleFitnesses(i), callbacks...);
    particleBestFitnesses(i) = particleFitnesses(i);
  }

  // Declare queue to keep track of improvements over a number of iterations.
  std::queue<ElemType> performanceHorizon;
  // Variable to store the position of the best particle.
  size_t bestParticle = 0;
  // Find the best fitness.
  ElemType bestFitness = std::numeric_limits<ElemType>::max();

  // Run PSO for horizonSize number of iterations.
  // This will allow the performanceHorizon to be updated.
  // With some initial values in this, we may proceed with the remaining steps
  // in the PSO method.
  // The performanceHorizon will be updated with the best particle
  // in a FIFO manner.
  for (size_t i = 0; (i < horizonSize) && !terminate; i++)
  {
    // Calculate fitness and evaluate personal best.
    for (size_t j = 0; (j < numParticles) && !terminate; j++)
    {
      particleFitnesses(j) = function.Evaluate(particlePositions.slice(j));
      terminate |= Callback::Evaluate(*this, function,
          particlePositions.slice(j), particleFitnesses(j), callbacks...);
      if (terminate)
        break;

      // Compare and copy fitness and position to particle best.
      if (particleFitnesses(j) < particleBestFitnesses(j))
      {
        particleBestFitnesses(j) = particleFitnesses(j);
        particleBestPositions.slice(j) = particlePositions.slice(j);
      }
    }

    // Evaluate local best and update velocity.
    instUpdatePolicy.As<InstUpdatePolicyType>().Update(
        particlePositions, particleVelocities, particleBestPositions,
        particleBestFitnesses);

    // In-place update of particle positions.
    particlePositions += particleVelocities;

    // Find the best particle.
    for (size_t j = 0; j < numParticles; j++)
    {
      if (particleBestFitnesses(j) < bestFitness)
      {
        bestParticle = j;
        bestFitness = particleBestFitnesses(bestParticle);
      }
    }

    terminate |= Callback::StepTaken(*this, function,
        particleBestPositions.slice(bestParticle), callbacks...);

    // Append bestFitness to performanceHorizon.
    performanceHorizon.push(bestFitness);
  }

  // Run the remaining iterations of PSO.
  for (size_t i = 0; (i < maxIterations - horizonSize) && !terminate; i++)
  {
    // Check if there is any improvement over the horizon.
    // If there is no significant improvement, terminate.
    if (performanceHorizon.front() - performanceHorizon.back() < impTolerance)
      break;

    // Calculate fitness and evaluate personal best.
    for (size_t j = 0; (j < numParticles) && !terminate; j++)
    {
      particleFitnesses(j) = function.Evaluate(particlePositions.slice(j));
      terminate |= Callback::Evaluate(*this, function,
          particlePositions.slice(j), particleFitnesses(j), callbacks...);

      // Compare and copy fitness and position to particle best.
      if (particleFitnesses(j) < particleBestFitnesses(j))
      {
        particleBestFitnesses(j) = particleFitnesses(j);
        particleBestPositions.slice(j) = particlePositions.slice(j);
      }
    }

    // Evaluate local best and update velocity.
    instUpdatePolicy.As<InstUpdatePolicyType>().Update(
        particlePositions, particleVelocities, particleBestPositions,
        particleBestFitnesses);

    // In-place update of particle positions.
    particlePositions += particleVelocities;

    // Find the best particle.
    for (size_t j = 0; j < numParticles; j++)
    {
      if (particleBestFitnesses(j) < bestFitness)
      {
        bestParticle = j;
        bestFitness = particleBestFitnesses(bestParticle);
      }
    }

    terminate |= Callback::StepTaken(*this, function,
        particleBestPositions.slice(bestParticle), callbacks...);

    // Pop the oldest value from performanceHorizon.
    performanceHorizon.pop();
    // Push most recent bestFitness to performanceHorizon.
    performanceHorizon.push(bestFitness);
  }

  // Copy results back.
  iterate = particleBestPositions.slice(bestParticle);

  Callback::EndOptimization(*this, function, iterate, callbacks...);
  return bestFitness;
}

} // ens

#endif
/**
 * @file lbest_update.hpp
 * @author Chintan Soni
 * @author Suryoday Basak
 *
 * Implementation of the lbest update policy for particle swarm optimization.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_PSO_UPDATE_POLICIES_LBEST_UPDATE_HPP
#define ENSMALLEN_PSO_UPDATE_POLICIES_LBEST_UPDATE_HPP
#include <assert.h>

namespace ens {

/**
 * The local best version (lbest) of PSO in which particles communicate with
 * only two neighbours each, thus forming a ring topology amongst them. This
 * approach allows PSO to converge at the global minimum, but takes
 * significantly more iterations to do so.
 *
 * The lbest update scheme is described as follows:
 *
 * \f{eqation}{
 * v_{i+1} = \phi (v_i + c_1 * r_1 * (p_{best} - p_{current}) +
 *           c_1 * r_1 * (l_{best} - p_{current}))
 * \f}
 *
 * where \f$ v_i \f$ is the velocity of a particle in iteration \f$ i \f$,
 *       \f$ p_{best} \f$ is the best position of an individual particle,
 *       \f$ p_{current} \f$ is the current position of the particle,
 *       \f$ l_{best} \f$ is the local best position,
 *       \f$ r_1 \f$ and \f$ r_2 \f$  are standard uniform random variables,
 *       \f$ c_1 \f$ is the exploitation factor,
 *       \f$ c_2 \f$ is the exploration factor, and
 *       \f$ \phi \f$ is the constriction factor.
 *
 * For more information, refer the following:
 *
 * @code
 * @article{Poli2007,
 *   author    = {Riccardo Poli and James Kennedy and Tim Blackwell},
 *   title     = {Particle swarm optimization},
 *   year      = {2007},
 *   month     = aug,
 *   publisher = {Springer},
 *   volume    = {1},
 *   number    = {1},
 *   pages     = {33--57},
 *   journal   = {Swarm Intelligence}
 * }
 * @endcod
 */
class LBestUpdate
{
 public:
  /**
   * The UpdatePolicyType policy classes must contain an internal 'Policy'
   * template class with two template arguments: MatType.  This is
   * instantiated at the start of the optimization, and holds parameters
   * specific to an individual optimization.
   */
  template<typename MatType>
  class Policy
  {
    public:
    /**
     * This is called by the optimizer method before the start of the iteration
     * update process.
     *
     * @param parent Instantiated parent class.
     */
     Policy(const LBestUpdate& /* parent */) : n(0)
     { /* Do nothing. */ }

     /**
      * The Initialize method is called by PSO Optimizer method before the
      * start of the iteration process. It calculates the value of the
      * constriction coefficent, initializes the local best indices of each
      * particle to itself, and sets the shape of the r1 and r2 vectors.
      *
      * @param exploitationFactor Influence of personal best achieved.
      * @param explorationFactor Influence of neighbouring particles.
      * @param numParticles The number of particles in the swarm.
      * @param iterate The user input, used for shaping intermediate vectors.
      */
     void Initialize(const double exploitationFactor,
                     const double explorationFactor,
                     const size_t numParticles,
                     MatType& iterate)
     {
       // Copy values to aliases.
       n = numParticles;
       c1 = exploitationFactor;
       c2 = explorationFactor;

       // Calculate the constriction factor
       static double phi = c1 + c2;
       assert(phi > 4.0 && "The sum of the exploitation and exploration "
           "factors must be greater than 4.");

       chi = 2.0 / std::abs(2.0 - phi - std::sqrt((phi - 4.0) * phi));

       // Initialize local best indices to self indices of particles.
       localBestIndices = arma::linspace<
           arma::Col<typename MatType::elem_type> >(0, n-1, n);

       // Set sizes r1 and r2.
       r1.set_size(iterate.n_rows, iterate.n_cols);
       r2.set_size(iterate.n_rows, iterate.n_cols);
     }

     /**
      * Update step for LBestPSO. Compares personal best of each particle with
      * that of its neighbours, and sets the best of the 3 as the lobal best.
      * This particle is then used for calculating the velocity for the update
      * step.
      *
      * @param particlePositions The current coordinates of particles.
      * @param particleVelocities The current velocities (will be modified).
      * @param particleFitnesses The current fitness values or particles.
      * @param particleBestPositions The personal best coordinates of particles.
      * @param particleBestFitnesses The personal best fitness values of
      *     particles.
      */
     void Update(arma::Cube<typename MatType::elem_type>& particlePositions,
                 arma::Cube<typename MatType::elem_type>& particleVelocities,
                 arma::Cube<typename MatType::elem_type>& particleBestPositions,
                 arma::Col<typename MatType::elem_type>& particleBestFitnesses)
     {
       // Velocity update logic.
       for (size_t i = 0; i < n; i++)
       {
         localBestIndices(i) =
             particleBestFitnesses(left(i)) < particleBestFitnesses(i) ?
             left(i) : i;
         localBestIndices(i) =
             particleBestFitnesses(right(i)) < particleBestFitnesses(i) ?
             right(i) : i;
       }

       for (size_t i = 0; i < n; i++)
       {
         // Generate random numbers for current particle.
         r1.randu();
         r2.randu();
         particleVelocities.slice(i) = chi * (particleVelocities.slice(i) +
             c1 * r1 % (particleBestPositions.slice(i) -
             particlePositions.slice(i)) + c2 * r2 %
             (particleBestPositions.slice(localBestIndices(i)) -
             particlePositions.slice(i)));
       }
     }

    private:
     //! Number of particles.
     size_t n;

     //! Exploitation factor.
     typename MatType::elem_type c1;

     //! Exploration factor.
     typename MatType::elem_type c2;

     //! Constriction factor chi.
     typename MatType::elem_type chi;

     //! Vectors of random numbers.
     MatType r1, r2;

     //! Indices of each particle's best neighbour.
     arma::Col<typename MatType::elem_type> localBestIndices;

     // Helper functions for calculating neighbours.
    inline size_t left(size_t index) { return (index + n - 1) % n; }
    inline size_t right(size_t index) { return (index + 1) % n; }
  };
};

} // ens

#endif
/**
 * @file qhadam.hpp
 * @author Niteya Shah
 *
 * Class wrapper for the QHAdam update Policy. QHAdam is a variant of the Adam
 * based on quasi hyperbolic moments.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_ADAM_QHADAM_HPP
#define ENSMALLEN_ADAM_QHADAM_HPP

#include <ensmallen_bits/sgd/sgd.hpp>
#include "qhadam_update.hpp"

namespace ens {

/**
 * QHadam is an variation of Adam with Quasi-Hyperbolic step. It can be
 * a weighted mean of the momentum step. Due to its paramterisation it can
 * recover many other optimisation strategies.
 *
 * For more information, see the following.
 *
 * @code
 * @inproceedings{ma2019qh,
 *   title={Quasi-hyperbolic momentum and Adam for deep learning},
 *   author={Jerry Ma and Denis Yarats},
 *   booktitle={International Conference on Learning Representations},
 *   year={2019}
 * }
 * @endcode
 *
 * QHAdam can optimize differentiable separable functions. For more details,
 * see the documentation on function types included with this distribution or
 * on the ensmallen website.
 */
class QHAdam
{
 public:
  /**
   * Construct the QHAdam optimizer with the given function and parameters.
   * QHAdam is sensitive to its paramters and hence a good hyper paramater
   * selection is necessary as its default may not fit every case.
   *
   * The maximum number of iterations refers to the maximum number of
   * points that are processed (i.e., one iteration equals one point; one
   * iteration does not equal one pass over the dataset).
   *
   * @param stepSize Step size for each iteration.
   * @param batchSize Number of points to process in a single step.
   * @param v1 The first quasi-hyperbolic term.
   * @param v1 The second quasi-hyperbolic term.
   * @param beta1 Exponential decay rate for the first moment estimates.
   * @param beta2 Exponential decay rate for the weighted infinity norm
   *     estimates.
   * @param epsilon Value used to initialise the mean squared gradient
   *     parameter.
   * @param maxIterations Maximum number of iterations allowed (0 means no
   *     limit).
   * @param tolerance Maximum absolute tolerance to terminate algorithm.
   * @param shuffle If true, the function order is shuffled; otherwise, each
   *     function is visited in linear order.
   * @param resetPolicy If true, parameters are reset before every Optimize
   *     call; otherwise, their values are retained.
   * @param exactObjective Calculate the exact objective (Default: estimate the
   *        final objective obtained on the last pass over the data).
   */
  QHAdam(const double stepSize = 0.001,
         const size_t batchSize = 32,
         const double v1 = 0.7,
         const double v2 = 1,
         const double beta1 = 0.9,
         const double beta2 = 0.999,
         const double epsilon = 1e-8,
         const size_t maxIterations = 100000,
         const double tolerance = 1e-5,
         const bool shuffle = true,
         const bool resetPolicy = true,
         const bool exactObjective = false);

  /**
   * Optimize the given function using QHAdam. The given starting point will be
   * modified to store the finishing point of the algorithm, and the final
   * objective value is returned.
   *
   * @tparam SeparableFunctionType Type of the function to optimize.
   * @tparam MatType Type of matrix to optimize with.
   * @tparam GradType Type of matrix to use to represent function gradients.
   * @tparam CallbackTypes Types of callback functions.
   * @param function Function to optimize.
   * @param iterate Starting point (will be modified).
   * @param callbacks Callback functions.
   * @return Objective value of the final point.
   */
  template<typename SeparableFunctionType,
           typename MatType,
           typename GradType,
           typename... CallbackTypes>
  typename std::enable_if<IsArmaType<GradType>::value,
      typename MatType::elem_type>::type
  Optimize(SeparableFunctionType& function,
           MatType& iterate,
           CallbackTypes&&... callbacks)
  {
    return optimizer.Optimize<SeparableFunctionType, MatType, GradType,
        CallbackTypes...>(function, iterate,
        std::forward<CallbackTypes>(callbacks)...);
  }

  //! Forward the MatType as GradType.
  template<typename SeparableFunctionType,
           typename MatType,
           typename... CallbackTypes>
  typename MatType::elem_type Optimize(SeparableFunctionType& function,
                                       MatType& iterate,
                                       CallbackTypes&&... callbacks)
  {
    return Optimize<SeparableFunctionType, MatType, MatType,
        CallbackTypes...>(function, iterate,
        std::forward<CallbackTypes>(callbacks)...);
  }

  //! Get the step size.
  double StepSize() const { return optimizer.StepSize(); }
  //! Modify the step size.
  double& StepSize() { return optimizer.StepSize(); }

  //! Get the batch size.
  size_t BatchSize() const { return optimizer.BatchSize(); }
  //! Modify the batch size.
  size_t& BatchSize() { return optimizer.BatchSize(); }

  //! Get the smoothing parameter.
  double Beta1() const { return optimizer.UpdatePolicy().Beta1(); }
  //! Modify the smoothing parameter.
  double& Beta1() { return optimizer.UpdatePolicy().Beta1(); }

  //! Get the second moment coefficient.
  double Beta2() const { return optimizer.UpdatePolicy().Beta2(); }
  //! Modify the second moment coefficient.
  double& Beta2() { return optimizer.UpdatePolicy().Beta2(); }

  //! Get the value used to initialise the mean squared gradient parameter.
  double Epsilon() const { return optimizer.UpdatePolicy().Epsilon(); }
  //! Modify the value used to initialise the mean squared gradient parameter.
  double& Epsilon() { return optimizer.UpdatePolicy().Epsilon(); }

  //! Get the maximum number of iterations (0 indicates no limit).
  size_t MaxIterations() const { return optimizer.MaxIterations(); }
  //! Modify the maximum number of iterations (0 indicates no limit).
  size_t& MaxIterations() { return optimizer.MaxIterations(); }

  //! Get the tolerance for termination.
  double Tolerance() const { return optimizer.Tolerance(); }
  //! Modify the tolerance for termination.
  double& Tolerance() { return optimizer.Tolerance(); }

  //! Get whether or not the individual functions are shuffled.
  bool Shuffle() const { return optimizer.Shuffle(); }
  //! Modify whether or not the individual functions are shuffled.
  bool& Shuffle() { return optimizer.Shuffle(); }

  //! Get whether or not the actual objective is calculated.
  bool ExactObjective() const { return optimizer.ExactObjective(); }
  //! Modify whether or not the actual objective is calculated.
  bool& ExactObjective() { return optimizer.ExactObjective(); }

  //! Get whether or not the update policy parameters are reset before
  //! Optimize call.
  bool ResetPolicy() const { return optimizer.ResetPolicy(); }
  //! Modify whether or not the update policy parameters
  //! are reset before Optimize call.
  bool& ResetPolicy() { return optimizer.ResetPolicy(); }

  //! Get the first quasi hyperbolic parameter.
  double V1() const { return optimizer.UpdatePolicy().V1(); }
  //! Modify the first quasi hyperbolic parameter.
  double& V1() { return optimizer.UpdatePolicy().V1(); }

  //! Get the second quasi hyperbolic parameter.
  double V2() const { return optimizer.UpdatePolicy().V2(); }
  //! Modify the second quasi hyperbolic parameter.
  double& V2() { return optimizer.UpdatePolicy().V2(); }

  private:
  //! The Stochastic Gradient Descent object with QHAdam policy.
  SGD<QHAdamUpdate> optimizer;
};

} // namespace ens

// Include implementation.
#include "qhadam_impl.hpp"

#endif
/**
 * @file qhadam_impl.hpp
 * @author Niteya Shah
 *
 * Implementation of QHAdam class wrapper.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_ADAM_QHADAM_IMPL_HPP
#define ENSMALLEN_ADAM_QHADAM_IMPL_HPP

// In case it hasn't been included yet.
#include "qhadam.hpp"

namespace ens {

inline QHAdam::QHAdam(
    const double stepSize,
    const size_t batchSize,
    const double v1,
    const double v2,
    const double beta1,
    const double beta2,
    const double epsilon,
    const size_t maxIterations,
    const double tolerance,
    const bool shuffle,
    const bool resetPolicy,
    const bool exactObjective) :
    optimizer(stepSize,
              batchSize,
              maxIterations,
              tolerance,
              shuffle,
              QHAdamUpdate(epsilon, beta1, beta2, v1, v2),
              NoDecay(),
              resetPolicy,
              exactObjective)
{ /* Nothing to do. */ }

} // namespace ens

 #endif
/**
 * @file qhadam_update.hpp
 * @author Niteya Shah
 *
 * Implments the QHAdam Optimizer. QHAdam is a variant of Adam which introduces
 * quasi hyperbolic moment terms to improve paramterisation and performance.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_ADAM_QHADAM_UPDATE_HPP
#define ENSMALLEN_ADAM_QHADAM_UPDATE_HPP

namespace ens {

/**
 * QHAdam is a optimising strategy based on the Quasi-Hyperbolic step when
 * applied to the Adam Optimiser.QH updates can be considered to a weighted
 * average of the momentum.QHAdam,based on its paramterisation can recover
 * many algorithms such as NAdam and RMSProp.
 *
 * For more information, see the following.
 *
 * @code
 * @inproceedings{ma2019qh,
 *   title={Quasi-hyperbolic momentum and Adam for deep learning},
 *   author={Jerry Ma and Denis Yarats},
 *   booktitle={International Conference on Learning Representations},
 *   year={2019}
 * }
 * @endcode
 */
class QHAdamUpdate
{
 public:
  /**
   * Construct the QHAdam update policy with the given parameters.
   *
   * @param epsilon The epsilon value used to initialise the squared gradient
   *        parameter.
   * @param beta1 The smoothing parameter.
   * @param beta2 The second moment coefficient.
   * @param v1 The first quasi-hyperbolic term.
   * @param v1 The second quasi-hyperbolic term.
   */
  QHAdamUpdate(const double epsilon = 1e-8,
               const double beta1 = 0.9,
               const double beta2 = 0.999,
               const double v1 = 0.7,
               const double v2 = 1) :
    epsilon(epsilon),
    beta1(beta1),
    beta2(beta2),
    v1(v1),
    v2(v2)
  {
    // Nothing to do.
  }

  //! Get the value used to initialise the squared gradient parameter.
  double Epsilon() const { return epsilon; }
  //! Modify the value used to initialise the squared gradient parameter.
  double& Epsilon() { return epsilon; }

  //! Get the smoothing parameter.
  double Beta1() const { return beta1; }
  //! Modify the smoothing parameter.
  double& Beta1() { return beta1; }

  //! Get the second moment coefficient.
  double Beta2() const { return beta2; }
  //! Modify the second moment coefficient.
  double& Beta2() { return beta2; }

  //! Get the first quasi-hyperbolic term.
  double V1() const { return v1; }
  //! Modify the first quasi-hyperbolic term.
  double& V1() { return v1; }

  //! Get the second quasi-hyperbolic term.
  double V2() const { return v2; }
  //! Modify the second quasi-hyperbolic term.
  double& V2() { return v2; }

  /**
   * The UpdatePolicyType policy classes must contain an internal 'Policy'
   * template class with two template arguments: MatType and GradType.  This is
   * instantiated at the start of the optimization, and holds parameters
   * specific to an individual optimization.
   */
  template<typename MatType, typename GradType>
  class Policy
  {
   public:
    /**
     * This constructor is called by the SGD Optimize() method before the start
     * of the iteration update process.
     *
     * @param parent AdamUpdate object.
     * @param rows Number of rows in the gradient matrix.
     * @param cols Number of columns in the gradient matrix.
     */
    Policy(QHAdamUpdate& parent, const size_t rows, const size_t cols) :
        parent(parent),
        iteration(0)
    {
      m.zeros(rows, cols);
      v.zeros(rows, cols);
    }

    /**
     * Update step for QHAdam.
     *
     * @param iterate Parameters that minimize the function.
     * @param stepSize Step size to be used for the given iteration.
     * @param gradient The gradient matrix.
     */
    void Update(MatType& iterate,
                const double stepSize,
                const GradType& gradient)
    {
      // Increment the iteration counter variable.
      ++iteration;

      // And update the iterate.
      m *= parent.beta1;
      m += (1 - parent.beta1) * gradient;

      v *= parent.beta2;
      v += (1 - parent.beta2) * (gradient % gradient);

      const double biasCorrection1 = 1.0 - std::pow(parent.beta1, iteration);
      const double biasCorrection2 = 1.0 - std::pow(parent.beta2, iteration);

      GradType mDash = m / biasCorrection1;
      GradType vDash = v / biasCorrection2;

      // QHAdam recovers Adam when v2 = v1 = 1.
      iterate -= stepSize *
          ((((1 - parent.v1) * gradient) + parent.v1 * mDash) /
           (arma::sqrt(((1 - parent.v2) * (gradient % gradient)) +
            parent.v2 * vDash) + parent.epsilon));
    }

   private:
    //! Instantiated parent object.
    QHAdamUpdate& parent;

    //! The exponential moving average of gradient values.
    GradType m;

    // The exponential moving average of squared gradient values.
    GradType v;

    // The number of iterations.
    size_t iteration;
  };

 private:
  // The epsilon value used to initialise the squared gradient parameter.
  double epsilon;

  // The smoothing parameter.
  double beta1;

  // The second moment coefficient.
  double beta2;

  // The first quasi-hyperbolic term.
  double v1;

  // The second quasi-hyperbolic term.
  double v2;
};

} // namespace ens

#endif
/**
 * @file rmsprop.hpp
 * @author Ryan Curtin
 * @author Marcus Edel
 * @author Vivek Pal
 *
 * RMSProp optimizer. RMSProp is an optimizer that utilizes the magnitude of
 * recent gradients to normalize the gradients.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_RMSPROP_RMSPROP_HPP
#define ENSMALLEN_RMSPROP_RMSPROP_HPP

#include <ensmallen_bits/sgd/sgd.hpp>
#include "rmsprop_update.hpp"

namespace ens {

/**
 * RMSProp is an optimizer that utilizes the magnitude of recent gradients to
 * normalize the gradients. In its basic form, given a step rate \f$ \gamma \f$
 * and a decay term \f$ \alpha \f$ we perform the following updates:
 *
 * \f{eqnarray*}{
 * r_t &=& (1 - \gamma) f'(\Delta_t)^2 + \gamma r_{t - 1} \\
 * v_{t + 1} &=& \frac{\alpha}{\sqrt{r_t}}f'(\Delta_t) \\
 * \Delta_{t + 1} &=& \Delta_t - v_{t + 1}
 * \f}
 *
 * For more information, see the following.
 *
 * @code
 * @misc{tieleman2012,
 *   title = {Lecture 6.5 - rmsprop, COURSERA: Neural Networks for Machine
 *            Learning},
 *   year  = {2012}
 * }
 * @endcode
 *
 * RMSProp can optimize differentiable separable functions.  For more details,
 * see the documentation on function types included with this distribution or on
 * the ensmallen website.
 */
class RMSProp
{
 public:
  /**
   * Construct the RMSProp optimizer with the given function and parameters. The
   * defaults here are not necessarily good for the given problem, so it is
   * suggested that the values used be tailored to the task at hand.  The
   * maximum number of iterations refers to the maximum number of points that
   * are processed (i.e., one iteration equals one point; one iteration does not
   * equal one pass over the dataset).
   *
   * @param stepSize Step size for each iteration.
   * @param batchSize Number of points to process in each step.
   * @param alpha Smoothing constant, similar to that used in AdaDelta and
   *        momentum methods.
   * @param epsilon Value used to initialise the mean squared gradient parameter.
   * @param maxIterations Maximum number of iterations allowed (0 means no
   *        limit).
   * @param tolerance Maximum absolute tolerance to terminate algorithm.
   * @param shuffle If true, the function order is shuffled; otherwise, each
   *        function is visited in linear order.
   * @param resetPolicy If true, parameters are reset before every Optimize
   *        call; otherwise, their values are retained.
   * @param exactObjective Calculate the exact objective (Default: estimate the
   *        final objective obtained on the last pass over the data).
   */
  RMSProp(const double stepSize = 0.01,
          const size_t batchSize = 32,
          const double alpha = 0.99,
          const double epsilon = 1e-8,
          const size_t maxIterations = 100000,
          const double tolerance = 1e-5,
          const bool shuffle = true,
          const bool resetPolicy = true,
          const bool exactObjective = false) :
      optimizer(stepSize,
                batchSize,
                maxIterations,
                tolerance,
                shuffle,
                RMSPropUpdate(epsilon, alpha),
                NoDecay(),
                resetPolicy,
                exactObjective)
  { /* Nothing to do. */ }

  /**
   * Optimize the given function using RMSProp. The given starting point will be
   * modified to store the finishing point of the algorithm, and the final
   * objective value is returned.
   *
   * @tparam SeparableFunctionType Type of the function to be optimized.
   * @tparam MatType Type of matrix to optimize with.
   * @tparam GradType Type of matrix to use to represent function gradients.
   * @tparam CallbackTypes Types of callback functions.
   * @param function Function to optimize.
   * @param iterate Starting point (will be modified).
   * @param callbacks Callback functions.
   * @return Objective value of the final point.
   */
  template<typename SeparableFunctionType,
           typename MatType,
           typename GradType,
           typename... CallbackTypes>
  typename std::enable_if<IsArmaType<GradType>::value,
      typename MatType::elem_type>::type
  Optimize(SeparableFunctionType& function,
           MatType& iterate,
           CallbackTypes&&... callbacks)
  {
    return optimizer.Optimize<SeparableFunctionType, MatType, GradType,
        CallbackTypes...>(function, iterate,
        std::forward<CallbackTypes>(callbacks)...);
  }

  //! Forward the MatType as GradType.
  template<typename SeparableFunctionType,
           typename MatType,
           typename... CallbackTypes>
  typename MatType::elem_type Optimize(SeparableFunctionType& function,
                                       MatType& iterate,
                                       CallbackTypes&&... callbacks)
  {
    return Optimize<SeparableFunctionType, MatType, MatType,
        CallbackTypes...>(function, iterate,
        std::forward<CallbackTypes>(callbacks)...);
  }

  //! Get the step size.
  double StepSize() const { return optimizer.StepSize(); }
  //! Modify the step size.
  double& StepSize() { return optimizer.StepSize(); }

  //! Get the batch size.
  size_t BatchSize() const { return optimizer.BatchSize(); }
  //! Modify the batch size.
  size_t& BatchSize() { return optimizer.BatchSize(); }

  //! Get the smoothing parameter.
  double Alpha() const { return optimizer.UpdatePolicy().Alpha(); }
  //! Modify the smoothing parameter.
  double& Alpha() { return optimizer.UpdatePolicy().Alpha(); }

  //! Get the value used to initialise the mean squared gradient parameter.
  double Epsilon() const { return optimizer.UpdatePolicy().Epsilon(); }
  //! Modify the value used to initialise the mean squared gradient parameter.
  double& Epsilon() { return optimizer.UpdatePolicy().Epsilon(); }

  //! Get the maximum number of iterations (0 indicates no limit).
  size_t MaxIterations() const { return optimizer.MaxIterations(); }
  //! Modify the maximum number of iterations (0 indicates no limit).
  size_t& MaxIterations() { return optimizer.MaxIterations(); }

  //! Get the tolerance for termination.
  double Tolerance() const { return optimizer.Tolerance(); }
  //! Modify the tolerance for termination.
  double& Tolerance() { return optimizer.Tolerance(); }

  //! Get whether or not the individual functions are shuffled.
  bool Shuffle() const { return optimizer.Shuffle(); }
  //! Modify whether or not the individual functions are shuffled.
  bool& Shuffle() { return optimizer.Shuffle(); }

  //! Get whether or not the actual objective is calculated.
  bool ExactObjective() const { return optimizer.ExactObjective(); }
  //! Modify whether or not the actual objective is calculated.
  bool& ExactObjective() { return optimizer.ExactObjective(); }

  //! Get whether or not the update policy parameters
  //! are reset before Optimize call.
  bool ResetPolicy() const { return optimizer.ResetPolicy(); }
  //! Modify whether or not the update policy parameters
  //! are reset before Optimize call.
  bool& ResetPolicy() { return optimizer.ResetPolicy(); }

 private:
  //! The Stochastic Gradient Descent object with RMSPropUpdate policy.
  SGD<RMSPropUpdate> optimizer;
};

} // namespace ens

#endif
/**
 * @file rmsprop_update.hpp
 * @author Ryan Curtin
 * @author Marcus Edel
 * @author Vivek Pal
 *
 * RMSProp optimizer. RMSProp is an optimizer that utilizes the magnitude of
 * recent gradients to normalize the gradients.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_RMSPROP_RMSPROP_UPDATE_HPP
#define ENSMALLEN_RMSPROP_RMSPROP_UPDATE_HPP

namespace ens {

/**
 * RMSProp is an optimizer that utilizes the magnitude of recent gradients to
 * normalize the gradients. In its basic form, given a step rate \f$ \gamma \f$
 * and a decay term \f$ \alpha \f$ we perform the following updates:
 *
 * \f{eqnarray*}{
 * r_t &=& (1 - \gamma) f'(\Delta_t)^2 + \gamma r_{t - 1} \\
 * v_{t + 1} &=& \frac{\alpha}{\sqrt{r_t}}f'(\Delta_t) \\
 * \Delta_{t + 1} &=& \Delta_t - v_{t + 1}
 * \f}
 *
 * For more information, see the following.
 *
 * @code
 * @misc{tieleman2012,
 *   title = {Lecture 6.5 - rmsprop, COURSERA: Neural Networks for Machine
 *            Learning},
 *   year  = {2012}
 * }
 * @endcode
 */
class RMSPropUpdate
{
 public:
  /**
   * Construct the RMSProp update policy with the given parameters.
   *
   * @param epsilon The epsilon value used to initialise the squared gradient
   *        parameter.
   * @param alpha The smoothing parameter.
   */
  RMSPropUpdate(const double epsilon = 1e-8,
                const double alpha = 0.99) :
    epsilon(epsilon),
    alpha(alpha)
  {
    // Nothing to do.
  }

  //! Get the value used to initialise the squared gradient parameter.
  double Epsilon() const { return epsilon; }
  //! Modify the value used to initialise the squared gradient parameter.
  double& Epsilon() { return epsilon; }

  //! Get the smoothing parameter.
  double Alpha() const { return alpha; }
  //! Modify the smoothing parameter.
  double& Alpha() { return alpha; }

  /**
   * The UpdatePolicyType policy classes must contain an internal 'Policy'
   * template class with two template arguments: MatType and GradType.  This is
   * instantiated at the start of the optimization, and holds parameters
   * specific to an individual optimization.
   */
  template<typename MatType, typename GradType>
  class Policy
  {
   public:
    /**
     * This constructor is called by the SGD Optimize() method before the start
     * of the iteration update process.
     *
     * @param parent AdamUpdate object.
     * @param rows Number of rows in the gradient matrix.
     * @param cols Number of columns in the gradient matrix.
     */
    Policy(RMSPropUpdate& parent, const size_t rows, const size_t cols) :
        parent(parent)
    {
      // Leaky sum of squares of parameter gradient.
      meanSquaredGradient.zeros(rows, cols);
    }

    /**
     * Update step for RMSProp.
     *
     * @param iterate Parameters that minimize the function.
     * @param stepSize Step size to be used for the given iteration.
     * @param gradient The gradient matrix.
     */
    void Update(MatType& iterate,
                const double stepSize,
                const GradType& gradient)
    {
      meanSquaredGradient *= parent.alpha;
      meanSquaredGradient += (1 - parent.alpha) * (gradient % gradient);
      iterate -= stepSize * gradient / (arma::sqrt(meanSquaredGradient) +
          parent.epsilon);
    }

   private:
    // Leaky sum of squares of parameter gradient.
    GradType meanSquaredGradient;
    // Reference to instantiated parent object.
    RMSPropUpdate& parent;
  };

 private:
  // The epsilon value used to initialise the squared gradient parameter.
  double epsilon;

  // The smoothing parameter.
  double alpha;
};

} // namespace ens

#endif
/**
 * @file exponential_schedule.hpp
 * @author Zhihao Lou
 *
 * Exponential (geometric) cooling schedule used in SA.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_SA_EXPONENTIAL_SCHEDULE_HPP
#define ENSMALLEN_SA_EXPONENTIAL_SCHEDULE_HPP

namespace ens {

/**
 * The exponential cooling schedule cools the temperature T at every step
 * according to the equation
 *
 * \f[
 * T_{n+1} = (1-\lambda) T_{n}
 * \f]
 *
 * where \f$ 0<\lambda<1 \f$ is the cooling speed. The smaller \f$ \lambda \f$
 * is, the slower the cooling speed, and better the final result will be. Some
 * literature uses \f$ \alpha = (-1 \lambda) \f$ instead. In practice,
 * \f$ \alpha \f$ is very close to 1 and will be awkward to input (e.g.
 * alpha = 0.999999 vs lambda = 1e-6).
 */
class ExponentialSchedule
{
 public:
  /*
   * Construct the ExponentialSchedule with the given parameter.
   *
   * @param lambda Cooling speed.
   */
  ExponentialSchedule(const double lambda = 0.001) : lambda(lambda) { }

  /**
   * Returns the next temperature given current status.  The current system's
   * energy is not used in this calculation.
   *
   * @param currentTemperature Current temperature of system.
   * @param currentEnergy Current energy of system (not used).
   */
  template<typename ElemType>
  double NextTemperature(
      const double currentTemperature,
      const ElemType /* currentEnergy */)
  {
    return (1 - lambda) * currentTemperature;
  }

  //! Get the cooling speed, lambda.
  double Lambda() const { return lambda; }
  //! Modify the cooling speed, lambda.
  double& Lambda() { return lambda; }

 private:
  //! The cooling speed.
  double lambda;
};

} // namespace ens

#endif
/**
 * @file sa.hpp
 * @author Zhihao Lou
 *
 * Simulated Annealing (SA).
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_SA_SA_HPP
#define ENSMALLEN_SA_SA_HPP

#include "exponential_schedule.hpp"

namespace ens {

/**
 * Simulated Annealing is an stochastic optimization algorithm which is able to
 * deliver near-optimal results quickly without knowing the gradient of the
 * function being optimized. It has unique hill climbing capability that makes
 * it less vulnerable to local minima.  This implementation uses exponential
 * cooling schedule and feedback move control by default, but the cooling
 * schedule can be changed via a template parameter.
 *
 * The algorithm keeps the temperature at initial temperature for initMove
 * steps to get rid of the dependency on the initial condition. After that, it
 * cools every step until the system is considered frozen or maxIterations is
 * reached.
 *
 * At each step, SA only perturbs one parameter at a time. When SA has perturbed
 * all parameters in a problem, a sweep has been completed. Every moveCtrlSweep
 * sweeps, the algorithm does feedback move control to change the average move
 * size depending on the responsiveness of each parameter. Parameter gain
 * controls the proportion of the feedback control.
 *
 * The system is considered "frozen" when its score fails to change more then
 * tolerance for maxToleranceSweep consecutive sweeps.
 *
 * SA can optimize arbitrary functions.  For more details, see the documentation
 * on function types included with this distribution or on the ensmallen
 * website.
 *
 * The CoolingScheduleType template parameter must implement the following
 * method:
 *
 *   double NextTemperature(const double currentTemperature,
 *                          const double currentValue);
 *
 * which returns the next temperature given current temperature and the value
 * of the function being optimized.
 *
 * @tparam CoolingScheduleType type for cooling schedule
 */
template<typename CoolingScheduleType = ExponentialSchedule>
class SA
{
 public:
  /**
   * Construct the SA optimizer with the given parameters.
   *
   * @param coolingSchedule Instantiated cooling schedule.
   * @param maxIterations Maximum number of iterations allowed
   *    (0 indicates no limit).
   * @param initT Initial temperature.
   * @param initMoves Number of initial iterations without changing temperature.
   * @param moveCtrlSweep Sweeps per feedback move control.
   * @param tolerance Tolerance to consider system frozen.
   * @param maxToleranceSweep Maximum sweeps below tolerance to consider system
   *    frozen.
   * @param maxMoveCoef Maximum move size.
   * @param initMoveCoef Initial move size.
   * @param gain Proportional control in feedback move control.
   */
  SA(const CoolingScheduleType& coolingSchedule = CoolingScheduleType(),
     const size_t maxIterations = 1000000,
     const double initT = 10000.,
     const size_t initMoves = 1000,
     const size_t moveCtrlSweep = 100,
     const double tolerance = 1e-5,
     const size_t maxToleranceSweep = 3,
     const double maxMoveCoef = 20,
     const double initMoveCoef = 0.3,
     const double gain = 0.3);

  /**
   * Optimize the given function using simulated annealing. The given starting
   * point will be modified to store the finishing point of the algorithm, and
   * the final objective value is returned.
   *
   * @tparam FunctionType Type of function to optimize.
   * @tparam MatType Type of objective matrix.
   * @tparam CallbackTypes Types of callback functions.
   * @param function Function to optimize.
   * @param iterate Starting point (will be modified).
   * @param callbacks Callback functions.
   * @return Objective value of the final point.
   */
  template<typename FunctionType, typename MatType, typename... CallbackTypes>
  typename MatType::elem_type Optimize(FunctionType& function,
                                       MatType& iterate,
                                       CallbackTypes&&... callbacks);

  //! Get the cooling schedule.
  CoolingScheduleType CoolingSchedule() const { return coolingSchedule; }
  //! Modify the cooling schedule.
  CoolingScheduleType& CoolingSchedule() { return coolingSchedule; }

  //! Get the temperature.
  double Temperature() const { return temperature; }
  //! Modify the temperature.
  double& Temperature() { return temperature; }

  //! Get the initial moves.
  size_t InitMoves() const { return initMoves; }
  //! Modify the initial moves.
  size_t& InitMoves() { return initMoves; }

  //! Get sweeps per move control.
  size_t MoveCtrlSweep() const { return moveCtrlSweep; }
  //! Modify sweeps per move control.
  size_t& MoveCtrlSweep() { return moveCtrlSweep; }

  //! Get the tolerance.
  double Tolerance() const { return tolerance; }
  //! Modify the tolerance.
  double& Tolerance() { return tolerance; }

  //! Get the maxToleranceSweep.
  size_t MaxToleranceSweep() const { return maxToleranceSweep; }
  //! Modify the maxToleranceSweep.
  size_t& MaxToleranceSweep() { return maxToleranceSweep; }

  //! Get the gain.
  double Gain() const { return gain; }
  //! Modify the gain.
  double& Gain() { return gain; }

  //! Get the maximum number of iterations.
  size_t MaxIterations() const { return maxIterations; }
  //! Modify the maximum number of iterations.
  size_t& MaxIterations() { return maxIterations; }

 private:
  //! The cooling schedule being used.
  CoolingScheduleType coolingSchedule;
  //! The maximum number of iterations.
  size_t maxIterations;
  //! The current temperature.
  double temperature;
  //! The number of initial moves before reducing the temperature.
  size_t initMoves;
  //! The number of sweeps before a MoveControl() call.
  size_t moveCtrlSweep;
  //! Tolerance for convergence.
  double tolerance;
  //! Number of sweeps in tolerance before system is considered frozen.
  size_t maxToleranceSweep;
  //! Maximum move.
  double maxMoveCoef;
  //! Initial move size.
  double initMoveCoef;
  //! Proportional control in feedback move control.
  double gain;

  /**
   * GenerateMove proposes a move on element iterate(idx), and determines if
   * that move is acceptable or not according to the Metropolis criterion.
   * After that it increments idx so the next call will make a move on next
   * parameters. When all elements of the state have been moved (a sweep), it
   * resets idx and increments sweepCounter. When sweepCounter reaches
   * moveCtrlSweep, it performs MoveControl() and resets sweepCounter.
   *
   * @param iterate Current optimization position.
   * @param accept Matrix representing which parameters have had accepted moves.
   * @param moveSize Strides for a move.
   * @param energy Current energy of the system.
   * @param idx Current parameter to modify.
   * @param sweepCounter Current counter representing how many sweeps have been
   *      completed.
   * @return Whether the optimization should be terminated.
   */
  template<typename FunctionType, typename MatType, typename... CallbackTypes>
  bool GenerateMove(FunctionType& function,
                    MatType& iterate,
                    MatType& accept,
                    MatType& moveSize,
                    typename MatType::elem_type& energy,
                    size_t& idx,
                    size_t& sweepCounter,
                    CallbackTypes&... callbacks);

  /**
   * MoveControl() uses a proportional feedback control to determine the size
   * parameter to pass to the move generation distribution. The target of such
   * move control is to make the acceptance ratio, accept/nMoves, be as close to
   * 0.44 as possible. Generally speaking, the larger the move size is, the
   * larger the function value change of the move will be, and less likely such
   * move will be accepted by the Metropolis criterion. Thus, the move size is
   * controlled by
   *
   * log(moveSize) = log(moveSize) + gain * (accept/nMoves - target)
   *
   * For more theory and the mysterious 0.44 value, see Jimmy K.-C. Lam and
   * Jean-Marc Delosme. `An efficient simulated annealing schedule: derivation'.
   * Technical Report 8816, Yale University, 1988.
   *
   * @param nMoves Number of moves since last call.
   * @param accept Matrix representing which parameters have had accepted moves.
   */
  template<typename MatType>
  void MoveControl(const size_t nMoves, MatType& accept, MatType& moveSize);
};

} // namespace ens

#include "sa_impl.hpp"

#endif
/**
 * @file sa_impl.hpp
 * @auther Zhihao Lou
 *
 * The implementation of the SA optimizer.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_SA_SA_IMPL_HPP
#define ENSMALLEN_SA_SA_IMPL_HPP

#include <ensmallen_bits/function.hpp>

namespace ens {

template<typename CoolingScheduleType>
SA<CoolingScheduleType>::SA(
    const CoolingScheduleType& coolingSchedule,
    const size_t maxIterations,
    const double initT,
    const size_t initMoves,
    const size_t moveCtrlSweep,
    const double tolerance,
    const size_t maxToleranceSweep,
    const double maxMoveCoef,
    const double initMoveCoef,
    const double gain) :
    coolingSchedule(coolingSchedule),
    maxIterations(maxIterations),
    temperature(initT),
    initMoves(initMoves),
    moveCtrlSweep(moveCtrlSweep),
    tolerance(tolerance),
    maxToleranceSweep(maxToleranceSweep),
    maxMoveCoef(maxMoveCoef),
    initMoveCoef(initMoveCoef),
    gain(gain)
{
  // Nothing to do.
}

//! Optimize the function (minimize).
template<typename CoolingScheduleType>
template<typename FunctionType, typename MatType, typename... CallbackTypes>
typename MatType::elem_type SA<CoolingScheduleType>::Optimize(
    FunctionType& function,
    MatType& iterateIn,
    CallbackTypes&&... callbacks)
{
  // Convenience typedefs.
  typedef typename MatType::elem_type ElemType;
  typedef typename MatTypeTraits<MatType>::BaseMatType BaseMatType;

  // Make sure we have the methods that we need.
  traits::CheckArbitraryFunctionTypeAPI<FunctionType, BaseMatType>();
  RequireFloatingPointType<BaseMatType>();

  BaseMatType& iterate = (BaseMatType&) iterateIn;

  const size_t rows = iterate.n_rows;
  const size_t cols = iterate.n_cols;

  // Controls early termination of the optimization process.
  bool terminate = false;

  size_t frozenCount = 0;
  ElemType energy = function.Evaluate(iterate);
  terminate |= Callback::Evaluate(*this, function, iterate, energy,
      callbacks...);

  ElemType oldEnergy;

  size_t idx = 0;
  size_t sweepCounter = 0;

  BaseMatType accept(rows, cols, arma::fill::zeros);
  BaseMatType moveSize(rows, cols, arma::fill::none);
  moveSize.fill(initMoveCoef);

  Callback::BeginOptimization(*this, function, iterate, callbacks...);

  // Initial moves to get rid of dependency of initial states.
  for (size_t i = 0; i < initMoves; ++i)
  {
    terminate |= GenerateMove(function, iterate, accept, moveSize, energy, idx,
        sweepCounter, callbacks...);
    if (terminate)
      break;
  }

  // Iterating and cooling.
  for (size_t i = 0; i != maxIterations && !terminate; ++i)
  {
    oldEnergy = energy;
    terminate |= GenerateMove(function, iterate, accept, moveSize, energy, idx,
        sweepCounter, callbacks...);
    if (terminate)
      break;
    terminate |= Callback::StepTaken(*this, function, iterate, callbacks...);
    temperature = coolingSchedule.NextTemperature(temperature, energy);

    // Determine if the optimization has entered (or continues to be in) a
    // frozen state.
    if (std::abs(energy - oldEnergy) < tolerance)
      ++frozenCount;
    else
      frozenCount = 0;

    // Terminate, if possible.
    if (frozenCount >= maxToleranceSweep * moveCtrlSweep * iterate.n_elem)
    {
      Info << "SA: minimized within tolerance " << tolerance << " for "
          << maxToleranceSweep << " sweeps after " << i << " iterations; "
          << "terminating optimization." << std::endl;

      Callback::EndOptimization(*this, function, iterate, callbacks...);
      return energy;
    }
  }

  Warn << "SA: maximum iterations (" << maxIterations << ") reached; "
      << "terminating optimization." << std::endl;

  Callback::EndOptimization(*this, function, iterate, callbacks...);
  return energy;
}

/**
 * GenerateMove proposes a move on element iterate(idx), and determines
 * it that move is acceptable or not according to the Metropolis criterion.
 * After that it increments idx so next call will make a move on next
 * parameters. When all elements of the state have been moved (a sweep), it
 * resets idx and increments sweepCounter. When sweepCounter reaches
 * moveCtrlSweep, it performs moveControl and resets sweepCounter.
 */
template<typename CoolingScheduleType>
template<typename FunctionType, typename MatType, typename... CallbackTypes>
bool SA<CoolingScheduleType>::GenerateMove(
    FunctionType& function,
    MatType& iterate,
    MatType& accept,
    MatType& moveSize,
    typename MatType::elem_type& energy,
    size_t& idx,
    size_t& sweepCounter,
    CallbackTypes&... callbacks)
{
  typedef typename MatType::elem_type ElemType;

  const ElemType prevEnergy = energy;
  const ElemType prevValue = iterate(idx);

  // It is possible to use a non-Laplace distribution here, but it is difficult
  // because the acceptance ratio should be as close to 0.44 as possible, and
  // MoveControl() is derived for the Laplace distribution.

  // Sample from a Laplace distribution with scale parameter moveSize(idx).
  const double unif = 2.0 * arma::randu() - 1.0;
  const ElemType move = (unif < 0) ? (moveSize(idx) * std::log(1 + unif)) :
      (-moveSize(idx) * std::log(1 - unif));

  iterate(idx) += move;
  energy = function.Evaluate(iterate);

  const bool terminate = Callback::Evaluate(*this, function, iterate, energy,
      callbacks...);

  // According to the Metropolis criterion, accept the move with probability
  // min{1, exp(-(E_new - E_old) / T)}.
  const double xi = arma::randu();
  const double delta = energy - prevEnergy;
  const double criterion = std::exp(-delta / temperature);
  if (delta <= 0. || criterion > xi)
  {
    accept(idx) += ElemType(1.);
  }
  else // Reject the move; restore previous state.
  {
    iterate(idx) = prevValue;
    energy = prevEnergy;
  }

  ++idx;
  if (idx == iterate.n_elem) // Finished with a sweep.
  {
    idx = 0;
    ++sweepCounter;
  }

  if (sweepCounter == moveCtrlSweep) // Do MoveControl().
  {
    MoveControl(moveCtrlSweep, accept, moveSize);
    sweepCounter = 0;
  }

  return terminate;
}

/**
 * MoveControl() uses a proportional feedback control to determine the size
 * parameter to pass to the move generation distribution. The target of such
 * move control is to make the acceptance ratio, accept/nMoves, be as close to
 * 0.44 as possible. Generally speaking, the larger the move size is, the larger
 * the function value change of the move will be, and less likely such move will
 * be accepted by the Metropolis criterion. Thus, the move size is controlled by
 *
 * log(moveSize) = log(moveSize) + gain * (accept/nMoves - target)
 *
 * For more theory and the mysterious 0.44 value, see Jimmy K.-C. Lam and
 * Jean-Marc Delosme. `An efficient simulated annealing schedule: derivation'.
 * Technical Report 8816, Yale University, 1988.
 */
template<typename CoolingScheduleType>
template<typename MatType>
inline void SA<CoolingScheduleType>::MoveControl(const size_t nMoves,
                                                 MatType& accept,
                                                 MatType& moveSize)
{
  MatType target;
  target.copy_size(accept);
  target.fill(0.44);
  moveSize = arma::log(moveSize);
  moveSize += gain * (accept / (double) nMoves - target);
  moveSize = arma::exp(moveSize);

  // To avoid the use of element-wise arma::min(), which is only available in
  // Armadillo after v3.930, we use a for loop here instead.
  for (size_t i = 0; i < accept.n_elem; ++i)
    moveSize(i) = (moveSize(i) > maxMoveCoef) ? maxMoveCoef : moveSize(i);

  accept.zeros();
}

} // namespace ens

#endif
/**
 * @file sarah.hpp
 * @author Marcus Edel
 *
 * StochAstic Recusive gRadient algoritHm (SARAH).
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_SARAH_SARAH_HPP
#define ENSMALLEN_SARAH_SARAH_HPP

#include "sarah_update.hpp"
#include "sarah_plus_update.hpp"

namespace ens {

/**
 * StochAstic Recusive gRadient algoritHm (SARAH). is a variance reducing
 * stochastic recursive gradient algorithm for minimizing a function
 * which can be expressed as a sum of other functions.
 *
 * For more information, see the following.
 *
 * @code
 * @article{Nguyen2017,
 *   author  = {{Nguyen}, L.~M. and {Liu}, J. and {Scheinberg},
 *              K. and {Tak{\'a}{\v c}}, M.},
 *   title   = {SARAH: A Novel Method for Machine Learning Problems Using
 *              Stochastic Recursive Gradient},
 *   journal = {ArXiv e-prints},
 *   url     = {https://arxiv.org/abs/1703.00102}
 *   year    = 2017,
 * }
 * @endcode
 *
 * SARAH can optimize differentiable separable functions.  For more details, see
 * the documentation on function types included with this distribution or on the
 * ensmallen website.
 *
 * @tparam UpdatePolicyType update policy used by SARAHType during the iterative
 *    update process.
 */
template<typename UpdatePolicyType = SARAHUpdate>
class SARAHType
{
 public:
  /**
   * Construct the SARAH optimizer with the given function and parameters. The
   * defaults here are not necessarily good for the given problem, so it is
   * suggested that the values used be tailored to the task at hand.  The
   * maximum number of iterations refers to the maximum number of points that
   * are processed (i.e., one iteration equals one point; one iteration does not
   * equal one pass over the dataset).
   *
   * @param stepSize Step size for each iteration.
   * @param batchSize Batch size to use for each step.
   * @param maxIterations Maximum number of iterations allowed (0 means no
   *     limit).
   * @param innerIterations The number of inner iterations allowed (0 means
   *    n / batchSize). Note that the full gradient is only calculated in
   *    the outer iteration.
   * @param tolerance Maximum absolute tolerance to terminate algorithm.
   * @param shuffle If true, the function order is shuffled; otherwise, each
   *     function is visited in linear order.
   * @param updatePolicy Instantiated update policy used to adjust the given
   *     parameters.
   * @param exactObjective Calculate the exact objective (Default: estimate the
   *        final objective obtained on the last pass over the data).
   */
  SARAHType(const double stepSize = 0.01,
            const size_t batchSize = 32,
            const size_t maxIterations = 1000,
            const size_t innerIterations = 0,
            const double tolerance = 1e-5,
            const bool shuffle = true,
            const UpdatePolicyType& updatePolicy = UpdatePolicyType(),
            const bool exactObjective = false);

  /**
   * Optimize the given function using SARAH. The given starting point will be
   * modified to store the finishing point of the algorithm, and the final
   * objective value is returned.
   *
   * @tparam SeparableFunctionType Type of the function to be optimized.
   * @tparam MatType Type of matrix to optimize with.
   * @tparam GradType Type of matrix to use to represent function gradients.
   * @tparam CallbackTypes Types of callback functions.
   * @param function Function to optimize.
   * @param iterate Starting point (will be modified).
   * @param callbacks Callback functions.
   * @return Objective value of the final point.
   */
  template<typename SeparableFunctionType,
           typename MatType,
           typename GradType,
           typename... CallbackTypes>
  typename std::enable_if<IsArmaType<GradType>::value,
      typename MatType::elem_type>::type
  Optimize(SeparableFunctionType& function,
           MatType& iterate,
           CallbackTypes&&... callbacks);

  //! Forward the MatType as GradType.
  template<typename SeparableFunctionType,
           typename MatType,
           typename... CallbackTypes>
  typename MatType::elem_type Optimize(SeparableFunctionType& function,
                                       MatType& iterate,
                                       CallbackTypes&&... callbacks)
  {
    return Optimize<SeparableFunctionType, MatType, MatType,
        CallbackTypes...>(function, iterate,
        std::forward<CallbackTypes>(callbacks)...);
  }

  //! Get the step size.
  double StepSize() const { return stepSize; }
  //! Modify the step size.
  double& StepSize() { return stepSize; }

  //! Get the batch size.
  size_t BatchSize() const { return batchSize; }
  //! Modify the batch size.
  size_t& BatchSize() { return batchSize; }

  //! Get the maximum number of iterations (0 indicates no limit).
  size_t MaxIterations() const { return maxIterations; }
  //! Modify the maximum number of iterations (0 indicates no limit).
  size_t& MaxIterations() { return maxIterations; }

  //! Get the maximum number of iterations (0 indicates default n / b).
  size_t InnerIterations() const { return innerIterations; }
  //! Modify the maximum number of iterations (0 indicates default n / b).
  size_t& InnerIterations() { return innerIterations; }

  //! Get the tolerance for termination.
  double Tolerance() const { return tolerance; }
  //! Modify the tolerance for termination.
  double& Tolerance() { return tolerance; }

  //! Get whether or not the individual functions are shuffled.
  bool Shuffle() const { return shuffle; }
  //! Modify whether or not the individual functions are shuffled.
  bool& Shuffle() { return shuffle; }

  //! Get whether or not the actual objective is calculated.
  bool ExactObjective() const { return exactObjective; }
  //! Modify whether or not the actual objective is calculated.
  bool& ExactObjective() { return exactObjective; }

  //! Get the update policy.
  const UpdatePolicyType& UpdatePolicy() const { return updatePolicy; }
  //! Modify the update policy.
  UpdatePolicyType& UpdatePolicy() { return updatePolicy; }

 private:
  //! The step size for each example.
  double stepSize;

  //! The batch size for processing.
  size_t batchSize;

  //! The maximum number of allowed iterations.
  size_t maxIterations;

  //! The maximum number of allowed inner iterations per epoch.
  size_t innerIterations;

  //! The tolerance for termination.
  double tolerance;

  //! Controls whether or not the individual functions are shuffled when
  //! iterating.
  bool shuffle;

  //! Controls whether or not the actual Objective value is calculated.
  bool exactObjective;

  //! The update policy used to update the parameters in each iteration.
  UpdatePolicyType updatePolicy;
};

// Convenience typedefs.

/**
 * Standard stochastic variance reduced gradient.
 */
using SARAH = SARAHType<SARAHUpdate>;

/**
 * Stochastic variance reduced gradient with Barzilai-Borwein.
 */
using SARAH_Plus = SARAHType<SARAHPlusUpdate>;

} // namespace ens

// Include implementation.
#include "sarah_impl.hpp"

#endif
/**
 * @file sarah_impl.hpp
 * @author Marcus Edel
 *
 * Implementation of StochAstic Recusive gRadient algoritHm (SARAH).
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_SARAH_SARAH_IMPL_HPP
#define ENSMALLEN_SARAH_SARAH_IMPL_HPP

// In case it hasn't been included yet.
#include "sarah.hpp"

#include <ensmallen_bits/function.hpp>

namespace ens {

template<typename UpdatePolicyType>
SARAHType<UpdatePolicyType>::SARAHType(
    const double stepSize,
    const size_t batchSize,
    const size_t maxIterations,
    const size_t innerIterations,
    const double tolerance,
    const bool shuffle,
    const UpdatePolicyType& updatePolicy,
    const bool exactObjective) :
    stepSize(stepSize),
    batchSize(batchSize),
    maxIterations(maxIterations),
    innerIterations(innerIterations),
    tolerance(tolerance),
    shuffle(shuffle),
    exactObjective(exactObjective),
    updatePolicy(updatePolicy)
{ /* Nothing to do. */ }

//! Optimize the function (minimize).
template<typename UpdatePolicyType>
template<typename SeparableFunctionType,
         typename MatType,
         typename GradType,
         typename... CallbackTypes>
typename std::enable_if<IsArmaType<GradType>::value,
typename MatType::elem_type>::type
SARAHType<UpdatePolicyType>::Optimize(
    SeparableFunctionType& functionIn,
    MatType& iterateIn,
    CallbackTypes&&... callbacks)
{
  // Convenience typedefs.
  typedef typename MatType::elem_type ElemType;
  typedef typename MatTypeTraits<MatType>::BaseMatType BaseMatType;
  typedef typename MatTypeTraits<GradType>::BaseMatType BaseGradType;

  typedef Function<SeparableFunctionType, BaseMatType, BaseGradType>
      FullFunctionType;
  FullFunctionType& function(static_cast<FullFunctionType&>(functionIn));

  traits::CheckSeparableFunctionTypeAPI<SeparableFunctionType,
      BaseMatType, BaseGradType>();
  RequireFloatingPointType<BaseMatType>();
  RequireFloatingPointType<BaseGradType>();
  RequireSameInternalTypes<BaseMatType, BaseGradType>();

  BaseMatType& iterate = (BaseMatType&) iterateIn;

  // Find the number of functions to use.
  const size_t numFunctions = function.NumFunctions();

  // To keep track of where we are and how things are going.
  ElemType overallObjective = 0;
  ElemType lastObjective = DBL_MAX;

  // Controls early termination of the optimization process.
  bool terminate = false;

  // Set epoch length to n / b if the user asked for.
  if (innerIterations == 0)
    innerIterations = numFunctions;

  // Now iterate!
  BaseGradType gradient(iterate.n_rows, iterate.n_cols);
  BaseGradType v(iterate.n_rows, iterate.n_cols);
  BaseGradType gradient0(iterate.n_rows, iterate.n_cols);
  BaseMatType iterate0;

  const size_t actualMaxIterations = (maxIterations == 0) ?
      std::numeric_limits<size_t>::max() : maxIterations;
  Callback::BeginOptimization(*this, function, iterate, callbacks...);
  for (size_t i = 0; i < actualMaxIterations && !terminate; ++i)
  {
    // Calculate the objective function.
    overallObjective = 0;
    for (size_t f = 0; f < numFunctions; f += batchSize)
    {
      const size_t effectiveBatchSize = std::min(batchSize, numFunctions - f);
      const ElemType objective = function.Evaluate(iterate, f,
          effectiveBatchSize);
      overallObjective += objective;

      terminate |= Callback::Evaluate(*this, function, iterate, objective,
          callbacks...);
    }

    if (std::isnan(overallObjective) || std::isinf(overallObjective))
    {
      Warn << "SARAH: converged to " << overallObjective
          << "; terminating  with failure.  Try a smaller step size?"
          << std::endl;

      Callback::EndOptimization(*this, function, iterate, callbacks...);
      return overallObjective;
    }

    if (std::abs(lastObjective - overallObjective) < tolerance)
    {
      Info << "SARAH: minimized within tolerance " << tolerance
          << "; terminating optimization." << std::endl;

      Callback::EndOptimization(*this, function, iterate, callbacks...);
      return overallObjective;
    }

    lastObjective = overallObjective;

    // Compute the full gradient.
    size_t effectiveBatchSize = std::min(batchSize, numFunctions);
    function.Gradient(iterate, 0, v, effectiveBatchSize);

    terminate |= Callback::Gradient(*this, function, iterate, v, callbacks...);

    for (size_t f = effectiveBatchSize; f < numFunctions;
        /* incrementing done manually */)
    {
      // Find the effective batch size (the last batch may be smaller).
      effectiveBatchSize = std::min(batchSize, numFunctions - f);

      function.Gradient(iterate, f, gradient, effectiveBatchSize);
      v += gradient;

      f += effectiveBatchSize;
    }
    v /= (double) numFunctions;

    if (terminate)
      break;

    // Update iterate with full gradient (v).
    iterate -= stepSize * v;

    const ElemType vNorm = arma::norm(v);

    for (size_t f = 0, currentFunction = 0; f < innerIterations;
        /* incrementing done manually */)
    {
      // Is this iteration the start of a sequence?
      if ((currentFunction % numFunctions) == 0)
      {
        currentFunction = 0;

        // Determine order of visitation.
        if (shuffle)
          function.Shuffle();
      }

      // Find the effective batch size (the last batch may be smaller).
      effectiveBatchSize = std::min(batchSize, numFunctions - currentFunction);

      // Calculate variance reduced gradient.
      function.Gradient(iterate, currentFunction, gradient,
          effectiveBatchSize);

      terminate |= Callback::Gradient(*this, function, iterate, gradient,
          callbacks...);

      // Avoid an unnecessary copy on the first iteration.
      if (f > 0)
      {
        function.Gradient(iterate0, currentFunction, gradient0,
            effectiveBatchSize);

        terminate |= Callback::Gradient(*this, function, iterate0, gradient0,
            callbacks...);

        // Store current parameter for the calculation of the variance reduced
        // gradient.
        iterate0 = iterate;

        // Use the update policy to take a step.
        if (terminate || updatePolicy.Update(iterate, v, gradient, gradient0,
            effectiveBatchSize, stepSize, vNorm))
        {
          break;
        }
      }
      else
      {
        // Store current parameter for the calculation of the variance reduced
        // gradient.
        iterate0 = iterate;

        // Use the update policy to take a step.
        if (terminate || updatePolicy.Update(iterate, v, gradient, gradient,
            effectiveBatchSize, stepSize, vNorm))
        {
          break;
        }
      }

      terminate |= Callback::StepTaken(*this, function, iterate, callbacks...);
      currentFunction += effectiveBatchSize;
      f += effectiveBatchSize;
    }
  }

  Info << "SARAH: maximum iterations (" << maxIterations << ") reached; "
      << "terminating optimization." << std::endl;

  // Calculate final objective.
  if (exactObjective)
  {
    overallObjective = 0;
    for (size_t i = 0; i < numFunctions; i += batchSize)
    {
      const size_t effectiveBatchSize = std::min(batchSize, numFunctions - i);
      const ElemType objective = function.Evaluate(iterate, i, effectiveBatchSize);
      overallObjective += objective;

      // The optimization is finished, so we don't need to care about the result
      // of the callback.
      (void) Callback::Evaluate(*this, function, iterate, objective,
          callbacks...);
    }
  }

  Callback::EndOptimization(*this, function, iterate, callbacks...);
  return overallObjective;
}

} // namespace ens

#endif
/**
 * @file sarah_plus_update.hpp
 * @author Marcus Edel
 *
 * Implementation of the SARAH+ update rule which provides an automatic and
 * adaptive choice of the inner loop size.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_SARAH_SARAH_PLUS_UPDATE_HPP
#define ENSMALLEN_SARAH_SARAH_PLUS_UPDATE_HPP

namespace ens {

/**
 * SARAH+ provides an automatic and adaptive choice of the inner loop size.
 */
class SARAHPlusUpdate
{
 public:
  /*
   * Construct the SARAH+ update policy.
   *
   * @param gamma Adaptive parameter for the inner loop.
   */
  SARAHPlusUpdate(const double gamma = 0.125) : gamma(gamma)
  {
    /* Nothing to do here. */
  }

  /**
   * Update step for SARAH+. The function parameters are updated in the negative
   * direction of the gradient.
   *
   * @param iterate Parameters that minimize the function.
   * @param v Unbiased estimator of the gradient.
   * @param gradient The current gradient matrix at time t.
   * @param gradient0 The old gradient matrix at time t - 1.
   * @param batchSize Batch size to be used for the given iteration.
   * @param stepSize Step size to be used for the given iteration.
   * @param vNorm The norm of the full gradient.
   */
  template<typename MatType, typename GradType>
  bool Update(MatType& iterate,
              GradType& v,
              const GradType& gradient,
              const GradType& gradient0,
              const size_t batchSize,
              const double stepSize,
              const double vNorm)
  {
    v += (gradient - gradient0) / (double) batchSize;
    iterate -= stepSize * v;

    if (arma::norm(v) <= gamma * vNorm)
      return true;

    return false;
  }

 private:
  //! Adaptive parameter for the inner loop.
  double gamma;
};

} // namespace ens

#endif
/**
 * @file svrg_update.hpp
 * @author Marcus Edel
 *
 * Vanilla update for SARAH.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_SARAH_SARAH_UPDATE_HPP
#define ENSMALLEN_SARAH_SARAH_UPDATE_HPP

namespace ens {

/**
 * Vanilla update policy for SARAH.
 */
class SARAHUpdate
{
 public:
  /**
   * Update step for SARAH. The function parameters are updated in the negative
   * direction of the gradient.
   *
   * @param iterate Parameters that minimize the function.
   * @param v Unbiased estimator of the gradient.
   * @param gradient The current gradient matrix at time t.
   * @param gradient0 The old gradient matrix at time t - 1.
   * @param batchSize Batch size to be used for the given iteration.
   * @param stepSize Step size to be used for the given iteration.
   * @param vNorm The norm of the full gradient.
   */
  template<typename MatType, typename GradType>
  bool Update(MatType& iterate,
              GradType& v,
              const GradType& gradient,
              const GradType& gradient0,
              const size_t batchSize,
              const double stepSize,
              const double /* vNorm */)
  {
    v += (gradient - gradient0) / (double) batchSize;
    iterate -= stepSize * v;
    return false;
  }
};

} // namespace ens

#endif
/**
 * @file lin_alg.hpp
 * @author Nishant Mehta
 *
 * Linear algebra utilities.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_SDP_LIN_ALG_HPP
#define ENSMALLEN_SDP_LIN_ALG_HPP

namespace ens {
namespace math {

inline size_t SvecIndex(size_t i, size_t j, size_t n)
{
  if (i > j)
    std::swap(i, j);

  return (j - i) + (n * (n + 1) - (n - i) * (n - i + 1)) / 2;
}

/**
 * Upper triangular representation of a symmetric matrix, scaled such that,
 * dot(Svec(A), Svec(B)) == dot(A, B) for symmetric A, B. Specifically,
 *
 * Svec(K) = [ K_11, sqrt(2) K_12, ..., sqrt(2) K_1n, K_22, ..., sqrt(2)
 * K_2n, ..., K_nn ]^T
 *
 * @param input A symmetric matrix.
 * @param output Upper triangular representation.
 */
template<typename MatAType, typename MatBType>
inline void Svec(const MatAType& input, MatBType& output)
{
  MatBType iMat(input);
  const size_t n = iMat.n_rows;
  const size_t n2bar = n * (n + 1) / 2;

  output.zeros(n2bar, 1);

  size_t idx = 0;
  for (size_t i = 0; i < n; i++)
  {
    for (size_t j = i; j < n; j++)
    {
      if (i == j)
        output(idx++, 0) = iMat(i, j);
      else
        output(idx++, 0) = arma::datum::sqrt2 * iMat(i, j);
    }
  }
}

template<typename MatAType, typename ElemType>
inline void Svec(const MatAType& input,
                 arma::SpMat<ElemType>& output)
{
  arma::SpMat<ElemType> iMat(input);

  const size_t n = iMat.n_rows;
  const size_t n2bar = n * (n + 1) / 2;

  output.zeros(n2bar, 1);

  const auto itEnd = iMat.end();
  for (auto it = iMat.begin(); it != itEnd; ++it)
  {
    const size_t i = it.row();
    const size_t j = it.col();
    if (i > j)
      continue;
    if (i == j)
      output(SvecIndex(i, j, n), 0) = *it;
    else
      output(SvecIndex(i, j, n), 0) = arma::datum::sqrt2 * (*it);
  }
}

/**
 * The inverse of Svec. That is, Smat(Svec(A)) == A.
 *
 * @param input Input matrix.
 * @param output The inverse of the input matrix.
 */
template<typename MatAType, typename MatBType>
inline void Smat(const MatAType& input, MatBType& output)
{
  MatBType iMat(input);

  const size_t n = static_cast<size_t>
      (ceil((-1. + sqrt(1. + 8. * iMat.n_elem))/2.));

  output.zeros(n, n);

  size_t idx = 0;
  for (size_t i = 0; i < n; i++)
  {
    for (size_t j = i; j < n; j++)
    {
      if (i == j)
        output(i, j) = iMat(idx++);
      else
        output(i, j) = output(j, i) = 0.5 * arma::datum::sqrt2 * iMat(idx++);
    }
  }
}

/**
 * If A is a symmetric matrix, then SymKronId returns an operator Op such that
 *
 *    Op * svec(X) == svec(0.5 * (AX + XA))
 *
 * for every symmetric matrix X
 *
 * @param A A symmetric matrix.
 * @param  The calculated operator.
 */
template<typename MatAType, typename MatBType>
inline void SymKronId(const MatAType& A, MatBType& op)
{
  MatBType iMat(A);

  // TODO(stephentu): there's probably an easier way to build this operator

  const size_t n = iMat.n_rows;
  const size_t n2bar = n * (n + 1) / 2;
  op.zeros(n2bar, n2bar);

  size_t idx = 0;
  for (size_t i = 0; i < n; i++)
  {
    for (size_t j = i; j < n; j++)
    {
      for (size_t k = 0; k < n; k++)
      {
        op(idx, SvecIndex(k, j, n)) +=
          ((k == j) ? 1. : 0.5 * arma::datum::sqrt2) * iMat(i, k);
        op(idx, SvecIndex(i, k, n)) +=
          ((k == i) ? 1. : 0.5 * arma::datum::sqrt2) * iMat(k, j);
      }
      op.row(idx) *= 0.5;
      if (i != j)
        op.row(idx) *= arma::datum::sqrt2;
      idx++;
    }
  }
}

} // namespace math
} // namespace ens

#endif
/**
 * @file lrsdp.hpp
 * @author Ryan Curtin
 *
 * An implementation of Monteiro and Burer's formulation of low-rank
 * semidefinite programs (LR-SDP).
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_SDP_LRSDP_HPP
#define ENSMALLEN_SDP_LRSDP_HPP

#include <ensmallen_bits/aug_lagrangian/aug_lagrangian.hpp>

#include "lrsdp_function.hpp"

namespace ens {

/**
 * LRSDP is the implementation of Monteiro and Burer's formulation of low-rank
 * semidefinite programs (LR-SDP).  This solver uses the augmented Lagrangian
 * optimizer to solve low-rank semidefinite programs.
 *
 * LRSDP can optimize semidefinite programs.  For more details, see the
 * documentation on function types included with this distribution or on the
 * ensmallen website.
 */
template <typename SDPType>
class LRSDP
{
 public:
  /**
   * Create an LRSDP to be optimized.  The solution will end up being a matrix
   * of size (rows) x (rank).  To construct each constraint and the objective
   * function, use the function SDP() in order to access the SDPType object
   * associated with this optimizer.
   *
   * @param numSparseConstraints Number of sparse constraints in the problem.
   * @param numDenseConstraints Number of dense constraints in the problem.
   * @param initialPoint Initial point of the optimization.
   * @param maxIterations Maximum number of iterations.
   */
  LRSDP(const size_t numSparseConstraints,
        const size_t numDenseConstraints,
        const arma::Mat<typename SDPType::ElemType>& initialPoint,
        const size_t maxIterations = 1000);

  /**
   * Create an LRSDP object with the given SDP problem to be solved, and the
   * given initial point.  Note that the SDP may be modified later by calling
   * SDP() to access the object.
   *
   * TODO: this is currently not implemented.
   *
   * @param sdp SDP to be solved.
   * @param initialPoint Initial point of the optimization.
   * @param maxIterations Maximum number of iterations.
   *
  LRSDP(const SDPType& sdp,
        const arma::mat& initialPoint,
        const size_t maxIterations = 1000);
   */

  /**
   * Optimize the LRSDP and return the final objective value.  The given
   * coordinates will be modified to contain the final solution.
   *
   * @param coordinates Starting coordinates for the optimization.
   * @param callbacks Callback functions.
   */
  template<typename MatType, typename... CallbackTypes>
  typename MatType::elem_type Optimize(MatType& coordinates,
                                       CallbackTypes&&... callbacks);

  //! Return the SDP that will be solved.
  const SDPType& SDP() const { return function.SDP(); }
  //! Modify the SDP that will be solved.
  SDPType& SDP() { return function.SDP(); }

  //! Return the function to be optimized.
  const LRSDPFunction<SDPType>& Function() const { return function; }
  //! Modify the function to be optimized.
  LRSDPFunction<SDPType>& Function() { return function; }

  //! Return the augmented Lagrangian object.
  const AugLagrangian& AugLag() const { return augLag; }
  //! Modify the augmented Lagrangian object.
  AugLagrangian& AugLag() { return augLag; }

  //! Get the maximum number of iterations.
  size_t MaxIterations() const { return maxIterations; }
  //! Modify the maximum number of iterations.
  size_t& MaxIterations() { return maxIterations; }

 private:
  //! Augmented lagrangian optimizer.
  AugLagrangian augLag;
  //! Function to optimize, which the AugLagrangian object holds.
  LRSDPFunction<SDPType> function;
  //! The maximum number of iterations for optimization.
  size_t maxIterations;
};

} // namespace ens

// Include implementation
#include "lrsdp_impl.hpp"

#endif
/**
 * @file lrsdp_function.hpp
 * @author Ryan Curtin
 * @author Abhishek Laddha
 *
 * A class that represents the objective function which LRSDP optimizes.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_SDP_LRSDP_FUNCTION_HPP
#define ENSMALLEN_SDP_LRSDP_FUNCTION_HPP

#include <ensmallen_bits/aug_lagrangian/aug_lagrangian.hpp>
#include "sdp.hpp"

namespace ens {

/**
 * The objective function that LRSDP is trying to optimize.
 *
 * Note: LRSDPfunction is designed and implemented to specifically work
 * with a combination of AugLagrangian and L-BFGS optimizer. Implemenation
 * of LRSDPFunction includes caching R * R^T matrix in order to avoid redundant
 * computations(Specifically with above two optimizers) of R * R^T matrix
 * through AugLagrangian optimizer call, as only L-BFGS takes part in updating
 * R(coordinates) matrix. So, be careful while using LRSDP with some other
 * optimizer. You may need to modify caching process of R * R^T matrix.
 * See EvaluateImpl() in lrsdp_function_impl.hpp for more details.
 */
template<typename SDPType>
class LRSDPFunction
{
 public:
  /**
   * Construct the LRSDPFunction from the given SDP.
   *
   * @param sdp
   * @param initialPoint
   */
  LRSDPFunction(const SDPType& sdp,
                const arma::Mat<typename SDPType::ElemType>& initialPoint);

  /**
   * Construct the LRSDPFunction with the given initial point and number of
   * constraints. Note n_cols of the initialPoint specifies the rank.
   *
   * Set the A_x, B_x, and C_x  matrices for each constraint using the A_x(),
   * B_x(), and C_x() functions, for x in {sparse, dense}.
   *
   * @param numSparseConstraints
   * @param numDenseConstraints
   * @param initialPoint
   */
  LRSDPFunction(const size_t numSparseConstraints,
                const size_t numDenseConstraints,
                const arma::Mat<typename SDPType::ElemType>& initialPoint);

  /**
   * Clean any memory associated with the LRSDPFunction.
   */
  ~LRSDPFunction();

  /**
   * Evaluate the objective function of the LRSDP (no constraints) at the given
   * coordinates.
   */
  template<typename MatType>
  typename MatType::elem_type Evaluate(const MatType& coordinates) const;

  /**
   * Evaluate the gradient of the LRSDP (no constraints) at the given
   * coordinates.
   */
  template<typename MatType, typename GradType>
  void Gradient(const MatType& coordinates, GradType& gradient) const;

  /**
   * Evaluate a particular constraint of the LRSDP at the given coordinates.
   */
  template<typename MatType>
  typename MatType::elem_type EvaluateConstraint(
      const size_t index,
      const MatType& coordinates) const;

  /**
   * Evaluate the gradient of a particular constraint of the LRSDP at the given
   * coordinates.
   */
  template<typename MatType, typename GradType>
  void GradientConstraint(const size_t index,
                          const MatType& coordinates,
                          GradType& gradient) const;

  //! Get the total number of constraints in the LRSDP.
  size_t NumConstraints() const { return sdp.NumConstraints(); }

  //! Get the initial point of the LRSDP.
  template<typename MatType = arma::mat>
  MatType GetInitialPoint() const
  {
    MatType result = arma::conv_to<MatType>::from(initialPoint);
    return result;
  }

  //! Return the SDP object representing the problem.
  const SDPType& SDP() const { return sdp; }

  //! Modify the SDP object representing the problem.
  SDPType& SDP() { return sdp; }

  //! Get R*R^T matrix.
  template<typename MatType>
  const MatType& RRT() const
  {
    return rrt.As<typename std::remove_reference<MatType>::type>();
  }

  //! Modify R*R^T matrix.
  template<typename MatType>
  MatType& RRT()
  {
    return rrt.As<typename std::remove_reference<MatType>::type>();
  }

  //! Get the Any object for rrt.
  Any& RRTAny() { return rrt; }

 private:
  //! SDP object representing the problem
  SDPType sdp;

  //! Initial point.
  arma::Mat<typename SDPType::ElemType> initialPoint;

  //! Cache R*R^T matrix.
  Any rrt;
};

// Declare specializations in lrsdp_function.cpp.
template<>
template<typename MatType>
inline typename MatType::elem_type
AugLagrangianFunction<LRSDPFunction<SDP<arma::sp_mat>>>::Evaluate(
    const MatType& coordinates) const;

template<>
template<typename MatType>
inline typename MatType::elem_type
AugLagrangianFunction<LRSDPFunction<SDP<arma::mat>>>::Evaluate(
    const MatType& coordinates) const;

template<>
template<typename MatType, typename GradType>
inline void AugLagrangianFunction<LRSDPFunction<SDP<arma::sp_mat>>>::Gradient(
    const MatType& coordinates,
    GradType& gradient) const;

template<>
template<typename MatType, typename GradType>
inline void AugLagrangianFunction<LRSDPFunction<SDP<arma::mat>>>::Gradient(
    const MatType& coordinates,
    GradType& gradient) const;

template<>
template<typename MatType>
inline typename MatType::elem_type
AugLagrangianFunction<LRSDPFunction<SDP<arma::sp_fmat>>>::Evaluate(
    const MatType& coordinates) const;

template<>
template<typename MatType>
inline typename MatType::elem_type
AugLagrangianFunction<LRSDPFunction<SDP<arma::fmat>>>::Evaluate(
    const MatType& coordinates) const;

template<>
template<typename MatType, typename GradType>
inline void AugLagrangianFunction<LRSDPFunction<SDP<arma::sp_fmat>>>::Gradient(
    const MatType& coordinates,
    GradType& gradient) const;

template<>
template<typename MatType, typename GradType>
inline void AugLagrangianFunction<LRSDPFunction<SDP<arma::fmat>>>::Gradient(
    const MatType& coordinates,
    GradType& gradient) const;

} // namespace ens

// Include implementation
#include "lrsdp_function_impl.hpp"

#endif // ENSMALLEN_SDP_LRSDP_FUNCTION_HPP
/**
 * @file lrsdp_function.cpp
 * @author Ryan Curtin
 * @author Abhishek Laddha
 *
 * Implementation of the LRSDPFunction class, and also template specializations
 * for faster execution with the AugLagrangian optimizer.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_SDP_LRSDP_FUNCTION_IMPL_HPP
#define ENSMALLEN_SDP_LRSDP_FUNCTION_IMPL_HPP

#include "lrsdp_function.hpp"

namespace ens {

template <typename SDPType>
LRSDPFunction<SDPType>::LRSDPFunction(
    const SDPType& sdp,
    const arma::Mat<typename SDPType::ElemType>& initialPoint):
    sdp(sdp),
    initialPoint(initialPoint)
{
  if (initialPoint.n_rows < initialPoint.n_cols)
  {
    Warn << "LRSDPFunction::LRSDPFunction(): solution matrix will have "
        << "more columns than rows.  It may be more efficient to find the "
        << "transposed solution." << std::endl;
  }
}

template<typename SDPType>
LRSDPFunction<SDPType>::LRSDPFunction(
    const size_t numSparseConstraints,
    const size_t numDenseConstraints,
    const arma::Mat<typename SDPType::ElemType>& initialPoint):
    sdp(initialPoint.n_rows, numSparseConstraints, numDenseConstraints),
    initialPoint(initialPoint)
{
  if (initialPoint.n_rows < initialPoint.n_cols)
  {
    Warn << "LRSDPFunction::LRSDPFunction(): solution matrix will have "
        << "more columns than rows.  It may be more efficient to find the "
        << "transposed solution." << std::endl;
  }
}

template<typename SDPType>
LRSDPFunction<SDPType>::~LRSDPFunction()
{
  rrt.Clean();
}

template<typename SDPType>
template<typename MatType>
typename MatType::elem_type LRSDPFunction<SDPType>::Evaluate(
    const MatType& /* coordinates */) const
{
  // Note: We don't require to update the R*R^T matrix here as the current
  // function is only used by AugLagrangian, which do not update the coordinates
  // matrix.
  return arma::accu(SDP().C() % rrt.As<MatType>());
}

template<typename SDPType>
template<typename MatType, typename GradType>
void LRSDPFunction<SDPType>::Gradient(const MatType& /* coordinates */,
                                      GradType& /* gradient */) const
{
  throw std::logic_error("LRSDPFunction::Gradient() not implemented for "
         "arbitrary optimizers!");
}

template<typename SDPType>
template<typename MatType>
typename MatType::elem_type LRSDPFunction<SDPType>::EvaluateConstraint(
    const size_t index,
    const MatType& coordinates) const
{
  // Note: We don't require to update the R*R^T matrix here as the current
  // function is only used by AugLagrangian, which do not update the coordinates
  // matrix.

  // Using cached R*R^T gives better optimization for sparse matrices.
  if (index < SDP().NumSparseConstraints())
  {
    return accu(SDP().SparseA()[index] % rrt.As<MatType>()) -
        SDP().SparseB()[index];
  }
  const size_t index1 = index - SDP().NumSparseConstraints();

  // For computation optimization we will be taking R^T * A first.
  return trace((trans(coordinates) * SDP().DenseA()[index1]) * coordinates)
                 - SDP().DenseB()[index1];
}

template<typename SDPType>
template<typename MatType, typename GradType>
void LRSDPFunction<SDPType>::GradientConstraint(
    const size_t /* index */,
    const MatType& /* coordinates */,
    GradType& /* gradient */) const
{
  throw std::logic_error("LRSDPFunction::GradientConstraint() not implemented "
         "for arbitrary optimizers!");
}

//! Utility function for updating R*R^T matrix.
//! Note: Caching R*R^T provide significant computation optimization
//! by reducing redundant R*R^T calculations in case of functions are not used
//! updating coordinates matrix, hence leaving R*R^T unchanged.
template<typename SDPType, typename MatType>
void UpdateRRT(LRSDPFunction<SDPType>& function,
               MatType&& newrrt)
{
  function.template RRT<MatType>() = std::move(newrrt);
}

//! Utility function for calculating part of the objective when AugLagrangian is
//! used with an LRSDPFunction.
template <typename MatrixType, typename VecType, typename MatType>
static inline void
UpdateObjective(typename MatType::elem_type& objective,
                const MatType& rrt,
                const std::vector<MatrixType>& ais,
                const VecType& bis,
                const arma::vec& lambda,
                const size_t lambdaOffset,
                const double sigma)
{
  for (size_t i = 0; i < ais.size(); ++i)
  {
    // Take the trace subtracted by the b_i.
    // Here taking R^T * A first is not recommended as we are already
    // using pre-computed R * R^T. Taking R^T * A first will result in increase
    // in number of computations.
    const double constraint = arma::accu(ais[i] % rrt) - bis[i];
    objective -= (lambda[lambdaOffset + i] * constraint);
    objective += (sigma / 2.) * constraint * constraint;
  }
}

//! Utility function for calculating part of the gradient when AugLagrangian is
//! used with an LRSDPFunction.
template <typename MatrixType, typename VecType, typename MatType>
static inline void
UpdateGradient(MatType& s,
               const MatType& rrt,
               const std::vector<MatrixType>& ais,
               const VecType& bis,
               const arma::vec& lambda,
               const size_t lambdaOffset,
               const double sigma)
{
  for (size_t i = 0; i < ais.size(); ++i)
  {
    // Here taking R^T * A first is not recommended as we are already
    // using pre-computed R * R^T. Taking R^T * A first will result in increase
    // in number of computations.
    const double constraint = arma::accu(ais[i] % rrt) - bis[i];
    const double y = lambda[lambdaOffset + i] - sigma * constraint;
    s -= y * ais[i];
  }
}

template<typename SDPType, typename MatType>
static inline double
EvaluateImpl(LRSDPFunction<SDPType>& function,
             const MatType& coordinates,
             const arma::vec& lambda,
             const double sigma)
{
  // We can calculate the entire objective in a smart way.
  // L(R, y, s) = Tr(C * (R R^T)) -
  //     sum_{i = 1}^{m} (y_i (Tr(A_i * (R R^T)) - b_i)) +
  //     (sigma / 2) * sum_{i = 1}^{m} (Tr(A_i * (R R^T)) - b_i)^2

  // Let's start with the objective: Tr(C * (R R^T)).
  // Simple, possibly slow solution-- see below for optimization opportunity
  //
  // Note that Tr(C^T * (R R^T)) = Tr( (CR)^T * R ), so
  // multiplying C * R first, and then taking the trace dot should be more
  // memory efficient.
  //
  // Similarly for the constraints, taking R^T * A first should be
  // more efficient.
  //
  // For computation optimization we will be taking R^T * C first.
  // Objective function = Tr((R^T * C) * R)

  // Calculate R*R^T for updating cache.
  MatType rrt = coordinates * trans(coordinates);

  // Update R*R^T matrix.
  // Note that we can only use this optimization in case of L-BFGS optimizer
  // or any other similar optimizer which calls Evaluate() before Gradient()
  // with same coordinates matrix and uses only Evaluate() to update
  // coordinates matrix.

  // Note: In case optimizer also uses Gradient() for updating coordinates
  // matrix than the same line of code can be used to update R*R^T through
  // Gradient().
  UpdateRRT(function, rrt);

  // Optimized objective function.
  typename MatType::elem_type objective =
      trace((trans(coordinates) * function.SDP().C()) * coordinates);

  // Now each constraint.
  UpdateObjective(objective, function.template RRT<MatType>(),
      function.SDP().SparseA(), function.SDP().SparseB(), lambda, 0, sigma);
  UpdateObjective(objective, function.template RRT<MatType>(),
      function.SDP().DenseA(), function.SDP().DenseB(), lambda,
      function.SDP().NumSparseConstraints(), sigma);

  return objective;
}

template<typename SDPType, typename MatType, typename GradType>
static inline void
GradientImpl(const LRSDPFunction<SDPType>& function,
             const MatType& coordinates,
             const arma::vec& lambda,
             const double sigma,
             GradType& gradient)
{
  // We can calculate the gradient in a smart way.
  // L'(R, y, s) = 2 * S' * R
  //   with
  // S' = C - sum_{i = 1}^{m} y'_i A_i
  // y'_i = y_i - sigma * (Trace(A_i * (R R^T)) - b_i)

  // Directly retrieve R*R^T from cache.
  const MatType& rrt = function.template RRT<MatType>();
  MatType s(function.SDP().C());

  UpdateGradient(
      s, rrt, function.SDP().SparseA(), function.SDP().SparseB(),
      lambda, 0, sigma);
  UpdateGradient(
      s, rrt, function.SDP().DenseA(), function.SDP().DenseB(),
      lambda, function.SDP().NumSparseConstraints(), sigma);

  gradient = 2 * s * coordinates;
}

// Template specializations for function and gradient evaluation.
// Note that C++ does not allow partial specialization of class members,
// so we have to go about this in a somewhat round-about way.
template<>
template<typename MatType>
inline typename MatType::elem_type
AugLagrangianFunction<LRSDPFunction<SDP<arma::sp_mat>>>::Evaluate(
    const MatType& coordinates) const
{
  return EvaluateImpl(function, coordinates, lambda, sigma);
}

template<>
template<typename MatType>
inline typename MatType::elem_type
AugLagrangianFunction<LRSDPFunction<SDP<arma::mat>>>::Evaluate(
    const MatType& coordinates) const
{
  return EvaluateImpl(function, coordinates, lambda, sigma);
}

template<>
template<typename MatType, typename GradType>
inline void AugLagrangianFunction<LRSDPFunction<SDP<arma::sp_mat>>>::Gradient(
    const MatType& coordinates,
    GradType& gradient) const
{
  GradientImpl(function, coordinates, lambda, sigma, gradient);
}

template<>
template<typename MatType, typename GradType>
inline void AugLagrangianFunction<LRSDPFunction<SDP<arma::mat>>>::Gradient(
    const MatType& coordinates,
    GradType& gradient) const
{
  GradientImpl(function, coordinates, lambda, sigma, gradient);
}

template<>
template<typename MatType>
inline typename MatType::elem_type
AugLagrangianFunction<LRSDPFunction<SDP<arma::sp_fmat>>>::Evaluate(
    const MatType& coordinates) const
{
  return EvaluateImpl(function, coordinates, lambda, sigma);
}

template<>
template<typename MatType>
inline typename MatType::elem_type
AugLagrangianFunction<LRSDPFunction<SDP<arma::fmat>>>::Evaluate(
    const MatType& coordinates) const
{
  return EvaluateImpl(function, coordinates, lambda, sigma);
}

template<>
template<typename MatType, typename GradType>
inline void AugLagrangianFunction<LRSDPFunction<SDP<arma::sp_fmat>>>::Gradient(
    const MatType& coordinates,
    GradType& gradient) const
{
  GradientImpl(function, coordinates, lambda, sigma, gradient);
}

template<>
template<typename MatType, typename GradType>
inline void AugLagrangianFunction<LRSDPFunction<SDP<arma::fmat>>>::Gradient(
    const MatType& coordinates,
    GradType& gradient) const
{
  GradientImpl(function, coordinates, lambda, sigma, gradient);
}

} // namespace ens

#endif
/**
 * @file lrsdp.cpp
 * @author Ryan Curtin
 *
 * An implementation of Monteiro and Burer's formulation of low-rank
 * semidefinite programs (LR-SDP).
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_SDP_LRSDP_IMPL_HPP
#define ENSMALLEN_SDP_LRSDP_IMPL_HPP

#include "lrsdp.hpp"

namespace ens {

template<typename SDPType>
LRSDP<SDPType>::LRSDP(const size_t numSparseConstraints,
                      const size_t numDenseConstraints,
                      const arma::Mat<typename SDPType::ElemType>& initialPoint,
                      const size_t maxIterations) :
    function(numSparseConstraints, numDenseConstraints, initialPoint),
    maxIterations(maxIterations)
{ }

template<typename SDPType>
template<typename MatType, typename... CallbackTypes>
typename MatType::elem_type LRSDP<SDPType>::Optimize(
    MatType& coordinates, CallbackTypes&&... callbacks)
{
  function.RRTAny().Clean();
  function.RRTAny().template Set<MatType>(
      new MatType(coordinates * coordinates.t()));

  augLag.Sigma() = 10;
  augLag.MaxIterations() = maxIterations;
  augLag.Optimize(function, coordinates, callbacks...);

  return function.Evaluate(coordinates);
}

} // namespace ens

#endif
/**
 * @file primal_dual.hpp
 * @author Stephen Tu
 *
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_SDP_PRIMAL_DUAL_HPP
#define ENSMALLEN_SDP_PRIMAL_DUAL_HPP

#include "sdp.hpp"

namespace ens {

/**
 * PrimalDualSolver is a primal dual interior point solver for semidefinite
 * programs.
 *
 * PrimalDualSolver can optimize semidefinite programs.  For more details, see the
 * documentation on function types included with this distribution or on the
 * ensmallen website.
 */
class PrimalDualSolver
{
 public:
  /**
   * Construct a new solver instance with the given optimization parameters.
   *
   * @param maxIterations Maximum number of iterations.
   * @param tau Step size modulating factor (between 0 and 1).
   * @param normXzTol Tolerance of norm(X*Z) required before terminating.  (X is
   *      the primal coordinates, Z is the dual coordinates.)
   * @param primalInfeasTol Primal infeasibility tolerance for termination.
   * @param dualInfeasTol Dual infeasibility tolerance for termination.
   */
  PrimalDualSolver(const size_t maxIterations = 1000,
                   const double tau = 0.99,
                   const double normXzTol = 1e-7,
                   const double primalInfeasTol = 1e-7,
                   const double dualInfeasTol = 1e-7);

  /**
   * Optimize the given SDP with the given initial coordinates.  To get a set of
   * initial coordinates from an SDP class, consider calling
   * SDP::GetInitialPoint().  The primal objective is returned, and the final
   * coordinates are stored in the given coordinates matrix.
   *
   * @tparam SDPType Type of SDP to optimize.
   * @tparam MatType Type of matrix to optimize with.
   * @tparam CallbackTypes Types of callback functions.
   * @param sdp The SDP to optimize.
   * @param coordinates The primal SDP coordinates to optimize.
   * @param callbacks Callback functions.
   */
  template<typename SDPType, typename MatType, typename... CallbackTypes>
  typename MatType::elem_type Optimize(const SDPType& sdp,
                                       MatType& coordinates,
                                       CallbackTypes&&... callbacks);

  /**
   * Optimize the given SDP with the given initial primal and dual coordinates.
   * To get a set of primal and dual initial coordinates from an SDP class,
   * consider calling SDP::GetInitialPoints().  The primal objective is
   * returned, and the final primal and dual variables are stored in the given
   * matrices.  Both ySparse and yDense should be vector shaped (one column).
   *
   * @tparam SDPType Type of SDP to optimize.
   * @tparam MatType Type of matrix to optimize with.
   * @tparam CallbackTypes Types of callback functions.
   * @param sdp The SDP to optimize.
   * @param coordinates The initial primal SDP coordinates to optimize.
   * @param ySparse The initial ySparse to optimize.
   * @param yDense The initial yDense to optimize.
   * @param dualCoordinates The initial dual SDP coordinates to optimize.
   * @param callbacks Callback functions.
   */
  template<typename SDPType, typename MatType, typename... CallbackTypes>
  typename MatType::elem_type Optimize(const SDPType& sdp,
                                       MatType& coordinates,
                                       MatType& ySparse,
                                       MatType& yDense,
                                       MatType& dualCoordinates,
                                       CallbackTypes&&... callbacks);

  //! Get the maximum number of iterations to run before converging.
  size_t MaxIterations() const { return maxIterations; }
  //! Modify the maximum number of iterations to run before converging.
  size_t& MaxIterations() { return maxIterations; }

  //! Get tau.
  double Tau() const { return tau; }
  //! Modify tau. Typical values are 0.99.
  double& Tau() { return tau; }

  //! Get the XZ tolerance.
  double NormXzTol() const { return normXzTol; }
  //! Modify the XZ tolerance.
  double& NormXzTol() { return normXzTol; }

  //! Get the primal infeasibility tolerance.
  double PrimalInfeasTol() const { return primalInfeasTol; }
  //! Modify the primal infeasibility tolerance.
  double& PrimalInfeasTol() { return primalInfeasTol; }

  //! Get the dual infeasibility tolerance.
  double DualInfeasTol() const { return dualInfeasTol; }
  //! Modify the dual infeasibility tolerance.
  double& DualInfeasTol() { return dualInfeasTol; }

 private:
  //! Maximum number of iterations to run. Set to 0 for no limit.
  size_t maxIterations;

  //! The step size modulating factor. Needs to be a scalar in (0, 1).
  double tau;

  //! The tolerance on the norm of XZ required before terminating.
  double normXzTol;

  //! The tolerance required on the primal constraints required before
  //! terminating.
  double primalInfeasTol;

  //! The tolerance required on the dual constraint required before terminating.
  double dualInfeasTol;
};

} // namespace ens

// Include implementation.
#include "primal_dual_impl.hpp"

#endif
/**
 * @file primal_dual_impl.hpp
 * @author Stephen Tu
 *
 * Contains an implementation of the "XZ+ZX" primal-dual infeasible interior
 * point method with a Mehrotra predictor-corrector update step presented and
 * analyzed in:
 *
 *   Primal-dual interior-point methods for semidefinite programming:
 *   Convergence rates, stability and numerical results.
 *   Farid Alizadeh, Jean-Pierre Haeberly, and Michael Overton.
 *   SIAM J. Optim. 1998.
 *   https://www.cs.nyu.edu/overton/papers/pdffiles/pdsdp.pdf
 *
 * We will refer to this paper as [AHO98] in this file.
 *
 * Note there are many optimizations that still need to be implemented. See the
 * code comments for more details.
 *
 * Also note the current implementation assumes the SDP problem has a strictly
 * feasible primal/dual point (and therefore the duality gap is zero), and
 * that the constraint matrices are linearly independent.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_SDP_PRIMAL_DUAL_IMPL_HPP
#define ENSMALLEN_SDP_PRIMAL_DUAL_IMPL_HPP

#include "primal_dual.hpp"
#include "lin_alg.hpp"

namespace ens {
inline PrimalDualSolver::PrimalDualSolver(const size_t maxIterations,
                                          const double tau,
                                          const double normXzTol,
                                          const double primalInfeasTol,
                                          const double dualInfeasTol) :
    maxIterations(maxIterations),
    tau(tau),
    normXzTol(normXzTol),
    primalInfeasTol(primalInfeasTol),
    dualInfeasTol(dualInfeasTol)
{
  // Nothing to do.
}

/**
 * Compute
 *
 *     alpha = min(1, tau * alphahat(A, dA))
 *
 * where
 *
 *     alphahat = sup{ alphahat : A + dA is psd }
 *
 * See (2.18) of [AHO98] for more details.
 */
template<typename MatType>
static inline bool
Alpha(const MatType& a, const MatType& dA, double tau, double& alpha)
{
  arma::mat l;
  if (!arma::chol(l, a, "lower"))
    return false;

  arma::mat lInv;
  if (!arma::inv(lInv, arma::trimatl(l)))
    return false;

  // TODO(stephentu): We only want the top eigenvalue, we should
  // be able to do better than full eigen-decomposition.
  arma::Col<typename MatType::elem_type> evals;
  if (!arma::eig_sym(evals, -lInv * dA * lInv.t()))
    return false;
  const double alphahatInv = evals(evals.n_elem - 1);
  double alphahat = 1. / alphahatInv;

  if (alphahat < 0.)
    // dA is PSD already
    alphahat = 1.;
  alpha = std::min(1., tau * alphahat);
  return true;
}

/**
 * Solve the following Lyapunov equation (for X)
 *
 *   AX + XA = H
 *
 * where A, H are symmetric matrices.
 *
 * TODO(stephentu): Note this method current uses arma's builtin arma::syl
 * method, which is overkill for this situation. See Lemma 7.2 of [AHO98] for
 * how to solve this Lyapunov equation using an eigenvalue decomposition of A.
 *
 */
template<typename MatType, typename AType, typename BType>
static inline void
SolveLyapunov(MatType& x, const AType& a, const BType& h)
{
  arma::syl(x, a, a, -h);
}

/**
 * Solve the following KKT system (2.10) of [AHO98]:
 *
 *     [ 0  A^T  I ] [ dsx ] = [ rd ]
 *     [ A   0   0 ] [  dy ] = [ rp ]
 *     [ E   0   F ] [ dsz ] = [ rc ]
 *     \---- M ----/
 *
 * where
 *
 *     A  = [ Asparse ]
 *          [ Adense  ]
 *     dy = [ dysparse  dydense ]
 *     E  = Z sym I
 *     F  = X sym I
 *
 */
template<typename MatType,
         typename SparseConstraintType,
         typename DenseConstraintType>
static inline void
SolveKKTSystem(const SparseConstraintType& aSparse,
               const DenseConstraintType& aDense,
               const MatType& dualCoordinates,
               const MatType& m,
               const MatType& fMat,
               const MatType& rp,
               const MatType& rd,
               const MatType& rc,
               MatType& dsX,
               MatType& dySparse,
               MatType& dyDense,
               MatType& dsZ)
{
  MatType frdRcMat, eInvFrdRcMat, eInvFrdATdyRcMat, frdATdyRcMat;
  MatType eInvFrdRc, eInvFrdATdyRc, dy;

  // Note: Whenever a formula calls for E^(-1) v for some v, we solve Lyapunov
  // equations instead of forming an explicit inverse.

  // Compute the RHS of (2.12)
  math::Smat(fMat * rd - rc, frdRcMat);
  SolveLyapunov(eInvFrdRcMat, dualCoordinates, 2. * frdRcMat);
  math::Svec(eInvFrdRcMat, eInvFrdRc);

  MatType rhs = rp;
  const size_t numConstraints = aSparse.n_rows + aDense.n_rows;
  if (aSparse.n_rows)
    rhs(arma::span(0, aSparse.n_rows - 1), 0) += aSparse * eInvFrdRc;
  if (aDense.n_rows)
    rhs(arma::span(aSparse.n_rows, numConstraints - 1), 0) += aDense * eInvFrdRc;

  if (!arma::solve(dy, m, rhs, arma::solve_opts::fast))
  {
    throw std::logic_error("PrimalDualSolver::SolveKKTSystem(): Could not "
        "solve KKT system.");
  }

  MatType subTerm(aSparse.n_cols, 1, arma::fill::zeros);
  
  if (aSparse.n_rows)
  {
    dySparse = dy(arma::span(0, aSparse.n_rows - 1), 0);
    subTerm += aSparse.t() * dySparse;
  }
  if (aDense.n_rows)
  {
    dyDense = dy(arma::span(aSparse.n_rows, numConstraints - 1), 0);
    subTerm += aDense.t() * dyDense;
  }

  // Compute dx from (2.13)
  math::Smat(fMat * (rd - subTerm) - rc,
      frdATdyRcMat);
  SolveLyapunov(eInvFrdATdyRcMat, dualCoordinates, 2. * frdATdyRcMat);
  math::Svec(eInvFrdATdyRcMat, eInvFrdATdyRc);
  dsX = -eInvFrdATdyRc;

  // Compute dz from (2.14)
  dsZ = rd - subTerm;
}

template<typename SDPType, typename MatType, typename... CallbackTypes>
typename MatType::elem_type PrimalDualSolver::Optimize(
    const SDPType& sdp,
    MatType& coordinates,
    CallbackTypes&&... callbacks)
{
  // Initialize the other parameters and then call the other overload.
  MatType ySparse(arma::ones<MatType>(sdp.NumSparseConstraints(), 1));
  MatType yDense(arma::ones<MatType>(sdp.NumDenseConstraints(), 1));
  MatType z(arma::eye<MatType>(sdp.N(), sdp.N()));

  return Optimize(sdp, coordinates, ySparse, yDense, z, callbacks...);
}

template<typename SDPType, typename MatType, typename... CallbackTypes>
typename MatType::elem_type PrimalDualSolver::Optimize(
    const SDPType& sdp,
    MatType& coordinates,
    MatType& ySparse,
    MatType& yDense,
    MatType& dualCoordinates,
    CallbackTypes&&... callbacks)
{
  MatType tmp;

  // Note that the algorithm we implement requires primal iterate X and
  // dual multiplier Z to be positive definite (but not feasible).
  if (coordinates.n_rows != sdp.N() || coordinates.n_cols != sdp.N())
  {
    throw std::logic_error("PrimalDualSolver::Optimize(): coordinates needs to "
        "be square n x n matrix.");
  }

  if (!arma::chol(tmp, coordinates))
  {
    throw std::logic_error("PrimalDualSolver::Optimize(): coordinates needs to "
        "be symmetric positive definite.");
  }

  if (ySparse.n_cols != 1)
  {
    throw std::logic_error("PrimalDualSolver::Optimize(): ySparse must have "
        "only one column.");
  }

  if (ySparse.n_rows != sdp.NumSparseConstraints())
  {
    throw std::logic_error("PrimalDualSolver::Optimize(): ySparse needs to have"
        " the same length as the number of sparse constraints.");
  }

  if (yDense.n_cols != 1)
  {
    throw std::logic_error("PrimalDualSolver::Optimize(): yDense must have only"
        " one column.");
  }

  if (yDense.n_rows != sdp.NumDenseConstraints())
  {
    throw std::logic_error("PrimalDualSolver::Optimize(): yDense needs to have "
        "the same length as the number of dense constraints.");
  }

  if (dualCoordinates.n_rows != sdp.N() || dualCoordinates.n_cols != sdp.N())
  {
    throw std::logic_error("PrimalDualSolver::Optimize(): dualCoordinates needs"
        " to be square n x n matrix.");
  }

  if (!arma::chol(tmp, dualCoordinates))
  {
    throw std::logic_error("PrimalDualSolver::Optimize(): dualCoordinates needs"
        " to be symmetric positive definite.");
  }

  const size_t n = sdp.N();
  const size_t n2bar = sdp.N2bar();

  // Form the A matrix in (2.7). Note we explicitly handle
  // sparse and dense constraints separately.

  typename SDPType::SparseConstraintType aSparse(sdp.NumSparseConstraints(),
                                                 n2bar);
  typename SDPType::SparseConstraintType aiSparse;

  for (size_t i = 0; i < sdp.NumSparseConstraints(); i++)
  {
    math::Svec(sdp.SparseA()[i], aiSparse);
    aSparse.row(i) = aiSparse.t();
  }

  typename SDPType::DenseConstraintType aDense(sdp.NumDenseConstraints(),
                                               n2bar);
  typename SDPType::DenseConstraintType aiDense;
  for (size_t i = 0; i < sdp.NumDenseConstraints(); i++)
  {
    math::Svec(sdp.DenseA()[i], aiDense);
    aDense.row(i) = aiDense.t();
  }

  typename SDPType::ObjectiveType sc;
  math::Svec(sdp.C(), sc);

  MatType sx, sz, dySparse, dyDense, dsx, dsz, dX, dZ;

  math::Svec(coordinates, sx);
  math::Svec(dualCoordinates, sz);

  MatType rp, rd, rc, gk;

  MatType rcMat, fMat, eInvFaSparseT, eInvFaDenseT, gkMat,
      m, dualCheck;

  rp.set_size(sdp.NumConstraints(), 1);

  eInvFaSparseT.set_size(n2bar, sdp.NumSparseConstraints());
  eInvFaDenseT.set_size(n2bar, sdp.NumDenseConstraints());
  m.zeros(sdp.NumConstraints(), sdp.NumConstraints());

  // Controls early termination of the optimization process.
  bool terminate = false;

  typename SDPType::ElemType primalObj = 0., alpha, beta;
  Callback::BeginOptimization(*this, sdp, coordinates, callbacks...);
  for (size_t iteration = 1; iteration != maxIterations && !terminate;
      iteration++)
  {
    // Note: The Mehrotra PC algorithm works like this at a high level.
    // We first solve a KKT system with mu=0. Then, we use the results
    // of this KKT system to get a better estimate of mu and solve
    // the KKT system again. Empirically, this PC step has been shown to
    // significantly reduce the number of required iterations (and is used
    // by most practical solver implementations).
    if (sdp.NumSparseConstraints())
    {
      rp(arma::span(0, sdp.NumSparseConstraints() - 1), 0) =
          sdp.SparseB() - aSparse * sx;
    }
    if (sdp.NumDenseConstraints())
    {
      rp(arma::span(sdp.NumSparseConstraints(), sdp.NumConstraints() - 1), 0) =
          sdp.DenseB() - aDense * sx;
    }

    // Rd = C - Z - smat A^T y
    rd = sc - sz - aSparse.t() * ySparse - aDense.t() * yDense;

    math::SymKronId(coordinates, fMat);

    // We compute E^(-1) F A^T by solving Lyapunov equations.
    // See (2.16).
    for (size_t i = 0; i < sdp.NumSparseConstraints(); i++)
    {
      SolveLyapunov(gkMat, dualCoordinates, coordinates * sdp.SparseA()[i] +
          sdp.SparseA()[i] * coordinates);
      math::Svec(gkMat, gk);
      eInvFaSparseT.col(i) = gk;
    }

    for (size_t i = 0; i < sdp.NumDenseConstraints(); i++)
    {
      SolveLyapunov(gkMat, dualCoordinates, coordinates * sdp.DenseA()[i] +
          sdp.DenseA()[i] * coordinates);
      math::Svec(gkMat, gk);
      eInvFaDenseT.col(i) = gk;
    }

    // Form the M = A E^(-1) F A^T matrix (2.15)
    //
    // Since we split A up into its sparse and dense components,
    // we have to handle each block separately.
    if (sdp.NumSparseConstraints())
    {
      m.submat(arma::span(0, sdp.NumSparseConstraints() - 1),
               arma::span(0, sdp.NumSparseConstraints() - 1)) =
          aSparse * eInvFaSparseT;
      if (sdp.NumDenseConstraints())
      {
        m.submat(arma::span(0, sdp.NumSparseConstraints() - 1),
                 arma::span(sdp.NumSparseConstraints(),
                            sdp.NumConstraints() - 1)) =
            aSparse * eInvFaDenseT;
      }
    }
    if (sdp.NumDenseConstraints())
    {
      if (sdp.NumSparseConstraints())
      {
        m.submat(arma::span(sdp.NumSparseConstraints(),
                            sdp.NumConstraints() - 1),
                 arma::span(0,
                            sdp.NumSparseConstraints() - 1)) =
            aDense * eInvFaSparseT;
      }
      m.submat(arma::span(sdp.NumSparseConstraints(),
                          sdp.NumConstraints() - 1),
               arma::span(sdp.NumSparseConstraints(),
                          sdp.NumConstraints() - 1)) =
          aDense * eInvFaDenseT;
    }

    const typename MatType::elem_type sxdotsz = arma::dot(sx, sz);

    // TODO(stephentu): computing these alphahats should take advantage of
    // the cholesky decomposition of X and Z which we should have available
    // when we use more efficient methods above.

    // This solves step (1) of Section 7, the "predictor" step.
    rcMat = -0.5 * (coordinates * dualCoordinates + dualCoordinates * coordinates);
    math::Svec(rcMat, rc);
    SolveKKTSystem(aSparse, aDense, dualCoordinates, m, fMat, rp, rd, rc, dsx,
        dySparse, dyDense, dsz);
    math::Smat(dsx, dX);
    math::Smat(dsz, dZ);

    // Step (2), determine step size lengths (alpha, beta)
    bool success = Alpha(coordinates, dX, tau, alpha);
    if (!success)
    {
      Warn << "PrimalDualSolver::Optimize(): cholesky decomposition of X "
          << "failed!  Terminating optimization.";

      Callback::EndOptimization(*this, sdp, coordinates, callbacks...);
      return primalObj;
    }

    success = Alpha(dualCoordinates, dZ, tau, beta);
    if (!success)
    {
      Warn << "PrimalDualSolver::Optimize(): cholesky decomposition of Z "
          << "failed!  Terminating optimization.";

      Callback::EndOptimization(*this, sdp, coordinates, callbacks...);
      return primalObj;
    }

    // See (7.1)
    const double sigma = std::pow(arma::dot(coordinates + alpha * dX,
                                            dualCoordinates + beta * dZ) /
        sxdotsz, 3);
    const double mu = sigma * sxdotsz / n;

    // Step (3), the "corrector" step.
    rcMat = mu * arma::eye<MatType>(n, n) - 0.5 *
        (coordinates * dualCoordinates +
         dualCoordinates * coordinates +
         dX * dZ +
         dZ * dX);
    math::Svec(rcMat, rc);
    SolveKKTSystem(aSparse, aDense, dualCoordinates, m, fMat, rp, rd, rc, dsx,
        dySparse, dyDense, dsz);
    math::Smat(dsx, dX);
    math::Smat(dsz, dZ);
    if (!Alpha(coordinates, dX, tau, alpha))
    {
      Warn << "PrimalDualSolver::Optimize(): cholesky decomposition of X "
          << "failed!  Terminating optimization.";

      Callback::EndOptimization(*this, sdp, coordinates, callbacks...);
      return primalObj;
    }
    if (!Alpha(dualCoordinates, dZ, tau, beta))
    {
      Warn << "PrimalDualSolver::Optimize(): cholesky decomposition of Z "
          << "failed!  Terminating optimization.";

      Callback::EndOptimization(*this, sdp, coordinates, callbacks...);
      return primalObj;
    }

    // Iterate update
    coordinates += alpha * dX;
    terminate |= Callback::StepTaken(*this, sdp, coordinates, callbacks...);

    math::Svec(coordinates, sx);
    if (dySparse.n_cols != 0)
      ySparse += beta * dySparse;
    if (dyDense.n_cols != 0)
      yDense += beta * dyDense;
    dualCoordinates += beta * dZ;
    math::Svec(dualCoordinates, sz);

    // Below, we check the KKT conditions. Recall the KKT conditions are
    //
    // (1) Primal feasibility
    // (2) Dual feasibility
    // (3) XZ = 0 (slackness condition)
    //
    // If the KKT conditions are satisfied to a certain degree of precision,
    // then we consider this a valid certificate of optimality and terminate.
    // Otherwise, we proceed onwards.

    const double normXZ = arma::norm(coordinates * dualCoordinates, "fro");

    const double sparsePrimalInfeas = arma::norm(sdp.SparseB() - aSparse * sx,
        2);
    const double densePrimalInfeas = arma::norm(sdp.DenseB() - aDense * sx, 2);
    const double primalInfeas = sqrt(sparsePrimalInfeas * sparsePrimalInfeas +
        densePrimalInfeas * densePrimalInfeas);

    primalObj = arma::dot(sdp.C(), coordinates);

    // const double dualObj = arma::dot(sdp.SparseB(), ySparse) +
    //      arma::dot(sdp.DenseB(), yDense);
    // TODO: dualObj seems to be unused

    // const double dualityGap = primalObj - dualObj;
    // TODO: dualityGap seems to be unused

    // TODO(stephentu): this dual check is quite expensive,
    // maybe make it optional?
    dualCheck = dualCoordinates - sdp.C();
    for (size_t i = 0; i < sdp.NumSparseConstraints(); i++)
      dualCheck += ySparse(i) * sdp.SparseA()[i];
    for (size_t i = 0; i < sdp.NumDenseConstraints(); i++)
      dualCheck += yDense(i) * sdp.DenseA()[i];
    const double dualInfeas = arma::norm(dualCheck, "fro");

    if (normXZ <= normXzTol && primalInfeas <= primalInfeasTol &&
        dualInfeas <= dualInfeasTol)
      return primalObj;
  }

  Warn << "PrimalDualSolver::Optimizer(): Did not converge after "
      << maxIterations << " iterations!" << std::endl;

  Callback::EndOptimization(*this, sdp, coordinates, callbacks...);
  return primalObj;
}

} // namespace ens

#endif
/**
 * @file sdp.hpp
 * @author Stephen Tu
 *
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_SDP_SDP_HPP
#define ENSMALLEN_SDP_SDP_HPP

namespace ens {

/**
 * Specify an SDP in primal form
 *
 *     min    dot(C, X)
 *     s.t.   dot(Ai, X) = bi, i=1,...,m, X >= 0
 *
 * This representation allows the constraint matrices Ai to be specified as
 * either dense matrices (arma::mat) or sparse matrices (arma::sp_mat).  After
 * initializing the SDP object, you will need to set the constraints yourself,
 * via the SparseA(), SparseB(), DenseA(), DenseB(), and C() functions.  Note
 * that for each matrix you add to either SparseA() or DenseA(), you must add
 * the corresponding b value to the corresponding vector SparseB() or DenseB().
 *
 * The objective matrix (C) may be stored as either dense or sparse depending on
 * the ObjectiveMatrixType parameter.
 *
 * @tparam ObjectiveMatrixType Should be either arma::mat or arma::sp_mat.
 */
template<typename ObjectiveMatrixType,
         typename DenseConstraintMatrixType =
             arma::Mat<typename ObjectiveMatrixType::elem_type>,
         typename SparseConstraintMatrixType =
             arma::SpMat<typename ObjectiveMatrixType::elem_type>,
         typename BVectorType =
             arma::Col<typename ObjectiveMatrixType::elem_type>>
class SDP
{
 public:
  //! Type of objective matrix.
  typedef ObjectiveMatrixType ObjectiveType;
  //! Type of element held by the SDP.
  typedef typename ObjectiveMatrixType::elem_type ElemType;
  //! Type of dense constraints.
  typedef DenseConstraintMatrixType DenseConstraintType;
  //! Type of sparse constraints.
  typedef SparseConstraintMatrixType SparseConstraintType;
  //! Type of B values.
  typedef BVectorType BType;

  /**
   * Initialize this SDP to an empty state.  To add constraints, you will have
   * to modify the constraints via the SparseA(), DenseA(), SparseB(), DenseB(),
   * and C() functions.  For the sake of speed, there is no error checking, so
   * if you specify an invalid SDP, whatever solver you use will gladly try to
   * solve it!  (And it will probably crash horribly.)
   */
  SDP();

  /**
   * Initialize this SDP to one which structurally has size n.  To set the
   * constraints you will still need to access through SparseA(), DenseA(),
   * SparseB(), DenseB(), and C().  Consider using move semantics to keep things
   * fast.  As with the previous constructor, there is no error checking for the
   * sake of speed, so if you build an invalid SDP, whatever solver you use will
   * gladly try to solve it!  (And it will probably crash horribly.)
   *
   * @param n Number of rows (and columns) in the objective matrix C.
   * @param numSparseConstraints Number of sparse constraints.
   * @param numDenseConstraints Number of dense constraints.
   */
  SDP(const size_t n,
      const size_t numSparseConstraints,
      const size_t numDenseConstraints);

  //! Return number of rows and columns in the objective matrix C.
  size_t N() const { return c.n_rows; }

  size_t N2bar() const { return N() * (N() + 1) / 2; }

  //! Return the number of sparse constraints (constraints with sparse Ai) in
  //! the SDP.
  size_t NumSparseConstraints() const { return sparseB.n_elem; }
  //! Return the number of dense constraints (constraints with dense Ai) in the
  //! SDP.
  size_t NumDenseConstraints() const { return denseB.n_elem; }

  //! Return the total number of constraints in the SDP.
  size_t NumConstraints() const { return sparseB.n_elem + denseB.n_elem; }

  //! Modify the sparse objective function matrix (sparseC).
  ObjectiveMatrixType& C() { return c; }
  //! Return the sparse objective function matrix (sparseC).
  const ObjectiveMatrixType& C() const { return c; }

  //! Return the vector of sparse A matrices (which correspond to the sparse
  //! constraints).
  const std::vector<SparseConstraintMatrixType>& SparseA() const
  { return sparseA; }

  //! Modify the vector of sparse A matrices (which correspond to the sparse
  //! constraints).
  std::vector<SparseConstraintMatrixType>& SparseA() { return sparseA; }

  //! Return the vector of dense A matrices (which correspond to the dense
  //! constraints).
  const std::vector<DenseConstraintMatrixType>& DenseA() const
  { return denseA; }

  //! Modify the vector of dense A matrices (which correspond to the dense
  //! constraints).
  std::vector<DenseConstraintMatrixType>& DenseA() { return denseA; }

  //! Return the vector of sparse B values.
  const BVectorType& SparseB() const { return sparseB; }
  //! Modify the vector of sparse B values.
  BVectorType& SparseB() { return sparseB; }

  //! Return the vector of dense B values.
  const BVectorType& DenseB() const { return denseB; }
  //! Modify the vector of dense B values.
  BVectorType& DenseB() { return denseB; }

  /**
   * Check whether or not the constraint matrices are linearly independent.
   *
   * Warning: possibly very expensive check.
   */
  bool HasLinearlyIndependentConstraints() const;

  //! Get an initial point for the primal coordinates.
  template<typename MatType = arma::mat>
  MatType GetInitialPoint() const;

  //! Get initial points for the primal and dual coordinates.
  template<typename MatType = arma::mat>
  void GetInitialPoints(MatType& coordinates,
                        MatType& ySparse,
                        MatType& yDense,
                        MatType& dualCoordinates) const;

 private:
  //! Objective function matrix c.
  ObjectiveMatrixType c;

  //! A_i for each sparse constraint.
  std::vector<SparseConstraintMatrixType> sparseA;
  //! b_i for each sparse constraint.
  BVectorType sparseB;

  //! A_i for each dense constraint.
  std::vector<DenseConstraintMatrixType> denseA;
  //! b_i for each dense constraint.
  BVectorType denseB;
};

} // namespace ens

// Include implementation.
#include "sdp_impl.hpp"

#endif
/**
 * @file sdp_impl.hpp
 * @author Stephen Tu
 *
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_SDP_SDP_IMPL_HPP
#define ENSMALLEN_SDP_SDP_IMPL_HPP

#include "sdp.hpp"
#include "lin_alg.hpp"

namespace ens {

template<typename ObjectiveMatrixType,
         typename DenseConstraintMatrixType,
         typename SparseConstraintMatrixType,
         typename BVectorType>
SDP<ObjectiveMatrixType,
    DenseConstraintMatrixType,
    SparseConstraintMatrixType,
    BVectorType>::SDP() :
    c(),
    sparseA(),
    sparseB(),
    denseA(),
    denseB()
{ /* Nothing to do. */ }

template<typename ObjectiveMatrixType,
         typename DenseConstraintMatrixType,
         typename SparseConstraintMatrixType,
         typename BVectorType>
SDP<ObjectiveMatrixType,
    DenseConstraintMatrixType,
    SparseConstraintMatrixType,
    BVectorType>::SDP(const size_t n,
                      const size_t numSparseConstraints,
                      const size_t numDenseConstraints) :
    c(n, n),
    sparseA(numSparseConstraints),
    sparseB(numSparseConstraints),
    denseA(numDenseConstraints),
    denseB(numDenseConstraints)
{
  for (size_t i = 0; i < numSparseConstraints; i++)
    sparseA[i].zeros(n, n);
  for (size_t i = 0; i < numDenseConstraints; i++)
    denseA[i].zeros(n, n);
}

template<typename ObjectiveMatrixType,
         typename DenseConstraintMatrixType,
         typename SparseConstraintMatrixType,
         typename BVectorType>
bool SDP<ObjectiveMatrixType,
         DenseConstraintMatrixType,
         SparseConstraintMatrixType,
         BVectorType>::HasLinearlyIndependentConstraints() const
{
  // Very inefficient, should only be used for testing/debugging.

  const size_t n2bar = N2bar();
  DenseConstraintMatrixType A(NumConstraints(), n2bar);
  if (A.n_rows > n2bar)
    return false;

  for (size_t i = 0; i < NumSparseConstraints(); i++)
  {
    DenseConstraintMatrixType sa;
    math::Svec(DenseConstraintMatrixType(SparseA()[i]), sa);
    A.row(i) = sa.t();
  }
  for (size_t i = 0; i < NumDenseConstraints(); i++)
  {
    DenseConstraintMatrixType sa;
    math::Svec(DenseA()[i], sa);
    A.row(NumSparseConstraints() + i) = sa.t();
  }

  const DenseConstraintMatrixType s = arma::svd(A);
  return s(s.n_elem - 1) > 1e-5;
}

//! Get an initial point for the primal coordinates.
template<typename ObjectiveMatrixType,
         typename DenseConstraintMatrixType,
         typename SparseConstraintMatrixType,
         typename BVectorType>
template<typename MatType>
MatType SDP<ObjectiveMatrixType,
            DenseConstraintMatrixType,
            SparseConstraintMatrixType,
            BVectorType>::GetInitialPoint() const
{
  return arma::eye<MatType>(c.n_rows, c.n_rows);
}

//! Get initial points for the primal and dual coordinates.
template<typename ObjectiveMatrixType,
         typename DenseConstraintMatrixType,
         typename SparseConstraintMatrixType,
         typename BVectorType>
template<typename MatType>
void SDP<ObjectiveMatrixType,
         DenseConstraintMatrixType,
         SparseConstraintMatrixType,
         BVectorType>::GetInitialPoints(MatType& coordinates,
                                        MatType& ySparse,
                                        MatType& yDense,
                                        MatType& dualCoordinates) const
{
  coordinates = arma::eye<MatType>(c.n_rows, c.n_rows);
  ySparse = arma::ones<MatType>(NumSparseConstraints(), 1);
  yDense = arma::ones<MatType>(NumDenseConstraints(), 1);
  dualCoordinates = arma::eye<MatType>(c.n_rows, c.n_rows);
}

} // namespace ens

#endif
/**
 * @file no_decay.hpp
 * @author Marcus Edel
 *
 * Definition of the policy type for the decay class.
 *
 * You should define your own decay update that looks like NoDecay.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */

#ifndef ENSMALLEN_SGD_DECAY_POLICIES_NO_DECAY_HPP
#define ENSMALLEN_SGD_DECAY_POLICIES_NO_DECAY_HPP

namespace ens {

/**
 * Definition of the NoDecay class. Use this as a template for your own.
 */
class NoDecay
{
 public:
  /**
   * This constructor is called before the first iteration.
   */
  NoDecay() { }

  /**
   * The DecayPolicyType policy classes must contain an internal 'Policy'
   * template class with two template arguments: MatType and GradType.  This is
   * initialized at the start of the optimization, and holds parameters specific
   * to an individual optimization.
   */
  template<typename MatType, typename GradType>
  class Policy
  {
   public:
    /**
     * This constructor is called by the SGD Optimize() method before the start
     * of the iteration update process.
     */
    Policy(NoDecay& /* parent */) { }

    /**
     * This function is called in each iteration after the policy update.
     *
     * @param iterate Parameters that minimize the function.
     * @param stepSize Step size to be used for the given iteration.
     * @param gradient The gradient matrix.
     */
    void Update(MatType& /* iterate */,
                double& /* stepSize */,
                const GradType& /* gradient */)
    {
      // Nothing to do here.
    }

    /**
     * This function is called in each iteration after the SVRG update step.
     *
     * @param iterate Parameters that minimize the function.
     * @param iterate0 The last function parameters at time t - 1.
     * @param gradient The current gradient matrix at time t.
     * @param fullGradient The computed full gradient.
     * @param stepSize Step size to be used for the given iteration.
     */
    void Update(const MatType& /* iterate */,
                const MatType& /* iterate0 */,
                const GradType& /* gradient */,
                const GradType& /* fullGradient */,
                const size_t /* numBatches */,
                double& /* stepSize */)
    {
      // Nothing to do here.
    }
  };
};

} // namespace ens

#endif // ENSMALLEN_SGD_DECAY_POLICIES_NO_DECAY_HPP
/**
 * @file sgd.hpp
 * @author Ryan Curtin
 * @author Arun Reddy
 * @author Abhinav Moudgil
 * @author Sourabh Varshney
 *
 * Stochastic Gradient Descent (SGD).
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_SGD_SGD_HPP
#define ENSMALLEN_SGD_SGD_HPP

#include "update_policies/vanilla_update.hpp"
#include "update_policies/momentum_update.hpp"
#include "update_policies/nesterov_momentum_update.hpp"
#include "decay_policies/no_decay.hpp"
#include "update_policies/quasi_hyperbolic_update.hpp"

namespace ens {

/**
 * Stochastic Gradient Descent is a technique for minimizing a function which
 * can be expressed as a sum of other functions.  That is, suppose we have
 *
 * \f[
 * f(A) = \sum_{i = 0}^{n} f_i(A)
 * \f]
 *
 * and our task is to minimize \f$ A \f$.  Stochastic gradient descent iterates
 * over each function \f$ f_i(A) \f$, based on the specified update policy. By
 * default vanilla update policy (see ens::VanillaUpdate) is used. The SGD class
 * supports either scanning through each of the \f$ n \f$ functions \f$
 * f_i(A)\f$ linearly, or in a random sequence.  The algorithm continues until
 * \f$ j\f$ reaches the maximum number of iterations---or when a full sequence
 * of updates through each of the \f$ n \f$ functions \f$ f_i(A) \f$ produces an
 * improvement within a certain tolerance \f$ \epsilon \f$.  That is,
 *
 * \f[
 * | f(A_{j + n}) - f(A_j) | < \epsilon.
 * \f]
 *
 * The parameter \f$\epsilon\f$ is specified by the tolerance parameter to the
 * constructor; \f$n\f$ is specified by the maxIterations parameter.
 *
 * This class is useful for data-dependent functions whose objective function
 * can be expressed as a sum of objective functions operating on an individual
 * point.  Then, SGD considers the gradient of the objective function operating
 * on an individual point in its update of \f$ A \f$.
 *
 * SGD can optimize differentiable separable functions.  For more details, see
 * the documentation on function types included with this distribution or on the
 * ensmallen website.
 *
 * @tparam UpdatePolicyType Update policy used by SGD during the iterative
 *     update process. By default vanilla update policy (see ens::VanillaUpdate)
 *     is used.
 * @tparam DecayPolicyType Decay policy used during the iterative update
 *     process to adjust the step size. By default the step size isn't going to
 *     be adjusted (i.e. NoDecay is used).
 */
template<typename UpdatePolicyType = VanillaUpdate,
         typename DecayPolicyType = NoDecay>
class SGD
{
 public:
  /**
   * Construct the SGD optimizer with the given function and parameters. The
   * defaults here are not necessarily good for the given problem, so it is
   * suggested that the values used be tailored to the task at hand.  The
   * maximum number of iterations refers to the maximum number of points that
   * are processed (i.e., one iteration equals one point; one iteration does not
   * equal one pass over the dataset).
   *
   * @param stepSize Step size for each iteration.
   * @param batchSize Batch size to use for each step.
   * @param maxIterations Maximum number of iterations allowed (0 means no
   *     limit).
   * @param tolerance Maximum absolute tolerance to terminate algorithm.
   * @param shuffle If true, the function order is shuffled; otherwise, each
   *     function is visited in linear order.
   * @param updatePolicy Instantiated update policy used to adjust the given
   *                     parameters.
   * @param decayPolicy Instantiated decay policy used to adjust the step size.
   * @param resetPolicy Flag that determines whether update policy parameters
   *                    are reset before every Optimize call.
   * @param exactObjective Calculate the exact objective (Default: estimate the
   *        final objective obtained on the last pass over the data).
   */
  SGD(const double stepSize = 0.01,
      const size_t batchSize = 32,
      const size_t maxIterations = 100000,
      const double tolerance = 1e-5,
      const bool shuffle = true,
      const UpdatePolicyType& updatePolicy = UpdatePolicyType(),
      const DecayPolicyType& decayPolicy = DecayPolicyType(),
      const bool resetPolicy = true,
      const bool exactObjective = false);

  /**
   * Clean any memory associated with the SGD object.
   */
  ~SGD();

  /**
   * Optimize the given function using stochastic gradient descent.  The given
   * starting point will be modified to store the finishing point of the
   * algorithm, and the final objective value is returned.
   *
   * @tparam SeparableFunctionType Type of the function to be optimized.
   * @tparam MatType Type of matrix to optimize with.
   * @tparam GradType Type of matrix to use to represent function gradients.
   * @tparam v Types of callback functions.
   * @param function Function to optimize.
   * @param iterate Starting point (will be modified).
   * @param callbacks Callback functions.
   * @return Objective value of the final point.
   */
  template<typename SeparableFunctionType,
           typename MatType,
           typename GradType,
           typename... CallbackTypes>
  typename std::enable_if<IsArmaType<GradType>::value,
      typename MatType::elem_type>::type
  Optimize(SeparableFunctionType& function,
           MatType& iterate,
           CallbackTypes&&... callbacks);

  //! Forward the MatType as GradType.
  template<typename SeparableFunctionType,
           typename MatType,
           typename... CallbackTypes>
  typename MatType::elem_type Optimize(SeparableFunctionType& function,
                                       MatType& iterate,
                                       CallbackTypes&&... callbacks)
  {
    return Optimize<SeparableFunctionType, MatType, MatType,
        CallbackTypes...>(function, iterate,
        std::forward<CallbackTypes>(callbacks)...);
  }

  //! Get the step size.
  double StepSize() const { return stepSize; }
  //! Modify the step size.
  double& StepSize() { return stepSize; }

  //! Get the batch size.
  size_t BatchSize() const { return batchSize; }
  //! Modify the batch size.
  size_t& BatchSize() { return batchSize; }

  //! Get the maximum number of iterations (0 indicates no limit).
  size_t MaxIterations() const { return maxIterations; }
  //! Modify the maximum number of iterations (0 indicates no limit).
  size_t& MaxIterations() { return maxIterations; }

  //! Get the tolerance for termination.
  double Tolerance() const { return tolerance; }
  //! Modify the tolerance for termination.
  double& Tolerance() { return tolerance; }

  //! Get whether or not the individual functions are shuffled.
  bool Shuffle() const { return shuffle; }
  //! Modify whether or not the individual functions are shuffled.
  bool& Shuffle() { return shuffle; }

  //! Get whether or not the actual objective is calculated.
  bool ExactObjective() const { return exactObjective; }
  //! Modify whether or not the actual objective is calculated.
  bool& ExactObjective() { return exactObjective; }

  //! Get whether or not the update policy parameters
  //! are reset before Optimize call.
  bool ResetPolicy() const { return resetPolicy; }
  //! Modify whether or not the update policy parameters
  //! are reset before Optimize call.
  bool& ResetPolicy() { return resetPolicy; }

  //! Get the update policy.
  const UpdatePolicyType& UpdatePolicy() const { return updatePolicy; }
  //! Modify the update policy.
  UpdatePolicyType& UpdatePolicy() { return updatePolicy; }

  //! Get the instantiated update policy type.  Be sure to check its type with
  //! Has() before using!
  const Any& InstUpdatePolicy() const { return instUpdatePolicy; }
  //! Modify the instantiated update policy type.  Be sure to check its type
  //! with Has() before using!
  Any& InstUpdatePolicy() { return instUpdatePolicy; }

  //! Get the step size decay policy.
  const DecayPolicyType& DecayPolicy() const { return decayPolicy; }
  //! Modify the step size decay policy.
  DecayPolicyType& DecayPolicy() { return decayPolicy; }

  //! Get the instantiated decay policy type.  Be sure to check its type with
  //! Has() before using!
  const Any& InstDecayPolicy() const { return instDecayPolicy; }
  //! Modify the instantiated decay policy type.  Be sure to check its type with
  //! Has() before using!
  Any& InstDecayPolicy() { return instDecayPolicy; }

 private:
  //! The step size for each example.
  double stepSize;

  //! The batch size for processing.
  size_t batchSize;

  //! The maximum number of allowed iterations.
  size_t maxIterations;

  //! The tolerance for termination.
  double tolerance;

  //! Controls whether or not the individual functions are shuffled when
  //! iterating.
  bool shuffle;

  //! Controls whether or not the actual Objective value is calculated.
  bool exactObjective;

  //! The update policy used to update the parameters in each iteration.
  UpdatePolicyType updatePolicy;

  //! The decay policy used to update the step size.
  DecayPolicyType decayPolicy;

  //! Flag indicating whether update policy
  //! should be reset before running optimization.
  bool resetPolicy;

  //! Flag indicating whether the update policy
  //! parameters have been initialized.
  bool isInitialized;

  //! The initialized update policy.
  Any instUpdatePolicy;
  //! The initialized decay policy.
  Any instDecayPolicy;
};

using StandardSGD = SGD<VanillaUpdate>;

using MomentumSGD = SGD<MomentumUpdate>;

using NesterovMomentumSGD = SGD<NesterovMomentumUpdate>;

using QHSGD = SGD<QHUpdate>;
} // namespace ens

// Include implementation.
#include "sgd_impl.hpp"

#endif
/**
 * @file sgd_impl.hpp
 * @author Ryan Curtin
 * @author Arun Reddy
 * @author Abhinav Moudgil
 *
 * Implementation of stochastic gradient descent.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_SGD_SGD_IMPL_HPP
#define ENSMALLEN_SGD_SGD_IMPL_HPP

// In case it hasn't been included yet.
#include "sgd.hpp"

#include <ensmallen_bits/function.hpp>

namespace ens {

template<typename UpdatePolicyType, typename DecayPolicyType>
SGD<UpdatePolicyType, DecayPolicyType>::SGD(
    const double stepSize,
    const size_t batchSize,
    const size_t maxIterations,
    const double tolerance,
    const bool shuffle,
    const UpdatePolicyType& updatePolicy,
    const DecayPolicyType& decayPolicy,
    const bool resetPolicy,
    const bool exactObjective) :
    stepSize(stepSize),
    batchSize(batchSize),
    maxIterations(maxIterations),
    tolerance(tolerance),
    shuffle(shuffle),
    exactObjective(exactObjective),
    updatePolicy(updatePolicy),
    decayPolicy(decayPolicy),
    resetPolicy(resetPolicy),
    isInitialized(false)
{ /* Nothing to do. */ }

template<typename UpdatePolicyType, typename DecayPolicyType>
SGD<UpdatePolicyType, DecayPolicyType>::~SGD()
{
  // Clean decay and update policies, if they were initialized.
  instDecayPolicy.Clean();
  instUpdatePolicy.Clean();
}

//! Optimize the function (minimize).
template<typename UpdatePolicyType, typename DecayPolicyType>
template<typename SeparableFunctionType,
         typename MatType,
         typename GradType,
         typename... CallbackTypes>
typename std::enable_if<IsArmaType<GradType>::value,
typename MatType::elem_type>::type
SGD<UpdatePolicyType, DecayPolicyType>::Optimize(
    SeparableFunctionType& function,
    MatType& iterateIn,
    CallbackTypes&&... callbacks)
{
  // Convenience typedefs.
  typedef typename MatType::elem_type ElemType;
  typedef typename MatTypeTraits<MatType>::BaseMatType BaseMatType;
  typedef typename MatTypeTraits<GradType>::BaseMatType BaseGradType;

  typedef Function<SeparableFunctionType, BaseMatType, BaseGradType>
      FullFunctionType;
  FullFunctionType& f(static_cast<FullFunctionType&>(function));

  // The update policy and decay policy internally use a templated class so that
  // we can know MatType and GradType only when Optimize() is called.
  typedef typename UpdatePolicyType::template Policy<BaseMatType, BaseGradType>
      InstUpdatePolicyType;
  typedef typename DecayPolicyType::template Policy<BaseMatType, BaseGradType>
      InstDecayPolicyType;

  // Make sure we have all the methods that we need.
  traits::CheckSeparableFunctionTypeAPI<FullFunctionType, BaseMatType,
      BaseGradType>();
  RequireFloatingPointType<BaseMatType>();
  RequireFloatingPointType<BaseGradType>();
  RequireSameInternalTypes<BaseMatType, BaseGradType>();

  BaseMatType& iterate = (BaseMatType&) iterateIn;

  // Find the number of functions to use.
  const size_t numFunctions = f.NumFunctions();

  // To keep track of where we are and how things are going.
  size_t currentFunction = 0;
  size_t epoch = 1;
  ElemType overallObjective = 0;
  ElemType lastObjective = DBL_MAX;

  // Controls early termination of the optimization process.
  bool terminate = false;

  // Initialize the decay policy if needed.
  if (!isInitialized || !instDecayPolicy.Has<InstDecayPolicyType>())
  {
    instDecayPolicy.Clean();
    instDecayPolicy.Set<InstDecayPolicyType>(
        new InstDecayPolicyType(decayPolicy));
  }

  // Initialize the update policy.
  if (resetPolicy || !isInitialized ||
      !instUpdatePolicy.Has<InstUpdatePolicyType>())
  {
    instUpdatePolicy.Clean();
    instUpdatePolicy.Set<InstUpdatePolicyType>(
        new InstUpdatePolicyType(updatePolicy, iterate.n_rows, iterate.n_cols));
    isInitialized = true;
  }

  // Now iterate!
  BaseGradType gradient(iterate.n_rows, iterate.n_cols);
  const size_t actualMaxIterations = (maxIterations == 0) ?
      std::numeric_limits<size_t>::max() : maxIterations;
  Callback::BeginOptimization(*this, f, iterate, callbacks...);
  terminate |= Callback::BeginEpoch(*this, f, iterate, epoch,
      overallObjective, callbacks...);
  for (size_t i = 0; i < actualMaxIterations && !terminate;
      /* incrementing done manually */)
  {
    // Find the effective batch size; we have to take the minimum of three
    // things:
    // - the batch size can't be larger than the user-specified batch size;
    // - the batch size can't be larger than the number of iterations left
    //       before actualMaxIterations is hit;
    // - the batch size can't be larger than the number of functions left.
    const size_t effectiveBatchSize = std::min(
        std::min(batchSize, actualMaxIterations - i),
        numFunctions - currentFunction);

    // Technically we are computing the objective before we take the step, but
    // for many FunctionTypes it may be much quicker to do it like this.
    const ElemType objective = f.EvaluateWithGradient(iterate, currentFunction,
        gradient, effectiveBatchSize);
    overallObjective += objective;

    terminate |= Callback::EvaluateWithGradient(*this, f, iterate, objective,
        gradient, callbacks...);

    // Use the update policy to take a step.
    instUpdatePolicy.As<InstUpdatePolicyType>().Update(iterate, stepSize,
        gradient);

    terminate |= Callback::StepTaken(*this, f, iterate, callbacks...);

    // Now update the learning rate if requested by the user.
    instDecayPolicy.As<InstDecayPolicyType>().Update(iterate, stepSize,
        gradient);

    i += effectiveBatchSize;
    currentFunction += effectiveBatchSize;

    // Is this iteration the start of a sequence?
    if ((currentFunction % numFunctions) == 0)
    {
      terminate |= Callback::EndEpoch(*this, f, iterate, epoch++,
          overallObjective / (ElemType) numFunctions, callbacks...);

      // Output current objective function.
      Info << "SGD: iteration " << i << ", objective " << overallObjective
         << "." << std::endl;

      if (std::isnan(overallObjective) || std::isinf(overallObjective))
      {
        Warn << "SGD: converged to " << overallObjective << "; terminating"
            << " with failure.  Try a smaller step size?" << std::endl;

        Callback::EndOptimization(*this, f, iterate, callbacks...);
        return overallObjective;
      }

      if (std::abs(lastObjective - overallObjective) < tolerance)
      {
        Info << "SGD: minimized within tolerance " << tolerance << "; "
            << "terminating optimization." << std::endl;

        Callback::EndOptimization(*this, f, iterate, callbacks...);
        return overallObjective;
      }

      terminate |= Callback::BeginEpoch(*this, f, iterate, epoch,
          overallObjective, callbacks...);

      // Reset the counter variables.
      lastObjective = overallObjective;
      overallObjective = 0;
      currentFunction = 0;

      if (shuffle) // Determine order of visitation.
        f.Shuffle();
    }
  }

  if (!terminate)
  {
    Info << "SGD: maximum iterations (" << maxIterations << ") reached; "
        << "terminating optimization." << std::endl;
  }

  // Calculate final objective if exactObjective is set to true.
  if (exactObjective)
  {
    overallObjective = 0;
    for (size_t i = 0; i < numFunctions; i += batchSize)
    {
      const size_t effectiveBatchSize = std::min(batchSize, numFunctions - i);
      const ElemType objective = f.Evaluate(iterate, i, effectiveBatchSize);
      overallObjective += objective;

      // The optimization is over, so it doesn't matter what the callback
      // returns.
      (void) Callback::Evaluate(*this, f, iterate, objective, callbacks...);
    }
  }

  Callback::EndOptimization(*this, f, iterate, callbacks...);
  return overallObjective;
}

} // namespace ens

#endif
/**
 * @file gradient_clipping.hpp
 * @author Konstantin Sidorov
 *
 * Gradient clipping update wrapper.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_SGD_GRADIENT_CLIPPING_HPP
#define ENSMALLEN_SGD_GRADIENT_CLIPPING_HPP

namespace ens {

/**
 * Interface for wrapping around update policies (e.g., VanillaUpdate)
 * and feeding a clipped gradient to them instead of the normal one.
 * (Clipping here is implemented as
 * \f$ g_{\text{clipped}} = \max(g_{\text{min}}, \min(g_{\text{min}}, g))) \f$.)
 *
 * @tparam UpdatePolicy A type of UpdatePolicy that sould be wrapped around.
 */
template<typename UpdatePolicyType>
class GradientClipping
{
 public:
  /**
   * Constructor for creating a GradientClipping instance.
   *
   * @param minGradient Minimum possible value of gradient element.
   * @param maxGradient Maximum possible value of gradient element.
   * @param updatePolicy An instance of the UpdatePolicyType
   *                     used for actual optimization.
   */
  GradientClipping(const double minGradient,
                   const double maxGradient,
                   UpdatePolicyType& updatePolicy) :
      minGradient(minGradient),
      maxGradient(maxGradient),
      updatePolicy(updatePolicy)
  {
    // Nothing to do here.
  }

  //! Get the update policy.
  UpdatePolicyType& UpdatePolicy() const { return updatePolicy; }
  //! Modify the update policy.
  UpdatePolicyType& UpdatePolicy() { return updatePolicy; }

  //! Get the minimum gradient value.
  double MinGradient() const { return minGradient; }
  //! Modify the minimum gradient value.
  double& MinGradient() { return minGradient; }

  //! Get the maximum gradient value.
  double MaxGradient() const { return maxGradient; }
  //! Modify the maximum gradient value.
  double& MaxGradient() { return maxGradient; }

  /**
   * The UpdatePolicyType policy classes must contain an internal 'Policy'
   * template class with two template arguments: MatType and GradType.  This is
   * instantiated at the start of the optimization, and holds parameters
   * specific to an individual optimization.
   */
  template<typename MatType, typename GradType>
  class Policy
  {
   public:
    /**
     * This is called by the optimizer method before the start of the iteration
     * update process.
     *
     * @param parent Instantiated parent class.
     * @param rows Number of rows in the gradient matrix.
     * @param cols Number of columns in the gradient matrix.
     */
    Policy(const GradientClipping<UpdatePolicyType>& parent,
           const size_t rows,
           const size_t cols) :
        parent(parent),
        instPolicy(parent.UpdatePolicy(), rows, cols)
    {
      // Nothing to do.
    }

    /**
     * Update step. First, the gradient is clipped, and then the actual update
     * policy does whatever update it needs to do.
     *
     * @param iterate Parameters that minimize the function.
     * @param stepSize Step size to be used for the given iteration.
     * @param gradient The gradient matrix.
     */
    void Update(MatType& iterate,
                const double stepSize,
                const GradType& gradient)
    {
      typedef typename GradType::elem_type GradElemType;

      // First, clip the gradient.
      GradType clippedGradient = arma::clamp(gradient,
          GradElemType(parent.minGradient),
          GradElemType(parent.maxGradient));

      // And only then do the update.
      instPolicy.Update(iterate, stepSize, clippedGradient);
    }

   private:
    // The instantiated parent class.
    const GradientClipping<UpdatePolicyType>& parent;
    // The instantiated update policy we will use.
    typename UpdatePolicyType::template Policy<MatType, GradType> instPolicy;
  };

 private:
  //! Minimum possible value of gradient element.
  double minGradient;

  //! Maximum possible value of gradient element.
  double maxGradient;

  //! An instance of the UpdatePolicy used for actual optimization.
  UpdatePolicyType updatePolicy;
};

} // namespace ens

#endif
/**
 * @file momentum_update.hpp
 * @author Arun Reddy
 *
 * Momentum update for Stochastic Gradient Descent.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_SGD_MOMENTUM_UPDATE_HPP
#define ENSMALLEN_SGD_MOMENTUM_UPDATE_HPP

namespace ens {

/**
 * Momentum update policy for Stochastic Gradient Descent (SGD).
 *
 * Learning with SGD can sometimes be slow.  Using momentum update for parameter
 * learning can accelerate the rate of convergence, specifically in the cases
 * where the surface curves much more steeply(a steep hilly terrain with high
 * curvature).  The momentum algorithm introduces a new velocity vector \f$ v
 * \f$ with the same dimension as the parameter \f$ A \f$.  Also it introduces a
 * new decay hyperparameter momentum \f$ mu \in (0,1] \f$.  The following update
 * scheme is used to update SGD in every iteration:
 *
 * \f[
 * v = mu*v - \alpha \nabla f_i(A)
 * A_{j + 1} = A_j + v
 * \f]
 *
 * where \f$ \alpha \f$ is a parameter which specifies the step size.  \f$ i \f$
 * is chosen according to \f$ j \f$ (the iteration number).  Common values of
 * \f$ mu \f$ include 0.5, 0.9 and 0.99.  Typically it begins with a small value
 * and later raised.
 *
 * For more information, please refer to the Section 8.3.2 of the following book
 *
 * @code
 * @article{rumelhart1988learning,
 *   title   = {Learning representations by back-propagating errors},
 *   author  = {Rumelhart, David E. and Hinton, Geoffrey E. and
 *              Williams, Ronald J.},
 *   journal = {Cognitive Modeling},
 *   volume  = {5},
 *   number  = {3},
 *   pages   = {1},
 *   year    = {1988}
 * }
 *
 * @code
 * @book{Goodfellow-et-al-2016,
 *  title     = {Deep Learning},
 *  author    = {Ian Goodfellow and Yoshua Bengio and Aaron Courville},
 *  publisher = {MIT Press},
 *  note      = {\url{http://www.deeplearningbook.org}},
 *  year      = {2016}
 * }
 */
class MomentumUpdate
{
 public:
  /**
   * Construct the momentum update policy with given momentum decay parameter.
   *
   * @param momentum The momentum decay hyperparameter
   */
  MomentumUpdate(const double momentum = 0.5) : momentum(momentum)
  { /* Do nothing. */ };

  //! Access the momentum.
  double Momentum() const { return momentum; }
  //! Modify the momentum.
  double& Momentum() { return momentum; }

  /**
   * The UpdatePolicyType policy classes must contain an internal 'Policy'
   * template class with two template arguments: MatType and GradType.  This is
   * instantiated at the start of the optimization, and holds parameters
   * specific to an individual optimization.
   */
  template<typename MatType, typename GradType>
  class Policy
  {
   public:
    /**
     * This is called by the optimizer method before the start of the iteration
     * update process.
     *
     * @param parent Instantiated parent class.
     * @param rows Number of rows in the gradient matrix.
     * @param cols Number of columns in the gradient matrix.
     */
    Policy(const MomentumUpdate& parent, const size_t rows, const size_t cols) :
        parent(parent),
        velocity(arma::zeros<MatType>(rows, cols))
    {
      // Nothing to do.
    }

    /**
     * Update step for SGD.  The momentum term makes the convergence faster on
     * the way as momentum term increases for dimensions pointing in the same
     * and reduces updates for dimensions whose gradients change directions.
     *
     * @param iterate Parameters that minimize the function.
     * @param stepSize Step size to be used for the given iteration.
     * @param gradient The gradient matrix.
     */
    void Update(MatType& iterate,
                const double stepSize,
                const GradType& gradient)
    {
      velocity = parent.momentum * velocity - stepSize * gradient;
      iterate += velocity;
    }

   private:
    // The instantiated parent class.
    const MomentumUpdate& parent;
    // The velocity matrix.
    MatType velocity;
  };

 private:
  // The momentum hyperparameter.
  double momentum;
};

} // namespace ens

#endif
/**
 * @file nesterov_momentum_update.hpp
 * @author Sourabh Varshney
 *
 * Nesterov Momentum Update for Stochastic Gradient Descent.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_SGD_NESTEROV_MOMENTUM_UPDATE_HPP
#define ENSMALLEN_SGD_NESTEROV_MOMENTUM_UPDATE_HPP

namespace ens {

/**
 * Nesterov Momentum update policy for Stochastic Gradient Descent (SGD).
 *
 * Learning with SGD can be slow. Applying Standard momentum can accelerate
 * the rate of convergence. Nesterov Momentum application can accelerate the
 * rate of convergence to O(1/k^2).
 *
 * @code
 * @techreport{Nesterov1983,
 *   title       = {A Method Of Solving A Convex Programming Problem With
 *                  Convergence Rate O(1/K^2)},
 *   author      = {Yuri Nesterov},
 *   institution = {Soviet Math. Dokl.},
 *   volume      = {27},
 *   year        = {1983},
 * }
 * @endcode
 */
class NesterovMomentumUpdate
{
 public:
  /**
   * Construct the Nesterov Momentum update policy with the given parameters.
   */
  NesterovMomentumUpdate(const double momentum = 0.5) : momentum(momentum)
  {
    // Nothing to do.
  }

  //! Get the value used to initialize the momentum coefficient.
  double Momentum() const { return momentum; }
  //! Modify the value used to initialize the momentum coefficient.
  double& Momentum() { return momentum; }

  /**
   * The UpdatePolicyType policy classes must contain an internal 'Policy'
   * template class with two template arguments: MatType and GradType.  This is
   * instantiated at the start of the optimization, and holds parameters
   * specific to an individual optimization.
   */
  template<typename MatType, typename GradType>
  class Policy
  {
   public:
    /**
     * This is called by the optimizer method before the start of the iteration
     * update process.
     *
     * @param parent Instantiated parent class.
     * @param rows Number of rows in the gradient matrix.
     * @param cols Number of columns in the gradient matrix.
     */
    Policy(const NesterovMomentumUpdate& parent,
           const size_t rows,
           const size_t cols) :
        parent(parent),
        velocity(arma::zeros<MatType>(rows, cols))
    {
      // Nothing to do.
    }

    /**
     * Update step for SGD.  The momentum term makes the convergence faster on
     * the way as momentum term increases for dimensions pointing in the same
     * direction and reduces updates for dimensions whose gradients change
     * directions.
     *
     * @param iterate Parameters that minimize the function.
     * @param stepSize Step size to be used for the given iteration.
     * @param gradient The gradient matrix.
     */
    void Update(MatType& iterate,
                const double stepSize,
                const GradType& gradient)
    {
      velocity = parent.momentum * velocity - stepSize * gradient;

      iterate += parent.momentum * velocity - stepSize * gradient;
    }

   private:
    // The parent class instantiation.
    const NesterovMomentumUpdate& parent;
    // The velocity matrix.
    MatType velocity;
  };

 private:
  // The Momentum coefficient.
  double momentum;
};

} // namespace ens

#endif
/**
 * @file quasi_hyperbolic_update.hpp
 * @author Niteya Shah
 *
 * Quasi Hyperbolic Update for Stochastic Gradient Descent.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_SGD_QH_UPDATE_HPP
#define ENSMALLEN_SGD_QH_UPDATE_HPP

namespace ens {

/**
 * Quasi Hyperbolic Update policy for Stochastic Gradient Descent (QHSGD).
 *
 * QHSGD is a update policy that is defined to be a parent of most update
 * policies (most update policies can reconstructed from QHSGD). This allows
 * this method to combine the features of many optimisers and provide better
 * optimisation control.
 *
 * @code
 * @inproceedings{ma2019qh,
 *   title={Quasi-hyperbolic momentum and Adam for deep learning},
 *   author={Jerry Ma and Denis Yarats},
 *   booktitle={International Conference on Learning Representations},
 *   year={2019}
 * }
 * @endcode
 */
class QHUpdate
{
 public:
  /**
   * Construct the Quasi Hyperbolic update policy with the given parameters.
   *
   * @param v The quasi hyperbolic term.
   * @param momentum The momentum term.
   */
  QHUpdate(const double v = 0.7,
           const double momentum = 0.999) :
       momentum(momentum),
       v(v)
  {
    // Nothing to do.
  }

  //! Get the value used to initialize the momentum coefficient.
  double Momentum() const { return momentum; }
  //! Modify the value used to initialize the momentum coefficient.
  double& Momentum() { return momentum; }

  //! Get the value used to initialize the momentum coefficient.
  double V() const { return v; }
  //! Modify the value used to initialize the momentum coefficient.
  double& V() { return v; }

  /**
   * The UpdatePolicyType policy classes must contain an internal 'Policy'
   * template class with two template arguments: MatType and GradType.  This is
   * instantiated at the start of the optimization, and holds parameters
   * specific to an individual optimization.
   */
  template<typename MatType, typename GradType>
  class Policy
  {
   public:
    /**
     * This constructor is called by the SGD Optimize() method before the start
     * of the iteration update process.
     *
     * @param parent AdamUpdate object.
     * @param rows Number of rows in the gradient matrix.
     * @param cols Number of columns in the gradient matrix.
     */
    Policy(QHUpdate& parent, const size_t rows, const size_t cols) :
        parent(parent)
    {
      // Initialize an empty velocity matrix.
      velocity.zeros(rows, cols);
    }

    /**
     * Update step for QHSGD.
     *
     * @param iterate Parameters that minimize the function.
     * @param stepSize Step size to be used for the given iteration.
     * @param gradient The gradient matrix.
     */
    void Update(MatType& iterate,
                const double stepSize,
                const GradType& gradient)
    {
      velocity *= parent.momentum;
      velocity += (1 - parent.momentum) * gradient;

      iterate -= stepSize * ((1 - parent.v) * gradient + parent.v * velocity);
    }

   private:
    //! Instantiated parent object.
    QHUpdate& parent;

    //! The velocity matrix.
    GradType velocity;
  };

 private:
  // The momentum coefficient.
  double momentum;

  //The quasi-hyperbolic term.
  double v;
};

} // namespace ens

#endif
/**
 * @file vanilla_update.hpp
 * @author Arun Reddy
 *
 * Vanilla update for Stochastic Gradient Descent.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_SGD_EMPTY_UPDATE_HPP
#define ENSMALLEN_SGD_EMPTY_UPDATE_HPP

namespace ens {

/**
 * Vanilla update policy for Stochastic Gradient Descent (SGD). The following
 * update scheme is used to update SGD in every iteration:
 *
 * \f[
 * A_{j + 1} = A_j + \alpha \nabla f_i(A)
 * \f]
 *
 * where \f$ \alpha \f$ is a parameter which specifies the step size.  \f$ i \f$
 * is chosen according to \f$ j \f$ (the iteration number).
 */
class VanillaUpdate
{
 public:
  /**
   * The UpdatePolicyType policy classes must contain an internal 'Policy'
   * template class with two template arguments: MatType and GradType.  This is
   * instantiated at the start of the optimization.
   */
  template<typename MatType, typename GradType>
  class Policy
  {
   public:
    /**
     * This is called by the optimizer method before the start of the iteration
     * update process.  The vanilla update doesn't initialize anything.
     *
     * @param parent Instantiated parent class.
     * @param rows Number of rows in the gradient matrix.
     * @param cols Number of columns in the gradient matrix.
     */
    Policy(const VanillaUpdate& /* parent */,
           const size_t /* rows */,
           const size_t /* cols */)
    { /* Do nothing. */ }

   /**
    * Update step for SGD.  The function parameters are updated in the negative
    * direction of the gradient.
    *
    * @param iterate Parameters that minimize the function.
    * @param stepSize Step size to be used for the given iteration.
    * @param gradient The gradient matrix.
    */
    void Update(MatType& iterate,
                const double stepSize,
                const GradType& gradient)
    {
      // Perform the vanilla SGD update.
      iterate -= stepSize * gradient;
    }
  };
};

} // namespace ens

#endif
/**
 * @file cyclical_decay.hpp
 * @author Marcus Edel
 *
 * Definition of the warm restart technique (SGDR) described in:
 * "SGDR: Stochastic Gradient Descent with Warm Restarts" by
 * I. Loshchilov et al.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */

#ifndef ENSMALLEN_SGDR_CYCLICAL_DECAY_HPP
#define ENSMALLEN_SGDR_CYCLICAL_DECAY_HPP

namespace ens {

/**
 * Simulate a new warm-started run/restart once a number of epochs are
 * performed. Importantly, the restarts are not performed from scratch but
 * emulated by increasing the step size while the old step size value of as an
 * initial parameter.
 *
 * For more information, please refer to:
 *
 * @code
 * @article{Loshchilov2016,
 *   author  = {Ilya Loshchilov and Frank Hutter},
 *   title   = {{SGDR:} Stochastic Gradient Descent with Restarts},
 *   journal = {CoRR},
 *   year    = {2016},
 *   url     = {https://arxiv.org/abs/1608.03983}
 * }
 * @endcode
 */
class CyclicalDecay
{
 public:
  /**
   * Construct the CyclicalDecay technique a restart method, where the
   * step size decays after each batch and peridically resets to its initial
   * value.
   *
   * @param epochRestart Initial epoch where decay is applied.
   * @param multFactor Factor to increase the number of epochs before a restart.
   * @param stepSize Initial step size for each restart.
   * @param batchSize Size of each mini-batch.
   * @param numFunctions The number of separable functions (the number of
   *        predictor points).
   */
  CyclicalDecay(const size_t epochRestart,
                const double multFactor,
                const double stepSize) :
      epochRestart(epochRestart),
      multFactor(multFactor),
      constStepSize(stepSize),
      nextRestart(epochRestart),
      batchRestart(0),
      epochBatches(0),
      epoch(0)
  { /* Nothing to do here */ }

  //! Get the step size.
  double StepSize() const { return constStepSize; }
  //! Modify the step size.
  double& StepSize() { return constStepSize; }

  //! Get the restart fraction.
  double EpochBatches() const { return epochBatches; }
  //! Modify the restart fraction.
  double& EpochBatches() { return epochBatches; }

  //! Get the epoch where decay is applied.
  size_t EpochRestart() const { return epochRestart; }
  //! Modify the epoch where decay is applied.
  size_t& EpochRestart() { return epochRestart; }

  //! Get the parameter to modify epochs before a restart.
  double MultFactor() const { return multFactor; }
  //! Modify the parameter to modify epochs before a restart.
  double& MultFactor() { return multFactor; }

  //! Get the next restart time.
  size_t NextRestart() const { return nextRestart; }
  //! Modify the next restart time.
  size_t& NextRestart() { return nextRestart; }

  //! Get the number of batches since the last restart.
  size_t BatchRestart() const { return batchRestart; }
  //! Modify the number of batches since the last restart.
  size_t& BatchRestart() { return batchRestart; }

  //! Get the epoch.
  size_t Epoch() const { return epoch; }
  //! Modify the epoch.
  size_t& Epoch() { return epoch; }

  /**
   * The DecayPolicyType policy classes must contain an internal 'Policy'
   * template class with two template arguments: MatType and GradType.  This is
   * initialized at the start of the optimization, and holds parameters specific
   * to an individual optimization.
   */
  template<typename MatType, typename GradType>
  class Policy
  {
   public:
    /**
     * This constructor is called by the SGD Optimize() method before the start
     * of the iteration update process.
     */
    Policy(CyclicalDecay& parent) : parent(parent) { }

    /**
     * This function is called in each iteration after the policy update.
     *
     * @param iterate Parameters that minimize the function.
     * @param stepSize Step size to be used for the given iteration.
     * @param gradient The gradient matrix.
     */
    void Update(MatType& /* iterate */,
                double& stepSize,
                const GradType& /* gradient */)
    {
      // Time to adjust the step size.
      if (parent.epoch >= parent.epochRestart)
      {
        // n_t = n_min^i + 0.5(n_max^i - n_min^i)(1 + cos(T_cur/T_i * pi)).
        stepSize = 0.5 * parent.constStepSize *
            (1 + cos((parent.batchRestart / parent.epochBatches)
            * arma::datum::pi));

        // Keep track of the number of batches since the last restart.
        parent.batchRestart++;
      }

      // Time to restart.
      if (parent.epoch > parent.nextRestart)
      {
        parent.batchRestart = 0;

        // Adjust the period of restarts.
        parent.epochRestart *= parent.multFactor;

        // Update the time for the next restart.
        parent.nextRestart += parent.epochRestart;
      }

      parent.epoch++;
    }

   private:
    // Reference to the parent object.
    CyclicalDecay& parent;
  };

 private:
  //! Epoch where decay is applied.
  size_t epochRestart;

  //! Parameter to increase the number of epochs before a restart.
  double multFactor;

  //! The step size for each example.
  double constStepSize;

  //! Locally-stored restart time.
  size_t nextRestart;

  //! Locally-stored number of batches since the last restart.
  size_t batchRestart;

  //! Locally-stored restart fraction.
  double epochBatches;

  //! Locally-stored epoch.
  size_t epoch;
};

} // namespace ens

#endif // ENSMALLEN_SGDR_CYCLICAL_DECAY_HPP
/**
 * @file sgdr.hpp
 * @author Marcus Edel
 *
 * Definition of the Stochastic Gradient Descent with Restarts (SGDR) as
 * described in: "SGDR: Stochastic Gradient Descent with Warm Restarts" by
 * I. Loshchilov et al.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_SGDR_SGDR_HPP
#define ENSMALLEN_SGDR_SGDR_HPP

#include <ensmallen_bits/sgd/sgd.hpp>
#include <ensmallen_bits/sgd/update_policies/momentum_update.hpp>
#include "cyclical_decay.hpp"

namespace ens {

/**
 * This class is based on Mini-batch Stochastic Gradient Descent class and
 * simulates a new warm-started run/restart once a number of epochs are
 * performed.
 *
 * For more information, please refer to:
 *
 * @code
 * @article{Loshchilov2016,
 *   title   = {{SGDR:} Stochastic Gradient Descent with Restarts},
 *   author  = {Ilya Loshchilov and Frank Hutter},
 *   journal = {CoRR},
 *   year    = {2016},
 *   url     = {https://arxiv.org/abs/1608.03983}
 * }
 * @endcode
 *
 * SGDR can optimize differentiable separable functions.  For more details, see
 * the documentation on function types included with this distribution or on the
 * ensmallen website.
 *
 * @tparam UpdatePolicyType Update policy used during the iterative update
 *         process. By default the momentum update policy (see
 *         ens::MomentumUpdate) is used.
 */
template<typename UpdatePolicyType = MomentumUpdate>
class SGDR
{
 public:
  //! Convenience typedef for the internal optimizer construction.
  using OptimizerType = SGD<UpdatePolicyType, CyclicalDecay>;

  /**
   * Construct the SGDR optimizer with the given function and
   * parameters.  The defaults here are not necessarily good for the given
   * problem, so it is suggested that the values used be tailored for the task
   * at hand.  The maximum number of iterations refers to the maximum number of
   * mini-batches that are processed.
   *
   * @param epochRestart Initial epoch where decay is applied.
   * @param batchSize Size of each mini-batch.
   * @param stepSize Step size for each iteration.
   * @param maxIterations Maximum number of iterations allowed (0 means no
   *        limit).
   * @param tolerance Maximum absolute tolerance to terminate algorithm.
   * @param shuffle If true, the mini-batch order is shuffled; otherwise, each
   *        mini-batch is visited in linear order.
   * @param updatePolicy Instantiated update policy used to adjust the given
   *        parameters.
   * @param resetPolicy If true, parameters are reset before every Optimize
   *        call; otherwise, their values are retained.
   * @param exactObjective Calculate the exact objective (Default: estimate the
   *        final objective obtained on the last pass over the data).
   */
  SGDR(const size_t epochRestart = 50,
       const double multFactor = 2.0,
       const size_t batchSize = 1000,
       const double stepSize = 0.01,
       const size_t maxIterations = 100000,
       const double tolerance = 1e-5,
       const bool shuffle = true,
       const UpdatePolicyType& updatePolicy = UpdatePolicyType(),
       const bool resetPolicy = true,
       const bool exactObjective = false);

  /**
   * Optimize the given function using SGDR.  The given starting point
   * will be modified to store the finishing point of the algorithm, and the
   * final objective value is returned.
   *
   * @tparam SeparableFunctionType Type of the function to be optimized.
   * @tparam MatType Type of matrix to optimize with.
   * @tparam GradType Type of matrix to use to represent function gradients.
   * @tparam CallbackTypes Types of callback functions.
   * @param function Function to be optimized.
   * @param iterate Starting point (will be modified).
   * @param callbacks Callback functions.
   * @return Objective value of the final point.
   */
  template<typename SeparableFunctionType,
           typename MatType,
           typename GradType,
           typename... CallbackTypes>
  typename std::enable_if<IsArmaType<GradType>::value,
      typename MatType::elem_type>::type
  Optimize(SeparableFunctionType& function,
           MatType& iterate,
           CallbackTypes&&... callbacks);

  //! Forward the MatType as GradType.
  template<typename SeparableFunctionType,
           typename MatType,
           typename... CallbackTypes>
  typename MatType::elem_type Optimize(SeparableFunctionType& function,
                                       MatType& iterate,
                                       CallbackTypes&&... callbacks)
  {
    return Optimize<SeparableFunctionType, MatType, MatType,
        CallbackTypes...>(function, iterate,
        std::forward<CallbackTypes>(callbacks)...);
  }

  //! Get the batch size.
  size_t BatchSize() const { return optimizer.BatchSize(); }
  //! Modify the batch size.
  size_t& BatchSize() { return optimizer.BatchSize(); }

  //! Get the step size.
  double StepSize() const { return optimizer.StepSize(); }
  //! Modify the step size.
  double& StepSize() { return optimizer.StepSize(); }

  //! Get the maximum number of iterations (0 indicates no limit).
  size_t MaxIterations() const { return optimizer.MaxIterations(); }
  //! Modify the maximum number of iterations (0 indicates no limit).
  size_t& MaxIterations() { return optimizer.MaxIterations(); }

  //! Get the tolerance for termination.
  double Tolerance() const { return optimizer.Tolerance(); }
  //! Modify the tolerance for termination.
  double& Tolerance() { return optimizer.Tolerance(); }

  //! Get whether or not the individual functions are shuffled.
  bool Shuffle() const { return optimizer.Shuffle(); }
  //! Modify whether or not the individual functions are shuffled.
  bool& Shuffle() { return optimizer.Shuffle(); }

  //! Get whether or not the actual objective is calculated.
  bool ExactObjective() const { return optimizer.ExactObjective(); }
  //! Modify whether or not the actual objective is calculated.
  bool& ExactObjective() { return optimizer.ExactObjective(); }

  //! Get the update policy.
  const UpdatePolicyType& UpdatePolicy() const
  {
    return optimizer.UpdatePolicy();
  }
  //! Modify the update policy.
  UpdatePolicyType& UpdatePolicy()
  {
    return optimizer.UpdatePolicy();
  }

  //! Get whether or not the update policy parameters
  //! are reset before Optimize call.
  bool ResetPolicy() const { return optimizer.ResetPolicy(); }
  //! Modify whether or not the update policy parameters
  //! are reset before Optimize call.
  bool& ResetPolicy() { return optimizer.ResetPolicy(); }

 private:
  //! The size of each mini-batch.
  size_t batchSize;

  //! Locally-stored optimizer instance.
  OptimizerType optimizer;
};

} // namespace ens

// Include implementation.
#include "sgdr_impl.hpp"

#endif
/**
 * @file sgdr_impl.hpp
 * @author Marcus Edel
 *
 * Implementation of SGDR method.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_SGDR_SGDR_IMPL_HPP
#define ENSMALLEN_SGDR_SGDR_IMPL_HPP

// In case it hasn't been included yet.
#include "sgdr.hpp"

namespace ens {

template<typename UpdatePolicyType>
SGDR<UpdatePolicyType>::SGDR(
    const size_t epochRestart,
    const double multFactor,
    const size_t batchSize,
    const double stepSize,
    const size_t maxIterations,
    const double tolerance,
    const bool shuffle,
    const UpdatePolicyType& updatePolicy,
    const bool resetPolicy,
    const bool exactObjective) :
    batchSize(batchSize),
    optimizer(OptimizerType(stepSize,
                            batchSize,
                            maxIterations,
                            tolerance,
                            shuffle,
                            updatePolicy,
                            CyclicalDecay(
                                epochRestart,
                                multFactor,
                                stepSize),
                            resetPolicy,
                            exactObjective))
{
  /* Nothing to do here */
}

template<typename UpdatePolicyType>
template<typename SeparableFunctionType, typename MatType, typename GradType,
         typename... CallbackTypes>
typename std::enable_if<IsArmaType<GradType>::value,
typename MatType::elem_type>::type
SGDR<UpdatePolicyType>::Optimize(
    SeparableFunctionType& function,
    MatType& iterate,
    CallbackTypes&&... callbacks)
{
  // If a user changed the step size he hasn't update the step size of the
  // cyclical decay instantiation, so we have to do it here.
  if (optimizer.StepSize() != optimizer.DecayPolicy().StepSize())
  {
    optimizer.DecayPolicy().StepSize() = optimizer.StepSize();
  }

  optimizer.DecayPolicy().EpochBatches() = function.NumFunctions() /
      double(optimizer.BatchSize());

  // If a user changed the batch size we have to update the restart fraction
  // of the cyclical decay instantiation.
  if (optimizer.BatchSize() != batchSize)
  {
    batchSize = optimizer.BatchSize();
  }

  return optimizer.Optimize(function, iterate, callbacks...);
}

} // namespace ens

#endif
/**
 * @file snapshot_ensembles.hpp
 * @author Marcus Edel
 *
 * Definition of the Snapshot ensembles technique described in:
 * "Snapshot ensembles: Train 1, get m for free" by G. Huang et al.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */

#ifndef ENSMALLEN_SGDR_SNAPSHOT_ENSEMBLES_HPP
#define ENSMALLEN_SGDR_SNAPSHOT_ENSEMBLES_HPP

namespace ens {

/**
 * Simulate a new warm-started run/restart once a number of epochs are
 * performed. Importantly, the restarts are not performed from scratch but
 * emulated by increasing the step size while the old step size value of as an
 * initial parameter.
 *
 * For more information, please refer to:
 *
 * @code
 * @inproceedings{Huang2017,
 *   title     = {Snapshot ensembles: Train 1, get m for free},
 *   author    = {Gao Huang, Yixuan Li, Geoff Pleiss, Zhuang Liu,
 *                John E. Hopcroft, and Kilian Q. Weinberger},
 *   booktitle = {Proceedings of the International Conference on Learning
 *                Representations (ICLR)},
 *   year      = {2017},
 *   url       = {https://arxiv.org/abs/1704.00109}
 * }
 * @endcode
 */
class SnapshotEnsembles
{
 public:
  /**
   * Construct the CyclicalDecay technique a restart method, where the
   * step size decays after each batch and peridically resets to its initial
   * value.
   *
   * @param epochRestart Initial epoch where decay is applied.
   * @param multFactor Factor to increase the number of epochs before a restart.
   * @param stepSize Initial step size for each restart.
   * @param batchSize Size of each mini-batch.
   * @param numFunctions The number of separable functions (the number of
   *        predictor points).
   * @param maxIterations Maximum number of iterations allowed (0 means no
   *        limit).
   * @param snapshots Maximum number of snapshots.
   */
  SnapshotEnsembles(const size_t epochRestart,
                    const double multFactor,
                    const double stepSize,
                    const size_t maxIterations,
                    const size_t snapshots) :
    epochRestart(epochRestart),
    multFactor(multFactor),
    constStepSize(stepSize),
    nextRestart(epochRestart),
    batchRestart(0),
    epochBatches(0),
    epoch(0)
  {
    snapshotEpochs = 0;
    for (size_t i = 0, er = epochRestart, nr = nextRestart;
        i < maxIterations; ++i)
    {
      if (i > nr)
      {
        er *= multFactor;
        nr += er;
        snapshotEpochs++;
      }
    }

    snapshotEpochs = epochRestart * std::pow(multFactor,
        snapshotEpochs - snapshots + 1);
  }

  //! Get the step size.
  double StepSize() const { return constStepSize; }
  //! Modify the step size.
  double& StepSize() { return constStepSize; }

  //! Get the restart fraction.
  double EpochBatches() const { return epochBatches; }
  //! Modify the restart fraction.
  double& EpochBatches() { return epochBatches; }

  //! Get the epoch where decay is applied.
  size_t EpochRestart() const { return epochRestart; }
  //! Modify the epoch where decay is applied.
  size_t& EpochRestart() { return epochRestart; }

  //! Get the factor for modifying epochs in a restart.
  double MultFactor() const { return multFactor; }
  //! Modify the factor for modifying epochs in a restart.
  double& MultFactor() { return multFactor; }

  //! Get the next restart time.
  size_t NextRestart() const { return nextRestart; }
  //! Modify the next restart time.
  size_t& NextRestart() { return nextRestart; }

  //! Get the number of batches since the last restart.
  size_t BatchRestart() const { return batchRestart; }
  //! Modify the number of batches since the last restart.
  size_t& BatchRestart() { return batchRestart; }

  //! Get the current epoch.
  size_t Epoch() const { return epoch; }
  //! Modify the current epoch.
  size_t& Epoch() { return epoch; }

  //! Get the number of epochs needed for a new snapshot.
  size_t SnapshotEpochs() const { return snapshotEpochs; }
  //! Modify the number of epochs needed for a new snapshot.
  size_t& SnapshotEpochs() { return snapshotEpochs; }

  /**
   * The DecayPolicyType policy classes must contain an internal 'Policy'
   * template class with two template arguments: MatType and GradType.  This is
   * initialized at the start of the optimization, and holds parameters specific
   * to an individual optimization.
   */
  template<typename MatType, typename GradType>
  class Policy
  {
   public:
    /**
     * This constructor is called by the SGD Optimize() method before the start
     * of the iteration update process.
     */
    Policy(SnapshotEnsembles& parent) : parent(parent) { }

    /**
     * This function is called in each iteration after the policy update.
     *
     * @param iterate Parameters that minimize the function.
     * @param stepSize Step size to be used for the given iteration.
     * @param gradient The gradient matrix.
     */
    void Update(MatType& iterate,
                double& stepSize,
                const GradType& /* gradient */)
    {
      // Time to adjust the step size.
      if (parent.epoch >= parent.epochRestart)
      {
        // n_t = n_min^i + 0.5(n_max^i - n_min^i)(1 + cos(T_cur/T_i * pi)).
        stepSize = 0.5 * parent.constStepSize *
            (1 + cos((parent.batchRestart / parent.epochBatches)
            * arma::datum::pi));

        // Keep track of the number of batches since the last restart.
        parent.batchRestart++;
      }

      // Time to restart.
      if (parent.epoch > parent.nextRestart)
      {
        parent.batchRestart = 0;

        // Adjust the period of restarts.
        parent.epochRestart *= parent.multFactor;

        // Create a new snapshot.
        if (parent.epochRestart >= parent.snapshotEpochs)
        {
          snapshots.push_back(iterate);
        }

        // Update the time for the next restart.
        parent.nextRestart += parent.epochRestart;
      }

      parent.epoch++;
    }

    //! Get the snapshots.
    std::vector<MatType> Snapshots() const { return snapshots; }
    //! Modify the snapshots.
    std::vector<MatType>& Snapshots() { return snapshots; }

   private:
    // Reference to the instantiated parent object.
    SnapshotEnsembles& parent;
    //! Locally-stored parameter snapshots.
    std::vector<MatType> snapshots;
  };

 private:
  //! Epoch where decay is applied.
  size_t epochRestart;

  //! Parameter to increase the number of epochs before a restart.
  double multFactor;

  //! The step size for each example.
  double constStepSize;

  //! Locally-stored restart time.
  size_t nextRestart;

  //! Locally-stored number of batches since the last restart.
  size_t batchRestart;

  //! Locally-stored restart fraction.
  double epochBatches;

  //! Locally-stored epoch.
  size_t epoch;

  //! Epochs where a new snapshot is created.
  size_t snapshotEpochs;
};

} // namespace ens

#endif // ENSMALLEN_SGDR_CYCLICAL_DECAY_HPP
/**
 * @file snapshots_sgdr.hpp
 * @author Marcus Edel
 *
 * Definition of the Stochastic Gradient Descent with Restarts (SGDR) as
 * described in: "SGDR: Stochastic Gradient Descent with Warm Restarts" by
 * I. Loshchilov et al and the Snapshot ensembles technique described in:
 * "Snapshot ensembles: Train 1, get m for free" by G. Huang et al.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_SGDR_SNAPSHOT_SGDR_HPP
#define ENSMALLEN_SGDR_SNAPSHOT_SGDR_HPP

#include <ensmallen_bits/sgd/sgd.hpp>
#include <ensmallen_bits/sgd/update_policies/momentum_update.hpp>
#include "snapshot_ensembles.hpp"

namespace ens {

/**
 * This class is based on Mini-batch Stochastic Gradient Descent class and
 * simulates a new warm-started run/restart once a number of epochs are
 * performed using the Snapshot ensembles technique.
 *
 * For more information, please refer to:
 *
 * @code
 * @article{Loshchilov2016,
 *   title   = {{SGDR:} Stochastic Gradient Descent with Restarts},
 *   author  = {Ilya Loshchilov and Frank Hutter},
 *   journal = {CoRR},
 *   year    = {2016},
 *   url     = {https://arxiv.org/abs/1608.03983}
 * }
 * @endcode
 *
 * @code
 * @inproceedings{Huang2017,
 *   title     = {Snapshot ensembles: Train 1, get m for free},
 *   author    = {Gao Huang, Yixuan Li, Geoff Pleiss, Zhuang Liu,
 *                John E. Hopcroft, and Kilian Q. Weinberger},
 *   booktitle = {Proceedings of the International Conference on Learning
 *                Representations (ICLR)},
 *   year      = {2017},
 *   url       = {https://arxiv.org/abs/1704.00109}
 * }
 * @endcode
 *
 * SnapshotSGDR can optimize differentiable separable functions.  For more
 * details, see the documentation on function types included with this
 * distribution or on the ensmallen website.
 *
 * @tparam UpdatePolicyType Update policy used during the iterative update
 *         process. By default the momentum update policy (see
 *         ens::MomentumUpdate) is used.
 */
template<typename UpdatePolicyType = MomentumUpdate>
class SnapshotSGDR
{
 public:
  //! Convenience typedef for the internal optimizer construction.
  using OptimizerType = SGD<UpdatePolicyType, SnapshotEnsembles>;

  /**
   * Construct the SnapshotSGDR optimizer with snapshot ensembles with the given
   * function and parameters. The defaults here are not necessarily good for
   * the given problem, so it is suggested that the values used be tailored for
   * the task at hand.  The maximum number of iterations refers to the maximum
   * number of mini-batches that are processed.
   *
   * @param epochRestart Initial epoch where decay is applied.
   * @param batchSize Size of each mini-batch.
   * @param stepSize Step size for each iteration.
   * @param maxIterations Maximum number of iterations allowed (0 means no
   *        limit).
   * @param tolerance Maximum absolute tolerance to terminate algorithm.
   * @param shuffle If true, the mini-batch order is shuffled; otherwise, each
   *        mini-batch is visited in linear order.
   * @param snapshots Maximum number of snapshots.
   * @param accumulate Accumulate the snapshot parameter (default true).
   * @param updatePolicy Instantiated update policy used to adjust the given
   *        parameters.
   * @param resetPolicy If true, parameters are reset before every Optimize
   *        call; otherwise, their values are retained.
   * @param exactObjective Calculate the exact objective (Default: estimate the
   *        final objective obtained on the last pass over the data).
   */
  SnapshotSGDR(const size_t epochRestart = 50,
               const double multFactor = 2.0,
               const size_t batchSize = 1000,
               const double stepSize = 0.01,
               const size_t maxIterations = 100000,
               const double tolerance = 1e-5,
               const bool shuffle = true,
               const size_t snapshots = 5,
               const bool accumulate = true,
               const UpdatePolicyType& updatePolicy = UpdatePolicyType(),
               const bool resetPolicy = true,
               const bool exactObjective = false);

  /**
   * Optimize the given function using SGDR.  The given starting point
   * will be modified to store the finishing point of the algorithm, and the
   * final objective value is returned.
   *
   * @tparam SeparableFunctionType Type of function to optimize.
   * @tparam MatType Type of matrix to optimize with.
   * @tparam GradType Type of matrix to use to represent function gradients.
   * @tparam CallbackTypes Types of callback functions.
   * @param function Function to optimize.
   * @param iterate Starting point (will be modified).
   * @param callbacks Callback functions.
   * @return Objective value of the final point.
   */
  template<typename SeparableFunctionType,
           typename MatType,
           typename GradType,
           typename... CallbackTypes>
  typename std::enable_if<IsArmaType<GradType>::value,
      typename MatType::elem_type>::type
  Optimize(SeparableFunctionType& function,
           MatType& iterate,
           CallbackTypes&&... callbacks);

  //! Forward the MatType as GradType.
  template<typename SeparableFunctionType,
           typename MatType,
           typename... CallbackTypes>
  typename MatType::elem_type Optimize(SeparableFunctionType& function,
                                       MatType& iterate,
                                       CallbackTypes&&... callbacks)
  {
    return Optimize<SeparableFunctionType, MatType, MatType,
        CallbackTypes...>(function, iterate,
        std::forward<CallbackTypes>(callbacks)...);
  }

  //! Get the batch size.
  size_t BatchSize() const { return optimizer.BatchSize(); }
  //! Modify the batch size.
  size_t& BatchSize() { return optimizer.BatchSize(); }

  //! Get the step size.
  double StepSize() const { return optimizer.StepSize(); }
  //! Modify the step size.
  double& StepSize() { return optimizer.StepSize(); }

  //! Get the maximum number of iterations (0 indicates no limit).
  size_t MaxIterations() const { return optimizer.MaxIterations(); }
  //! Modify the maximum number of iterations (0 indicates no limit).
  size_t& MaxIterations() { return optimizer.MaxIterations(); }

  //! Get the tolerance for termination.
  double Tolerance() const { return optimizer.Tolerance(); }
  //! Modify the tolerance for termination.
  double& Tolerance() { return optimizer.Tolerance(); }

  //! Get whether or not the individual functions are shuffled.
  bool Shuffle() const { return optimizer.Shuffle(); }
  //! Modify whether or not the individual functions are shuffled.
  bool& Shuffle() { return optimizer.Shuffle(); }

  //! Get whether or not the actual objective is calculated.
  bool ExactObjective() const { return optimizer.ExactObjective(); }
  //! Modify whether or not the actual objective is calculated.
  bool& ExactObjective() { return optimizer.ExactObjective(); }

  //! Get the snapshots.
  std::vector<arma::mat> Snapshots() const
  {
    return optimizer.DecayPolicy().Snapshots();
  }
  //! Modify the snapshots.
  std::vector<arma::mat>& Snapshots()
  {
    return optimizer.DecayPolicy().Snapshots();
  }

  //! Get whether or not to accumulate the snapshots.
  bool Accumulate() const { return accumulate; }
  //! Modify whether or not to accumulate the snapshots.
  bool& Accumulate() { return accumulate; }

  //! Get the update policy.
  const UpdatePolicyType& UpdatePolicy() const
  {
    return optimizer.UpdatePolicy();
  }
  //! Modify the update policy.
  UpdatePolicyType& UpdatePolicy()
  {
    return optimizer.UpdatePolicy();
  }

  //! Get whether or not the update policy parameters
  //! are reset before Optimize call.
  bool ResetPolicy() const { return optimizer.ResetPolicy(); }
  //! Modify whether or not the update policy parameters
  //! are reset before Optimize call.
  bool& ResetPolicy() { return optimizer.ResetPolicy(); }

 private:
  //! The size of each mini-batch.
  size_t batchSize;

  //! Whether or not to accumulate the snapshots.
  bool accumulate;

  //! Controls whether or not the actual Objective value is calculated.
  bool exactObjective;

  //! Locally-stored optimizer instance.
  OptimizerType optimizer;
};

} // namespace ens

// Include implementation.
#include "snapshot_sgdr_impl.hpp"

#endif
/**
 * @file snapshots_sgdr_impl.hpp
 * @author Marcus Edel
 *
 * Implementation of SGDR method using snapshots ensembles.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_SGDR_SNAPSHOT_SGDR_IMPL_HPP
#define ENSMALLEN_SGDR_SNAPSHOT_SGDR_IMPL_HPP

// In case it hasn't been included yet.
#include "snapshot_sgdr.hpp"

namespace ens {

template<typename UpdatePolicyType>
SnapshotSGDR<UpdatePolicyType>::SnapshotSGDR(
    const size_t epochRestart,
    const double multFactor,
    const size_t batchSize,
    const double stepSize,
    const size_t maxIterations,
    const double tolerance,
    const bool shuffle,
    const size_t snapshots,
    const bool accumulate,
    const UpdatePolicyType& updatePolicy,
    const bool resetPolicy,
    const bool exactObjective) :
    batchSize(batchSize),
    accumulate(accumulate),
    exactObjective(exactObjective),
    optimizer(OptimizerType(stepSize,
                            batchSize,
                            maxIterations,
                            tolerance,
                            shuffle,
                            updatePolicy,
                            SnapshotEnsembles(
                                epochRestart,
                                multFactor,
                                stepSize,
                                maxIterations,
                                snapshots),
                            resetPolicy,
                            exactObjective))
{
  /* Nothing to do here */
}

template<typename UpdatePolicyType>
template<typename SeparableFunctionType,
         typename MatType,
         typename GradType,
         typename... CallbackTypes>
typename std::enable_if<IsArmaType<GradType>::value,
typename MatType::elem_type>::type
SnapshotSGDR<UpdatePolicyType>::Optimize(
    SeparableFunctionType& function,
    MatType& iterate,
    CallbackTypes&&... callbacks)
{
  // If a user changed the step size he hasn't update the step size of the
  // cyclical decay instantiation, so we have to do here.
  if (optimizer.StepSize() != optimizer.DecayPolicy().StepSize())
  {
    optimizer.DecayPolicy().StepSize() = optimizer.StepSize();
  }

  optimizer.DecayPolicy().EpochBatches() = function.NumFunctions() /
      double(batchSize);

  // If a user changed the batch size we have to update the restart fraction
  // of the cyclical decay instantiation.
  if (optimizer.BatchSize() != batchSize)
  {
    batchSize = optimizer.BatchSize();
  }

  typename MatType::elem_type overallObjective = optimizer.Optimize(function,
      iterate, callbacks...);

  typedef typename MatTypeTraits<MatType>::BaseMatType BaseMatType;
  typedef typename MatTypeTraits<GradType>::BaseMatType BaseGradType;

  typedef SnapshotEnsembles::Policy<BaseMatType, BaseGradType>
      InstDecayPolicyType;

  // Accumulate snapshots.
  if (accumulate)
  {
    Any& instDecayPolicy = optimizer.InstDecayPolicy();
    size_t numSnapshots =
        instDecayPolicy.As<InstDecayPolicyType>().Snapshots().size();

    for (size_t i = 0; i < numSnapshots; ++i)
    {
      iterate += instDecayPolicy.As<InstDecayPolicyType>().Snapshots()[i];
    }
    iterate /= (numSnapshots + 1);

    // Calculate final objective.
    overallObjective = 0;
    for (size_t i = 0; i < function.NumFunctions(); ++i)
    {
      const typename MatType::elem_type objective = function.Evaluate(
          iterate, i, 1);
      overallObjective += objective;
    }
  }

  return overallObjective;
}

} // namespace ens

#endif
/**
 * @file smorms3.hpp
 * @author Vivek Pal
 *
 * SMORMS3 i.e. squared mean over root mean squared cubed optimizer. It is a
 * hybrid of RMSprop, which estimates a safe and optimal distance based on
 * curvature and Yann LeCun‚Äôs method in "No more pesky learning rates".
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_SMORMS3_SMORMS3_HPP
#define ENSMALLEN_SMORMS3_SMORMS3_HPP

#include <ensmallen_bits/sgd/sgd.hpp>

#include "smorms3_update.hpp"

namespace ens {

/**
 * SMORMS3 is an optimizer that estimates a safe and optimal distance based on
 * curvature and normalizing the stepsize in the parameter space. It is a hybrid
 * of RMSprop and Yann LeCun‚Äôs method in "No more pesky learning rates".
 *
 * For more information, see the following.
 *
 * @code
 * @misc{Funk2015,
 *   author = {Simon Funk},
 *   title  = {RMSprop loses to SMORMS3 - Beware the Epsilon!},
 *   year   = {2015}
 *   url    = {http://sifter.org/~simon/journal/20150420.html}
 * }
 * @endcode
 *
 * SMORMS3 can optimize differentiable separable functions.  For more details,
 * see the documentation on function types included with this distribution or on
 * the ensmallen website.
 */
class SMORMS3
{
 public:
  /**
   * Construct the SMORMS3 optimizer with the given function and parameters. The
   * defaults here are not necessarily good for the given problem, so it is
   * suggested that the values used be tailored to the task at hand.  The
   * maximum number of iterations refers to the maximum number of points that
   * are processed (i.e., one iteration equals one point; one iteration does not
   * equal one pass over the dataset).
   *
   * @param stepSize Step size for each iteration.
   * @param batchSize Number of points to process at each step.
   * @param epsilon Value used to initialise the mean squared gradient
   *        parameter.
   * @param maxIterations Maximum number of iterations allowed (0 means no
   *        limit).
   * @param tolerance Maximum absolute tolerance to terminate algorithm.
   * @param shuffle If true, the function order is shuffled; otherwise, each
   *        function is visited in linear order.
   * @param resetPolicy If true, parameters are reset before every Optimize
   *        call; otherwise, their values are retained.
   * @param exactObjective Calculate the exact objective (Default: estimate the
   *        final objective obtained on the last pass over the data).
   */
  SMORMS3(const double stepSize = 0.001,
          const size_t batchSize = 32,
          const double epsilon = 1e-16,
          const size_t maxIterations = 100000,
          const double tolerance = 1e-5,
          const bool shuffle = true,
          const bool resetPolicy = true,
          const bool exactObjective = false);

  /**
   * Optimize the given function using SMORMS3. The given starting point will
   * be modified to store the finishing point of the algorithm, and the final
   * objective value is returned.
   *
   * @tparam SeparableFunctionType Type of the function to be optimized.
   * @tparam MatType Type of matrix to optimize with.
   * @tparam GradType Type of matrix to use to represent function gradients.
   * @tparam CallbackTypes Types of callback functions.
   * @param function Function to optimize.
   * @param iterate Starting point (will be modified).
   * @param callbacks Callback functions.
   * @return Objective value of the final point.
   */
  template<typename SeparableFunctionType,
           typename MatType,
           typename GradType,
           typename... CallbackTypes>
  typename std::enable_if<IsArmaType<GradType>::value,
      typename MatType::elem_type>::type
  Optimize(SeparableFunctionType& function,
           MatType& iterate,
           CallbackTypes&&... callbacks)
  {
    // TODO: disallow sp_mat

    return optimizer.Optimize<SeparableFunctionType, MatType, GradType,
        CallbackTypes...>(function, iterate,
        std::forward<CallbackTypes>(callbacks)...);
  }

  //! Forward the MatType as GradType.
  template<typename SeparableFunctionType,
           typename MatType,
           typename... CallbackTypes>
  typename MatType::elem_type Optimize(SeparableFunctionType& function,
                                       MatType& iterate,
                                       CallbackTypes&&... callbacks)
  {
    return Optimize<SeparableFunctionType, MatType, MatType,
        CallbackTypes...>(function, iterate,
        std::forward<CallbackTypes>(callbacks)...);
  }

  //! Get the step size.
  double StepSize() const { return optimizer.StepSize(); }
  //! Modify the step size.
  double& StepSize() { return optimizer.StepSize(); }

  //! Get the batch size.
  size_t BatchSize() const { return optimizer.BatchSize(); }
  //! Modify the batch size.
  size_t& BatchSize() { return optimizer.BatchSize(); }

  //! Get the value used to initialise the mean squared gradient parameter.
  double Epsilon() const { return optimizer.UpdatePolicy().Epsilon(); }
  //! Modify the value used to initialise the mean squared gradient parameter.
  double& Epsilon() { return optimizer.UpdatePolicy().Epsilon(); }

  //! Get the maximum number of iterations (0 indicates no limit).
  size_t MaxIterations() const { return optimizer.MaxIterations(); }
  //! Modify the maximum number of iterations (0 indicates no limit).
  size_t& MaxIterations() { return optimizer.MaxIterations(); }

  //! Get the tolerance for termination.
  double Tolerance() const { return optimizer.Tolerance(); }
  //! Modify the tolerance for termination.
  double& Tolerance() { return optimizer.Tolerance(); }

  //! Get whether or not the individual functions are shuffled.
  bool Shuffle() const { return optimizer.Shuffle(); }
  //! Modify whether or not the individual functions are shuffled.
  bool& Shuffle() { return optimizer.Shuffle(); }

  //! Get whether or not the actual objective is calculated.
  bool ExactObjective() const { return optimizer.ExactObjective(); }
  //! Modify whether or not the actual objective is calculated.
  bool& ExactObjective() { return optimizer.ExactObjective(); }

  //! Get whether or not the update policy parameters
  //! are reset before Optimize call.
  bool ResetPolicy() const { return optimizer.ResetPolicy(); }
  //! Modify whether or not the update policy parameters
  //! are reset before Optimize call.
  bool& ResetPolicy() { return optimizer.ResetPolicy(); }

 private:
  //! The Stochastic Gradient Descent object with SMORMS3Update update policy.
  SGD<SMORMS3Update> optimizer;
};

} // namespace ens

// Include implementation.
#include "smorms3_impl.hpp"

#endif
/**
 * @file smorms3_impl.hpp
 * @author Vivek Pal
 *
 * Implementation of the SMORMS3 constructor.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_SMORMS3_SMORMS3_IMPL_HPP
#define ENSMALLEN_SMORMS3_SMORMS3_IMPL_HPP

// In case it hasn't been included yet.
#include "smorms3.hpp"

namespace ens {

inline SMORMS3::SMORMS3(const double stepSize,
                        const size_t batchSize,
                        const double epsilon,
                        const size_t maxIterations,
                        const double tolerance,
                        const bool shuffle,
                        const bool resetPolicy,
                        const bool exactObjective) :
    optimizer(stepSize,
              batchSize,
              maxIterations,
              tolerance,
              shuffle,
              SMORMS3Update(epsilon),
              NoDecay(),
              resetPolicy,
              exactObjective)
{ /* Nothing to do. */ }

} // namespace ens

#endif
/**
 * @file smorms3_update.hpp
 * @author Vivek Pal
 *
 * SMORMS3 update for Stochastic Gradient Descent.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_SMORMS3_SMORMS3_UPDATE_HPP
#define ENSMALLEN_SMORMS3_SMORMS3_UPDATE_HPP

namespace ens {

/**
 * SMORMS3 is an optimizer that estimates a safe and optimal distance based on
 * curvature and normalizing the stepsize in the parameter space. It is a hybrid
 * of RMSprop and Yann LeCun‚Äôs method in "No more pesky learning rates".
 *
 * For more information, see the following.
 *
 * @code
 * @misc{Funk2015,
 *   author = {Simon Funk},
 *   title  = {RMSprop loses to SMORMS3 - Beware the Epsilon!},
 *   year   = {2015}
 *   url    = {http://sifter.org/~simon/journal/20150420.html}
 * }
 * @endcode
 */

class SMORMS3Update
{
 public:
  /**
   * Construct the SMORMS3 update policy with given epsilon parameter.
   *
   * @param epsilon Value used to initialise the mean squared gradient
   *        parameter.
   */
  SMORMS3Update(const double epsilon = 1e-16) : epsilon(epsilon)
  { /* Do nothing. */ }

  //! Get the value used to initialise the mean squared gradient parameter.
  double Epsilon() const { return epsilon; }
  //! Modify the value used to initialise the mean squared gradient parameter.
  double& Epsilon() { return epsilon; }

  /**
   * The UpdatePolicyType policy classes must contain an internal 'Policy'
   * template class with two template arguments: MatType and GradType.  This is
   * instantiated at the start of the optimization.
   */
  template<typename MatType, typename GradType>
  class Policy
  {
   public:
    /**
     * This is called by the optimizer method before the start of the iteration
     * update process.
     *
     * @param parent Instantiated parent class.
     * @param rows Number of rows in the gradient matrix.
     * @param cols Number of columns in the gradient matrix.
     */
    Policy(SMORMS3Update& parent, const size_t rows, const size_t cols) :
        parent(parent)
    {
      // Initialise the parameters mem, g and g2.
      mem.ones(rows, cols);
      g.zeros(rows, cols);
      g2.zeros(rows, cols);
    }

    /**
     * Update step for SMORMS3.
     *
     * @param iterate Parameter that minimizes the function.
     * @param stepSize Step size to be used for the given iteration.
     * @param gradient The gradient matrix.
     */
    void Update(MatType& iterate,
                const double stepSize,
                const GradType& gradient)
    {
      // Update the iterate.
      MatType r = 1 / (mem + 1);

      g = (1 - r) % g;
      g += r % gradient;

      g2 = (1 - r) % g2;
      g2 += r % (gradient % gradient);

      MatType x = (g % g) / (g2 + parent.epsilon);

      x.transform( [stepSize](typename MatType::elem_type &v)
          { return std::min(v, (typename MatType::elem_type) stepSize); } );

      iterate -= gradient % x / (arma::sqrt(g2) + parent.epsilon);

      mem %= (1 - x);
      mem += 1;
    }

   private:
    // Instantiated parent object.
    SMORMS3Update& parent;
    // Memory parameter.
    MatType mem;
    // Gradient estimate parameter.
    GradType g;
    // Squared gradient estimate parameter.
    GradType g2;
  };

 private:
  //! The value used to initialise the mean squared gradient parameter.
  double epsilon;
};

} // namespace ens

#endif
/**
 * @file spalera_sgd.hpp
 * @author Marcus Edel
 *
 * SPALeRA Stochastic Gradient Descent (SPALeRASGD).
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_SPALERA_SGD_SPALERA_SGD_HPP
#define ENSMALLEN_SPALERA_SGD_SPALERA_SGD_HPP

#include <ensmallen_bits/spalera_sgd/spalera_stepsize.hpp>
#include <ensmallen_bits/sgd/decay_policies/no_decay.hpp>

namespace ens {

/**
 * SPALeRA Stochastic Gradient Descent is a technique for minimizing a
 * function which can be expressed as a sum of other functions.  That is,
 * suppose we have
 *
 * \f[
 * f(A) = \sum_{i = 0}^{n} f_i(A)
 * \f]
 *
 * and our task is to minimize \f$ A \f$.  SPALeRA SGD iterates over batches
 * of functions \f$ \{ f_{i0}(A), f_{i1}(A), \ldots, f_{i(m - 1)}(A) \f$ for
 * some batch size \f$ m \f$, producing the following update scheme:
 *
 * \f[
 * A_{j + 1} = A_j + \alpha \left(\sum_{k = 0}^{m - 1} \nabla f_{ik}(A) \right)
 * \f]
 *
 * where \f$ \alpha \f$ is a parameter which specifies the step size.  Each
 * batch is passed through either sequentially or randomly.  The algorithm
 * continues until \f$ j \f$ reaches the maximum number of iterations---or when
 * a full sequence of updates through each of the batches produces an
 * improvement within a certain tolerance \f$ \epsilon \f$.
 *
 * The parameter \f$ \epsilon \f$ is specified by the tolerance parameter tot he
 * constructor, as is the maximum number of iterations specified by the
 * maxIterations parameter.
 *
 * This class is useful for data-dependent functions whose objective function
 * can be expressed as a sum of objective functions operating on an individual
 * point.  Then, SPALeRA SGD considers the gradient of the objective function
 * operation on an individual batches in its update of \f$ A \f$.
 *
 * For more information, please refer to:
 *
 * @code
 * @misc{Schoenauer2017,
 *   title   = {Stochastic Gradient Descent:
 *              Going As Fast As Possible But Not Faster},
 *   author  = {Schoenauer-Sebag, Alice; Schoenauer, Marc; Sebag, Michele},
 *   journal = {CoRR},
 *   year    = {2017},
 *   url     = {https://arxiv.org/abs/1709.01427},
 * }
 * @endcode
 *
 * SPALeRASGD can optimize differentiable separable functions.  For more
 * details, see the documentation on function types included with this
 * distribution or on the ensmallen website.
 *
 * @tparam DecayPolicyType Decay policy used during the iterative update
 *     process to adjust the step size. By default the step size isn't going to
 *     be adjusted.
 */
template<typename DecayPolicyType = NoDecay>
class SPALeRASGD
{
 public:
  /**
   * Construct the SPALeRASGD optimizer with the given function and parameters.
   * The defaults here are not necessarily good for the given problem, so it is
   * suggested that the values used be tailored to the task at hand.  The
   * maximum number of iterations refers to the maximum number of points that
   * are processed (i.e., one iteration equals one point; one iteration does not
   * equal one pass over the dataset).
   *
   * @param stepSize Step size for each iteration.
   * @param batchSize Batch size to use for each step.
   * @param maxIterations Maximum number of iterations allowed (0 means no
   *     limit).
   * @param tolerance Maximum absolute tolerance to terminate algorithm.
   * @param lambda Page-Hinkley update parameter.
   * @param alpha Memory parameter of the Agnostic Learning Rate adaptation.
   * @param epsilon Numerical stability parameter.
   * @param adaptRate Agnostic learning rate update rate.
   * @param shuffle If true, the function order is shuffled; otherwise, each
   *    function is visited in linear order.
   * @param decayPolicy Instantiated decay policy used to adjust the step size.
   * @param resetPolicy Flag that determines whether update policy parameters
   *    are reset before every Optimize call.
   * @param exactObjective Calculate the exact objective (Default: estimate the
   *        final objective obtained on the last pass over the data).
   */
  SPALeRASGD(const double stepSize = 0.01,
             const size_t batchSize = 32,
             const size_t maxIterations = 100000,
             const double tolerance = 1e-5,
             const double lambda = 0.01,
             const double alpha = 0.001,
             const double epsilon = 1e-6,
             const double adaptRate = 3.10e-8,
             const bool shuffle = true,
             const DecayPolicyType& decayPolicy = DecayPolicyType(),
             const bool resetPolicy = true,
             const bool exactObjective = false);

  /**
   * Clean any memory associated with the SPALeRA SGD object.
   */
  ~SPALeRASGD();

  /**
   * Optimize the given function using SPALeRA SGD.  The given starting point
   * will be modified to store the finishing point of the algorithm, and the
   * final objective value is returned.
   *
   * @tparam SeparableFunctionType Type of the function to be optimized.
   * @tparam MatType Type of matrix to optimize with.
   * @tparam GradType Type of matrix to use to represent function gradients.
   * @tparam CallbackTypes Types of callback functions.
   * @param function Function to optimize.
   * @param iterate Starting point (will be modified).
   * @param callbacks Callback functions.
   * @return Objective value of the final point.
   */
  template<typename SeparableFunctionType,
           typename MatType,
           typename GradType,
           typename... CallbackTypes>
  typename std::enable_if<IsArmaType<GradType>::value,
      typename MatType::elem_type>::type
  Optimize(SeparableFunctionType& function,
           MatType& iterate,
           CallbackTypes&&... callbacks);

  //! Forward the MatType as GradType.
  template<typename SeparableFunctionType,
           typename MatType,
           typename... CallbackTypes>
  typename MatType::elem_type Optimize(SeparableFunctionType& function,
                                       MatType& iterate,
                                       CallbackTypes&&... callbacks)
  {
    return Optimize<SeparableFunctionType, MatType, MatType,
        CallbackTypes...>(function, iterate,
        std::forward<CallbackTypes>(callbacks)...);
  }

  //! Get the batch size.
  size_t BatchSize() const { return batchSize; }
  //! Modify the batch size.
  size_t& BatchSize() { return batchSize; }

  //! Get the step size.
  double StepSize() const { return stepSize; }
  //! Modify the step size.
  double& StepSize() { return stepSize; }

  //! Get the maximum number of iterations (0 indicates no limit).
  size_t MaxIterations() const { return maxIterations; }
  //! Modify the maximum number of iterations (0 indicates no limit).
  size_t& MaxIterations() { return maxIterations; }

  //! Get the tolerance for termination.
  double Tolerance() const { return tolerance; }
  //! Modify the tolerance for termination.
  double& Tolerance() { return tolerance; }

  //! Get the tolerance for termination.
  double Alpha() const { return updatePolicy.Alpha(); }
  //! Modify the tolerance for termination.
  double& Alpha() { return updatePolicy.Alpha(); }

  //! Get the agnostic learning rate update rate.
  double AdaptRate() const { return updatePolicy.AdaptRate(); }
  //! Modify the agnostic learning rate update rate.
  double& AdaptRate() { return updatePolicy.AdaptRate(); }

  //! Get whether or not the individual functions are shuffled.
  bool Shuffle() const { return shuffle; }
  //! Modify whether or not the individual functions are shuffled.
  bool& Shuffle() { return shuffle; }

  //! Get whether or not the actual objective is calculated.
  bool ExactObjective() const { return exactObjective; }
  //! Modify whether or not the actual objective is calculated.
  bool& ExactObjective() { return exactObjective; }

  //! Get whether or not the update policy parameters
  //! are reset before Optimize call.
  bool ResetPolicy() const { return resetPolicy; }
  //! Modify whether or not the update policy parameters
  //! are reset before Optimize call.
  bool& ResetPolicy() { return resetPolicy; }

  //! Get the update policy.
  SPALeRAStepsize UpdatePolicy() const { return updatePolicy; }
  //! Modify the update policy.
  SPALeRAStepsize& UpdatePolicy() { return updatePolicy; }

  //! Get the decay policy.
  DecayPolicyType DecayPolicy() const { return decayPolicy; }
  //! Modify the decay policy.
  DecayPolicyType& DecayPolicy() { return decayPolicy; }

 private:
  //! The step size for each example.
  double stepSize;

  //! The batch size for processing.
  size_t batchSize;

  //! The maximum number of allowed iterations.
  size_t maxIterations;

  //! The tolerance for termination.
  double tolerance;

  //! Page-Hinkley update parameter.
  double lambda;

  //! Controls whether or not the individual functions are shuffled when
  //! iterating.
  bool shuffle;

  //! Controls whether or not the actual Objective value is calculated.
  bool exactObjective;

  //! The update policy used to update the parameters in each iteration.
  SPALeRAStepsize updatePolicy;

  //! The decay policy used to update the parameters in each iteration.
  DecayPolicyType decayPolicy;

  //! Flag that determines whether update policy parameters
  //! are reset before every Optimize call.
  bool resetPolicy;

  //! Whether or not the decay policy is initialized.
  bool isInitialized;

  //! The initialized update policy.
  Any instUpdatePolicy;

  //! The initialized decay policy.
  Any instDecayPolicy;
};

} // namespace ens

// Include implementation.
#include "spalera_sgd_impl.hpp"

#endif
/**
 * @file spalera_sgd_impl.hpp
 * @author Marcus Edel
 *
 * Implementation of SPALeRA SGD.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_SPALERA_SGD_SPALERA_SGD_IMPL_HPP
#define ENSMALLEN_SPALERA_SGD_SPALERA_SGD_IMPL_HPP

// In case it hasn't been included yet.
#include "spalera_sgd.hpp"

#include <ensmallen_bits/function.hpp>

namespace ens {

template<typename DecayPolicyType>
SPALeRASGD<DecayPolicyType>::SPALeRASGD(const double stepSize,
                                        const size_t batchSize,
                                        const size_t maxIterations,
                                        const double tolerance,
                                        const double lambda,
                                        const double alpha,
                                        const double epsilon,
                                        const double adaptRate,
                                        const bool shuffle,
                                        const DecayPolicyType& decayPolicy,
                                        const bool resetPolicy,
                                        const bool exactObjective) :
    stepSize(stepSize),
    batchSize(batchSize),
    maxIterations(maxIterations),
    tolerance(tolerance),
    lambda(lambda),
    shuffle(shuffle),
    exactObjective(exactObjective),
    updatePolicy(SPALeRAStepsize(alpha, epsilon, adaptRate)),
    decayPolicy(decayPolicy),
    resetPolicy(resetPolicy),
    isInitialized(false)
{ /* Nothing to do. */ }

template<typename DecayPolicyType>
SPALeRASGD<DecayPolicyType>::~SPALeRASGD()
{
  instUpdatePolicy.Clean();
  instDecayPolicy.Clean();
}

//! Optimize the function (minimize).
template<typename DecayPolicyType>
template<typename SeparableFunctionType,
         typename MatType,
         typename GradType,
         typename... CallbackTypes>
typename std::enable_if<IsArmaType<GradType>::value,
typename MatType::elem_type>::type
SPALeRASGD<DecayPolicyType>::Optimize(
    SeparableFunctionType& function,
    MatType& iterateIn,
    CallbackTypes&&... callbacks)
{
  // Convenience typedefs.
  typedef typename MatType::elem_type ElemType;
  typedef typename MatTypeTraits<MatType>::BaseMatType BaseMatType;
  typedef typename MatTypeTraits<GradType>::BaseMatType BaseGradType;

  typedef Function<SeparableFunctionType, BaseMatType, BaseGradType>
      FullFunctionType;
  FullFunctionType& f(static_cast<FullFunctionType&>(function));

  traits::CheckSeparableFunctionTypeAPI<FullFunctionType, BaseMatType,
      BaseGradType>();
  RequireDenseFloatingPointType<BaseMatType>();
  RequireFloatingPointType<BaseGradType>();
  RequireSameInternalTypes<BaseMatType, BaseGradType>();

  BaseMatType& iterate = (BaseMatType&) iterateIn;

  // The update policy and decay policy internally use a templated class so that
  // we can know MatType and GradType only when Optimize() is called.
  typedef typename SPALeRAStepsize::Policy<BaseMatType, BaseGradType>
      InstUpdatePolicyType;
  typedef typename DecayPolicyType::template Policy<BaseMatType, BaseGradType>
      InstDecayPolicyType;

  // Find the number of functions to use.
  const size_t numFunctions = f.NumFunctions();

  // To keep track of where we are and how things are going.
  size_t currentFunction = 0;
  size_t epoch = 1;
  ElemType overallObjective = 0;
  ElemType lastObjective = DBL_MAX;

  // Controls early termination of the optimization process.
  bool terminate = false;

  Callback::BeginOptimization(*this, f, iterate, callbacks...);

  // Calculate the first objective function.
  for (size_t i = 0; i < numFunctions; i += batchSize)
  {
    const size_t effectiveBatchSize = std::min(batchSize, numFunctions - i);
    const ElemType objective = f.Evaluate(iterate, i, effectiveBatchSize);
    overallObjective += objective;

    terminate |= Callback::Evaluate(*this, f, iterate, objective, callbacks...);
  }

  ElemType currentObjective = overallObjective / numFunctions;

  // Initialize the decay policy if needed.
  if (!isInitialized || !instDecayPolicy.Has<InstDecayPolicyType>())
  {
    instDecayPolicy.Clean();
    instDecayPolicy.Set<InstDecayPolicyType>(
        new InstDecayPolicyType(decayPolicy));
  }

  // Initialize the update policy.
  if (resetPolicy || !isInitialized ||
      !instUpdatePolicy.Has<InstUpdatePolicyType>())
  {
    instUpdatePolicy.Clean();
    instUpdatePolicy.Set<InstUpdatePolicyType>(
        new InstUpdatePolicyType(updatePolicy, iterate.n_rows, iterate.n_cols,
                                 currentObjective * lambda));
    isInitialized = true;
  }

  // Now iterate!
  BaseGradType gradient(iterate.n_rows, iterate.n_cols);
  const size_t actualMaxIterations = (maxIterations == 0) ?
      std::numeric_limits<size_t>::max() : maxIterations;
  terminate |= Callback::BeginEpoch(*this, f, iterate, epoch, overallObjective,
      callbacks...);
  for (size_t i = 0; i < actualMaxIterations && !terminate;
      /* incrementing done manually */)
  {
    // Calculate gradient and objective.
    // Find the effective batch size; we have to take the minimum of three
    // things:
    // - the batch size can't be larger than the user-specified batch size;
    // - the batch size can't be larger than the number of iterations left
    //       before actualMaxIterations is hit;
    // - the batch size can't be larger than the number of functions left.
    const size_t effectiveBatchSize = std::min(
        std::min(batchSize, actualMaxIterations - i),
        numFunctions - currentFunction);

    currentObjective = f.EvaluateWithGradient(iterate, currentFunction,
        gradient, effectiveBatchSize);

    terminate |= Callback::EvaluateWithGradient(*this, f, iterate,
        currentObjective, gradient, callbacks...);
    if (terminate)
      break;

    // Use the update policy to take a step.
    if (!instUpdatePolicy.As<InstUpdatePolicyType>().Update(stepSize,
        currentObjective, effectiveBatchSize, numFunctions, iterate, gradient))
    {
      Warn << "SPALeRA SGD: converged to " << overallObjective << "; "
          << "terminating with failure.  Try a smaller step size?"
          << std::endl;

      Callback::EndOptimization(*this, f, iterate, callbacks...);
      return overallObjective;
    }
    terminate |= Callback::StepTaken(*this, f, iterate, callbacks...);

    // Now update the learning rate if requested by the user.
    instDecayPolicy.As<InstDecayPolicyType>().Update(iterate, stepSize,
        gradient);

    i += effectiveBatchSize;
    currentFunction += effectiveBatchSize;
    overallObjective += currentObjective;

    // Is this iteration the start of a sequence?
    if ((currentFunction % numFunctions) == 0)
    {
      terminate |= Callback::EndEpoch(*this, f, iterate, epoch++,
          overallObjective / (ElemType) numFunctions, callbacks...);

      // Output current objective function.
      Info << "SPALeRA SGD: iteration " << i << ", objective "
          << overallObjective << "." << std::endl;

      if (std::isnan(overallObjective) || std::isinf(overallObjective))
      {
        Warn << "SPALeRA SGD: converged to " << overallObjective
            << "; terminating with failure.  Try a smaller step size?"
            << std::endl;

        Callback::EndOptimization(*this, f, iterate, callbacks...);
        return overallObjective;
      }

      if (std::abs(lastObjective - overallObjective) < tolerance)
      {
        Info << "SPALeRA SGD: minimized within tolerance " << tolerance
            << "; terminating optimization." << std::endl;

        Callback::EndOptimization(*this, f, iterate, callbacks...);
        return overallObjective;
      }

      // Reset the counter variables.
      lastObjective = overallObjective;
      overallObjective = 0;
      currentFunction = 0;

      terminate |= Callback::BeginEpoch(*this, f, iterate, epoch,
          overallObjective, callbacks...);

      if (shuffle) // Determine order of visitation.
        f.Shuffle();
    }
  }

  Info << "SPALeRA SGD: maximum iterations (" << maxIterations
      << ") reached; terminating optimization." << std::endl;

  // Calculate final objective if exactObjective is set to true.
  if (exactObjective)
  {
    overallObjective = 0;
    for (size_t i = 0; i < numFunctions; i += batchSize)
    {
      const size_t effectiveBatchSize = std::min(batchSize, numFunctions - i);
      const ElemType objective = f.Evaluate(iterate, i, effectiveBatchSize);
      overallObjective += objective;

      // The optimization is over, so we don't need to care about the result of
      // the callback.
      (void) Callback::Evaluate(*this, f, iterate, objective, callbacks...);
    }
  }

  Callback::EndOptimization(*this, f, iterate, callbacks...);
  return overallObjective;
}

} // namespace ens

#endif
/**
 * @file spalera_stepsize.hpp
 * @author Marcus Edel
 *
 * Definition of the SPALeRA stepsize technique as described in:
 * "Stochastic Gradient Descent: Going As Fast As Possible But Not Faster" by
 * A. Schoenauer Sebag et al.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */

#ifndef ENSMALLEN_SPALERA_SGD_SPALERA_STEPSIZE_HPP
#define ENSMALLEN_SPALERA_SGD_SPALERA_STEPSIZE_HPP

namespace ens {

/**
 * Definition of the SPALeRA stepize technique, which implementes a change
 * detection mechanism with an agnostic adaptation scheme.
 *
 * For more information, please refer to:
 *
 * @code
 * @misc{Schoenauer2017,
 *   title   = {Stochastic Gradient Descent:
 *              Going As Fast As Possible But Not Faster},
 *   author  = {Schoenauer-Sebag, Alice; Schoenauer, Marc; Sebag, Michele},
 *   journal = {CoRR},
 *   year    = {2017},
 *   url     = {https://arxiv.org/abs/1709.01427},
 * }
 * @endcode
 */
class SPALeRAStepsize
{
 public:
  /**
   * Construct the SPALeRAStepsize object with the given parameters.
   * The defaults here are not necessarily good for the given
   * problem, so it is suggested that the values used be tailored to the task at
   * hand.
   *
   * @param alpha Memory parameter of the agnostic learning rate adaptation.
   * @param epsilon Numerical stability parameter.
   * @param adaptRate Agnostic learning rate update rate.
   */
  SPALeRAStepsize(const double alpha = 0.001,
                  const double epsilon = 1e-6,
                  const double adaptRate = 3.10e-8) :
      alpha(alpha),
      epsilon(epsilon),
      adaptRate(adaptRate),
      lambda(0)
  {
    /* Nothing to do here. */
  }

  //! Get the agnostic learning rate adaptation parameter.
  double Alpha() const { return alpha; }
  //! Modify the agnostic learning rate adaptation parameter.
  double& Alpha() { return alpha; }

  //! Get the numerical stability parameter.
  double Epsilon() const { return epsilon; }
  //! Modify the numerical stability parameter.
  double& Epsilon() { return epsilon; }

  //! Get the agnostic learning rate update rate.
  double AdaptRate() const { return adaptRate; }
  //! Modify the agnostic learning rate update rate.
  double& AdaptRate() { return adaptRate; }

  //! Get the Page-Hinkley update parameter lambda.
  double Lambda() const { return lambda; }
  //! Modify the Page-Hinkley update parameter lambda.
  double& Lambda() { return lambda; }

  /**
   * The UpdatePolicyType policy classes must contain an internal 'Policy'
   * template class with two template arguments: MatType and GradType.  This is
   * instantiated at the start of the optimization.
   */
  template<typename MatType, typename GradType>
  class Policy
  {
   public:
    /**
     * This is called by the optimizer method before the start of the iteration
     * update process.
     *
     * @param parent Instantiated parent class.
     * @param rows Number of rows in the gradient matrix.
     * @param cols Number of columns in the gradient matrix.
     * @param lambda Page-Hinkley update parameter.
     */
    Policy(SPALeRAStepsize& parent,
           const size_t rows,
           const size_t cols,
           const double lambda) :
        parent(parent),
        mu0(0),
        un(0),
        mn(0),
        relaxedObjective(0),
        phCounter(0),
        eveCounter(0)
    {
      learningRates.ones(rows, cols);
      relaxedSums.zeros(rows, cols);

      parent.lambda = lambda;
    }

    /**
     * This function is called in each iteration.
     *
     * @param stepSize Step size to be used for the given iteration.
     * @param objective The current function loss.
     * @param batchSize Batch size to be used for the given iteration.
     * @param numFunctions The number of functions.
     * @param iterate Parameters that minimize the function.
     * @param gradient The gradient matrix.
     *
     * @return Stop or continue the learning process.
     */
    bool Update(const double stepSize,
                const typename MatType::elem_type objective,
                const size_t batchSize,
                const size_t numFunctions,
                MatType& iterate,
                const GradType& gradient)
    {
      // The ratio of mini-batch size to training set size; needed for the
      // Page-Hinkley relaxed objective computations.
      const double mbRatio = batchSize / (double) numFunctions;

      // Page-Hinkley iteration, check if we have to reset the parameter and
      // adjust the step size.
      if (phCounter > (1 / mbRatio))
      {
        relaxedObjective = (1 - mbRatio) * relaxedObjective + mbRatio *
            objective;
      }
      else
      {
        relaxedObjective = phCounter * relaxedObjective + objective;
        relaxedObjective /= (phCounter + 1);
      }

      // Update the mu0 parameter.
      mu0 = phCounter * mu0 + relaxedObjective;
      mu0 = mu0 / (phCounter + 1);

      // Update the un parameter.
      un += relaxedObjective - mu0;

      // Updating the mn parameter.
      if (un < mn)
        mn = un;

      // If the condition is true we reset the parameter and update parameter.
      if ((un - mn) > parent.lambda)
      {
        // Backtracking, reset the parameter.
        iterate = previousIterate;

        // Dividing learning rates by 2 as proposed in:
        // Stochastic Gradient Descent: Going As Fast As Possible But Not
        // Faster.
        learningRates /= 2;

        if (arma::any(arma::vectorise(learningRates) <= 1e-15))
        {
          // Stop because learning rate too low.
          return false;
        }

        // Reset evaluation and Page-Hinkley counter parameter.
        mu0 = un = mn = relaxedObjective = phCounter = eveCounter = 0;
      }
      else
      {
        const double paramMean = (parent.alpha / (2 - parent.alpha) *
            (1 - std::pow(1 - parent.alpha, 2 * (eveCounter + 1)))) /
            iterate.n_elem;

        const double paramStd = (parent.alpha / std::sqrt(iterate.n_elem)) /
            std::sqrt(iterate.n_elem);

        const typename MatType::elem_type normGradient =
            std::sqrt(arma::accu(arma::pow(gradient, 2)));

        relaxedSums *= (1 - parent.alpha);
        if (normGradient > parent.epsilon)
          relaxedSums += gradient * (parent.alpha / normGradient);

        learningRates %= arma::exp((arma::pow(relaxedSums, 2) - paramMean) *
            (parent.adaptRate / paramStd));

        previousIterate = iterate;

        iterate -= stepSize * (learningRates % gradient);

        // Keep track of the the number of evaluations and Page-Hinkley steps.
        eveCounter++;
        phCounter++;
      }

      return true;
    }

   private:
    //! Instantiated parent object.
    SPALeRAStepsize& parent;

    //! Page-Hinkley update parameter.
    double mu0;

    //! Page-Hinkley update parameter.
    double un;

    //! Page-Hinkley update parameter.
    double mn;

    //! Page-Hinkley update parameter.
    typename MatType::elem_type relaxedObjective;

    //! Page-Hinkley step counter.
    size_t phCounter;

    //! Evaluations step counter.
    size_t eveCounter;

    //! Locally-stored parameter wise learning rates.
    MatType learningRates;

    //! Locally-stored parameter wise sums.
    MatType relaxedSums;

    //! Locally-stored previous parameter matrix (backtracking).
    MatType previousIterate;
  };

 private:

  //! Memory parameter of the agnostic learning rate adaptation.
  double alpha;

  //! Numerical stability parameter.
  double epsilon;

  //! Agnostic learning rate update rate.
  double adaptRate;

  //! Page-Hinkley update parameter.
  double lambda;
};

} // namespace ens

#endif // ENSMALLEN_SPALERA_SGD_SPALERA_STEPSIZE_HPP
/**
 * @file spsa.hpp
 * @author N Rajiv Vaidyanathan
 * @author Marcus Edel
 *
 * SPSA (Simultaneous perturbation stochastic approximation) method.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_SPSA_SPSA_HPP
#define ENSMALLEN_SPSA_SPSA_HPP

namespace ens {

/**
 * Implementation of the SPSA method. The SPSA algorithm approximates the
 * gradient of the function by finite differences along stochastic directions.
 *
 * For more information, see the following.
 *
 * @code
 * @article{Spall1998,
 *   author  = {Spall, J. C.},
 *   title   = {An Overview of the Simultaneous Perturbation Method for
 *              Efficient Optimization},
 *   journal = {Johns Hopkins APL Technical Digest},
 *   volume  = {19},
 *   number  = {4},
 *   pages   = {482--492},
 *   year    = {1998}
 * }
 * @endcode
 *
 * SPSA can optimize arbitrary functions.  For more details,
 * see the documentation on function types included with this distribution or on
 * the ensmallen website.
 */
class SPSA
{
 public:
  /**
   * Construct the SPSA optimizer with the given function and parameters.  The
   * defaults here are not necessarily good for the given problem, so it is
   * suggested that the values used be tailored to the task at hand.
   *
   * @param alpha Scaling exponent for the step size.
   * @param gamma Scaling exponent for evaluation step size.
   * @param stepSize Scaling parameter for step size (named as 'a' in the paper).
   * @param evaluationStepSize Scaling parameter for evaluation step size (named
   *     as 'c' in the paper).
   * @param maxIterations Maximum number of iterations allowed (0 means no
   *     limit).
   * @param tolerance Maximum absolute tolerance to terminate algorithm.
   */
  SPSA(const double alpha = 0.602,
       const double gamma = 0.101,
       const double stepSize = 0.16,
       const double evaluationStepSize = 0.3,
       const size_t maxIterations = 100000,
       const double tolerance = 1e-5);

  /**
   * Optimize the given function, starting from the coordinates given in the
   * 'iterate' matrix.  The final best set of coordinates is stored in the
   * 'iterate' matrix, and the best objective is returned.
   *
   * @tparam ArbitraryFunctionType Type of function to optimize.
   * @tparam MatType Type of matrix to optimize with.
   * @tparam CallbackTypes Types of callback functions.
   * @param function Function to optimize.
   * @param iterate Initial coordinates to start from (this matrix will also be
   *     used to store final coordinates).
   * @param callbacks Callback functions.
   * @return Objective value of the final point.
   */
  template<typename ArbitraryFunctionType,
           typename MatType,
           typename... CallbackTypes>
  typename MatType::elem_type Optimize(ArbitraryFunctionType& function,
                                       MatType& iterate,
                                       CallbackTypes&&... callbacks);

  //! Get the scaling exponent for the step size.
  double Alpha() const { return alpha; }
  //! Modify the scaling exponent for the step size.
  double& Alpha() { return alpha; }

  //! Get the scaling exponent for evaluation step size.
  double Gamma() const { return gamma; }
  //! Modify the scaling exponent for evaluation step size.
  double& Gamma() { return gamma; }

  //! Get the scaling parameter for step size.
  double StepSize() const { return stepSize; }
  //! Modify the scaling parameter for step size.
  double& StepSize() { return stepSize; }

  //! Get the scaling parameter for step size.
  double EvaluationStepSize() const { return evaluationStepSize; }
  //! Modify the scaling parameter for step size.
  double& EvaluationStepSize() { return evaluationStepSize; }

  //! Get the maximum number of iterations (0 indicates no limit).
  size_t MaxIterations() const { return maxIterations; }
  //! Modify the maximum number of iterations (0 indicates no limit).
  size_t& MaxIterations() { return maxIterations; }

 private:
  //! Scaling exponent for the step size.
  double alpha;

  //! Scaling exponent for evaluation step size.
  double gamma;

  //! Scaling parameter for step size.
  double stepSize;

  //! Scaling parameter for step size.
  double evaluationStepSize;

  //! Control the amount of gradient update.
  double ak;

  //! The maximum number of allowed iterations.
  size_t maxIterations;

  //! The tolerance for termination.
  double tolerance;
};

} // namespace ens

// Include implementation.
#include "spsa_impl.hpp"

#endif
/**
 * @file spsa.hpp
 * @author N Rajiv Vaidyanathan
 * @author Marcus Edel
 *
 * SPSA (Simultaneous perturbation stochastic approximation)
 * update for faster convergence.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_SPSA_SPSA_IMPL_HPP
#define ENSMALLEN_SPSA_SPSA_IMPL_HPP

// In case it hasn't been included yet.
#include "spsa.hpp"

#include <ensmallen_bits/function.hpp>

namespace ens {

inline SPSA::SPSA(const double alpha,
                  const double gamma,
                  const double stepSize,
                  const double evaluationStepSize,
                  const size_t maxIterations,
                  const double tolerance) :
    alpha(alpha),
    gamma(gamma),
    stepSize(stepSize),
    evaluationStepSize(evaluationStepSize),
    ak(0.001 * maxIterations),
    maxIterations(maxIterations),
    tolerance(tolerance)
{ /* Nothing to do. */ }

template<typename ArbitraryFunctionType,
         typename MatType,
         typename... CallbackTypes>
typename MatType::elem_type SPSA::Optimize(ArbitraryFunctionType& function,
                                           MatType& iterate,
                                           CallbackTypes&&... callbacks)
{
  // Convenience typedefs.
  typedef typename MatType::elem_type ElemType;
  typedef typename MatTypeTraits<MatType>::BaseMatType BaseMatType;

  // Make sure that we have the methods that we need.
  traits::CheckArbitraryFunctionTypeAPI<ArbitraryFunctionType,
      MatType>();
  RequireFloatingPointType<MatType>();

  BaseMatType gradient(iterate.n_rows, iterate.n_cols);
  arma::Mat<ElemType> spVector(iterate.n_rows, iterate.n_cols);

  // To keep track of where we are and how things are going.
  ElemType overallObjective = 0;
  ElemType lastObjective = DBL_MAX;

  // Controls early termination of the optimization process.
  bool terminate = false;

  Callback::BeginOptimization(*this, function, iterate, callbacks...);
  for (size_t k = 0; k < maxIterations && !terminate; ++k)
  {
    // Output current objective function.
    Info << "SPSA: iteration " << k << ", objective " << overallObjective
        << "." << std::endl;

    if (std::isnan(overallObjective) || std::isinf(overallObjective))
    {
      Warn << "SPSA: converged to " << overallObjective << "; terminating"
          << " with failure.  Try a smaller step size?" << std::endl;

      Callback::EndOptimization(*this, function, iterate, callbacks...);
      return overallObjective;
    }

    if (std::abs(lastObjective - overallObjective) < tolerance)
    {
      Warn << "SPSA: minimized within tolerance " << tolerance << "; "
          << "terminating optimization." << std::endl;
      Callback::EndOptimization(*this, function, iterate, callbacks...);
      return overallObjective;
    }

    // Reset the counter variables.
    lastObjective = overallObjective;

    // Gain sequences.
    const double akLocal = stepSize / std::pow(k + 1 + ak, alpha);
    const double ck = evaluationStepSize / std::pow(k + 1, gamma);

    // Choose stochastic directions.
    spVector = arma::conv_to<arma::Mat<ElemType>>::from(
        arma::randi(iterate.n_rows, iterate.n_cols,
        arma::distr_param(0, 1))) * 2 - 1;

    iterate += ck * spVector;
    const double fPlus = function.Evaluate(iterate);
    terminate |= Callback::Evaluate(*this, function, iterate, fPlus,
        callbacks...);

    iterate -= 2 * ck * spVector;
    const double fMinus = function.Evaluate(iterate);
    terminate |= Callback::Evaluate(*this, function, iterate, fMinus,
        callbacks...);

    iterate += ck * spVector;
    if (terminate)
      break;

    gradient = (fPlus - fMinus) * (1 / (2 * ck * spVector));
    iterate -= akLocal * gradient;

    terminate |= Callback::StepTaken(*this, function, iterate, callbacks...);

    overallObjective = function.Evaluate(iterate);
    terminate |= Callback::Evaluate(*this, function, iterate, overallObjective,
        callbacks...);
  }

  // Calculate final objective.  The optimization is over, so the result of the
  // callback doesn'tatter.
  const ElemType objective = function.Evaluate(iterate);
  (void) Callback::Evaluate(*this, function, iterate, objective, callbacks...);

  Callback::EndOptimization(*this, function, iterate, callbacks...);
  return objective;
}

} // namespace ens

#endif
/**
 * @file barzilai_borwein_decay.hpp
 * @author Marcus Edel
 *
 * Barzilai-Borwein decay policy.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_SVRG_BARZILIA_BORWEIN_DECAY_HPP
#define ENSMALLEN_SVRG_BARZILIA_BORWEIN_DECAY_HPP

namespace ens {

/**
 * Barzilai-Borwein decay policy for Stochastic variance reduced gradient
 * (SVRG).
 *
 * For more information, please refer to:
 *
 * @code
 * @incollection{Tan2016,
 *   title     = {Barzilai-Borwein Step Size for Stochastic Gradient Descent},
 *   author    = {Tan, Conghui and Ma, Shiqian and Dai, Yu-Hong
 *                and Qian, Yuqiu},
 *   booktitle = {Advances in Neural Information Processing Systems 29},
 *   editor    = {D. D. Lee and M. Sugiyama and U. V. Luxburg and I. Guyon
 *                and R. Garnett},
 *   pages     = {685--693},
 *   year      = {2016},
 *   publisher = {Curran Associates, Inc.}
 * }
 * @endcode
 */
class BarzilaiBorweinDecay
{
 public:
  /*
   * Construct the Barzilai-Borwein decay policy.
   *
   * @param maxStepSize The maximum step size.
   * @param eps The eps coefficient to avoid division by zero (numerical
   *    stability).
   */
  BarzilaiBorweinDecay(const double maxStepSize = DBL_MAX,
                       const double epsilon = 1e-7) :
      epsilon(epsilon),
      maxStepSize(maxStepSize)
  { /* Nothing to do. */}

  //! Get the numerical stability parameter.
  double Epsilon() const { return epsilon; }
  //! Modify the numerical stability parameter.
  double& Epsilon() { return epsilon; }

  //! Get the maximum step size.
  double MaxStepSize() const { return maxStepSize; }
  //! Modify the maximum step size.
  double& MaxStepSize() { return maxStepSize; }

  /**
   * The DecayPolicyType policy classes must contain an internal 'Policy'
   * template class with two template arguments: MatType and GradType.  This is
   * initialized at the start of the optimization, and holds parameters specific
   * to an individual optimization.
   */
  template<typename MatType, typename GradType>
  class Policy
  {
   public:
    /**
     * This constructor is called by the SGD Optimize() method before the start
     * of the iteration update process.
     */
    Policy(BarzilaiBorweinDecay& parent) : parent(parent) { /* Do nothing. */ }

    /**
     * Barzilai-Borwein update step for SVRG.
     *
     * @param iterate The current function parameter at time t.
     * @param iterate0 The last function parameters at time t - 1.
     * @param gradient The current gradient matrix at time t.
     * @param fullGradient The computed full gradient.
     * @param numBatches The number of batches.
     * @param stepSize Step size to be used for the given iteration.
     */
    void Update(const MatType& iterate,
                const MatType& iterate0,
                const GradType& /* gradient */,
                const GradType& fullGradient,
                const size_t numBatches,
                double& stepSize)
    {
      if (!fullGradient0.is_empty())
      {
        // Step size selection based on Barzilai-Borwein (BB).
        stepSize = std::pow(arma::norm(iterate - iterate0), 2.0) /
            (arma::dot(iterate - iterate0, fullGradient - fullGradient0) +
             parent.epsilon) / (double) numBatches;

        stepSize = std::min(stepSize, parent.maxStepSize);
      }

      fullGradient0 = std::move(fullGradient);
    }

   private:
    //! Reference to instantiated parent object.
    BarzilaiBorweinDecay& parent;

    //! Locally-stored full gradient.
    GradType fullGradient0;
  };

  //! The value used for numerical stability.
  double epsilon;

  //! The maximum step size.
  double maxStepSize;
};

} // namespace ens

#endif // ENSMALLEN_SVRG_BARZILIA_BORWEIN_DECAY_HPP
/**
 * @file svrg.hpp
 * @author Marcus Edel
 *
 * Stochastic variance reduced gradient (SVRG).
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_SVRG_SVRG_HPP
#define ENSMALLEN_SVRG_SVRG_HPP

#include <ensmallen_bits/sgd/decay_policies/no_decay.hpp>

#include "svrg_update.hpp"
#include "barzilai_borwein_decay.hpp"

namespace ens {

/**
 * Stochastic Variance Reduced Gradient is a technique for minimizing a function
 * which can be expressed as a sum of other functions.  That is, suppose we have
 *
 * \f[
 * f(A) = \sum_{i = 0}^{n} f_i(A)
 * \f]
 *
 * and our task is to minimize \f$ A \f$.  Stochastic Variance Reduced Gradient
 * iterates over each function \f$ f_i(A) \f$, based on the specified update
 * policy. By default vanilla update policy is used. The SVRG class supports
 * either scanning through each of the \f$ n \f$
 * functions \f$ f_i(A)\f$ linearly, or in a random sequence.  The algorithm
 * continues until \f$ j\f$ reaches the maximum number of iterations---or when a
 * full sequence of updates through each of the \f$ n \f$ functions \f$ f_i(A)
 * \f$ produces an improvement within a certain tolerance \f$ \epsilon \f$.
 * That is,
 *
 * \f[
 * | f(A_{j + n}) - f(A_j) | < \epsilon.
 * \f]
 *
 * The parameter \f$\epsilon\f$ is specified by the tolerance parameter to the
 * constructor; \f$n\f$ is specified by the maxIterations parameter.
 *
 * This class is useful for data-dependent functions whose objective function
 * can be expressed as a sum of objective functions operating on an individual
 * point.  Then, SVRG considers the gradient of the objective function operating
 * on an individual point in its update of \f$ A \f$.
 *
 * SVRG can optimize differentiable separable functions.  For more
 * details, see the documentation on function types included with this
 * distribution or on the ensmallen website.
 *
 * For more information, please refer to:
 *
 * @code
 * @inproceedings{Johnson2013,
 *   author    = {Johnson, Rie and Zhang, Tong},
 *   title     = {Accelerating Stochastic Gradient Descent Using Predictive
 *                Variance Reduction},
 *   booktitle = {Proceedings of the 26th International Conference on Neural
 *                Information Processing Systems - Volume 1},
 *   series    = {NIPS'13},
 *   year      = {2013},
 *   location  = {Lake Tahoe, Nevada},
 *   pages     = {315--323},
 *   numpages  = {9},
 *   publisher = {Curran Associates Inc.},
 * }
 * @endcode
 *
 * @tparam UpdatePolicyType update policy used by SVRG during the iterative
 *     update process. By default vanilla update policy (see ens::VanillaUpdate)
 *     is used.
 * @tparam DecayPolicyType Decay policy used during the iterative update
 *     process to adjust the step size. By default the step size isn't going to
 *     be adjusted (i.e. NoDecay is used).
 */
template<typename UpdatePolicyType = SVRGUpdate,
         typename DecayPolicyType = NoDecay>
class SVRGType
{
 public:
  /**
   * Construct the SVRG optimizer with the given function and parameters.  The
   * defaults here are not necessarily good for the given problem, so it is
   * suggested that the values used be tailored to the task at hand.  The
   * maximum number of iterations refers to the maximum number of points that
   * are processed (i.e., one iteration equals one point; one iteration does not
   * equal one pass over the dataset).
   *
   * @param stepSize Step size for each iteration.
   * @param batchSize Batch size to use for each step.
   * @param maxIterations Maximum number of iterations allowed (0 means no
   *     limit).
   * @param innerIterations The number of inner iterations allowed (0 means
   *    n / batchSize). Note that the full gradient is only calculated in
   *    the outer iteration.
   * @param tolerance Maximum absolute tolerance to terminate algorithm.
   * @param shuffle If true, the function order is shuffled; otherwise, each
   *     function is visited in linear order.
   * @param updatePolicy Instantiated update policy used to adjust the given
   *     parameters.
   * @param decayPolicy Instantiated decay policy used to adjust the step size.
   * @param resetPolicy Flag that determines whether update policy parameters
   *     are reset before every Optimize call.
   * @param exactObjective Calculate the exact objective (Default: estimate the
   *        final objective obtained on the last pass over the data).
   */
  SVRGType(const double stepSize = 0.01,
           const size_t batchSize = 32,
           const size_t maxIterations = 1000,
           const size_t innerIterations = 0,
           const double tolerance = 1e-5,
           const bool shuffle = true,
           const UpdatePolicyType& updatePolicy = UpdatePolicyType(),
           const DecayPolicyType& decayPolicy = DecayPolicyType(),
           const bool resetPolicy = true,
           const bool exactObjective = false);

  /**
   * Clean any memory associated with the SVRGType object.
   */
  ~SVRGType();

  /**
   * Optimize the given function using SVRG. The given starting point will be
   * modified to store the finishing point of the algorithm, and the final
   * objective value is returned.
   *
   * @tparam SeparableFunctionType Type of the function to be optimized.
   * @tparam MatType Type of matrix to optimize with.
   * @tparam GradType Type of matrix to use to represent function gradients.
   * @tparam CallbackTypes Types of callback functions.
   * @param function Function to optimize.
   * @param iterate Starting point (will be modified).
   * @param callbacks Callback functions.
   * @return Objective value of the final point.
   */
  template<typename SeparableFunctionType,
           typename MatType,
           typename GradType,
           typename... CallbackTypes>
  typename std::enable_if<IsArmaType<GradType>::value,
      typename MatType::elem_type>::type
  Optimize(SeparableFunctionType& function,
           MatType& iterate,
           CallbackTypes&&... callbacks);

  //! Forward the MatType as GradType.
  template<typename SeparableFunctionType,
           typename MatType,
           typename... CallbackTypes>
  typename MatType::elem_type Optimize(SeparableFunctionType& function,
                                       MatType& iterate,
                                       CallbackTypes&&... callbacks)
  {
    return Optimize<SeparableFunctionType, MatType, MatType,
        CallbackTypes...>(function, iterate,
        std::forward<CallbackTypes>(callbacks)...);
  }

  //! Get the step size.
  double StepSize() const { return stepSize; }
  //! Modify the step size.
  double& StepSize() { return stepSize; }

  //! Get the batch size.
  size_t BatchSize() const { return batchSize; }
  //! Modify the batch size.
  size_t& BatchSize() { return batchSize; }

  //! Get the maximum number of iterations (0 indicates no limit).
  size_t MaxIterations() const { return maxIterations; }
  //! Modify the maximum number of iterations (0 indicates no limit).
  size_t& MaxIterations() { return maxIterations; }

  //! Get the maximum number of iterations (0 indicates default n / b).
  size_t InnerIterations() const { return innerIterations; }
  //! Modify the maximum number of iterations (0 indicates default n / b).
  size_t& InnerIterations() { return innerIterations; }

  //! Get the tolerance for termination.
  double Tolerance() const { return tolerance; }
  //! Modify the tolerance for termination.
  double& Tolerance() { return tolerance; }

  //! Get whether or not the individual functions are shuffled.
  bool Shuffle() const { return shuffle; }
  //! Modify whether or not the individual functions are shuffled.
  bool& Shuffle() { return shuffle; }

  //! Get whether or not the actual objective is calculated.
  bool ExactObjective() const { return exactObjective; }
  //! Modify whether or not the actual objective is calculated.
  bool& ExactObjective() { return exactObjective; }

  //! Get whether or not the update policy parameters
  //! are reset before Optimize call.
  bool ResetPolicy() const { return resetPolicy; }
  //! Modify whether or not the update policy parameters
  //! are reset before Optimize call.
  bool& ResetPolicy() { return resetPolicy; }

  //! Get the update policy.
  const UpdatePolicyType& UpdatePolicy() const { return updatePolicy; }
  //! Modify the update policy.
  UpdatePolicyType& UpdatePolicy() { return updatePolicy; }

  //! Get the step size decay policy.
  const DecayPolicyType& DecayPolicy() const { return decayPolicy; }
  //! Modify the step size decay policy.
  DecayPolicyType& DecayPolicy() { return decayPolicy; }

 private:
  //! The step size for each example.
  double stepSize;

  //! The batch size for processing.
  size_t batchSize;

  //! The maximum number of allowed iterations.
  size_t maxIterations;

  //! The maximum number of allowed inner iterations per epoch.
  size_t innerIterations;

  //! The tolerance for termination.
  double tolerance;

  //! Controls whether or not the individual functions are shuffled when
  //! iterating.
  bool shuffle;

  //! Controls whether or not the actual Objective value is calculated.
  bool exactObjective;

  //! The update policy used to update the parameters in each iteration.
  UpdatePolicyType updatePolicy;

  //! The decay policy used to update the step size.
  DecayPolicyType decayPolicy;

  //! Flag indicating whether update policy
  //! should be reset before running optimization.
  bool resetPolicy;

  //! Whether the instantiated policies are initialized.
  bool isInitialized;

  //! Instantiated update policy.
  Any instUpdatePolicy;
  //! Instantiated decay policy.
  Any instDecayPolicy;
};

// Convenience typedefs.

/**
 * Standard stochastic variance reduced gradient.
 */
using SVRG = SVRGType<SVRGUpdate, NoDecay>;

/**
 * Stochastic variance reduced gradient with Barzilai-Borwein.
 */
using SVRG_BB = SVRGType<SVRGUpdate, BarzilaiBorweinDecay>;

} // namespace ens

// Include implementation.
#include "svrg_impl.hpp"

#endif
/**
 * @file svrg_impl.hpp
 * @author Marcus Edel
 *
 * Implementation of stochastic variance reduced gradient (SVRG).
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_SVRG_SVRG_IMPL_HPP
#define ENSMALLEN_SVRG_SVRG_IMPL_HPP

// In case it hasn't been included yet.
#include "svrg.hpp"

namespace ens {

template<typename UpdatePolicyType, typename DecayPolicyType>
SVRGType<UpdatePolicyType, DecayPolicyType>::SVRGType(
    const double stepSize,
    const size_t batchSize,
    const size_t maxIterations,
    const size_t innerIterations,
    const double tolerance,
    const bool shuffle,
    const UpdatePolicyType& updatePolicy,
    const DecayPolicyType& decayPolicy,
    const bool resetPolicy,
    const bool exactObjective) :
    stepSize(stepSize),
    batchSize(batchSize),
    maxIterations(maxIterations),
    innerIterations(innerIterations),
    tolerance(tolerance),
    shuffle(shuffle),
    exactObjective(exactObjective),
    updatePolicy(updatePolicy),
    decayPolicy(decayPolicy),
    resetPolicy(resetPolicy),
    isInitialized(false)
{ /* Nothing to do. */ }

template<typename UpdatePolicyType, typename DecayPolicyType>
SVRGType<UpdatePolicyType, DecayPolicyType>::~SVRGType()
{
  instUpdatePolicy.Clean();
  instDecayPolicy.Clean();
}

//! Optimize the function (minimize).
template<typename UpdatePolicyType, typename DecayPolicyType>
template<typename SeparableFunctionType,
         typename MatType,
         typename GradType,
         typename... CallbackTypes>
typename std::enable_if<IsArmaType<GradType>::value,
typename MatType::elem_type>::type
SVRGType<UpdatePolicyType, DecayPolicyType>::Optimize(
    SeparableFunctionType& functionIn,
    MatType& iterateIn,
    CallbackTypes&&... callbacks)
{
  // Convenience typedefs.
  typedef typename MatType::elem_type ElemType;
  typedef typename MatTypeTraits<MatType>::BaseMatType BaseMatType;
  typedef typename MatTypeTraits<GradType>::BaseMatType BaseGradType;

  typedef Function<SeparableFunctionType, BaseMatType, BaseGradType>
      FullFunctionType;
  FullFunctionType& function(static_cast<FullFunctionType&>(functionIn));

  traits::CheckSeparableFunctionTypeAPI<SeparableFunctionType,
      BaseMatType, BaseGradType>();
  RequireFloatingPointType<BaseMatType>();
  RequireFloatingPointType<BaseGradType>();
  RequireSameInternalTypes<BaseMatType, BaseGradType>();

  typedef typename UpdatePolicyType::template Policy<BaseMatType, BaseGradType>
      InstUpdatePolicyType;
  typedef typename DecayPolicyType::template Policy<BaseMatType, BaseGradType>
      InstDecayPolicyType;

  BaseMatType& iterate = (BaseMatType&) iterateIn;

  // Find the number of functions to use.
  const size_t numFunctions = function.NumFunctions();

  // To keep track of where we are and how things are going.
  ElemType overallObjective = 0;
  ElemType lastObjective = DBL_MAX;

  // Controls early termination of the optimization process.
  bool terminate = false;

  // Set epoch length to n / b if the user asked for.
  if (innerIterations == 0)
    innerIterations = numFunctions;

  // Initialize the decay policy.
  if (!isInitialized ||
      !instDecayPolicy.Has<InstDecayPolicyType>())
  {
    instDecayPolicy.Clean();
    instDecayPolicy.Set<InstDecayPolicyType>(
        new InstDecayPolicyType(decayPolicy));
  }

  // Initialize the update policy.
  if (resetPolicy || !isInitialized ||
      !instUpdatePolicy.Has<InstUpdatePolicyType>())
  {
    instUpdatePolicy.Clean();
    instUpdatePolicy.Set<InstUpdatePolicyType>(
        new InstUpdatePolicyType(updatePolicy, iterate.n_rows, iterate.n_cols));
    isInitialized = true;
  }

  // Now iterate!
  BaseGradType gradient(iterate.n_rows, iterate.n_cols);
  BaseGradType gradient0(iterate.n_rows, iterate.n_cols);
  BaseMatType iterate0;

  // Find the number of batches.
  size_t numBatches = numFunctions / batchSize;
  if (numFunctions % batchSize != 0)
    ++numBatches; // Capture last few.

  const size_t actualMaxIterations = (maxIterations == 0) ?
      std::numeric_limits<size_t>::max() : maxIterations;
  Callback::BeginOptimization(*this, function, iterate, callbacks...);
  for (size_t i = 0; i < actualMaxIterations && !terminate; ++i)
  {
    // Calculate the objective function.
    overallObjective = 0;
    for (size_t f = 0; f < numFunctions; f += batchSize)
    {
      const size_t effectiveBatchSize = std::min(batchSize, numFunctions - f);
      const ElemType objective = function.Evaluate(iterate, f,
          effectiveBatchSize);
      terminate |= Callback::Evaluate(*this, function, iterate, objective,
          callbacks...);
      overallObjective += objective;
    }

    if (terminate)
      break;

    if (std::isnan(overallObjective) || std::isinf(overallObjective))
    {
      Warn << "SVRG: converged to " << overallObjective
          << "; terminating  with failure.  Try a smaller step size?"
          << std::endl;

      Callback::EndOptimization(*this, function, iterate, callbacks...);
      return overallObjective;
    }

    if (std::abs(lastObjective - overallObjective) < tolerance)
    {
      Info << "SVRG: minimized within tolerance " << tolerance
          << "; terminating optimization." << std::endl;

      Callback::EndOptimization(*this, function, iterate, callbacks...);
      return overallObjective;
    }

    lastObjective = overallObjective;

    // Compute the full gradient.
    size_t effectiveBatchSize = std::min(batchSize, numFunctions);
    BaseGradType fullGradient(iterate.n_rows, iterate.n_cols);
    function.Gradient(iterate, 0, fullGradient, effectiveBatchSize);

    terminate |= Callback::Gradient(*this, function, iterate, fullGradient,
        callbacks...);
    for (size_t f = effectiveBatchSize; f < numFunctions;
        /* incrementing done manually */)
    {
      // Find the effective batch size (the last batch may be smaller).
      effectiveBatchSize = std::min(batchSize, numFunctions - f);

      function.Gradient(iterate, f, gradient, effectiveBatchSize);
      terminate |= Callback::Gradient(*this, function, iterate, gradient,
        callbacks...);

      fullGradient += gradient;

      f += effectiveBatchSize;
    }
    fullGradient /= (double) numFunctions;
    if (terminate)
      break;

    // Store current parameter for the calculation of the variance reduced
    // gradient.
    iterate0 = iterate;

    for (size_t f = 0, currentFunction = 0; f < innerIterations;
        /* incrementing done manually */)
    {
      // Is this iteration the start of a sequence?
      if ((currentFunction % numFunctions) == 0)
      {
        currentFunction = 0;

        // Determine order of visitation.
        if (shuffle)
          function.Shuffle();
      }

      // Find the effective batch size (the last batch may be smaller).
      effectiveBatchSize = std::min(batchSize, numFunctions - currentFunction);

      // Calculate variance reduced gradient.
      function.Gradient(iterate, currentFunction, gradient,
          effectiveBatchSize);
      terminate |= Callback::Gradient(*this, function, iterate, gradient,
        callbacks...);

      function.Gradient(iterate0, currentFunction, gradient0,
          effectiveBatchSize);
      terminate |= Callback::Gradient(*this, function, iterate0, gradient0,
        callbacks...);

      if (terminate)
        break;

      // Use the update policy to take a step.
      instUpdatePolicy.As<InstUpdatePolicyType>().Update(iterate, fullGradient,
          gradient, gradient0, effectiveBatchSize, stepSize);

      terminate |= Callback::StepTaken(*this, function, iterate, callbacks...);

      currentFunction += effectiveBatchSize;
      f += effectiveBatchSize;
    }

    // Update the learning rate if requested by the user.
    instDecayPolicy.As<InstDecayPolicyType>().Update(iterate, iterate0,
        gradient, fullGradient, numBatches, stepSize);
  }

  Info << "SVRG: maximum iterations (" << maxIterations << ") reached; "
      << "terminating optimization." << std::endl;

  // Calculate final objective if exactObjective is set to true.
  if (exactObjective)
  {
    overallObjective = 0;
    for (size_t i = 0; i < numFunctions; i += batchSize)
    {
      const size_t effectiveBatchSize = std::min(batchSize, numFunctions - i);
      const ElemType objective = function.Evaluate(iterate, i,
          effectiveBatchSize);
      overallObjective += objective;

      // The optimization is finished, so it doesn't matter what the callback
      // returns.
      (void) Callback::Evaluate(*this, function, iterate, objective,
          callbacks...);
    }
  }

  Callback::EndOptimization(*this, function, iterate, callbacks...);
  return overallObjective;
}

} // namespace ens

#endif
/**
 * @file svrg_update.hpp
 * @author Marcus Edel
 *
 * Vanilla update for stochastic variance reduced gradient (SVRG).
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_SVRG_SVRG_UPDATE_HPP
#define ENSMALLEN_SVRG_SVRG_UPDATE_HPP

namespace ens {

/**
 * Vanilla update policy for Stochastic variance reduced gradient (SVRG).
 * The following update scheme is used to update SGD in every iteration:
 */
class SVRGUpdate
{
 public:
  /**
   * The UpdatePolicyType policy classes must contain an internal 'Policy'
   * template class with two template arguments: MatType and GradType.  This is
   * instantiated at the start of the optimization.
   */
  template<typename MatType, typename GradType>
  class Policy
  {
   public:
    /**
     * This is called by the optimizer method before the start of the iteration
     * update process.
     *
     * @param parent Instantiated parent class.
     * @param rows Number of rows in the gradient matrix.
     * @param cols Number of columns in the gradient matrix.
     */
    Policy(SVRGUpdate& /* parent */,
           const size_t /* rows */,
           const size_t /* cols */)
    { /* Do nothing. */ }

    /**
     * Update step for SVRG. The function parameters are updated in the negative
     * direction of the gradient.
     *
     * @param iterate Parameters that minimize the function.
     * @param fullGradient The computed full gradient.
     * @param gradient The current gradient matrix at time t.
     * @param gradient0 The old gradient matrix at time t - 1.
     * @param batchSize Batch size to be used for the given iteration.
     * @param stepSize Step size to be used for the given iteration.
     */
    void Update(MatType& iterate,
                const GradType& fullGradient,
                const GradType& gradient,
                const GradType& gradient0,
                const size_t batchSize,
                const double stepSize)
    {
      // Perform the vanilla SVRG update.
      iterate -= stepSize * (fullGradient + (gradient - gradient0) /
          (double) batchSize);
    }
  };
};

} // namespace ens

#endif
/**
 * @file swats.hpp
 * @author Marcus Edel
 *
 * SWATS is a simple strategy which switches from Adam to SGD when a triggering
 * condition is satisfied.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_SWATS_SWATS_HPP
#define ENSMALLEN_SWATS_SWATS_HPP

#include <ensmallen_bits/sgd/sgd.hpp>
#include "swats_update.hpp"

namespace ens {

/**
 * SWATS is a simple strategy which switches from Adam to SGD when a triggering
 * condition is satisfied. The condition relates to the projection of Adam steps
 * on the gradient subspace.
 *
 * For more information, see the following.
 *
 * @code
 * @article{Keskar2017,
 *   author  = {Nitish Shirish Keskar and Richard Socher},
 *   title   = {Improving Generalization Performance by Switching from Adam to
 *              {SGD}},
 *   journal = {CoRR},
 *   volume  = {abs/1712.07628},
 *   year    = {2017}
 *   url     = {http://arxiv.org/abs/1712.07628},
 * }
 * @endcode
 *
 * SWATS can optimize differentiable separable functions.  For more details, see
 * the documentation on function types include with this distribution or on the
 * ensmallen website.
 */
class SWATS
{
 public:
  /**
   * Construct the SWATS optimizer with the given function and parameters. The
   * defaults here are not necessarily good for the given problem, so it is
   * suggested that the values used be tailored to the task at hand.  The
   * maximum number of iterations refers to the maximum number of points that
   * are processed (i.e., one iteration equals one point; one iteration does not
   * equal one pass over the dataset).
   *
   * @param stepSize Step size for each iteration.
   * @param batchSize Number of points to process in a single step.
   * @param beta1 Exponential decay rate for the first moment estimates.
   * @param beta2 Exponential decay rate for the weighted infinity norm
            estimates.
   * @param epsilon Value used to initialise the mean squared gradient
   *        parameter.
   * @param maxIterations Maximum number of iterations allowed (0 means no
   *        limit).
   * @param tolerance Maximum absolute tolerance to terminate algorithm.
   * @param shuffle If true, the function order is shuffled; otherwise, each
   *        function is visited in linear order.
   * @param resetPolicy If true, parameters are reset before every Optimize
   *        call; otherwise, their values are retained.
   * @param exactObjective Calculate the exact objective (Default: estimate the
   *        final objective obtained on the last pass over the data).
   */
  SWATS(const double stepSize = 0.001,
        const size_t batchSize = 32,
        const double beta1 = 0.9,
        const double beta2 = 0.999,
        const double epsilon = 1e-8,
        const size_t maxIterations = 100000,
        const double tolerance = 1e-5,
        const bool shuffle = true,
        const bool resetPolicy = true,
        const bool exactObjective = false);

  /**
   * Optimize the given function using SWATS. The given starting point will
   * be modified to store the finishing point of the algorithm, and the final
   * objective value is returned.
   *
   * @tparam SeparableFunctionType Type of the function to be optimized.
   * @tparam MatType Type of matrix to optimize with.
   * @tparam GradType Type of matrix to use to represent function gradients.
   * @tparam CallbackTypes Types of callback functions.
   * @param function Function to optimize.
   * @param iterate Starting point (will be modified).
   * @param callbacks Callback functions.
   * @return Objective value of the final point.
   */
  template<typename SeparableFunctionType,
           typename MatType,
           typename GradType,
           typename... CallbackTypes>
  typename std::enable_if<IsArmaType<GradType>::value,
      typename MatType::elem_type>::type
  Optimize(SeparableFunctionType& function,
           MatType& iterate,
           CallbackTypes&&... callbacks)
  {
    return optimizer.Optimize<SeparableFunctionType, MatType, GradType,
        CallbackTypes...>(function, iterate,
        std::forward<CallbackTypes>(callbacks)...);
  }

  //! Forward the MatType as GradType.
  template<typename SeparableFunctionType,
           typename MatType,
           typename... CallbackTypes>
  typename MatType::elem_type Optimize(SeparableFunctionType& function,
                                       MatType& iterate,
                                       CallbackTypes&&... callbacks)
  {
    return Optimize<SeparableFunctionType, MatType, MatType,
        CallbackTypes...>(function, iterate,
        std::forward<CallbackTypes>(callbacks)...);
  }

  //! Get the step size.
  double StepSize() const { return optimizer.StepSize(); }
  //! Modify the step size.
  double& StepSize() { return optimizer.StepSize(); }

  //! Get the batch size.
  size_t BatchSize() const { return optimizer.BatchSize(); }
  //! Modify the batch size.
  size_t& BatchSize() { return optimizer.BatchSize(); }

  //! Get the smoothing parameter.
  double Beta1() const { return optimizer.UpdatePolicy().Beta1(); }
  //! Modify the smoothing parameter.
  double& Beta1() { return optimizer.UpdatePolicy().Beta1(); }

  //! Get the second moment coefficient.
  double Beta2() const { return optimizer.UpdatePolicy().Beta2(); }
  //! Modify the second moment coefficient.
  double& Beta2() { return optimizer.UpdatePolicy().Beta2(); }

  //! Get the value used to initialise the mean squared gradient parameter.
  double Epsilon() const { return optimizer.UpdatePolicy().Epsilon(); }
  //! Modify the value used to initialise the mean squared gradient parameter.
  double& Epsilon() { return optimizer.UpdatePolicy().Epsilon(); }

  //! Get the maximum number of iterations (0 indicates no limit).
  size_t MaxIterations() const { return optimizer.MaxIterations(); }
  //! Modify the maximum number of iterations (0 indicates no limit).
  size_t& MaxIterations() { return optimizer.MaxIterations(); }

  //! Get the tolerance for termination.
  double Tolerance() const { return optimizer.Tolerance(); }
  //! Modify the tolerance for termination.
  double& Tolerance() { return optimizer.Tolerance(); }

  //! Get whether or not the individual functions are shuffled.
  bool Shuffle() const { return optimizer.Shuffle(); }
  //! Modify whether or not the individual functions are shuffled.
  bool& Shuffle() { return optimizer.Shuffle(); }

  //! Get whether or not the actual objective is calculated.
  bool ExactObjective() const { return optimizer.ExactObjective(); }
  //! Modify whether or not the actual objective is calculated.
  bool& ExactObjective() { return optimizer.ExactObjective(); }

  //! Get whether or not the update policy parameters
  //! are reset before Optimize call.
  bool ResetPolicy() const { return optimizer.ResetPolicy(); }
  //! Modify whether or not the update policy parameters
  //! are reset before Optimize call.
  bool& ResetPolicy() { return optimizer.ResetPolicy(); }

 private:
  //! The SWATS update policy.
  SGD<SWATSUpdate> optimizer;
};

} // namespace ens

// Include implementation.
#include "swats_impl.hpp"

#endif
/**
 * @file swats_impl.hpp
 * @author Marcus Edel
 *
 * Implementation of the SWATS optimizer.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_SWATS_SWATS_IMPL_HPP
#define ENSMALLEN_SWATS_SWATS_IMPL_HPP

// In case it hasn't been included yet.
#include "swats.hpp"

namespace ens {

inline SWATS::SWATS(
    const double stepSize,
    const size_t batchSize,
    const double beta1,
    const double beta2,
    const double epsilon,
    const size_t maxIterations,
    const double tolerance,
    const bool shuffle,
    const bool resetPolicy,
    const bool exactObjective) :
    optimizer(stepSize,
              batchSize,
              maxIterations,
              tolerance,
              shuffle,
              SWATSUpdate(epsilon, beta1, beta2),
              NoDecay(),
              resetPolicy,
              exactObjective)
{ /* Nothing to do. */ }

} // namespace ens

#endif
/**
 * @file swats_update.hpp
 * @author Marcus Edel
 *
 * SWATS update rule for Switches from Adam to SGD method.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_SWATS_SWATS_UPDATE_HPP
#define ENSMALLEN_SWATS_SWATS_UPDATE_HPP

namespace ens {

/**
 * SWATS is a simple strategy which switches from Adam to SGD when a triggering
 * condition is satisfied. The condition relates to the projection of Adam steps
 * on the gradient subspace.
 *
 * For more information, see the following.
 *
 * @code
 * @article{Keskar2017,
 *   author  = {Nitish Shirish Keskar and Richard Socher},
 *   title   = {Improving Generalization Performance by Switching from Adam to
 *              {SGD}},
 *   journal = {CoRR},
 *   volume  = {abs/1712.07628},
 *   year    = {2017}
 *   url     = {http://arxiv.org/abs/1712.07628},
 * }
 * @endcode
 */
class SWATSUpdate
{
 public:
  /**
   * Construct the SWATS update policy with given parameter.
   *
   * @param epsilon The epsilon value used to initialise the squared gradient
   *        parameter.
   * @param beta1 The smoothing parameter.
   * @param beta2 The second moment coefficient.
   */
  SWATSUpdate(const double epsilon = 1e-8,
              const double beta1 = 0.9,
              const double beta2 = 0.999) :
    epsilon(epsilon),
    beta1(beta1),
    beta2(beta2),
    phaseSGD(false),
    sgdRate(0),
    sgdLambda(0)
  {
    // Nothing to do.
  }

  //! Get the value used to initialise the squared gradient parameter.
  double Epsilon() const { return epsilon; }
  //! Modify the value used to initialise the squared gradient parameter.
  double& Epsilon() { return epsilon; }

  //! Get the smoothing parameter.
  double Beta1() const { return beta1; }
  //! Modify the smoothing parameter.
  double& Beta1() { return beta1; }

  //! Get the second moment coefficient.
  double Beta2() const { return beta2; }
  //! Modify the second moment coefficient.
  double& Beta2() { return beta2; }

  //! Get whether the current phase is SGD.
  bool PhaseSGD() const { return phaseSGD; }
  //! Modify whether the current phase is SGD.
  bool& PhaseSGD() { return phaseSGD; }

  //! Get the SGD scaling parameter.
  double SGDRate() const { return sgdRate; }
  //! Modify the SGD scaling parameter.
  double& SGDRate() { return sgdRate; }

  //! Get the SGD step size.
  double SGDLambda() const { return sgdLambda; }
  //! Modify the SGD step size.
  double& SGDLambda() { return sgdLambda; }

  /**
   * The UpdatePolicyType policy classes must contain an internal 'Policy'
   * template class with two template arguments: MatType and GradType.  This is
   * instantiated at the start of the optimization.
   */
  template<typename MatType, typename GradType>
  class Policy
  {
   public:
    /**
     * This is called by the optimizer method before the start of the iteration
     * update process.
     *
     * @param parent Instantiated parent class.
     * @param rows Number of rows in the gradient matrix.
     * @param cols Number of columns in the gradient matrix.
     */
    Policy(SWATSUpdate& parent, const size_t rows, const size_t cols) :
        parent(parent),
        iteration(0)
    {
      m.zeros(rows, cols);
      v.zeros(rows, cols);

      sgdV.zeros(rows, cols);
    }

    /**
     * Update step for SWATS.
     *
     * @param iterate Parameters that minimize the function.
     * @param stepSize Step size to be used for the given iteration.
     * @param gradient The gradient matrix.
     */
    void Update(MatType& iterate,
                const double stepSize,
                const GradType& gradient)
    {
      // Increment the iteration counter variable.
      ++iteration;

      if (parent.phaseSGD)
      {
        // Note we reuse the exponential moving average parameter here instead
        // of introducing a new parameter (sgdV) as done in the paper.
        v *= parent.beta1;
        v += gradient;

        iterate -= (1 - parent.beta1) * parent.sgdRate * v;
        return;
      }

      m *= parent.beta1;
      m += (1 - parent.beta1) * gradient;

      v *= parent.beta2;
      v += (1 - parent.beta2) * (gradient % gradient);

      const double biasCorrection1 = 1.0 - std::pow(parent.beta1, iteration);
      const double biasCorrection2 = 1.0 - std::pow(parent.beta2, iteration);

      GradType delta = stepSize * m / biasCorrection1 /
          (arma::sqrt(v / biasCorrection2) + parent.epsilon);
      iterate -= delta;

      const double deltaGradient = arma::dot(delta, gradient);
      if (deltaGradient != 0)
      {
        const double rate = arma::dot(delta, delta) / deltaGradient;
        parent.sgdLambda = parent.beta2 * parent.sgdLambda +
            (1 - parent.beta2) * rate;
        parent.sgdRate = parent.sgdLambda / biasCorrection2;

        if (std::abs(parent.sgdRate - rate) < parent.epsilon && iteration > 1)
        {
          parent.phaseSGD = true;
          v.zeros();
        }
      }
    }

   private:
    //! Reference to instantiated parent object.
    SWATSUpdate& parent;

    //! The exponential moving average of gradient values.
    GradType m;

    //! The exponential moving average of squared gradient values (Adam).
    GradType v;

    //! The exponential moving average of squared gradient values (SGD).
    GradType sgdV;

    //! The number of iterations.
    size_t iteration;
  };

 private:
  //! The epsilon value used to initialise the squared gradient parameter.
  double epsilon;

  //! The smoothing parameter.
  double beta1;

  //! The second moment coefficient.
  double beta2;

  //! Wether to use the SGD or Adam update rule.
  bool phaseSGD;

  //! SGD scaling parameter.
  double sgdRate;

  //! SGD learning rate.
  double sgdLambda;
};

} // namespace ens

#endif
/**
 * @file any.hpp
 * @author Ryan Curtin
 *
 * A simple and dangerous implementation of 'Any' that can be used when the
 * class needs to hold some specific information for which the type is not
 * known.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_UTILITY_ANY_HPP
#define ENSMALLEN_UTILITY_ANY_HPP

#include <typeinfo>
#include <typeindex>

namespace ens {

/**
 * A utility class that can hold any C++ class as a void*.  It does some very
 * basic type checking to ensure that you cast it correctly.  If you call
 * Clean(), it will properly call the destructor on the given type.
 *
 * The Any is holding nothing if Has<void>() returns true.
 */
class Any
{
 public:
  /**
   * Create an Any object that holds nothing.
   */
  Any() :
      held(NULL),
      type(typeid(void)),
      destructor([](const void*) {}) // Fake destructor.
  {
    // Nothing to do.
  }

  /**
   * Get the Any, cast as the thing we want.
   */
  template<typename T>
  const T& As() const
  {
    if (std::type_index(typeid(T)) != type)
    {
      std::string error = "Invalid cast to type '";
      error += typeid(T).name();
      error += "' when Any is holding '";
      error += type.name();
      error += "'!";
      throw std::invalid_argument(error);
    }

    return *reinterpret_cast<const T*>(held);
  }

  /**
   * Get the Any, cast as the thing we want.
   */
  template<typename T>
  T& As()
  {
    if (std::type_index(typeid(T)) != type)
    {
      std::string error = "Invalid cast to type '";
      error += typeid(T).name();
      error += "' when Any is holding '";
      error += type.name();
      error += "'!";
      throw std::invalid_argument(error);
    }

    return *reinterpret_cast<T*>(held);
  }

  /**
   * Set the Any as the given type.
   */
  template<typename T>
  void Set(T* t)
  {
    type = std::type_index(typeid(T));
    held = (void*) t;
    destructor = [](const void* x) { delete static_cast<const T*>(x); };
  }

  /**
   * Determine if the Any is currently holding the given type.
   */
  template<typename T>
  bool Has()
  {
    return (std::type_index(typeid(T)) == type);
  }

  /**
   * Call delete on the thing we are holding.  Be careful with this one.  It
   * automatically does nothing if 'held' is NULL, but that's the only guarantee
   * you get.  Also, I hope you used 'new' to make the thing you're holding.
   */
  void Clean()
  {
    if (held)
    {
      destructor(held);
      held = NULL;
      type = std::type_index(typeid(void));
      destructor = [](const void*) { }; // Fake destructor.
    }
  }

 private:
  // The thing we are holding.
  void* held;
  // The type of the thing we are holding.
  std::type_index type;
  // A pointer to the destructor.
  void (*destructor)(const void*);
};

} // namespace ens

#endif
/**
 * @file arma_traits.hpp
 * @author Ryan Curtin
 * @author Marcus Edel
 *
 * Some traits used for template metaprogramming (SFINAE) with Armadillo types.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_UTILITY_ARMA_TRAITS_HPP
#define ENSMALLEN_UTILITY_ARMA_TRAITS_HPP

namespace ens {

// Structs have public members by default (that's why they are chosen over
// classes).

/**
 * If value == true, then MatType is some sort of Armadillo vector or subview.
 * You might use this struct like this:
 *
 * @code
 * // Only accepts VecTypes that are actually Armadillo vector types.
 * template<typename MatType>
 * void Function(const MatType& argumentA,
 *               typename std::enable_if_t<IsArmaType<MatType>::value>* = 0);
 * @endcode
 *
 * The use of the enable_if_t object allows the compiler to instantiate
 * Function() only if VecType is one of the Armadillo vector types.  It has a
 * default argument because it isn't meant to be used in either the function
 * call or the function body.
 */
template<typename MatType>
struct IsArmaType
{
  const static bool value = false;
};

// Commenting out the first template per case, because
// Visual Studio doesn't like this instantiaion pattern (error C2910).
// template<>
template<typename eT>
struct IsArmaType<arma::Col<eT> >
{
  const static bool value = true;
};

// template<>
template<typename eT>
struct IsArmaType<arma::SpCol<eT> >
{
  const static bool value = true;
};

// template<>
template<typename eT>
struct IsArmaType<arma::Row<eT> >
{
  const static bool value = true;
};

// template<>
template<typename eT>
struct IsArmaType<arma::SpRow<eT> >
{
  const static bool value = true;
};

// template<>
template<typename eT>
struct IsArmaType<arma::subview<eT> >
{
  const static bool value = true;
};

// template<>
template<typename eT>
struct IsArmaType<arma::subview_col<eT> >
{
  const static bool value = true;
};

// template<>
template<typename eT>
struct IsArmaType<arma::subview_row<eT> >
{
  const static bool value = true;
};

// template<>
template<typename eT>
struct IsArmaType<arma::SpSubview<eT> >
{
  const static bool value = true;
};


#if ((ARMA_VERSION_MAJOR >= 10) || \
    ((ARMA_VERSION_MAJOR == 9) && (ARMA_VERSION_MINOR >= 869)))

  // Armadillo 9.869+ has SpSubview_col and SpSubview_row

  template<typename eT>
  struct IsArmaType<arma::SpSubview_col<eT> >
  {
    const static bool value = true;
  };

  template<typename eT>
  struct IsArmaType<arma::SpSubview_row<eT> >
  {
    const static bool value = true;
  };

#endif


// template<>
template<typename eT>
struct IsArmaType<arma::Mat<eT> >
{
  const static bool value = true;
};

// template<>
template<typename eT>
struct IsArmaType<arma::SpMat<eT> >
{
  const static bool value = true;
};

// template<>
template<typename eT>
struct IsArmaType<arma::Cube<eT> >
{
  const static bool value = true;
};

// template<>
template<typename eT>
struct IsArmaType<arma::subview_cube<eT> >
{
  const static bool value = true;
};


template <int N, typename... T>
struct tuple_element;

template <typename T0, typename... T>
struct tuple_element<0, T0, T...> {
    typedef T0 type;
};
template <int N, typename T0, typename... T>
struct tuple_element<N, T0, T...> {
    typedef typename tuple_element<N-1, T...>::type type;
};

} // namespace ens

#endif
/**
 * @file epsilon.hpp
 * @author Rahul Ganesh Prabhu
 * @author Nanubala Gnana Sai
 *
 * Epsilon indicator
 * A binary quality indicator that is capable of detecting whether one
 * approximation set is better than another.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */

#ifndef ENSMALLEN_INDICATORS_EPSILON_HPP
#define ENSMALLEN_INDICATORS_EPSILON_HPP

namespace ens {

/**
 * The epsilon indicator is one of the binary quality indicators that was proposed by
 * Zitzler et. al.. The indicator originally calculates a weak dominance relation 
 * between two approximation sets. It returns "epsilon" which is the factor by which 
 * the given approximation set is worse than the reference front with respect to 
 * all the objectives.
 * 
 * \f[ I_{\epsilon}(A,B) = \max_{z^2 \in B} \
 *                \min_{z^1 \in A} \
 *                \max_{1 \leq i \leq n} \ \frac{z^1_i}{z^2_i}\
 *                \f]
 *
 * For more information, please see:
 *
 * @code
 * @article{1197687,
 *    author   = {E. Zitzler and L. Thiele and M. Laumanns and C. M. Fonseca and
 *                V. G. da Fonseca},
 *    title    = {Performance assessment of multiobjective optimizers: an
 *                analysis and review},
 *    journal  = {IEEE Transactions on Evolutionary Computation},
 *    year     = {2003},
 * }
 * @endcode
 */
  class Epsilon
  {
   public:
    /**
     * Default constructor does nothing, but is required to satisfy the Indicator
     * policy.
     */
    Epsilon() { }

    /**
     * Find the epsilon value of the front with respect to the given reference
     * front.
     *
     * @tparam CubeType The cube data type of front.
     * @param front The given approximation front.
     * @param referenceFront The given reference front.
     * @return The epsilon value of the front.
     */
    template<typename CubeType>
    static typename CubeType::elem_type Evaluate(const CubeType& front,
                                                 const CubeType& referenceFront)
    {
      // Convenience typedefs.
      typedef typename CubeType::elem_type ElemType;
      ElemType eps = 0;
      for (size_t i = 0; i < referenceFront.n_slices; i++)
      {
        ElemType epsjMin = std::numeric_limits<ElemType>::max();
        for (size_t j = 0; j < front.n_slices; j++)
        {
          arma::Mat<ElemType> frontRatio = front.slice(j) / referenceFront.slice(i);
          frontRatio.replace(arma::datum::inf, -1.); // Handle zero division case.
          ElemType epsj = frontRatio.max();
          if (epsj < epsjMin)
            epsjMin = epsj;
        }
        if (epsjMin > eps)
          eps = epsjMin;
      }

      return eps;
    }
  };

} // namespace ens

#endif
/**
 * @file igd_plus.hpp
 * @author Rahul Ganesh Prabhu
 * @author Nanubala Gnana Sai
 *
 * Inverse Generational Distance Plus (IGD+) indicator.
 * The average distance from each reference point to its nearest solution.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */

#ifndef ENSMALLEN_INDICATORS_IGD_PLUS_HPP
#define ENSMALLEN_INDICATORS_IGD_PLUS_HPP

namespace ens {

/**
 * The IGD indicator returns the average distance from each point in the reference
 * front to the nearest point to it's solution. IGD+ is an improvement upon
 * the IGD indicator, which fixes misleading results given by IGD in certain
 * cases via a different distance metric:
 *
 * \f[ d^{+}(z,a) = \sqrt{\sum_{i = 1}^{n}( \max\{a_i - z_i, 0\})^2 \ } \
 *    \f]
 *
 * For more information see:
 *
 * @code
 * @article{10.1007/978-3-319-15892-1_8,
 *    author   = {Ishibuchi, Hisao and Masuda, Hiroyuki and Tanigaki, Yuki
 *                and Nojima, Yusuke},
 *    title    = {Modified Distance Calculation in Generational Distance
 *                and Inverted Generational Distance},
 *    book     = {Evolutionary Multi-Criterion Optimization}
 *    year     = {2015}
 * }
 * @endcode
 */
  class IGDPlus
  {
   public:
    /**
     * Default constructor does nothing, but is required to satisfy the Indicator
     * policy.
     */
    IGDPlus() { }

    /**
     * Find the IGD+ value of the front with respect to the given reference
     * front.
     *
     * @tparam CubeType The cube data type of front.
     * @param front The given approximation front.
     * @param referenceFront The given reference front.
     * @return The IGD value of the front.
     */
    template<typename CubeType>
    static typename CubeType::elem_type Evaluate(const CubeType& front,
                                                 const CubeType& referenceFront)
    {
      // Convenience typedefs.
      typedef typename CubeType::elem_type ElemType;
      ElemType igd = 0;
      for (size_t i = 0; i < referenceFront.n_slices; i++)
      {
        ElemType min = std::numeric_limits<ElemType>::max();
        for (size_t j = 0; j < front.n_slices; j++)
        {
          ElemType dist = 0;
          for (size_t k = 0; k < front.slice(j).n_rows; k++)
          {
            ElemType z = referenceFront(k, 0, i);
            ElemType a = front(k, 0, j);
            // Assuming minimization of all objectives.
            dist += std::pow(std::max<ElemType>(a - z, 0), 2);
          }
          dist = std::sqrt(dist);
          if (dist < min)
            min = dist;
        }
        igd += min;
      }
      igd /= referenceFront.n_slices;

      return igd;
    }
  };

} // namespace ens

#endif
/**
 * @file wn_grad.hpp
 * @author Marcus Edel
 *
 * WNGrad is a general nonlinear update rule for the learning rate.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_WN_GRAD_WN_GRAD_HPP
#define ENSMALLEN_WN_GRAD_WN_GRAD_HPP

#include <ensmallen_bits/sgd/sgd.hpp>
#include "wn_grad_update.hpp"

namespace ens {

/**
 * WNGrad is a general nonlinear update rule for the learning rate, so that
 * the learning rate can be initialized at a high value, and is subsequently
 * decreased according to gradient observations.
 *
 * For more information, see the following.
 *
 * @code
 * @article{Wu2018,
 *   author  = {{Wu}, X. and {Ward}, R. and {Bottou}, L.},
 *   title   = {WNGrad: Learn the Learning Rate in Gradient Descent},
 *   journal = {ArXiv e-prints},
 *   year    = {2018},
 *   url     = {https://arxiv.org/abs/1803.02865},
 * }
 * @endcode
 *
 * WNGrad can optimize differentiable separable functions.  For more
 * details, see the documentation on function types included with this
 * distribution or on the ensmallen website.
 */
class WNGrad
{
 public:
  /**
   * Construct the WNGrad optimizer with the given function and parameters. The
   * defaults here are not necessarily good for the given problem, so it is
   * suggested that the values used be tailored to the task at hand.  The
   * maximum number of iterations refers to the maximum number of points that
   * are processed (i.e., one iteration equals one point; one iteration does not
   * equal one pass over the dataset).
   *
   * @param stepSize Step size for each iteration.
   * @param batchSize Number of points to process in a single step.
   * @param maxIterations Maximum number of iterations allowed (0 means no
   *        limit).
   * @param tolerance Maximum absolute tolerance to terminate algorithm.
   * @param shuffle If true, the function order is shuffled; otherwise, each
   *        function is visited in linear order.
   * @param resetPolicy If true, parameters are reset before every Optimize
   *        call; otherwise, their values are retained.
   * @param exactObjective Calculate the exact objective (Default: estimate the
   *        final objective obtained on the last pass over the data).
   */
  WNGrad(const double stepSize = 0.562,
         const size_t batchSize = 32,
         const size_t maxIterations = 100000,
         const double tolerance = 1e-5,
         const bool shuffle = true,
         const bool resetPolicy = true,
         const bool exactObjective = false);

  /**
   * Optimize the given function using WNGrad. The given starting point will
   * be modified to store the finishing point of the algorithm, and the final
   * objective value is returned.
   *
   * @tparam SeparableFunctionType Type of the function to be optimized.
   * @tparam MatType Type of matrix to optimize with.
   * @tparam GradType Type of matrix to use to represent function gradients.
   * @tparam CallbackTypes Types of callback functions.
   * @param function Function to optimize.
   * @param iterate Starting point (will be modified).
   * @param callbacks Callback functions.
   * @return Objective value of the final point.
   */
  template<typename SeparableFunctionType,
           typename MatType,
           typename GradType,
           typename... CallbackTypes>
  typename std::enable_if<IsArmaType<GradType>::value,
      typename MatType::elem_type>::type
  Optimize(SeparableFunctionType& function,
           MatType& iterate,
           CallbackTypes&&... callbacks)
  {
    return optimizer.Optimize<SeparableFunctionType, MatType, GradType,
        CallbackTypes...>(function, iterate,
        std::forward<CallbackTypes>(callbacks)...);
  }

  //! Forward the MatType as GradType.
  template<typename SeparableFunctionType,
           typename MatType,
           typename... CallbackTypes>
  typename MatType::elem_type Optimize(SeparableFunctionType& function,
                                       MatType& iterate,
                                       CallbackTypes&&... callbacks)
  {
    return Optimize<SeparableFunctionType, MatType, MatType,
        CallbackTypes...>(function, iterate,
        std::forward<CallbackTypes>(callbacks)...);
  }

  //! Get the step size.
  double StepSize() const { return optimizer.StepSize(); }
  //! Modify the step size.
  double& StepSize() { return optimizer.StepSize(); }

  //! Get the batch size.
  size_t BatchSize() const { return optimizer.BatchSize(); }
  //! Modify the batch size.
  size_t& BatchSize() { return optimizer.BatchSize(); }

  //! Get the maximum number of iterations (0 indicates no limit).
  size_t MaxIterations() const { return optimizer.MaxIterations(); }
  //! Modify the maximum number of iterations (0 indicates no limit).
  size_t& MaxIterations() { return optimizer.MaxIterations(); }

  //! Get the tolerance for termination.
  double Tolerance() const { return optimizer.Tolerance(); }
  //! Modify the tolerance for termination.
  double& Tolerance() { return optimizer.Tolerance(); }

  //! Get whether or not the individual functions are shuffled.
  bool Shuffle() const { return optimizer.Shuffle(); }
  //! Modify whether or not the individual functions are shuffled.
  bool& Shuffle() { return optimizer.Shuffle(); }

  //! Get whether or not the actual objective is calculated.
  bool ExactObjective() const { return optimizer.ExactObjective(); }
  //! Modify whether or not the actual objective is calculated.
  bool& ExactObjective() { return optimizer.ExactObjective(); }

  //! Get whether or not the update policy parameters
  //! are reset before Optimize call.
  bool ResetPolicy() const { return optimizer.ResetPolicy(); }
  //! Modify whether or not the update policy parameters
  //! are reset before Optimize call.
  bool& ResetPolicy() { return optimizer.ResetPolicy(); }

 private:
  //! The WNGrad update policy.
  SGD<WNGradUpdate> optimizer;
};

} // namespace ens

// Include implementation.
#include "wn_grad_impl.hpp"

#endif
/**
 * @file wn_grad_impl.hpp
 * @author Marcus Edel
 *
 * Implementation of the WNGrad optimizer.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_WN_GRAD_WN_GRAD_IMPL_HPP
#define ENSMALLEN_WN_GRAD_WN_GRAD_IMPL_HPP

// In case it hasn't been included yet.
#include "wn_grad.hpp"

namespace ens {

inline WNGrad::WNGrad(
    const double stepSize,
    const size_t batchSize,
    const size_t maxIterations,
    const double tolerance,
    const bool shuffle,
    const bool resetPolicy,
    const bool exactObjective) :
    optimizer(stepSize,
              batchSize,
              maxIterations,
              tolerance,
              shuffle,
              WNGradUpdate(),
              NoDecay(),
              resetPolicy,
              exactObjective)
{ /* Nothing to do. */ }

} // namespace ens

#endif
/**
 * @file wn_grad_update.hpp
 * @author Marcus Edel
 *
 * WNGrad update rule for the WNGrad method.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_WN_GRAD_WN_GRAD_UPDATE_HPP
#define ENSMALLEN_WN_GRAD_WN_GRAD_UPDATE_HPP

namespace ens {

/**
 * WNGrad is a general nonlinear update rule for the learning rate, so that
 * the learning rate can be initialized at a high value, and is subsequently
 * decreased according to gradient observations.
 *
 * For more information, see the following.
 *
 * @code
 * @article{Wu2018,
 *   author  = {{Wu}, X. and {Ward}, R. and {Bottou}, L.},
 *   title   = {WNGrad: Learn the Learning Rate in Gradient Descent},
 *   journal = {ArXiv e-prints},
 *   year    = {2018},
 *   url     = {https://arxiv.org/abs/1803.02865},
 * }
 * @endcode
 */
class WNGradUpdate
{
 public:
  /**
   * Construct the WNGrad update policy.
   */
  WNGradUpdate() : b(1.0)
  {
    // Nothing to do here.
  }

  //! Get the learning rate adjustment.
  double B() const { return b; }
  //! Modify the learning rate adjustment.
  double& B() { return b; }

  /**
   * The UpdatePolicyType policy classes must contain an internal 'Policy'
   * template class with two template arguments: MatType and GradType.  This is
   * instantiated at the start of the optimization.
   */
  template<typename MatType, typename GradType>
  class Policy
  {
   public:
    /**
     * This is called by the optimizer method before the start of the iteration
     * update process.
     *
     * @param parent Instantiated parent class.
     * @param rows Number of rows in the gradient matrix.
     * @param cols Number of columns in the gradient matrix.
     */
    Policy(WNGradUpdate& parent,
           const size_t /* rows */,
           const size_t /* cols */) :
        parent(parent)
    {
      /* Nothing to do. */
    }

    /**
     * Update step for WNGrad.
     *
     * @param iterate Parameters that minimize the function.
     * @param stepSize Step size to be used for the given iteration.
     * @param gradient The gradient matrix.
     */
    void Update(MatType& iterate,
                const double stepSize,
                const GradType& gradient)
    {
      parent.b += std::pow(stepSize, 2.0) / parent.b *
          std::pow(arma::norm(gradient), 2);
      iterate -= stepSize * gradient / parent.b;
    }

   private:
    //! Reference to the instantiated parent object.
    WNGradUpdate& parent;
  };

 private:
  //! Learning rate adjustment.
  double b;
};

} // namespace ens

#endif
/**
 * @file yogi.hpp
 * @author Marcus Edel 
 *
 * Class wrapper for the Yogi update Policy. Yogi is based on Adam with more
 * fine grained effective learning rate control.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_YOGI_YOGI_HPP
#define ENSMALLEN_YOGI_YOGI_HPP

#include <ensmallen_bits/sgd/sgd.hpp>
#include "yogi_update.hpp"

namespace ens {

/**
 * Yogi is an variation of Adam with more fine grained effective learning rate
 * control.
 *
 * For more information, see the following.
 *
 * @code
 * @inproceedings{Zaheer2018,
 *   author    = {Zaheer, Manzil and Reddi, Sashank J. and Sachan, Devendra
 *                and Kale, Satyen and Kumar, Sanjiv},
 *   title     = {Adaptive Methods for Nonconvex Optimization},
 *   year      = {2018},
 *   publisher = {Curran Associates Inc.},
 *   booktitle = {Proceedings of the 32nd International Conference on Neural
 *                Information Processing Systems},
 *   pages     = {9815‚Äì9825},
 *   series    = {NIPS'18}
 * }
 * @endcode
 *
 * Yogi can optimize differentiable separable functions. For more details,
 * see the documentation on function types included with this distribution or
 * on the ensmallen website.
 */
class Yogi 
{
 public:
  /**
   * Construct the Yogi optimizer with the given function and parameters.
   * Yogi is sensitive to its paramters and hence a good hyper paramater
   * selection is necessary as its default may not fit every case.
   *
   * The maximum number of iterations refers to the maximum number of
   * points that are processed (i.e., one iteration equals one point; one
   * iteration does not equal one pass over the dataset).
   *
   * @param stepSize Step size for each iteration.
   * @param batchSize Number of points to process in a single step.
   * @param beta1 Exponential decay rate for the first moment estimates.
   * @param beta2 Exponential decay rate for the weighted infinity norm
   *     estimates.
   * @param epsilon Value used to initialise the mean squared gradient
   *     parameter.
   * @param maxIterations Maximum number of iterations allowed (0 means no
   *     limit).
   * @param tolerance Maximum absolute tolerance to terminate algorithm.
   * @param shuffle If true, the function order is shuffled; otherwise, each
   *     function is visited in linear order.
   * @param resetPolicy If true, parameters are reset before every Optimize
   *     call; otherwise, their values are retained.
   * @param exactObjective Calculate the exact objective (Default: estimate the
   *        final objective obtained on the last pass over the data).
   */
  Yogi(const double stepSize = 0.001,
       const size_t batchSize = 32,
       const double beta1 = 0.9,
       const double beta2 = 0.999,
       const double epsilon = 1e-8,
       const size_t maxIterations = 100000,
       const double tolerance = 1e-5,
       const bool shuffle = true,
       const bool resetPolicy = true,
       const bool exactObjective = false);

  /**
   * Optimize the given function using Yogi. The given starting point will be
   * modified to store the finishing point of the algorithm, and the final
   * objective value is returned.
   *
   * @tparam SeparableFunctionType Type of the function to optimize.
   * @tparam MatType Type of matrix to optimize with.
   * @tparam GradType Type of matrix to use to represent function gradients.
   * @tparam CallbackTypes Types of callback functions.
   * @param function Function to optimize.
   * @param iterate Starting point (will be modified).
   * @param callbacks Callback functions.
   * @return Objective value of the final point.
   */
  template<typename SeparableFunctionType,
           typename MatType,
           typename GradType,
           typename... CallbackTypes>
  typename std::enable_if<IsArmaType<GradType>::value,
      typename MatType::elem_type>::type
  Optimize(SeparableFunctionType& function,
           MatType& iterate,
           CallbackTypes&&... callbacks)
  {
    return optimizer.Optimize<SeparableFunctionType, MatType, GradType,
        CallbackTypes...>(function, iterate,
        std::forward<CallbackTypes>(callbacks)...);
  }

  //! Forward the MatType as GradType.
  template<typename SeparableFunctionType,
           typename MatType,
           typename... CallbackTypes>
  typename MatType::elem_type Optimize(SeparableFunctionType& function,
                                       MatType& iterate,
                                       CallbackTypes&&... callbacks)
  {
    return Optimize<SeparableFunctionType, MatType, MatType,
        CallbackTypes...>(function, iterate,
        std::forward<CallbackTypes>(callbacks)...);
  }

  //! Get the step size.
  double StepSize() const { return optimizer.StepSize(); }
  //! Modify the step size.
  double& StepSize() { return optimizer.StepSize(); }

  //! Get the batch size.
  size_t BatchSize() const { return optimizer.BatchSize(); }
  //! Modify the batch size.
  size_t& BatchSize() { return optimizer.BatchSize(); }

  //! Get the smoothing parameter.
  double Beta1() const { return optimizer.UpdatePolicy().Beta1(); }
  //! Modify the smoothing parameter.
  double& Beta1() { return optimizer.UpdatePolicy().Beta1(); }

  //! Get the second moment coefficient.
  double Beta2() const { return optimizer.UpdatePolicy().Beta2(); }
  //! Modify the second moment coefficient.
  double& Beta2() { return optimizer.UpdatePolicy().Beta2(); }

  //! Get the value used to initialise the mean squared gradient parameter.
  double Epsilon() const { return optimizer.UpdatePolicy().Epsilon(); }
  //! Modify the value used to initialise the mean squared gradient parameter.
  double& Epsilon() { return optimizer.UpdatePolicy().Epsilon(); }

  //! Get the maximum number of iterations (0 indicates no limit).
  size_t MaxIterations() const { return optimizer.MaxIterations(); }
  //! Modify the maximum number of iterations (0 indicates no limit).
  size_t& MaxIterations() { return optimizer.MaxIterations(); }

  //! Get the tolerance for termination.
  double Tolerance() const { return optimizer.Tolerance(); }
  //! Modify the tolerance for termination.
  double& Tolerance() { return optimizer.Tolerance(); }

  //! Get whether or not the individual functions are shuffled.
  bool Shuffle() const { return optimizer.Shuffle(); }
  //! Modify whether or not the individual functions are shuffled.
  bool& Shuffle() { return optimizer.Shuffle(); }

  //! Get whether or not the actual objective is calculated.
  bool ExactObjective() const { return optimizer.ExactObjective(); }
  //! Modify whether or not the actual objective is calculated.
  bool& ExactObjective() { return optimizer.ExactObjective(); }

  //! Get whether or not the update policy parameters are reset before
  //! Optimize call.
  bool ResetPolicy() const { return optimizer.ResetPolicy(); }
  //! Modify whether or not the update policy parameters
  //! are reset before Optimize call.
  bool& ResetPolicy() { return optimizer.ResetPolicy(); }

  private:
  //! The Stochastic Gradient Descent object with Yogi policy.
  SGD<YogiUpdate> optimizer;
};

} // namespace ens

// Include implementation.
#include "yogi_impl.hpp"

#endif
/**
 * @file yogi_impl.hpp
 * @author Marcus Edel
 *
 * Implementation of Yogi class wrapper.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_YOGI_YOGI_IMPL_HPP
#define ENSMALLEN_YOGI_YOGI_IMPL_HPP

// In case it hasn't been included yet.
#include "yogi.hpp"

namespace ens {

inline Yogi::Yogi(
    const double stepSize,
    const size_t batchSize,
    const double beta1,
    const double beta2,
    const double epsilon,
    const size_t maxIterations,
    const double tolerance,
    const bool shuffle,
    const bool resetPolicy,
    const bool exactObjective) :
    optimizer(stepSize,
              batchSize,
              maxIterations,
              tolerance,
              shuffle,
              YogiUpdate(epsilon, beta1, beta2),
              NoDecay(),
              resetPolicy,
              exactObjective)
{ /* Nothing to do. */ }

} // namespace ens

 #endif
/**
 * @file yogi_update.hpp
 * @author Marcus Edel
 *
 * Implements the Yogi Optimizer. Yogi is a variant of Adam with more fine
 * grained effective learning rate control.
 *
 * ensmallen is free software; you may redistribute it and/or modify it under
 * the terms of the 3-clause BSD license.  You should have received a copy of
 * the 3-clause BSD license along with ensmallen.  If not, see
 * http://www.opensource.org/licenses/BSD-3-Clause for more information.
 */
#ifndef ENSMALLEN_YOGI_YOGI_UPDATE_HPP
#define ENSMALLEN_YOGI_YOGI_UPDATE_HPP

namespace ens {

/**
 * Yogi builds upon the Adam update strategy but provides more fine grained
 * effective learning rate control.
 *
 * For more information, see the following.
 *
 * @code
 * @inproceedings{Zaheer2018,
 *   author    = {Zaheer, Manzil and Reddi, Sashank J. and Sachan, Devendra
 *                and Kale, Satyen and Kumar, Sanjiv},
 *   title     = {Adaptive Methods for Nonconvex Optimization},
 *   year      = {2018},
 *   publisher = {Curran Associates Inc.},
 *   booktitle = {Proceedings of the 32nd International Conference on Neural
 *                Information Processing Systems},
 *   pages     = {9815‚Äì9825},
 *   series    = {NIPS'18}
 * }
 * @endcode
 */
class YogiUpdate
{
 public:
  /**
   * Construct the Yogi update policy with the given parameters.
   *
   * @param epsilon The epsilon value used to initialise the squared gradient
   *     parameter.
   * @param beta1 The smoothing parameter.
   * @param beta2 The second moment coefficient.
   * @param v1 The first quasi-hyperbolic term.
   * @param v1 The second quasi-hyperbolic term.
   */
  YogiUpdate(const double epsilon = 1e-8,
             const double beta1 = 0.9,
             const double beta2 = 0.999) :
    epsilon(epsilon),
    beta1(beta1),
    beta2(beta2)
  {
    // Nothing to do.
  }

  //! Get the value used to initialise the squared gradient parameter.
  double Epsilon() const { return epsilon; }
  //! Modify the value used to initialise the squared gradient parameter.
  double& Epsilon() { return epsilon; }

  //! Get the smoothing parameter.
  double Beta1() const { return beta1; }
  //! Modify the smoothing parameter.
  double& Beta1() { return beta1; }

  //! Get the second moment coefficient.
  double Beta2() const { return beta2; }
  //! Modify the second moment coefficient.
  double& Beta2() { return beta2; }

  /**
   * The UpdatePolicyType policy classes must contain an internal 'Policy'
   * template class with two template arguments: MatType and GradType.  This is
   * instantiated at the start of the optimization, and holds parameters
   * specific to an individual optimization.
   */
  template<typename MatType, typename GradType>
  class Policy
  {
   public:
    /**
     * This constructor is called by the SGD Optimize() method before the start
     * of the iteration update process.
     *
     * @param parent YogiUpdate object.
     * @param rows Number of rows in the gradient matrix.
     * @param cols Number of columns in the gradient matrix.
     */
    Policy(YogiUpdate& parent, const size_t rows, const size_t cols) :
        parent(parent)
    {
      m.zeros(rows, cols);
      v.zeros(rows, cols);
    }

    /**
     * Update step for Yogi.
     *
     * @param iterate Parameters that minimize the function.
     * @param stepSize Step size to be used for the given iteration.
     * @param gradient The gradient matrix.
     */
    void Update(MatType& iterate,
                const double stepSize,
                const GradType& gradient)
    {
      m *= parent.beta1;
      m += (1 - parent.beta1) * gradient;

      const MatType gSquared = arma::square(gradient);
      v -= (1 - parent.beta2) * arma::sign(v - gSquared) % gSquared;

      // Now update the iterate.
      iterate -= stepSize * m / (arma::sqrt(v) + parent.epsilon);
    }

   private:
    //! Instantiated parent object.
    YogiUpdate& parent;

    //! The exponential moving average of gradient values.
    GradType m;

    // The exponential moving average of squared gradient values.
    GradType v;
  };

 private:
  // The epsilon value used to initialise the squared gradient parameter.
  double epsilon;

  // The smoothing parameter.
  double beta1;

  // The second moment coefficient.
  double beta2;
};

} // namespace ens

#endif
 asm    -dylink.0¯ libRlapack.solibRblas.so±$``` ` `` `|| ` `|`|`|`` `  ` ``|| `| `| `|``` |`|||`| `` `|` ` ` ` `
 ` `||` âŒΩenv_ZN4Rcpp8RostreamILb1EEC1Ev  env_ZN4Rcpp10RstreambufILb1EEC2Ev  env3_ZNSt3__213basic_ostreamIcNS_11char_traitsIcEEED2Ev env._ZNSt3__29basic_iosIcNS_11char_traitsIcEEED2Ev  env_ZN4Rcpp8RostreamILb1EED1Ev  env_ZN4Rcpp8RostreamILb1EED2Ev env_ZN4Rcpp8RostreamILb0EEC1Ev  env_ZN4Rcpp10RstreambufILb0EEC2Ev  env_ZN4Rcpp8RostreamILb0EED1Ev  env_ZN4Rcpp8RostreamILb0EED2Ev env
Rf_install  envg_ZN4Rcpp22ArmaMat_InputParameterIdN4arma3MatIdEERKS3_NS_6traits17integral_constantIbLb0EEEEC2EP7SEXPREC envg_ZN4Rcpp22ArmaVec_InputParameterIdN4arma3ColIdEERKS3_NS_6traits17integral_constantIbLb0EEEEC2EP7SEXPREC env+_ZN4Rcpp4wrapIdEEP7SEXPRECRKN4arma3MatIT_EE  envC_ZN4Rcpp12RObject_ImplINS_15PreserveStorageEEaSIP7SEXPRECEERS2_RKT_ env_ZN4arma3MatIdED2Ev  env__ZN4Rcpp22ArmaVec_InputParameterIdN4arma3ColIdEERKS3_NS_6traits17integral_constantIbLb0EEEED2Ev  env__ZN4Rcpp22ArmaMat_InputParameterIdN4arma3MatIdEERKS3_NS_6traits17integral_constantIbLb0EEEED2Ev  env_ZN4Rcpp8RNGScopeD2Ev  env6_ZN4Rcpp15PreserveStorageINS_12RObject_ImplIS0_EEED2Ev  env_Unwind_CallPersonality  env__cxa_begin_catch  env__cxa_end_catch env	Rf_onintr env4_Z29rcpp_exception_to_r_conditionRKN4Rcpp9exceptionE  env
Rf_protect  env_ZSt9terminatev env'_ZN4Rcpp8internal10resumeJumpEP7SEXPREC env*_Z24exception_to_r_conditionRKSt9exception  envR_ZNSt3__212basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEC2B7v160006IDnEEPKc envW_Z19string_to_try_errorRKNSt3__212basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEE  envC_ZNSt3__212basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEED2Ev  envRf_lang2 envRf_eval envRf_unprotect env_ZN4Rcpp9DimensionC2ERKmS2_ envO_ZN4Rcpp13RcppArmadillo9arma_wrapIN4arma3MatIdEEEEP7SEXPRECRKT_RKNS_9DimensionE env _ZN4Rcpp12Rcpp_protectEP7SEXPREC  envB_ZN4Rcpp15PreserveStorageINS_12RObject_ImplIS0_EEE5set__EP7SEXPREC env_ZN4Rcpp6ShieldIP7SEXPRECED2Ev  envfree env4_ZN4Rcpp15PreserveStorageINS_6VectorILi14ES0_EEED2Ev  envRf_mkString  envRf_setAttrib envstrlen  envK_ZNSt3__212basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEE6__initEPKcm env?_Z31exception_to_condition_templateISt9exceptionEP7SEXPRECRKT_b env,_ZNK4Rcpp9exception21copy_stack_trace_to_rEv envD_Z31exception_to_condition_templateIN4Rcpp9exceptionEEP7SEXPRECRKT_b env/_ZN4Rcpp8internal18isLongjumpSentinelEP7SEXPREC  env-_ZN4Rcpp8internal16getLongjumpTokenEP7SEXPREC  envR_ReleaseObject envR_ContinueUnwind envR_registerRoutines envR_useDynamicSymbols env5_ZNSt3__215basic_streambufIcNS_11char_traitsIcEEED2Ev  env_ZN4Rcpp8RostreamILb1EED0Ev env_ZdlPv env_ZN4Rcpp8RostreamILb0EED0Ev envR_GetCCallable env_Z13get_last_callv env!_ZN4Rcpp7ShelterIP7SEXPRECEclES2_ envY_Z21get_exception_classesRKNSt3__212basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEE  enva_Z14make_conditionRKNSt3__212basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEP7SEXPRECS9_S9_ env_ZN4Rcpp7ShelterIP7SEXPRECED2Ev  envRf_lang1  env%_ZN4Rcpp14Rcpp_fast_evalEP7SEXPRECS1_ envCDR  envCAR  env._ZN4Rcpp8internal17is_Rcpp_eval_callEP7SEXPREC  envRf_allocVector env	Rf_mkChar  envSET_STRING_ELT envSET_VECTOR_ELT env)_ZN4Rcpp13unwindProtectEPFP7SEXPRECPvES2_ env
Rf_findFun envTYPEOF  env	Rf_length  env _ZN4Rcpp8internal3nthEP7SEXPRECi envmalloc  envR_MakeUnwindCont env
saveSetjmp envgetTempRet0 envR_PreserveObject env__cxa_allocate_exception  env'_ZN4Rcpp17LongjumpExceptionC2EP7SEXPREC env__cxa_free_exception envR_UnwindProtect env__cxa_throw env
testSetjmp env__wasm_longjmp envRf_inherits env
VECTOR_ELT env	Rf_nthcdr envw_ZN4Rcpp6VectorILi16ENS_15PreserveStorageEEC2ImEET_PNS_6traits9enable_ifIXsr6traits13is_arithmeticIS4_EE5valueEvE4typeE envG_ZNSt3__212basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEC2ERKS5_ env≠_ZN4Rcpp6VectorILi19ENS_15PreserveStorageEE16create__dispatchINS_6traits12named_objectIA1_cEENS5_IiEENS5_INS0_ILi16ES1_EEEEEES2_NS4_17integral_constantIbLb1EEERKT_RKT0_RKT1_ env†_ZN4Rcpp20AttributeProxyPolicyINS_6VectorILi19ENS_15PreserveStorageEEEE14AttributeProxyC2ERS3_RKNSt3__212basic_stringIcNS7_11char_traitsIcEENS7_9allocatorIcEEEE envi_ZN4Rcpp20AttributeProxyPolicyINS_6VectorILi19ENS_15PreserveStorageEEEE14AttributeProxyaSIA17_cEERS5_RKT_ env4_ZN4Rcpp15PreserveStorageINS_6VectorILi19ES0_EEED2Ev  env4_ZN4Rcpp15PreserveStorageINS_6VectorILi16ES0_EEED2Ev  env@_ZN4Rcpp15PreserveStorageINS_6VectorILi16ES0_EEE5set__EP7SEXPREC enve_ZN4Rcpp20AttributeProxyPolicyINS_6VectorILi19ENS_15PreserveStorageEEEE14AttributeProxy3setEP7SEXPREC envË_ZNKSt3__211__copy_loopINS_17_ClassicAlgPolicyEEclB7v160006IPKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEESB_N4Rcpp8internal14Proxy_IteratorINSD_12string_proxyILi16ENSC_15PreserveStorageEEEEEEENS_4pairIT_T1_EESK_T0_SL_ envá_ZN4Rcpp8internal12string_proxyILi16ENS_15PreserveStorageEE3setINSt3__212basic_stringIcNS5_11char_traitsIcEENS5_9allocatorIcEEEEEEvRKT_ envr_ZN4Rcpp8internal28make_charsexp__impl__cstringERKNSt3__212basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEE  envI_ZN4Rcpp8internal12string_proxyILi16ENS_15PreserveStorageEE3setEP7SEXPREC env1_ZN4Rcpp6VectorILi19ENS_15PreserveStorageEEC2ERKi env™_ZN4Rcpp6VectorILi19ENS_15PreserveStorageEE15replace_elementINS_6traits12named_objectIA1_cEEEEvNS_8internal14Proxy_IteratorINS8_13generic_proxyILi19ES1_EEEEP7SEXPRECiRKT_ envß_ZN4Rcpp6VectorILi19ENS_15PreserveStorageEE15replace_elementINS_6traits12named_objectIiEEEEvNS_8internal14Proxy_IteratorINS7_13generic_proxyILi19ES1_EEEEP7SEXPRECiRKT_ envµ_ZN4Rcpp6VectorILi19ENS_15PreserveStorageEE15replace_elementINS_6traits12named_objectINS0_ILi16ES1_EEEEEEvNS_8internal14Proxy_IteratorINS8_13generic_proxyILi19ES1_EEEEP7SEXPRECiRKT_ env@_ZN4Rcpp15PreserveStorageINS_6VectorILi19ES0_EEE5set__EP7SEXPREC env”_ZN4Rcpp6VectorILi19ENS_15PreserveStorageEE25replace_element__dispatchINS_6traits12named_objectIA1_cEEEEvNS4_17integral_constantIbLb1EEENS_8internal14Proxy_IteratorINSA_13generic_proxyILi19ES1_EEEEP7SEXPRECiRKT_ env–_ZN4Rcpp6VectorILi19ENS_15PreserveStorageEE25replace_element__dispatchINS_6traits12named_objectIiEEEEvNS4_17integral_constantIbLb1EEENS_8internal14Proxy_IteratorINS9_13generic_proxyILi19ES1_EEEEP7SEXPRECiRKT_ envﬁ_ZN4Rcpp6VectorILi19ENS_15PreserveStorageEE25replace_element__dispatchINS_6traits12named_objectINS0_ILi16ES1_EEEEEEvNS4_17integral_constantIbLb1EEENS_8internal14Proxy_IteratorINSA_13generic_proxyILi19ES1_EEEEP7SEXPRECiRKT_ envﬂ_ZN4Rcpp6VectorILi19ENS_15PreserveStorageEE37replace_element__dispatch__isArgumentINS_6traits12named_objectIA1_cEEEEvNS4_17integral_constantIbLb0EEENS_8internal14Proxy_IteratorINSA_13generic_proxyILi19ES1_EEEEP7SEXPRECiRKT_ env_ZN4Rcpp4wrapEPKc  envJ_ZN4Rcpp8internal13generic_proxyILi19ENS_15PreserveStorageEE3setEP7SEXPREC env‹_ZN4Rcpp6VectorILi19ENS_15PreserveStorageEE37replace_element__dispatch__isArgumentINS_6traits12named_objectIiEEEEvNS4_17integral_constantIbLb0EEENS_8internal14Proxy_IteratorINS9_13generic_proxyILi19ES1_EEEEP7SEXPRECiRKT_ envc_ZN4Rcpp8internal26primitive_wrap__impl__castIiEEP7SEXPRECRKT_NS_6traits17integral_constantIbLb0EEE  envÍ_ZN4Rcpp6VectorILi19ENS_15PreserveStorageEE37replace_element__dispatch__isArgumentINS_6traits12named_objectINS0_ILi16ES1_EEEEEEvNS4_17integral_constantIbLb0EEENS_8internal14Proxy_IteratorINSA_13generic_proxyILi19ES1_EEEEP7SEXPRECiRKT_ env__ZNSt3__212basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEE25__init_copy_ctor_externalEPKcm env5_ZNSt3__215basic_streambufIcNS_11char_traitsIcEEEC2Ev  env_ZNSt3__28ios_base4initEPv envR_FlushConsole envRprintf envREprintf env7_ZN4Rcpp6MatrixILi14ENS_15PreserveStorageEEC2EP7SEXPREC env3_ZNK4Rcpp6MatrixILi14ENS_15PreserveStorageEE4ncolEv  env7_ZN4Rcpp6VectorILi14ENS_15PreserveStorageEEC2EP7SEXPREC env3_ZNK4Rcpp6VectorILi14ENS_15PreserveStorageEE4dimsEv  env_ZN4arma3MatIdEC2EPdjjbb env_ZN4arma3MatIdE9init_coldEv envmemcpy envRf_isMatrix  env_ZNSt9exceptionD2Ev  envRf_getAttrib envINTEGER  env@_ZN4Rcpp15PreserveStorageINS_6VectorILi14ES0_EEE5set__EP7SEXPREC envZ_ZN4Rcpp6traits14r_vector_cacheILi14ENS_15PreserveStorageEE6updateERKNS_6VectorILi14ES2_EE env#_ZN4Rcpp6r_castILi14EEEP7SEXPRECS2_  env1_ZN4Rcpp8internal10basic_castILi14EEEP7SEXPRECS3_  envRf_coerceVector envRf_type2char  env-_ZN4Rcpp14not_compatibleC2IJPKcS3_EEES3_DpOT_ env_ZN4Rcpp14not_compatibleD2Ev  envj_ZN10tinyformat6formatIJPKcS2_EEENSt3__212basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEES2_DpRKT_ env[_ZN10tinyformat6formatIJPKcS2_EEEvRNSt3__213basic_ostreamIcNS3_11char_traitsIcEEEES2_DpRKT_ envI_ZNKSt3__215basic_stringbufIcNS_11char_traitsIcEENS_9allocatorIcEEE3strEv envJ_ZNSt3__219basic_ostringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEED1Ev  env]_ZN10tinyformat7vformatERNSt3__213basic_ostreamIcNS0_11char_traitsIcEEEEPKcRKNS_10FormatListE envJ_ZNSt3__219basic_ostringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEED2Ev envh_ZN10tinyformat6detail10formatImplERNSt3__213basic_ostreamIcNS1_11char_traitsIcEEEEPKcPKNS0_9FormatArgEi envd_ZN10tinyformat6detail24printFormatStringLiteralERNSt3__213basic_ostreamIcNS1_11char_traitsIcEEEEPKc envP_ZN4Rcpp4stopERKNSt3__212basic_stringIcNS0_11char_traitsIcEENS0_9allocatorIcEEEE envz_ZN10tinyformat6detail21streamStateFromFormatERNSt3__213basic_ostreamIcNS1_11char_traitsIcEEEERbRiPKcPKNS0_9FormatArgES8_i env`_ZNK10tinyformat6detail9FormatArg6formatERNSt3__213basic_ostreamIcNS2_11char_traitsIcEEEEPKcS9_i env8_ZNSt3__29basic_iosIcNS_11char_traitsIcEEE7copyfmtERKS3_ env:_ZNSt3__213basic_ostreamIcNS_11char_traitsIcEEE5writeEPKcl env/_ZN10tinyformat6detail18parseIntAndAdvanceERPKc  env)_ZNK10tinyformat6detail9FormatArg5toIntEv  env_ZN4Rcpp9exceptionC2EPKcb env_ZN4Rcpp9exceptionD2Ev  env_ZNKSt3__28ios_base6getlocEv env_ZNSt3__26localeD1Ev  env%_ZNKSt3__26locale9use_facetERNS0_2idE env=_ZNSt3__213basic_ostreamIcNS_11char_traitsIcEEE6sentryC1ERS3_ env:_ZNSt3__213basic_ostreamIcNS_11char_traitsIcEEE6sentryD1Ev  env7_ZNSt3__28ios_base33__set_badbit_and_consider_rethrowEv envI_ZNSt3__212basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEE6__initEmc env_ZNSt3__28ios_base5clearEj env^_ZN10tinyformat11formatValueIPKcEEvRNSt3__213basic_ostreamIcNS3_11char_traitsIcEEEES2_S2_iRKT_ env:_ZN10tinyformat6detail12convertToIntIPKcLb0EE6invokeERKS3_  envr_ZN10tinyformat6detail17formatValueAsTypeIPKcPKvLb1EE6invokeERNSt3__213basic_ostreamIcNS7_11char_traitsIcEEEERKS3_ env\_ZN10tinyformat6detail15formatTruncatedERNSt3__213basic_ostreamIcNS1_11char_traitsIcEEEEPKci env5_ZNSt3__213basic_ostreamIcNS_11char_traitsIcEEElsEPKv envF_ZNSt3__215basic_stringbufIcNS_11char_traitsIcEENS_9allocatorIcEEED2Ev  env _ZN4arma10arma_checkIPKcEEvbRKT_ env_ZN4arma6memory7acquireIdEEPT_j  env"_ZN4arma10arma_checkIA53_cEEvbRKT_ envposix_memalign envW_ZNSt11logic_errorC1ERKNSt3__212basic_stringIcNS0_11char_traitsIcEENS0_9allocatorIcEEEE env_ZNSt9bad_allocC1Ev  env3_ZNK4Rcpp6VectorILi14ENS_15PreserveStorageEE4sizeEv  env_ZN4arma3ColIdEC2EPdjbb env
Rf_xlength  envn_ZN4Rcpp8internal34primitive_range_wrap__impl__nocastIPKddEEP7SEXPRECT_S6_NSt3__226random_access_iterator_tagE env9_ZN4Rcpp12RObject_ImplINS_15PreserveStorageEEC2EP7SEXPREC env¢_ZN4Rcpp20AttributeProxyPolicyINS_12RObject_ImplINS_15PreserveStorageEEEE14AttributeProxyC2ERS3_RKNSt3__212basic_stringIcNS7_11char_traitsIcEENS7_9allocatorIcEEEE envt_ZN4Rcpp20AttributeProxyPolicyINS_12RObject_ImplINS_15PreserveStorageEEEE14AttributeProxyaSINS_9DimensionEEERS5_RKT_ env _ZNK4Rcpp9DimensioncvP7SEXPRECEv  envg_ZN4Rcpp20AttributeProxyPolicyINS_12RObject_ImplINS_15PreserveStorageEEEE14AttributeProxy3setEP7SEXPREC envÇ_ZN4Rcpp8internal34primitive_range_wrap__impl__nocastINSt3__211__wrap_iterIPKiEEiEEP7SEXPRECT_S9_NS2_26random_access_iterator_tagE env_Znwm  env__cxa_atexit envB_ZN4arma3MatIdEC2INS_4fill10fill_randnEEEjjRKNS3_10fill_classIT_EE envò_ZN3ens6L_BFGS8OptimizeI24LinearRegressionFunctionN4arma3MatIdEES5_JEEENSt3__29enable_ifIXsr10IsArmaTypeIT1_EE5valueENT0_9elem_typeEE4typeERT_RS9_DpOT2_ 
env_ZN4arma3MatIdE5randnEv  env#_ZN4arma8arma_rng5randnIdE4fillEPdj env1_ZN4arma12arma_rng_alt14randn_dual_valIdEEvRT_S3_ env"_ZN4arma12arma_rng_alt9randn_valEv envRf_runif envlog "env_ZN4arma3MatIdEC2Ejj env_ZN4arma4CubeIdEC2Ejjj envmemset envu_ZN3ens23AddEvaluateWithGradientI24LinearRegressionFunctionN4arma3MatIdEES4_Lb1ELb0EE20EvaluateWithGradientERKS4_RS4_ 
envô_ZN4arma4normINS_3MatIdEEEENS_10enable_if2IXsr12is_arma_typeIT_EE5valueENS4_8pod_typeEE6resultERKS4_jPKNS_20arma_real_or_cx_onlyINS4_9elem_typeEE6resultE 
envO_ZN3ens6L_BFGS19ChooseScalingFactorIN4arma3MatIdEENS2_4CubeIdEEEEdmRKT_RKT0_SC_ envP_ZN3ens6L_BFGS15SearchDirectionIN4arma3MatIdEENS2_4CubeIdEEEEvRKT_mdRKT0_SC_RS7_ env_ZN4arma3MatIdEaSERKS1_ envÄ_ZN3ens6L_BFGS10LineSearchINS_8FunctionI24LinearRegressionFunctionN4arma3MatIdEES6_EEdS6_S6_JEEEbRT_RT0_RT1_RT2_SD_RKSE_RdDpRT3_ envW_ZN3ens6L_BFGS14UpdateBasisSetIN4arma3MatIdEES4_NS2_4CubeIdEEEEvmRKT_S9_RKT0_SC_RT1_SE_ env_ZN4arma4CubeIdED2Ev  env_ZN4arma4CubeIdE9init_coldEv env_ZNSt3__25mutexD1Ev  env7_ZN24LinearRegressionFunction8EvaluateERKN4arma3MatIdEE env;_ZN24LinearRegressionFunction8GradientERKN4arma3MatIdEERS2_ env<_ZN4arma7op_norm21vec_norm_2_direct_stdIdEET_RKNS_3MatIS2_EE 	env"_ZN4arma10arma_checkIA37_cEEvbRKT_ envI_ZN4arma7op_norm10vec_norm_kINS_3MatIdEEEENT_8pod_typeERKNS_5ProxyIS4_EEi envL_ZN4arma7op_norm10mat_norm_1IdEENS_12get_pod_typeIT_E6resultERKNS_3MatIS3_EE 	envL_ZN4arma7op_norm10mat_norm_2IdEENS_12get_pod_typeIT_E6resultERKNS_3MatIS3_EE 	env<_ZN4arma7op_norm21vec_norm_1_direct_stdIdEET_RKNS_3MatIS2_EE 	env5_ZNSt3__213basic_ostreamIcNS_11char_traitsIcEEE3putEc env7_ZNSt3__213basic_ostreamIcNS_11char_traitsIcEEE5flushEv  env_ZNK4arma4CubeIdE5sliceEj env>_ZN4arma6op_dot5applyINS_3MatIdEES3_EENT_9elem_typeERKS4_RKT0_ envõ_ZN4arma4normINS_3MatIdEEEENS_10enable_if2IXsr12is_arma_typeIT_EE5valueENS4_8pod_typeEE6resultERKS4_PKcPKNS_20arma_real_or_cx_onlyINS4_9elem_typeEE6resultE 
env_ZN4arma3ColIdEC2Ej env_ZN4arma3MatIdEmLEd envt_ZN4arma8eop_coreINS_16eop_scalar_timesEE18apply_inplace_plusINS_3MatIdEEEEvRNS4_INT_9elem_typeEEERKNS_3eOpIS6_S1_EE envu_ZN4arma8eop_coreINS_16eop_scalar_timesEE19apply_inplace_minusINS_3MatIdEEEEvRNS4_INT_9elem_typeEEERKNS_3eOpIS6_S1_EE env_ZN4arma3MatIdE9init_warmEjj env_ZN4arma4CubeIdE5sliceEj envE_ZN4arma3MatIdEaSIS1_S1_NS_11eglue_minusEEERS1_RKNS_5eGlueIT_T0_T1_EE env_ZN4arma4CubeIdE10delete_matEv env_ZN4arma4CubeIdE10create_matEv env_ZnamRKSt9nothrow_t env?_ZN4arma3MatIdEC2IS1_S1_NS_10glue_timesEEERKNS_4GlueIT_T0_T1_EE envﬂ_ZN4arma4normINS_5eGlueINS_3ColIdEENS_4GlueINS_3MatIdEES6_NS_10glue_timesEEENS_11eglue_minusEEEEENS_10enable_if2IXsr12is_arma_typeIT_EE5valueENSC_8pod_typeEE6resultERKSC_jPKNS_20arma_real_or_cx_onlyINSC_9elem_typeEE6resultE 
envπ_ZN4arma7op_norm10vec_norm_1INS_5eGlueINS_3ColIdEENS_4GlueINS_3MatIdEES7_NS_10glue_timesEEENS_11eglue_minusEEEEENT_8pod_typeERKNS_5ProxyISC_EEPKNS_11arma_not_cxINSC_9elem_typeEE6resultE envπ_ZN4arma7op_norm10vec_norm_2INS_5eGlueINS_3ColIdEENS_4GlueINS_3MatIdEES7_NS_10glue_timesEEENS_11eglue_minusEEEEENT_8pod_typeERKNS_5ProxyISC_EEPKNS_11arma_not_cxINSC_9elem_typeEE6resultE envè_ZN4arma7op_norm10vec_norm_kINS_5eGlueINS_3ColIdEENS_4GlueINS_3MatIdEES7_NS_10glue_timesEEENS_11eglue_minusEEEEENT_8pod_typeERKNS_5ProxyISC_EEi envg_ZN4arma3MatIdEC2INS_3ColIdEENS_4GlueIS1_S1_NS_10glue_timesEEENS_11eglue_minusEEERKNS_5eGlueIT_T0_T1_EE env?_ZN4arma7op_norm24vec_norm_2_direct_robustIdEET_RKNS_3MatIS2_EE 	envpow envÇ_ZN4arma10eglue_coreINS_11eglue_minusEE5applyINS_3MatIdEENS_3ColIdEENS_4GlueIS5_S5_NS_10glue_timesEEEEEvRT_RKNS_5eGlueIT0_T1_S1_EE env|_ZN4arma27glue_times_redirect2_helperILb0EE5applyINS_3MatIdEES4_EEvRNS3_INT_9elem_typeEEERKNS_4GlueIS5_T0_NS_10glue_timesEEE envP_ZN4arma10glue_times5applyIdLb0ELb0ELb0ENS_3MatIdEES3_EEvRNS2_IT_EERKT3_RKT4_S4_ env_ZN4arma3MatIdE9steal_memERS1_ env7_ZN4arma26arma_assert_trans_mul_sizeILb0ELb0EEEvjjjjPKc envO_ZN4arma4gemvILb1ELb0ELb0EE15apply_blas_typeIdNS_3MatIdEEEEvPT_RKT0_PKS5_S5_S5_ envO_ZN4arma4gemvILb0ELb0ELb0EE15apply_blas_typeIdNS_3MatIdEEEEvPT_RKT0_PKS5_S5_S5_ env]_ZN4arma4gemmILb0ELb0ELb0ELb0EE15apply_blas_typeIdNS_3MatIdEES4_EEvRNS3_IT_EERKT0_RKT1_S5_S5_ env_ZN4arma3MatIdE9steal_memERS1_b env3_ZNSt3__213basic_ostreamIcNS_11char_traitsIcEEElsEj env_ZN4arma10arma_checkIPcEEvbRKT_ env"_ZN4arma10arma_checkIA74_cEEvbRKT_ envQ_ZN4arma16gemv_emul_tinysqILb1ELb0ELb0EE5applyIdNS_3MatIdEEEEvPT_RKT0_PKS5_S5_S5_ env2_ZN4arma21arma_assert_blas_sizeINS_3MatIdEEEEvRKT_ env:_ZN4arma4blas4gemvIdEEvPKcPKiS5_PKT_S8_S5_S8_S5_S8_PS6_S5_ envdgemv_ envY_ZNSt13runtime_errorC1ERKNSt3__212basic_stringIcNS0_11char_traitsIcEENS0_9allocatorIcEEEE envQ_ZN4arma16gemv_emul_tinysqILb0ELb0ELb0EE5applyIdNS_3MatIdEEEEvPT_RKT0_PKS5_S5_S5_ env[_ZN4arma16gemm_emul_tinysqILb0ELb0ELb0EE5applyIdNS_3MatIdEES4_EEvRNS3_IT_EERKT0_RKT1_S5_S5_ env:_ZN4arma21arma_assert_blas_sizeINS_3MatIdEES2_EEvRKT_RKT0_ env@_ZN4arma4blas4gemmIdEEvPKcS3_PKiS5_S5_PKT_S8_S5_S8_S5_S8_PS6_S5_ envdgemm_ env_ZN4arma3MatIdE5resetEv env _ZN4arma27glue_times_redirect2_helperILb0EE5applyINS_2OpINS_3MatIdEENS_10op_htrans2EEENS_5eGlueINS_3ColIdEENS_4GlueIS5_S5_NS_10glue_timesEEENS_11eglue_minusEEEEEvRNS4_INT_9elem_typeEEERKNSB_ISG_T0_SC_EE envP_ZN4arma10glue_times5applyIdLb1ELb0ELb1ENS_3MatIdEES3_EEvRNS2_IT_EERKT3_RKT4_S4_ env7_ZN4arma26arma_assert_trans_mul_sizeILb1ELb0EEEvjjjjPKc envO_ZN4arma4gemvILb1ELb1ELb0EE15apply_blas_typeIdNS_3MatIdEEEEvPT_RKT0_PKS5_S5_S5_ envQ_ZN4arma4syrkILb1ELb1ELb0EE15apply_blas_typeIdNS_3MatIdEEEEvRNS3_IT_EERKT0_S5_S5_ env]_ZN4arma4gemmILb1ELb0ELb1ELb0EE15apply_blas_typeIdNS_3MatIdEES4_EEvRNS3_IT_EERKT0_RKT1_S5_S5_ envQ_ZN4arma16gemv_emul_tinysqILb1ELb1ELb0EE5applyIdNS_3MatIdEEEEvPT_RKT0_PKS5_S5_S5_ envJ_ZN4arma8syrk_vecILb1ELb1ELb0EE5applyIdNS_3MatIdEEEEvRNS3_IT_EERKT0_S5_S5_ envK_ZN4arma9syrk_emulILb1ELb1ELb0EE5applyIdNS_3MatIdEEEEvRNS3_IT_EERKT0_S5_S5_ env7_ZN4arma4blas4syrkIdEEvPKcS3_PKiS5_PKT_S8_S5_S8_PS6_S5_  envL_ZN4arma11syrk_helper35inplace_copy_upper_tri_to_lower_triIdEEvRNS_3MatIT_EE envG_ZN4arma6op_dot10direct_dotIdEENS_14arma_real_onlyIT_E6resultEjPKS3_S7_ 
envdsyrk_ env _ZN4arma4blas3dotIdEET_jPKS2_S4_ 
envddot_ env[_ZN4arma16gemm_emul_tinysqILb1ELb1ELb0EE5applyIdNS_3MatIdEES4_EEvRNS3_IT_EERKT0_RKT1_S5_S5_ env}_ZN4arma9as_scalarINS_2OpINS1_INS_3eOpINS_3MatIdEENS_7eop_absEEENS_6op_sumEEENS_6op_maxEEEEENT_9elem_typeERKNS_4BaseISC_SB_EE 	env*_ZNK4arma3MatIdE22internal_has_nonfiniteEv  envy_ZN4arma3svdINS_3MatIdEEEEbRNS_3ColINT_8pod_typeEEERKNS_4BaseINS4_9elem_typeES4_EEPKNS_19arma_blas_type_onlyIS9_E6resultE env3_ZN4arma7op_norm21vec_norm_1_direct_memIdEET_jPKS2_ envdasum_ 
env3_ZN4arma7op_norm21vec_norm_2_direct_memIdEET_jPKS2_ envdnrm2_ 
envZ_ZN4arma3MatIdEC2INS_2OpINS_3eOpIS1_NS_7eop_absEEENS_6op_sumEEENS_6op_maxEEERKNS3_IT_T0_EE env"_ZN4arma10arma_checkIA61_cEEvbRKT_ envs_ZN4arma6op_max5applyINS_2OpINS_3eOpINS_3MatIdEENS_7eop_absEEENS_6op_sumEEEEEvRNS4_INT_9elem_typeEEERKNS2_ISA_S0_EE env"_ZN4arma10arma_checkIA38_cEEvbRKT_ envH_ZN4arma3MatIdEC2INS_3eOpIS1_NS_7eop_absEEENS_6op_sumEEERKNS_2OpIT_T0_EE envU_ZN4arma6op_max13apply_noaliasIdEEvRNS_3MatIT_EERKS4_jPKNS_11arma_not_cxIS3_E6resultE env'_ZN4arma6op_max10direct_maxIdEET_PKS2_j enva_ZN4arma6op_sum5applyINS_3eOpINS_3MatIdEENS_7eop_absEEEEEvRNS3_INT_9elem_typeEEERKNS_2OpIS7_S0_EE envq_ZN4arma6op_sum19apply_noalias_proxyINS_3eOpINS_3MatIdEENS_7eop_absEEEEEvRNS3_INT_9elem_typeEEERKNS_5ProxyIS7_EEj env%_ZN4arma8arrayops9is_finiteIdEEbPKT_j env_ZN4arma3MatIdEC2ERKS1_ env6_ZN4arma6auxlib6svd_dcIdEEbRNS_3ColIT_EERNS_3MatIS3_EE env_ZN4arma3MatIdE10soft_resetEv env?_ZN4arma3MatIdEC2ILb0EEEjjRKNS_23arma_initmode_indicatorIXT_EEE env_ZN4arma3MatIdE8set_sizeEj env _ZN4arma8podarrayIiE9init_coldEj envB_ZN4arma6lapack5gesddIdEEvPcPiS3_PT_S3_S5_S5_S3_S5_S3_S5_S3_S3_S3_ !env _ZN4arma8podarrayIdE9init_coldEj env_ZN4arma8podarrayIdED2Ev  env_ZN4arma8podarrayIiED2Ev  envdgesdd_ env_ZN4arma6memory7acquireIiEEPT_j  env)_ZN4arma17arma_check_boundsIA35_cEEvbRKT_ env _ZNK4arma4CubeIdE11get_mat_ptrEj envJ_ZN4arma7op_norm12vec_norm_maxINS_3MatIdEEEENT_8pod_typeERKNS_5ProxyIS4_EE 	envN_ZN4arma7op_norm12mat_norm_infIdEENS_12get_pod_typeIT_E6resultERKNS_3MatIS3_EE 	envJ_ZN4arma7op_norm12vec_norm_minINS_3MatIdEEEENT_8pod_typeERKNS_5ProxyIS4_EE 	env_ZNSt3__25mutex4lockEv env#_ZNK4arma4CubeIdE14create_mat_ptrEj env_ZNSt3__25mutex6unlockEv envW_ZNSt11logic_errorC2ERKNSt3__212basic_stringIcNS0_11char_traitsIcEENS0_9allocatorIcEEEE env"_ZnwmSt11align_val_tRKSt9nothrow_t env/_ZN4arma3MatIdEC2ERKNS_18arma_vec_indicatorEjjt env*_ZN4arma8arrayops11inplace_mulIdEEvPT_S2_j env/_ZN4arma8arrayops16inplace_mul_baseIdEEvPT_S2_j env\_ZN4arma10eglue_coreINS_11eglue_minusEE5applyINS_3MatIdEES5_S5_EEvRT_RKNS_5eGlueIT0_T1_S1_EE env_ZdaPv env_ZdlPvSt11align_val_t envpthread_mutex_init envpthread_mutex_destroy  env__stack_pointerenv__memory_base GOT.mem
R_NilValueGOT.mem2_ZTINSt3__213basic_ostreamIcNS_11char_traitsIcEEEEenv__table_base GOT.mem_ZTISt9exceptionGOT.mem_ZTVN4Rcpp8RostreamILb0EEEGOT.mem_ZTVN4Rcpp8RostreamILb1EEEGOT.mem_ZTISt11logic_errorGOT.func_ZNSt11logic_errorD1EvGOT.mem_ZTIN4Rcpp9exceptionEGOT.memI_ZTTNSt3__219basic_ostringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEEGOT.memR_GlobalEnvGOT.mem_ZTTN4Rcpp8RostreamILb0EEEGOT.mem_ZTTN4Rcpp8RostreamILb1EEEGOT.mem_ZSt7nothrowGOT.mem4_ZTINSt3__215basic_streambufIcNS_11char_traitsIcEEEEGOT.func=_ZNSt3__215basic_streambufIcNS_11char_traitsIcEEE9pbackfailEiGOT.func9_ZNSt3__215basic_streambufIcNS_11char_traitsIcEEE5uflowEvGOT.func=_ZNSt3__215basic_streambufIcNS_11char_traitsIcEEE9underflowEvGOT.func<_ZNSt3__215basic_streambufIcNS_11char_traitsIcEEE6xsgetnEPclGOT.func=_ZNSt3__215basic_streambufIcNS_11char_traitsIcEEE9showmanycEvGOT.funcS_ZNSt3__215basic_streambufIcNS_11char_traitsIcEEE7seekposENS_4fposI11__mbstate_tEEjGOT.funcQ_ZNSt3__215basic_streambufIcNS_11char_traitsIcEEE7seekoffExNS_8ios_base7seekdirEjGOT.func<_ZNSt3__215basic_streambufIcNS_11char_traitsIcEEE6setbufEPclGOT.funcE_ZNSt3__215basic_streambufIcNS_11char_traitsIcEEE5imbueERKNS_6localeEGOT.func5_ZNSt3__215basic_streambufIcNS_11char_traitsIcEEED2EvGOT.memK_ZTCN4Rcpp8RostreamILb0EEE0_NSt3__213basic_ostreamIcNS1_11char_traitsIcEEEEGOT.mem_ZTIN4Rcpp8RostreamILb0EEEGOT.func;_ZTv0_n12_NSt3__213basic_ostreamIcNS_11char_traitsIcEEED0EvGOT.func;_ZTv0_n12_NSt3__213basic_ostreamIcNS_11char_traitsIcEEED1EvGOT.func3_ZNSt3__213basic_ostreamIcNS_11char_traitsIcEEED0EvGOT.func3_ZNSt3__213basic_ostreamIcNS_11char_traitsIcEEED1EvGOT.memK_ZTCN4Rcpp8RostreamILb1EEE0_NSt3__213basic_ostreamIcNS1_11char_traitsIcEEEEGOT.mem_ZTIN4Rcpp8RostreamILb1EEEGOT.mem_ZTVN4Rcpp9exceptionEGOT.func_ZN4Rcpp9exceptionD2EvGOT.memE_ZTVNSt3__215basic_stringbufIcNS_11char_traitsIcEENS_9allocatorIcEEEEGOT.memI_ZTVNSt3__219basic_ostringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEEGOT.mem_ZTVN4Rcpp14not_compatibleEGOT.mem_ZTIN4Rcpp14not_compatibleEGOT.func_ZN4Rcpp14not_compatibleD2EvGOT.mem_ZTIN4Rcpp12not_a_matrixEGOT.func_ZNSt9exceptionD2EvGOT.mem_ZTIN4Rcpp17LongjumpExceptionEGOT.mem_ZGVN4arma5DatumIdE3infEGOT.mem_ZGVN4arma5DatumIdE3nanEGOT.memR_ClassSymbolGOT.mem	R_BaseEnvGOT.mem_ZTVSt9exceptionGOT.mem_ZTVSt18bad_variant_accessGOT.mem_ZTVSt12out_of_rangeGOT.mem_ZTISt12out_of_rangeGOT.func_ZNSt12out_of_rangeD1EvGOT.mem_ZTISt13runtime_errorGOT.func_ZNSt13runtime_errorD1EvGOT.func_ZNK4Rcpp12not_a_matrix4whatEvGOT.func_ZN4Rcpp12not_a_matrixD0EvGOT.mem_ZTSN4Rcpp12not_a_matrixEGOT.func_ZNK4Rcpp9exception4whatEvGOT.func_ZN4Rcpp9exceptionD0EvGOT.func _ZNK4Rcpp14not_compatible4whatEvGOT.func_ZN4Rcpp14not_compatibleD0EvGOT.mem_ZTSN4Rcpp14not_compatibleEGOT.mem_ZTSN4Rcpp10RstreambufILb0EEEGOT.func%_ZN4Rcpp10RstreambufILb0EE8overflowEiGOT.func&_ZN4Rcpp10RstreambufILb0EE6xsputnEPKclGOT.func!_ZN4Rcpp10RstreambufILb0EE4syncEvGOT.func_ZN4Rcpp10RstreambufILb0EED0EvGOT.mem_ZTIN4Rcpp10RstreambufILb0EEEGOT.mem_ZTSN4Rcpp10RstreambufILb1EEEGOT.func%_ZN4Rcpp10RstreambufILb1EE8overflowEiGOT.func&_ZN4Rcpp10RstreambufILb1EE6xsputnEPKclGOT.func!_ZN4Rcpp10RstreambufILb1EE4syncEvGOT.func_ZN4Rcpp10RstreambufILb1EED0EvGOT.mem_ZTIN4Rcpp10RstreambufILb1EEEGOT.mem_ZTSN4Rcpp8RostreamILb0EEEGOT.func#_ZTv0_n12_N4Rcpp8RostreamILb0EED0EvGOT.func#_ZTv0_n12_N4Rcpp8RostreamILb0EED1EvGOT.func_ZN4Rcpp8RostreamILb0EED0EvGOT.func_ZN4Rcpp8RostreamILb0EED1EvGOT.mem_ZTSN4Rcpp8RostreamILb1EEEGOT.func#_ZTv0_n12_N4Rcpp8RostreamILb1EED0EvGOT.func#_ZTv0_n12_N4Rcpp8RostreamILb1EED1EvGOT.func_ZN4Rcpp8RostreamILb1EED0EvGOT.func_ZN4Rcpp8RostreamILb1EED1EvGOT.func_RcppEnsmallen_lin_reg_lbfgsGOT.mem_ZTSN4Rcpp9exceptionEGOT.mem(_ZTVN10__cxxabiv120__si_class_type_infoEGOT.mem_ZTSN4Rcpp17LongjumpExceptionEGOT.mem*_ZTSN4Rcpp8internal20InterruptedExceptionEGOT.mem%_ZTVN10__cxxabiv117__class_type_infoEGOT.mem*_ZTIN4Rcpp8internal20InterruptedExceptionEGOT.mem_ZTISt9bad_allocGOT.func_ZNSt9bad_allocD1EvGOT.mem_ZNSt3__25ctypeIcE2idEGOT.funcm_ZN10tinyformat6detail9FormatArg10formatImplIPKcEEvRNSt3__213basic_ostreamIcNS5_11char_traitsIcEEEES4_S4_iPKvGOT.func4_ZN10tinyformat6detail9FormatArg9toIntImplIPKcEEiPKvGOT.memR_DimSymbolGOT.mem_ZTVN4Rcpp12not_a_matrixEGOT.func'_ZN4Rcpp8internal9maybeJumpEPv8RbooleanGOT.func)_ZN4Rcpp8internal19Rcpp_protected_evalEPvGOT.memR_NamesSymbolGOT.mem_ZN4arma5DatumIdE3infEGOT.mem_ZN4arma5DatumIdE3nanEGOT.mem__wasm_lpad_contextGOT.mem_ZTVN4Rcpp10RstreambufILb0EEEGOT.mem_ZTVN4Rcpp10RstreambufILb1EEEenv__cpp_exception env__c_longjmp envmemory env__indirect_function_tablep êé                                                 
 

 				
#
	  

	 !  			  
«! A€ A√ A© Aú Aè A– A¯ A‹ AÑ A· A Aò Aœ A¥ Aç A» A¥ A® A‹ AË A‹ Aê Aà AÄ A¯ A Aê Aà AÄ AÃ A§ A‡ A∏”ô¢__wasm_call_ctors Õ__wasm_apply_data_relocs Œ_ZN4Rcpp8RostreamILb1EEC1Ev œ_ZTVN4Rcpp8RostreamILb1EEEå_ZTTN4Rcpp8RostreamILb1EEEã_ZN4Rcpp10RstreambufILb1EEC2Ev —_ZN4Rcpp8RostreamILb1EED1Ev ”_ZN4Rcpp8RostreamILb1EED2Ev ‘_ZN4Rcpp8RostreamILb0EEC1Ev ’_ZTVN4Rcpp8RostreamILb0EEEä_ZTTN4Rcpp8RostreamILb0EEEâ_ZN4Rcpp10RstreambufILb0EEC2Ev ÷_ZN4Rcpp8RostreamILb0EED1Ev ÿ_ZN4Rcpp8RostreamILb0EED2Ev ‘_RcppEnsmallen_lin_reg_lbfgs Ÿg_ZN4Rcpp22ArmaMat_InputParameterIdN4arma3MatIdEERKS3_NS_6traits17integral_constantIbLb0EEEEC2EP7SEXPREC ⁄g_ZN4Rcpp22ArmaVec_InputParameterIdN4arma3ColIdEERKS3_NS_6traits17integral_constantIbLb0EEEEC2EP7SEXPREC €._Z13lin_reg_lbfgsRKN4arma3MatIdEERKNS_3ColIdEE ·+_ZN4Rcpp4wrapIdEEP7SEXPRECRKN4arma3MatIT_EE ‹C_ZN4Rcpp12RObject_ImplINS_15PreserveStorageEEaSIP7SEXPRECEERS2_RKT_ ›_ZN4arma3MatIdED2Ev ﬁ__ZN4Rcpp22ArmaVec_InputParameterIdN4arma3ColIdEERKS3_NS_6traits17integral_constantIbLb0EEEED2Ev ﬂ__ZN4Rcpp22ArmaMat_InputParameterIdN4arma3MatIdEERKS3_NS_6traits17integral_constantIbLb0EEEED2Ev ﬂ_ZN4Rcpp8RNGScopeD2Ev ‡6_ZN4Rcpp15PreserveStorageINS_12RObject_ImplIS0_EEED2Ev ·4_Z29rcpp_exception_to_r_conditionRKN4Rcpp9exceptionE ‚'_ZN4Rcpp8internal10resumeJumpEP7SEXPREC „*_Z24exception_to_r_conditionRKSt9exception ‰R_ZNSt3__212basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEC2B7v160006IDnEEPKc ÂW_Z19string_to_try_errorRKNSt3__212basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEE Ê*_ZTIN4Rcpp8internal20InterruptedExceptionEà_ZTIN4Rcpp17LongjumpExceptionEá_ZTIN4Rcpp9exceptionEÜ_ZN4Rcpp9DimensionC2ERKmS2_ ÁO_ZN4Rcpp13RcppArmadillo9arma_wrapIN4arma3MatIdEEEEP7SEXPRECRKT_RKNS_9DimensionE Ë _ZN4Rcpp12Rcpp_protectEP7SEXPREC ÍB_ZN4Rcpp15PreserveStorageINS_12RObject_ImplIS0_EEE5set__EP7SEXPREC Î_ZN4Rcpp6ShieldIP7SEXPRECED2Ev Ï4_ZN4Rcpp15PreserveStorageINS_6VectorILi14ES0_EEED2Ev ·?_Z31exception_to_condition_templateISt9exceptionEP7SEXPRECRKT_b Ó,_ZNK4Rcpp9exception21copy_stack_trace_to_rEv ÔD_Z31exception_to_condition_templateIN4Rcpp9exceptionEEP7SEXPRECRKT_b Ó/_ZN4Rcpp8internal18isLongjumpSentinelEP7SEXPREC -_ZN4Rcpp8internal16getLongjumpTokenEP7SEXPREC ÒR_init_RcppEnsmallen Ú_ZN4arma5DatumIdE3nanEÖ_ZGVN4arma5DatumIdE3nanEÑ_ZN4arma5DatumIdE3infEÉ_ZGVN4arma5DatumIdE3infEÇ#_ZTv0_n12_N4Rcpp8RostreamILb1EED1Ev Û_ZN4Rcpp8RostreamILb1EED0Ev Ù#_ZTv0_n12_N4Rcpp8RostreamILb1EED0Ev ı#_ZTv0_n12_N4Rcpp8RostreamILb0EED1Ev ˆ_ZN4Rcpp8RostreamILb0EED0Ev ˜#_ZTv0_n12_N4Rcpp8RostreamILb0EED0Ev ¯_Z13get_last_callv ˘!_ZN4Rcpp7ShelterIP7SEXPRECEclES2_ ˙Y_Z21get_exception_classesRKNSt3__212basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEE ˚a_Z14make_conditionRKNSt3__212basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEP7SEXPRECS9_S9_ ¸_ZN4Rcpp7ShelterIP7SEXPRECED2Ev ˛%_ZN4Rcpp14Rcpp_fast_evalEP7SEXPRECS1_ ˇ._ZN4Rcpp8internal17is_Rcpp_eval_callEP7SEXPREC Ä)_ZN4Rcpp8internal19Rcpp_protected_evalEPv Å)_ZN4Rcpp13unwindProtectEPFP7SEXPRECPvES2_ Ç _ZN4Rcpp8internal3nthEP7SEXPRECi É'_ZN4Rcpp17LongjumpExceptionC2EP7SEXPREC Ñ'_ZN4Rcpp8internal9maybeJumpEPv8Rboolean Öw_ZN4Rcpp6VectorILi16ENS_15PreserveStorageEEC2ImEET_PNS_6traits9enable_ifIXsr6traits13is_arithmeticIS4_EE5valueEvE4typeE ÜG_ZNSt3__212basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEC2ERKS5_ á≠_ZN4Rcpp6VectorILi19ENS_15PreserveStorageEE16create__dispatchINS_6traits12named_objectIA1_cEENS5_IiEENS5_INS0_ILi16ES1_EEEEEES2_NS4_17integral_constantIbLb1EEERKT_RKT0_RKT1_ à†_ZN4Rcpp20AttributeProxyPolicyINS_6VectorILi19ENS_15PreserveStorageEEEE14AttributeProxyC2ERS3_RKNSt3__212basic_stringIcNS7_11char_traitsIcEENS7_9allocatorIcEEEE âi_ZN4Rcpp20AttributeProxyPolicyINS_6VectorILi19ENS_15PreserveStorageEEEE14AttributeProxyaSIA17_cEERS5_RKT_ ä4_ZN4Rcpp15PreserveStorageINS_6VectorILi19ES0_EEED2Ev ·4_ZN4Rcpp15PreserveStorageINS_6VectorILi16ES0_EEED2Ev ·@_ZN4Rcpp15PreserveStorageINS_6VectorILi16ES0_EEE5set__EP7SEXPREC ãe_ZN4Rcpp20AttributeProxyPolicyINS_6VectorILi19ENS_15PreserveStorageEEEE14AttributeProxy3setEP7SEXPREC åË_ZNKSt3__211__copy_loopINS_17_ClassicAlgPolicyEEclB7v160006IPKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEESB_N4Rcpp8internal14Proxy_IteratorINSD_12string_proxyILi16ENSC_15PreserveStorageEEEEEEENS_4pairIT_T1_EESK_T0_SL_ éá_ZN4Rcpp8internal12string_proxyILi16ENS_15PreserveStorageEE3setINSt3__212basic_stringIcNS5_11char_traitsIcEENS5_9allocatorIcEEEEEEvRKT_ èr_ZN4Rcpp8internal28make_charsexp__impl__cstringERKNSt3__212basic_stringIcNS1_11char_traitsIcEENS1_9allocatorIcEEEE êI_ZN4Rcpp8internal12string_proxyILi16ENS_15PreserveStorageEE3setEP7SEXPREC ë1_ZN4Rcpp6VectorILi19ENS_15PreserveStorageEEC2ERKi í™_ZN4Rcpp6VectorILi19ENS_15PreserveStorageEE15replace_elementINS_6traits12named_objectIA1_cEEEEvNS_8internal14Proxy_IteratorINS8_13generic_proxyILi19ES1_EEEEP7SEXPRECiRKT_ ìß_ZN4Rcpp6VectorILi19ENS_15PreserveStorageEE15replace_elementINS_6traits12named_objectIiEEEEvNS_8internal14Proxy_IteratorINS7_13generic_proxyILi19ES1_EEEEP7SEXPRECiRKT_ îµ_ZN4Rcpp6VectorILi19ENS_15PreserveStorageEE15replace_elementINS_6traits12named_objectINS0_ILi16ES1_EEEEEEvNS_8internal14Proxy_IteratorINS8_13generic_proxyILi19ES1_EEEEP7SEXPRECiRKT_ ï@_ZN4Rcpp15PreserveStorageINS_6VectorILi19ES0_EEE5set__EP7SEXPREC ã”_ZN4Rcpp6VectorILi19ENS_15PreserveStorageEE25replace_element__dispatchINS_6traits12named_objectIA1_cEEEEvNS4_17integral_constantIbLb1EEENS_8internal14Proxy_IteratorINSA_13generic_proxyILi19ES1_EEEEP7SEXPRECiRKT_ ñ–_ZN4Rcpp6VectorILi19ENS_15PreserveStorageEE25replace_element__dispatchINS_6traits12named_objectIiEEEEvNS4_17integral_constantIbLb1EEENS_8internal14Proxy_IteratorINS9_13generic_proxyILi19ES1_EEEEP7SEXPRECiRKT_ óﬁ_ZN4Rcpp6VectorILi19ENS_15PreserveStorageEE25replace_element__dispatchINS_6traits12named_objectINS0_ILi16ES1_EEEEEEvNS4_17integral_constantIbLb1EEENS_8internal14Proxy_IteratorINSA_13generic_proxyILi19ES1_EEEEP7SEXPRECiRKT_ òﬂ_ZN4Rcpp6VectorILi19ENS_15PreserveStorageEE37replace_element__dispatch__isArgumentINS_6traits12named_objectIA1_cEEEEvNS4_17integral_constantIbLb0EEENS_8internal14Proxy_IteratorINSA_13generic_proxyILi19ES1_EEEEP7SEXPRECiRKT_ ô_ZN4Rcpp4wrapEPKc öJ_ZN4Rcpp8internal13generic_proxyILi19ENS_15PreserveStorageEE3setEP7SEXPREC õ‹_ZN4Rcpp6VectorILi19ENS_15PreserveStorageEE37replace_element__dispatch__isArgumentINS_6traits12named_objectIiEEEEvNS4_17integral_constantIbLb0EEENS_8internal14Proxy_IteratorINS9_13generic_proxyILi19ES1_EEEEP7SEXPRECiRKT_ úc_ZN4Rcpp8internal26primitive_wrap__impl__castIiEEP7SEXPRECRKT_NS_6traits17integral_constantIbLb0EEE ùÍ_ZN4Rcpp6VectorILi19ENS_15PreserveStorageEE37replace_element__dispatch__isArgumentINS_6traits12named_objectINS0_ILi16ES1_EEEEEEvNS4_17integral_constantIbLb0EEENS_8internal14Proxy_IteratorINSA_13generic_proxyILi19ES1_EEEEP7SEXPRECiRKT_ ü_ZTVN4Rcpp10RstreambufILb1EEEÅ_ZN4Rcpp10RstreambufILb1EED0Ev †!_ZN4Rcpp10RstreambufILb1EE4syncEv °&_ZN4Rcpp10RstreambufILb1EE6xsputnEPKcl ¢%_ZN4Rcpp10RstreambufILb1EE8overflowEi £_ZTVN4Rcpp10RstreambufILb0EEEÄ_ZN4Rcpp10RstreambufILb0EED0Ev †!_ZN4Rcpp10RstreambufILb0EE4syncEv °&_ZN4Rcpp10RstreambufILb0EE6xsputnEPKcl §%_ZN4Rcpp10RstreambufILb0EE8overflowEi £7_ZN4Rcpp6MatrixILi14ENS_15PreserveStorageEEC2EP7SEXPREC •3_ZNK4Rcpp6MatrixILi14ENS_15PreserveStorageEE4ncolEv ¶7_ZN4Rcpp6VectorILi14ENS_15PreserveStorageEEC2EP7SEXPREC ß3_ZNK4Rcpp6VectorILi14ENS_15PreserveStorageEE4dimsEv ®_ZN4arma3MatIdEC2EPdjjbb ©_ZN4arma3MatIdE9init_coldEv ™_ZTVN4Rcpp12not_a_matrixE_ZTIN4Rcpp12not_a_matrixE~@_ZN4Rcpp15PreserveStorageINS_6VectorILi14ES0_EEE5set__EP7SEXPREC ´Z_ZN4Rcpp6traits14r_vector_cacheILi14ENS_15PreserveStorageEE6updateERKNS_6VectorILi14ES2_EE ¨#_ZN4Rcpp6r_castILi14EEEP7SEXPRECS2_ ≠1_ZN4Rcpp8internal10basic_castILi14EEEP7SEXPRECS3_ Æ-_ZN4Rcpp14not_compatibleC2IJPKcS3_EEES3_DpOT_ Ø_ZN4Rcpp14not_compatibleD2Ev ∞_ZTIN4Rcpp14not_compatibleE}_ZTVN4Rcpp14not_compatibleE|j_ZN10tinyformat6formatIJPKcS2_EEENSt3__212basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEES2_DpRKT_ ±[_ZN10tinyformat6formatIJPKcS2_EEEvRNSt3__213basic_ostreamIcNS3_11char_traitsIcEEEES2_DpRKT_ ≥J_ZNSt3__219basic_ostringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEED1Ev ¥_ZN4Rcpp14not_compatibleD0Ev µ _ZNK4Rcpp14not_compatible4whatEv ∂4_ZN10tinyformat6detail9FormatArg9toIntImplIPKcEEiPKv ∑m_ZN10tinyformat6detail9FormatArg10formatImplIPKcEEvRNSt3__213basic_ostreamIcNS5_11char_traitsIcEEEES4_S4_iPKv ∏]_ZN10tinyformat7vformatERNSt3__213basic_ostreamIcNS0_11char_traitsIcEEEEPKcRKNS_10FormatListE πJ_ZNSt3__219basic_ostringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEED2Ev ∫h_ZN10tinyformat6detail10formatImplERNSt3__213basic_ostreamIcNS1_11char_traitsIcEEEEPKcPKNS0_9FormatArgEi ªd_ZN10tinyformat6detail24printFormatStringLiteralERNSt3__213basic_ostreamIcNS1_11char_traitsIcEEEEPKc ΩP_ZN4Rcpp4stopERKNSt3__212basic_stringIcNS0_11char_traitsIcEENS0_9allocatorIcEEEE æz_ZN10tinyformat6detail21streamStateFromFormatERNSt3__213basic_ostreamIcNS1_11char_traitsIcEEEERbRiPKcPKNS0_9FormatArgES8_i ø`_ZNK10tinyformat6detail9FormatArg6formatERNSt3__213basic_ostreamIcNS2_11char_traitsIcEEEEPKcS9_i ¿/_ZN10tinyformat6detail18parseIntAndAdvanceERPKc √)_ZNK10tinyformat6detail9FormatArg5toIntEv ƒ_ZN4Rcpp9exceptionC2EPKcb ≈_ZN4Rcpp9exceptionD2Ev ∆_ZTVN4Rcpp9exceptionE{_ZN4Rcpp9exceptionD0Ev »_ZNK4Rcpp9exception4whatEv ∂^_ZN10tinyformat11formatValueIPKcEEvRNSt3__213basic_ostreamIcNS3_11char_traitsIcEEEES2_S2_iRKT_ …:_ZN10tinyformat6detail12convertToIntIPKcLb0EE6invokeERKS3_  r_ZN10tinyformat6detail17formatValueAsTypeIPKcPKvLb1EE6invokeERNSt3__213basic_ostreamIcNS7_11char_traitsIcEEEERKS3_ À\_ZN10tinyformat6detail15formatTruncatedERNSt3__213basic_ostreamIcNS1_11char_traitsIcEEEEPKci ÃF_ZNSt3__215basic_stringbufIcNS_11char_traitsIcEENS_9allocatorIcEEED2Ev Œ_ZN4Rcpp12not_a_matrixD0Ev œ_ZNK4Rcpp12not_a_matrix4whatEv – _ZN4arma10arma_checkIPKcEEvbRKT_ —_ZN4arma6memory7acquireIdEEPT_j “"_ZN4arma10arma_checkIA53_cEEvbRKT_ ‘3_ZNK4Rcpp6VectorILi14ENS_15PreserveStorageEE4sizeEv ÷_ZN4arma3ColIdEC2EPdjbb ◊n_ZN4Rcpp8internal34primitive_range_wrap__impl__nocastIPKddEEP7SEXPRECT_S6_NSt3__226random_access_iterator_tagE ÿ9_ZN4Rcpp12RObject_ImplINS_15PreserveStorageEEC2EP7SEXPREC Ÿ¢_ZN4Rcpp20AttributeProxyPolicyINS_12RObject_ImplINS_15PreserveStorageEEEE14AttributeProxyC2ERS3_RKNSt3__212basic_stringIcNS7_11char_traitsIcEENS7_9allocatorIcEEEE ât_ZN4Rcpp20AttributeProxyPolicyINS_12RObject_ImplINS_15PreserveStorageEEEE14AttributeProxyaSINS_9DimensionEEERS5_RKT_ ⁄ _ZNK4Rcpp9DimensioncvP7SEXPRECEv €g_ZN4Rcpp20AttributeProxyPolicyINS_12RObject_ImplINS_15PreserveStorageEEEE14AttributeProxy3setEP7SEXPREC åÇ_ZN4Rcpp8internal34primitive_range_wrap__impl__nocastINSt3__211__wrap_iterIPKiEEiEEP7SEXPRECT_S9_NS2_26random_access_iterator_tagE ‹*_ZTSN4Rcpp8internal20InterruptedExceptionEz_ZTSN4Rcpp17LongjumpExceptionEy_ZTSN4Rcpp9exceptionEx_ZTIN4Rcpp8RostreamILb1EEEwK_ZTCN4Rcpp8RostreamILb1EEE0_NSt3__213basic_ostreamIcNS1_11char_traitsIcEEEEv_ZTSN4Rcpp8RostreamILb1EEEu_ZTIN4Rcpp8RostreamILb0EEEtK_ZTCN4Rcpp8RostreamILb0EEE0_NSt3__213basic_ostreamIcNS1_11char_traitsIcEEEEs_ZTSN4Rcpp8RostreamILb0EEEr_ZTIN4Rcpp10RstreambufILb1EEEq_ZTSN4Rcpp10RstreambufILb1EEEp_ZTIN4Rcpp10RstreambufILb0EEEo_ZTSN4Rcpp10RstreambufILb0EEEn_ZTSN4Rcpp14not_compatibleEm_ZTSN4Rcpp12not_a_matrixElB_ZN4arma3MatIdEC2INS_4fill10fill_randnEEEjjRKNS3_10fill_classIT_EE ‚ò_ZN3ens6L_BFGS8OptimizeI24LinearRegressionFunctionN4arma3MatIdEES5_JEEENSt3__29enable_ifIXsr10IsArmaTypeIT1_EE5valueENT0_9elem_typeEE4typeERT_RS9_DpOT2_ „_ZN4arma3MatIdE5randnEv ‰#_ZN4arma8arma_rng5randnIdE4fillEPdj Â1_ZN4arma12arma_rng_alt14randn_dual_valIdEEvRT_S3_ Ê"_ZN4arma12arma_rng_alt9randn_valEv Á_ZN4arma3MatIdEC2Ejj Ë_ZN4arma4CubeIdEC2Ejjj Èu_ZN3ens23AddEvaluateWithGradientI24LinearRegressionFunctionN4arma3MatIdEES4_Lb1ELb0EE20EvaluateWithGradientERKS4_RS4_ Íô_ZN4arma4normINS_3MatIdEEEENS_10enable_if2IXsr12is_arma_typeIT_EE5valueENS4_8pod_typeEE6resultERKS4_jPKNS_20arma_real_or_cx_onlyINS4_9elem_typeEE6resultE ÎO_ZN3ens6L_BFGS19ChooseScalingFactorIN4arma3MatIdEENS2_4CubeIdEEEEdmRKT_RKT0_SC_ ÏP_ZN3ens6L_BFGS15SearchDirectionIN4arma3MatIdEENS2_4CubeIdEEEEvRKT_mdRKT0_SC_RS7_ Ì_ZN4arma3MatIdEaSERKS1_ ÓÄ_ZN3ens6L_BFGS10LineSearchINS_8FunctionI24LinearRegressionFunctionN4arma3MatIdEES6_EEdS6_S6_JEEEbRT_RT0_RT1_RT2_SD_RKSE_RdDpRT3_ ÔW_ZN3ens6L_BFGS14UpdateBasisSetIN4arma3MatIdEES4_NS2_4CubeIdEEEEvmRKT_S9_RKT0_SC_RT1_SE_ _ZN4arma4CubeIdED2Ev Ò_ZN4arma4CubeIdE9init_coldEv Ú7_ZN24LinearRegressionFunction8EvaluateERKN4arma3MatIdEE Û;_ZN24LinearRegressionFunction8GradientERKN4arma3MatIdEERS2_ Ù<_ZN4arma7op_norm21vec_norm_2_direct_stdIdEET_RKNS_3MatIS2_EE ı"_ZN4arma10arma_checkIA37_cEEvbRKT_ ‘I_ZN4arma7op_norm10vec_norm_kINS_3MatIdEEEENT_8pod_typeERKNS_5ProxyIS4_EEi ˆL_ZN4arma7op_norm10mat_norm_1IdEENS_12get_pod_typeIT_E6resultERKNS_3MatIS3_EE ˜L_ZN4arma7op_norm10mat_norm_2IdEENS_12get_pod_typeIT_E6resultERKNS_3MatIS3_EE ¯<_ZN4arma7op_norm21vec_norm_1_direct_stdIdEET_RKNS_3MatIS2_EE ˙_ZNK4arma4CubeIdE5sliceEj ˚>_ZN4arma6op_dot5applyINS_3MatIdEES3_EENT_9elem_typeERKS4_RKT0_ ¸õ_ZN4arma4normINS_3MatIdEEEENS_10enable_if2IXsr12is_arma_typeIT_EE5valueENS4_8pod_typeEE6resultERKS4_PKcPKNS_20arma_real_or_cx_onlyINS4_9elem_typeEE6resultE ˝_ZN4arma3ColIdEC2Ej ˛_ZN4arma3MatIdEmLEd ˇt_ZN4arma8eop_coreINS_16eop_scalar_timesEE18apply_inplace_plusINS_3MatIdEEEEvRNS4_INT_9elem_typeEEERKNS_3eOpIS6_S1_EE Äu_ZN4arma8eop_coreINS_16eop_scalar_timesEE19apply_inplace_minusINS_3MatIdEEEEvRNS4_INT_9elem_typeEEERKNS_3eOpIS6_S1_EE Å_ZN4arma3MatIdE9init_warmEjj Ç_ZN4arma4CubeIdE5sliceEj ˚E_ZN4arma3MatIdEaSIS1_S1_NS_11eglue_minusEEERS1_RKNS_5eGlueIT_T0_T1_EE Ö_ZN4arma4CubeIdE10delete_matEv Ü_ZN4arma4CubeIdE10create_matEv á?_ZN4arma3MatIdEC2IS1_S1_NS_10glue_timesEEERKNS_4GlueIT_T0_T1_EE àﬂ_ZN4arma4normINS_5eGlueINS_3ColIdEENS_4GlueINS_3MatIdEES6_NS_10glue_timesEEENS_11eglue_minusEEEEENS_10enable_if2IXsr12is_arma_typeIT_EE5valueENSC_8pod_typeEE6resultERKSC_jPKNS_20arma_real_or_cx_onlyINSC_9elem_typeEE6resultE âπ_ZN4arma7op_norm10vec_norm_1INS_5eGlueINS_3ColIdEENS_4GlueINS_3MatIdEES7_NS_10glue_timesEEENS_11eglue_minusEEEEENT_8pod_typeERKNS_5ProxyISC_EEPKNS_11arma_not_cxINSC_9elem_typeEE6resultE äπ_ZN4arma7op_norm10vec_norm_2INS_5eGlueINS_3ColIdEENS_4GlueINS_3MatIdEES7_NS_10glue_timesEEENS_11eglue_minusEEEEENT_8pod_typeERKNS_5ProxyISC_EEPKNS_11arma_not_cxINSC_9elem_typeEE6resultE ãè_ZN4arma7op_norm10vec_norm_kINS_5eGlueINS_3ColIdEENS_4GlueINS_3MatIdEES7_NS_10glue_timesEEENS_11eglue_minusEEEEENT_8pod_typeERKNS_5ProxyISC_EEi åg_ZN4arma3MatIdEC2INS_3ColIdEENS_4GlueIS1_S1_NS_10glue_timesEEENS_11eglue_minusEEERKNS_5eGlueIT_T0_T1_EE ç?_ZN4arma7op_norm24vec_norm_2_direct_robustIdEET_RKNS_3MatIS2_EE éÇ_ZN4arma10eglue_coreINS_11eglue_minusEE5applyINS_3MatIdEENS_3ColIdEENS_4GlueIS5_S5_NS_10glue_timesEEEEEvRT_RKNS_5eGlueIT0_T1_S1_EE è|_ZN4arma27glue_times_redirect2_helperILb0EE5applyINS_3MatIdEES4_EEvRNS3_INT_9elem_typeEEERKNS_4GlueIS5_T0_NS_10glue_timesEEE êP_ZN4arma10glue_times5applyIdLb0ELb0ELb0ENS_3MatIdEES3_EEvRNS2_IT_EERKT3_RKT4_S4_ ë_ZN4arma3MatIdE9steal_memERS1_ í7_ZN4arma26arma_assert_trans_mul_sizeILb0ELb0EEEvjjjjPKc ìO_ZN4arma4gemvILb1ELb0ELb0EE15apply_blas_typeIdNS_3MatIdEEEEvPT_RKT0_PKS5_S5_S5_ îO_ZN4arma4gemvILb0ELb0ELb0EE15apply_blas_typeIdNS_3MatIdEEEEvPT_RKT0_PKS5_S5_S5_ ï]_ZN4arma4gemmILb0ELb0ELb0ELb0EE15apply_blas_typeIdNS_3MatIdEES4_EEvRNS3_IT_EERKT0_RKT1_S5_S5_ ñ_ZN4arma3MatIdE9steal_memERS1_b ó_ZN4arma10arma_checkIPcEEvbRKT_ —"_ZN4arma10arma_checkIA74_cEEvbRKT_ ‘Q_ZN4arma16gemv_emul_tinysqILb1ELb0ELb0EE5applyIdNS_3MatIdEEEEvPT_RKT0_PKS5_S5_S5_ ô2_ZN4arma21arma_assert_blas_sizeINS_3MatIdEEEEvRKT_ ö:_ZN4arma4blas4gemvIdEEvPKcPKiS5_PKT_S8_S5_S8_S5_S8_PS6_S5_ õQ_ZN4arma16gemv_emul_tinysqILb0ELb0ELb0EE5applyIdNS_3MatIdEEEEvPT_RKT0_PKS5_S5_S5_ ù[_ZN4arma16gemm_emul_tinysqILb0ELb0ELb0EE5applyIdNS_3MatIdEES4_EEvRNS3_IT_EERKT0_RKT1_S5_S5_ û:_ZN4arma21arma_assert_blas_sizeINS_3MatIdEES2_EEvRKT_RKT0_ ü@_ZN4arma4blas4gemmIdEEvPKcS3_PKiS5_S5_PKT_S8_S5_S8_S5_S8_PS6_S5_ †_ZN4arma3MatIdE5resetEv ° _ZN4arma27glue_times_redirect2_helperILb0EE5applyINS_2OpINS_3MatIdEENS_10op_htrans2EEENS_5eGlueINS_3ColIdEENS_4GlueIS5_S5_NS_10glue_timesEEENS_11eglue_minusEEEEEvRNS4_INT_9elem_typeEEERKNSB_ISG_T0_SC_EE ¢P_ZN4arma10glue_times5applyIdLb1ELb0ELb1ENS_3MatIdEES3_EEvRNS2_IT_EERKT3_RKT4_S4_ £7_ZN4arma26arma_assert_trans_mul_sizeILb1ELb0EEEvjjjjPKc §O_ZN4arma4gemvILb1ELb1ELb0EE15apply_blas_typeIdNS_3MatIdEEEEvPT_RKT0_PKS5_S5_S5_ •Q_ZN4arma4syrkILb1ELb1ELb0EE15apply_blas_typeIdNS_3MatIdEEEEvRNS3_IT_EERKT0_S5_S5_ ¶]_ZN4arma4gemmILb1ELb0ELb1ELb0EE15apply_blas_typeIdNS_3MatIdEES4_EEvRNS3_IT_EERKT0_RKT1_S5_S5_ ßQ_ZN4arma16gemv_emul_tinysqILb1ELb1ELb0EE5applyIdNS_3MatIdEEEEvPT_RKT0_PKS5_S5_S5_ ®J_ZN4arma8syrk_vecILb1ELb1ELb0EE5applyIdNS_3MatIdEEEEvRNS3_IT_EERKT0_S5_S5_ ©K_ZN4arma9syrk_emulILb1ELb1ELb0EE5applyIdNS_3MatIdEEEEvRNS3_IT_EERKT0_S5_S5_ ™7_ZN4arma4blas4syrkIdEEvPKcS3_PKiS5_PKT_S8_S5_S8_PS6_S5_ ´L_ZN4arma11syrk_helper35inplace_copy_upper_tri_to_lower_triIdEEvRNS_3MatIT_EE ¨G_ZN4arma6op_dot10direct_dotIdEENS_14arma_real_onlyIT_E6resultEjPKS3_S7_ ≠ _ZN4arma4blas3dotIdEET_jPKS2_S4_ Æ[_ZN4arma16gemm_emul_tinysqILb1ELb1ELb0EE5applyIdNS_3MatIdEES4_EEvRNS3_IT_EERKT0_RKT1_S5_S5_ Ø}_ZN4arma9as_scalarINS_2OpINS1_INS_3eOpINS_3MatIdEENS_7eop_absEEENS_6op_sumEEENS_6op_maxEEEEENT_9elem_typeERKNS_4BaseISC_SB_EE ∞*_ZNK4arma3MatIdE22internal_has_nonfiniteEv ±y_ZN4arma3svdINS_3MatIdEEEEbRNS_3ColINT_8pod_typeEEERKNS_4BaseINS4_9elem_typeES4_EEPKNS_19arma_blas_type_onlyIS9_E6resultE ≤3_ZN4arma7op_norm21vec_norm_1_direct_memIdEET_jPKS2_ ≥3_ZN4arma7op_norm21vec_norm_2_direct_memIdEET_jPKS2_ ¥Z_ZN4arma3MatIdEC2INS_2OpINS_3eOpIS1_NS_7eop_absEEENS_6op_sumEEENS_6op_maxEEERKNS3_IT_T0_EE µ"_ZN4arma10arma_checkIA61_cEEvbRKT_ ‘s_ZN4arma6op_max5applyINS_2OpINS_3eOpINS_3MatIdEENS_7eop_absEEENS_6op_sumEEEEEvRNS4_INT_9elem_typeEEERKNS2_ISA_S0_EE ∂"_ZN4arma10arma_checkIA38_cEEvbRKT_ ‘H_ZN4arma3MatIdEC2INS_3eOpIS1_NS_7eop_absEEENS_6op_sumEEERKNS_2OpIT_T0_EE ∑U_ZN4arma6op_max13apply_noaliasIdEEvRNS_3MatIT_EERKS4_jPKNS_11arma_not_cxIS3_E6resultE ∏'_ZN4arma6op_max10direct_maxIdEET_PKS2_j πa_ZN4arma6op_sum5applyINS_3eOpINS_3MatIdEENS_7eop_absEEEEEvRNS3_INT_9elem_typeEEERKNS_2OpIS7_S0_EE ∫q_ZN4arma6op_sum19apply_noalias_proxyINS_3eOpINS_3MatIdEENS_7eop_absEEEEEvRNS3_INT_9elem_typeEEERKNS_5ProxyIS7_EEj ª%_ZN4arma8arrayops9is_finiteIdEEbPKT_j º_ZN4arma3MatIdEC2ERKS1_ Ω6_ZN4arma6auxlib6svd_dcIdEEbRNS_3ColIT_EERNS_3MatIS3_EE æ_ZN4arma3MatIdE10soft_resetEv ø?_ZN4arma3MatIdEC2ILb0EEEjjRKNS_23arma_initmode_indicatorIXT_EEE ¿_ZN4arma3MatIdE8set_sizeEj ¡ _ZN4arma8podarrayIiE9init_coldEj ¬B_ZN4arma6lapack5gesddIdEEvPcPiS3_PT_S3_S5_S5_S3_S5_S3_S5_S3_S3_S3_ √ _ZN4arma8podarrayIdE9init_coldEj ƒ_ZN4arma8podarrayIdED2Ev ≈_ZN4arma8podarrayIiED2Ev ≈_ZN4arma6memory7acquireIiEEPT_j ∆)_ZN4arma17arma_check_boundsIA35_cEEvbRKT_ « _ZNK4arma4CubeIdE11get_mat_ptrEj »J_ZN4arma7op_norm12vec_norm_maxINS_3MatIdEEEENT_8pod_typeERKNS_5ProxyIS4_EE …N_ZN4arma7op_norm12mat_norm_infIdEENS_12get_pod_typeIT_E6resultERKNS_3MatIS3_EE  J_ZN4arma7op_norm12vec_norm_minINS_3MatIdEEEENT_8pod_typeERKNS_5ProxyIS4_EE À#_ZNK4arma4CubeIdE14create_mat_ptrEj Ã/_ZN4arma3MatIdEC2ERKNS_18arma_vec_indicatorEjjt Õ*_ZN4arma8arrayops11inplace_mulIdEEvPT_S2_j Œ/_ZN4arma8arrayops16inplace_mul_baseIdEEvPT_S2_j œ\_ZN4arma10eglue_coreINS_11eglue_minusEE5applyINS_3MatIdEES5_S5_EEvRT_RKNS_5eGlueIT0_T1_S1_EE –_ZNSt18bad_variant_accessC2Ev —_ZNSt18bad_variant_accessD2Ev “	 #“◊ﬂ‡‘÷
•Äé˙#.-  AqE@#hBÄÄÄÄÄÄÄ¸ˇ 7 #.A:  #--  AqE@#gBÄÄÄÄÄÄÄ¯ˇ 7 #-A:  #" AÄj #"A   ¬  AÙj AjA   ¬#" AÃj #"AjA   ¬  A¿j AjA   ¬#A¥j”#AjA #¬# Ak"$  #A‘j6 (!# Ak" $    6  A6  (!  (!# Ak"$   6  6 (!# Ak" (6  6 ( (Aˇˇˇˇp" A6  Aj$   Aj$  Aj$ #Aÿj”#AjA #¬ù	##\6##,6##
6##6 #AÄj#[Aj" 6 #AÑj#Z6 #Aàj  6 #Aåj#Y6 #Aêj#XAj" 6 #Aîj#W6 #Aòj#6 #A†j#Aïj6 #A§j#V6 #A¿j#"6 #Aƒj#U6 #A»j#T6 #A‘j#"6 #Aÿj#S6 #A‹j#R6 #A‡j#Aj6 #A‰j#!Aj6 #AËj#!A j6 #AÏj#A j6 #A¯j#6 #A¸j# 6 #AÄj#6 #Aåj#6 #Aêj#6 #Aîj#6 #Aòj  6 #Aúj#Q6 #A†j#6 #A¨j#6 #A∞j#P6 #A¥j#O6 #A¿j#6 #Aƒj#N6 #A»j#M6 #AÃj#Aj6 #A–j#Aj6 #A‘j#A j6 #Aÿj#A j6 #A‰j#6 #AËj# 6 #AÏj#6 #A¯j#6 #A¸j#6 #AÄj#6 #AÑj  6 #Aàj#L6 #Aåj#6 #Aîj#K6 #Aòj#6 #Aúj#J6 #A†j#6 #A§j#6 #A®j#6 #A¨j#6 #A∞j#I6 #A¥j#6 #A∏j#6 #Aºj#6 #A¿j#6 #Aƒj#6 #A»j#H6 #AÃj#G6 #A–j  6 #A‘j#F6 #Aÿj#6 #A‡j#E6 #A‰j#6 #AËj#D6 #AÏj#6 #Aj#6 #AÙj#6 #A¯j#6 #A¸j#C6 #AÄj#6 #AÑj#6 #Aàj#6 #Aåj#6 #Aêj#6 #Aîj#B6 #Aòj#A6 #Aúj  6 #A†j#@6 #A§j#6 #A®j  6 #A¨j#?6 #A∞j#6 #A∏j#(6 #Aºj#)6 #A¿j#>6 #Aƒj#=6 #AÃj#
6 #A–j#$6 #A‘j#<6 #Aÿj#;6 #A‹j  6 #A‡j#:6 #A‰j#6 #AÏj#*6 #Aj#+6 #AÙj#96 #A¯j#86 v# !  #"A j6$   Aj6   A$j!@  #Aj  Aj"–" #"Aj6   A j6 @  $   #Aj	  $  	   D   ( "6    Ak( j (6     ( Ak( j" { BÄÄÄÄp7H  #k!  z"  Aj6    #AÄj   #" A$j  4   ( "6    Ak( j (6   Aj7   Ajv# !  #"A j6$   Aj6   A$j!@  #Aj  Aj"–" #"Aj6   A j6 @  $   #Aj	  $  	   #j!  z"  Aj6    #AÙj   #	" A$j  £# A–k"$ #AÏj-  E@#"Aôj
! AÏjA:   AËj 6  #( "6Ã  6»@@@#Aêj-  Aq@#Aåj( !#"Aîj AÁ	j;! AêjA:   Aåj 6   @ AÄj  ! @ A¿j !@   Aj Aj·@  6º A»j Aºj $  	  $  	  $   	  $  A«j	  $  A»j@	 !  $ #i"A 6  #6  @@@@ ("AF@  @ AF@  ( !  AG@  !  $ @ $  	    A   ! @ AF@@  !  $ @ $  	  @ AÄj#A∫j!@ !  $  	  $ @ $  	  #0!#AËj(     ( !A"#( !   (»!    A«j A»j A–j$  a# !   " (!  (!@  Ä! $   )	    6   60  BÄÄÄÄÄÄ¿ 7    l6   6  ;# !   Å" (!@  Aj   ∑A A ∏ $   )	   ]# A k"$    ( 6   (6@@ Aj Aj Aj#!   $!  $  È	  È A j$   D# Ak"$   ( %"6@   & $  Aj'	  Aj' Aj$      (@  ( (  A 6      Aj  )b# !@@#A†j-  Aq@#Aúj( !#"Aîj A⁄	j;! A†jA:   Aúj 6    $    3# !@  (Ì $    #"( 6    ( 6     /    - 0   1@  2!   3  4    A.     ,-  Ç# Ak"$    (     , A H*%"6@ #A˘j
  %"6@   (     , A H*%" 6@  #( !%"6 @  #/( #AÔj*+  #A¢j
 + $ @ '	  $ @ Aj'	  $ @ Aj'	  $  Aj'	  ' Aj' Aj' Aj' Aj$   ∏# Ak"$   A 6  B 7  A :    6@  A¡"6   6    Aj6  ("Aj!@  F@   6 A 6  Aj! $  Aj›	  A:  Aj› Aj$   ( " ( 6   ( 6  Ö# A k"$ #! Aj  ( "   (Atj∫ª! @ Aj AÛj!@ Aj   º Ω $  	  $   	    (    A j$ .# Ak"$    6@ Ajﬁ $   Aj$    #( G@    )    ( G@   6   (Ì    ( ç6'  ( #( G@# !@A" $    R@#Aòj-  Aq@#Aîj( !#"Aîj A˚j;! AòjA:   Aîj 6     õ# A k"$ @@ Aj! Aj  ( Ak( (!@#A®j-  Aq@#A§j( !#"Aîj Aˇ	j;! A®jA:   A§j 6      $  	  @@ Aj!    ( (  !    !  A 6@@ @ Aj"<=! @#A∞j-  Aq@#A¨j( !#"Aîj A⁄
j;! A∞jA:   A¨j 6   =!#( "! Aj"      Aj>=?=!#( ˝ $  Aj@  	  $  Aj	  Aj@   Aj A j$  –# Aêk"$ @  ("  ("F@#( ˝ AÑj  kAmA ^"(!  (!  (!  A 6Ä  6|@ A j!# A k"$   (|6  (Ä6# Ak"$   (6  (6# Ak"$   (6  (6# A k"$   )7 Aj Aj    Ajg (!  )7      kAmAlj6 A j$  Aj$  Aj$   (6   (6 A j$  A– j#A˙	j!@  A‹ j _"6h #" Aåj6l A6D@ A,j  Aı	j!@  A8j _" 6H  Aƒ j6L@ Aj#Aïj!@ Aj _!  6(  6$@  AË j A» j A$j` $  	  $  	  $   	  $  	  $  	  $  	        @ A‹ j#AÖj! @ A– j A j  a#AÔ
jb $   	    (p˝ $  A jc	  $  d	  A jc d Aêj$ (@  #A¸j[E   LAG   MAF!    A \   A #A†jA A 5  A 6     ( Ak( j   9     ( Ak( j8     ( Ak( j   9     ( Ak( j:•# Ak" $   #Aãj
A%"6@   #( B%"6 !@@ C!@ #( F  DE  "C! D!  $ @  Aj'	   $   Aj'	   Aj'  Aj'  Aj$    #( G@    ( Aj6  %Å# Ak"$  AAF%"6@ A   (     , A HGH A#AÖjGH A#AÛjGH A#A¢jGH $  Aj'	  Aj' Aj$  Ÿ# Ak"$  AAF%"6@ A   (     , A H*I A I A I AAF%" 6@  A #AΩ
jGH  A#A˜jGH  A#AíjGH #f(   + #/(  + $ @ Aj'	  $  Aj'	  Aj' Aj' Aj$  S@#A∏j-  Aq@#A¥j( !#"Aîj A≈
j;! A∏jA:   A¥j 6      ## !@  ( " $    A 6   +# Ak"$   6   6#e AjJ Aj$ ’# Ak"$ #"Aãj
!  A(j
#0( K%"6@@ A”j
!#Aéj
!  LA !AG  MAG  A N G  AND G  ANAND G  ANAN#( G  AN G  AN!  $  Aj'	    F! Aj' Aj$     (   (!‰	# A k"	! 	$ A(O"A 6 A!
A!@@ 
AG@ 	A†k""$  Ak""	$   6  6  6  6  6P!  6  6  6  6  6  %"6 A !@ A  Q!R!@@ @ S@@AT!  U! 	$  V	     #d  W  6  6  6  6  6@ ' ( A j$  #,A X 	$   6  6  6  6  6 '  6  6  6  6  6	 ! 	$  (! ( "(  ( (Y"
@ (! (! (! (! (! ((  Z  %   M J@ E@  D   ]D#(     6  1@    ( 26     @  AZ D# !  #"( 6  ( !  A 6   6@  A Fe $   d	   4  , A N@   ) 7    (6     (  (y  Ê# A0k"$  A6    k!@ AAF%" 6, (! A 6(  6$@ A$j  A  l A6   6 Aj  A m A6  6 Aj  A n #A≤j!@ Aj  a  f $  	  $ @ A,j'	  $  c	   A,j' A0j$ "    6    (   , A H
6      *f  0    ( G@   6   (Ì    ( ç6    6S# Ak"$   (!  ( ( !   %"6@    + $  Aj'	  Aj' Aj$    AºA¿A‰◊D @  G@  h  (Aj6 Aj!   6    ( 6   (6
    ij   (     , A HG   ( (   ( HG# !  #"( 6  ( !  A 6   6@  A ( Fo $   c	   5# Ak"$    ( 6   (6 Aj   p Aj$ 5# Ak"$    ( 6   (6 Aj   q Aj$ 5# Ak"$    ( 6   (6 Aj   r Aj$ 5# Ak"$    ( 6   (6 Aj   s Aj$ 5# Ak"$    ( 6   (6 Aj   v Aj$ 5# Ak"$    ( 6   (6 Aj   x Aj$ *    (tu   ( " (     , A HGH   @  *#(    ( (   ( I*    (wu   ( " (     , A HGHT# Ak"$  AAF%"6  ( ! @ û! $  Aj'	    6  Aj' Aj$     AƒA»A‡◊+    (( u   ( " (     , A HGH   79 |A , # Ak" $    6   6 #A€j  }  Aj$  G# Ak"$ A! AG@  : A    AjA  ( (0 AG! Aj$  , # Ak" $    6   6 #A€j  ~  Aj$  7# !@@   Å!   Ç! $   )	    ( 6  
   Ç(y# Ak"$   #"( 6  ( !  A 6   6@  %"6@   åä $ @ Aj'	  $   )	  Aj' Aj$   ;  ( ÜE@#c! AT"  Aj6  #*#+X   ( #b( àâw   A ;  A 6   6   6   A   6     l6  A AA  ;@ E   Ñ  ( " F   ("E    AtÖ  ï# Ak"$  #Açj6  (!  ( "AˇˇM@A  AÄÄI ∏ ∏¢D  ‡ˇˇˇÔAd Aj±    ("AM@  A0jA  !A  ≤!  (6   6  Aj$ 3    ( G@   6   (Ì    ( ç6  Aj  ã    ( û6    LAG  ç  ≥# Ak"$ @  LAG@  L"AKA tAÄ»ÉqEr  Aé!  Aj$   AT! A: @  L!  A:    è6 A:  Aè6 #AÄj Aj Ajê A : #(#)X $  - @ V	  -# !  #'Aj6 @  Aj   í $       #'Aj6   Aj  áO# Aêk"$ @@ Aj≤!    ì   Ajî $  ï	  ï Aêj$ î# !  #&"A j68   Aj6   A8j!@  #Aj  Aj" –"#&"Aj6   A j6 @  z" B 7   #%Aj6   A60  B 7( $  #Aj	  $  	  \# A k"$  #a"6 #`"6  6  6  6  6 A6  Aj6     ñ A j$    #ó" A8j  	   ë9   (  Aj  , A H   ¨       ´     (  (ò5   ( "6    Ak( j (6   Aj∞   Ajñ
# A†k"$     ( Ak( j"(!
 (! (! º! Aj!	@@@@  6ú  L@   ô-  E@@ Aj#A‹j! ö $  	     ô! A : õ A6î   Aõj Aîj   Aúj õ!@  (ú"L@@@ Aj#A˚j!   ö $   	    Alj!@ - õE@      (îú@@@ Aj≤! ( Ak(  j    ( Ak( jù 	 ( Ak( j" ( AÄr6      (îú  	îA ! ( - " ¿A H!@  F@@   (   - "¿A H" (  « $  	   (   , A H j"-  A+F@ A :   Aj!   $  ï	   ï (úAj!       ( Ak"( j 6   ( j 6   ( j 
6   ( j ¡ A†j$ "  (L"AF@    A ¬"6L ¿\ !@@@ ,  "A%G@      kû     kû - A%G Aj"! Aj! B# !@@A T!   (     , A HA°!  $  V	   #
#$X É# Ak"$ @@ -  A%G@@@ Aj#Aòj!   ö $   	      ( Ak"( jA 6   ( jA6   ( jA ¡    ( "Ak( j" (AÄ‡~q6  Aj!
@ Ak!@@  Aj"6 @@@@@ , "	A+k @ 	A k  
 ( j" ( AÄr6  ! !   ( j"- A q A0¡ 
  ( "Ak( j" ( Aœ~qAr6    ( jA ¡ 
  ( "Ak( j" ( Aœ~qA r6  ! ! 
 ( j- Aq A:   
 ( j" ( AÄr6  A :  A! ! 	A0kAˇq"A	M@   Ak( j ü6 ( "-  !	 	AˇqA*G@ A
I@@  ( "L@@@ Aj#Aõj! ö $  	    Aj6   Alj†!  ( ! A N   Ak( jA ¡    ( "Ak( j" (Aœ~qA r6A  k!   ( !A !   Ak( j 6  ( "Aj"6  - !	A!
 	AˇqA.F@  Aj6 @@ - "A*F@  Aj6   ( "J@  Aj6   Alj†!@@ Aj#A∑j! ö $  	   A0kAˇqA	M@ ü!A ! A-G  Aj6  ü A !    ( Ak( j 6 ( !@@@@@@@@@@@@@@@@@@@@@ -  "AË k"AMA A tAï†q AÃ Fr@  Aj"6 @A! ¿"A· k @ A¡ k	  E Aÿ G    ( Ak( j" (AÄÄr6A!  ( !  ( !  ( !    ( "Ak( j" (AÄÄr6   Ak"( j" (A˚}qAÄr6   ( j"   (AµqAr6    ( "Ak( j" (AÄÄr6   Ak( j"   (A˚}qAr6    ( "Ak( j" (AÄÄr6   Ak"( j" (AµqAr6   ( j"   (A˚}q6	@@ Aj#AÄj!   ö $   	    ( ! 	AˇqA.F@    Ak( j(6    Ak( j"   (Ar6@@ Aj#AΩj! 
  ö $   	  @@ Aj#A÷j! 	  ö $   	  A¿ !    ( Ak"( j" (Aµq r6 
 	AˇqA.Gr   ( j" ( j6   ( j" (Aœ~qAr6   ( jA0¡   ( !     ( Aj!   Aj$  ô# Ak"$   ( E@@@ Aj#AÍj! ö $  	    ("E@@@ Aj#AÍj! ö $  	    (!      (    Aj$    (LAF@  A ¬   6LV# Ak"$  Aj"  £@ #_•"    ( ( !  $  Aj§	  Aj§ Aj$   @  ( !@ -  "A0kAˇqA	KE@   Aj"6  A
l jA0k! ë# Ak"$   ( E@@@ Aj#AÍj! ö $  	    ("E@@@ Aj#AÍj! ö $  	    (!  (     Aj$ C# !  ##Aj6 @  Aj  $   á	   B 7   :   A 6  Ç  ##Aj6 # Ak"$    Aj6@ ("( @ ( ! (!@  G@ Ak!  6 (( 9 $   Aj$   Aj  áπ
# Ak"$ @@@ Aj  ¶"
-  E     ( Ak( j"(! (!@ º!  "j"  A∞qA F!	 !A !# Ak"$ @ "E  (! 	 k"A J@    ( (0  G   k"kA   H"A J@ Aj"  ©@  (  , A H  ( (0 ! $  Aj	  Aj  G  	k"A J@  	  ( (0  G A 6 ! Aj$      ( Ak( j" (Ar™ $  
ß	   $ @    ( Ak( j® $ @ $  	  
ß Aj$   	   ¢9:  Ak-  A F@   ≠ ( ! A N@    Æ   ÕB# Ak"$ @@ Aj#A◊j!   ö $   	    Aj$ A     ( Ø@ A  A J!@@     G  j-    û Aj!       ,«   #%Aj6   A j  7	   á9 #AÚj,# Ak"$   @  ( 6 Aj”  Aj$    AAˇˇˇˇ⁄{# Ak"$ AT!  ( !  A: @   !  A: @   µ A : ##	X $  - !    Aq: 	  $  - @ V	  )# Ak"$   @  6 Aj”  Aj$ #^! #]!AT∂   X 
   ( π     A  É" A;  ∞# Ak"$  A   kAu"F%"6@ û! $  Aj'	  Av!A !@ A LE@  At"j   j+ 9   Ar"j   j+ 9   Ar"j   j+ 9   Ar"j   j+ 9  Ak! Aj!@@@@ As j   At"j   j+ 9  Ar!  At"j   j+ 9  Aj!  At"j   j+ 9  Aj' Aj$  5# !  #"( 6    ( 6@   & $   	       æø     (   (¿∞# Ak"$  A   kAu"F%"6@ û! $  Aj'	  Av!A !@ A LE@  At"j   j( 6   Ar"j   j( 6   Ar"j   j( 6   Ar"j   j( 6  Ak! Aj!@@@@ As j   At"j   j( 6  Ar!  At"j   j( 6  Aj!  At"j   j( 6  Aj' Aj$  !  - E@# !@  ﬁ $    ( "( " @   6  9 #AÃj #A¿j“# A– k"$   6L  6H A : @ B¿ò÷≈◊„Îäƒ 78 B£Ñ…‰êîÁ„;70 A26( Bñ¨ù˜˘ıÄÈ<7  Bç€◊Ö˙ﬁ±ÿ>7 BÕô≥ÊÃô≥ˆ?7 B≠ÜÒÿÆ‹çç?7 BäÄÄÄ†7 @@ A» j!   (A#AÒj√!     ƒ $   	  A– j$ 5   A 6    6   6   B 7    l6  Ñ  ≈  Ô|~# A†k"$  Aj ( " ("À!@ A†
j    ( Ã!@ A–j    ( Ã!	@ A†j (  (À"
("@ 
( A  AtÕ  (!@ Aj (  (À"("@ ( A  AtÕ@ A¿j (  (À"("@ ( A  AtÕ@ Aj (  (À"("@ ( A  AtÕ@    Œ9 E!A !@@    (GrE   - @  +! AA œ  +c  +" b       	–"ΩBˇˇˇˇˇˇˇˇˇ É"B}B˛ˇˇˇˇˇˇV BÄÄÄÄÄÄÄ}BˇˇˇˇˇˇˇÔˇ Vq        	 — 
 “  “    Aj     ” + D        bqE   +   +"°D      ? ô" ô"  d" D      ?c£f      
    	‘ Aj! +    
 	’ ’  A†j$  $  	   $  	   $  	   $  
	   $  	’	   $  ’	   $  	     (   (∆  LA!@  K@   Atj   Atj« Aj! Aj!  K@   Atj»9 £|@D        D  ¿ˇˇˇﬂA…" †D       >¢D      ø†" ¢D        D  ¿ˇˇˇﬂA…" †D       >¢D      ø†" ¢†"D      ?f      D       ¿¢ £ü"¢9    ¢9 ~|@D        D      ?…" †D      ø†" ¢D        D      ?…"   †D      ø†"   ¢†" D      ?f     D       ¿¢  £ü¢I   A 6    6   6   B 7    l6  Ñ  ("@  ( A  AtÕ  å# !  B 7   B 7   6   6   6     l"6  A(j"B 7   B 70  B 78    l6@  ÷ $  ◊	   ("@  ( A  AtÕ  |   ÿ    Ÿß|# Ak"$    6 |D          (E @@  ( AG@  (AG@@ Ak   ⁄ E#Aµ	j€  ‹@@@ Ak   ›  ﬁ#Aê	j˘   ﬂ Aj$ y| @  Ak  ( p" ‚   ‚"   „!  „ D      ? D        b£D      ? #AûjA ‰"£D      ? D        b¨|# A†k"$   “ Aj  ( Â!	@ A@k  ( Â!
   ( k"A   M! !@@  F@  Ê@  O@ D      øÊ 
 	 A†j$  As jAt" 	( j+ !    ( p"‚ „! 
(  j+ !   ‚6     ¢°9  Á Aj!    Ak"  ( "j p"‚!  ‚" „!  kAt" 	( jD      ? £D      ? D        b"9   „! 
(  j  ¢"9   9  6   Ë $  
	  !   $  		  G@   F    (  (È  ( " ( "F  ("E    AtÖ  ö
|~# A@j"$  B 7 @  „"Ω"Bˇˇˇˇˇˇˇˇˇ É"P B S"	 B}BˇˇˇˇˇˇˇTqr BÄÄÄÄÄÄÄ}BÄÄÄÄÄÄÄˇ T 	qrE    +¢! + !DˇˇˇˇˇˇÔ!D      ?!A !	D      ?!@  “  9  6   Á    Œ"9   b    c"!D      ‡?!@@   ¢ †d DÕÃÃÃÃÃ @!  „"   +"¢c D      ‡?!   ö¢dE   +0c    +8d    !  ¢! 	Aj"	  ((I  9  6   Á  9 A!
 A@k$  
â# A0k"$    ( p!   6   6 (! (!	@ ( " ( "F  	FqE@ A$j"   	  #AµjÉ@  Ñ $  A$j	     Í Î  6   6 (! ( " ( "F  ("FqE@ A$j"     #AµjÉ@  Ñ $  A$j	     Í Î A0j$  2   Ï@  (   (E   ( (  A 6   A(j◊  ´# Ak"$  #AŸj6  (!  ( "AˇK  ("AˇKrE@A  AÄI ∏ ∏¢ ∏¢D  ‡ˇˇˇÔAd Aj±    ("A¿ M@  A– jA  !A  ≤!  (6   6   Ì Aj$ €|# A‡k"$   (!  ( !   6   6  6 A j AjÔ! @ (( "  ( "F ($"AFqE@@ A‘j" A  #AµjÉ@ Ñ $  A‘j	   $   	  @ AjAA ! $   	    A‡j$   ¢ ¸# A†k"$   ( ! BÄÄÄÄÄÄÄÄ@7‡  6–   (6  6  6 A j AjÔ! @ (( "  ( "F ($"AFqE@@ Aîj" A  #AµjÉ@ Ñ $  Aîj	   $   	    Aj6ò  A–j6î@  Aîjé $   	    A†j$  ô|~# Ak"$   ( !|  ("AM@  £  6 A6 Aj  Aj§"ΩBˇˇˇˇˇˇˇˇˇ É"B}BˇˇˇˇˇˇˇT BÄÄÄÄÄÄÄ}BÄÄÄÄÄÄÄˇ TrE@  ı! Aj$  _| ∑!  ( " (!  ( ! A !@  F@ D      ? £ˆ    Atj+ ô ˆ†! Aj!     A AŸµ|# A∞k"$   ü@#Aÿj!#"A¿j AÇjÕ Õ"  ( Ak( jA
¬‡ · A 6  A6 B 7 BÄÄÄÄ7 @   A † $  	  (| ( + D          A∞j$ t# Ak"$ AT! A: @   !  A: @   µ A : ##	X $  - !    Aq: 	  $  - @ V	  S|# Ak"$   ( !|  (" AM@   °   6 A6 Aj  Aj¢ Aj$    ( M#A∏jª   º(   ( (G#A£j≥  (  (  ( ô›|# Ak"$    6 |D          (E   ,  A !@@@  ( AG@  (AG@@@ A+k  AÈ F  A… G Ω A_qA∆ F#Aµ	j˘  A+F AÈ FrE A… GqE@  æ A_qA∆ F#Aê	j˘  ø  ⁄ Aj$ @# Ak"$    Aj AA≈" ("@  ( A  AtÕ Aj$      (    (∆  œ|# Ak"$  ( "(!@  ( " ( "F   ("FqE@ Aj"     #A¨jÉ@  Ñ $  Aj	   (! +!@  ( "AqE@A !  ( "AqE@@   F   At"j" +    j+ ¢†9   Aj!   @   F   At"j" +    j+ ¢†9   Aj!    ( !A ! @   F   At"j" +    j+ ¢†9   Aj!    Aj$  œ|# Ak"$  ( "(!@  ( " ( "F   ("FqE@ Aj"     #AµjÉ@  Ñ $  Aj	   (! +!@  ( "AqE@A !  ( "AqE@@   F   At"j" +    j+ ¢°9   Aj!   @   F   At"j" +    j+ ¢°9   Aj!    ( !A ! @   F   At"j" +    j+ ¢°9   Aj!    Aj$  ò# Ak"$ @   ( F@  ( F  /! #A˚jA   /"AF"6@ E   rE@ AF! AF!@@@ Ak  AF@A! #Aˆ j6 AF@A! #A1j6A! ∏ ∏¢D  ‡ˇˇˇÔAdE  rAÄÄIr  #Açj6A AjÅ  l"  (G@ AF#AöjÇ  (!@   AM@ @  ( (  A0jA  !A   M @  ( (  B 7   A 6   B 7 ≤! 6   6   A ;   6   6   6  Aj$ x# Aêk"$ @@ Aj≤!  Õ#AﬂjÕ Äò Ä#AŸjÕ Äò Ä   Ajî $  ï	  ï Aêj$ t# Ak"$ AT! A: @   _!  A: @   µ A : ##	X $  - !    Aq: 	  $  - @ V	  !   ( "(  (È   »  â@  ("E   ($E @  O@ AI  (AO  ($"@ …  A 6$ At"  ($j( "@ A   ($ jA 6  Aj!  (!  î@  ("E@  A 6$@@  (AK  AM@    A@k6$  A At AˇˇˇˇK#Ó"6$ EA !@  O  ($ AtjA 6  Aj!  (!  ’ '   B 7   A 6   B 7  A 6   ¯  k|# Ak"$    6 |D          ( (E @@@ Ak  A Ò A Ú E#Aµ	j€  Û Aj$ ∞|  ( "( "("A~q!A! A !@   OE@  ( "	  At"j+   (0"j+ °ô†!  	 At"
j+   
j+ °ô†!  Aj!  Aj!   G|  At"  ( j+  (0  j+ °ô† †∏|~# A∞k"$   ( "( "("	A~q!
A! @   	OE@ ( "  At"j+   (0"j+ °" ¢ †!  At"j+   j+ °" ¢ †!  Aj!  Aj!  	 
G| 
At"  ( j+  (0  j+ °" ¢ † †ü"Ω"B}BˇˇˇˇˇˇˇT Bˇˇˇˇˇˇˇˇˇ ÉBÄÄÄÄÄÄÄ}BÄÄÄÄÄÄÄˇ T B YqrE@@@  Ù!   ı! $   	    A∞j$  n| ∑!  ( " ( "(!A !@  F@ D      ? £ˆ  At" ( j+   (0 j+ °ô ˆ†! Aj!  H ( "( !  A6   6  (!  A 6    6  B 7  Ñ   ˜  ò|  (!D      ˇ!A!  ( "! @  ME@  +ô"  + ô"   c"  c! Aj!  Aj!   AkK@  + ô"   c!D        ! D        b|A! D        !@   OE@  Aj!  + £" ¢ †! +  £" ¢ †! Aj!     AkK| +  £" ¢ † †ü¢D        „ ( "(!@  ( "AqE@A !  ( " (0"rAqE@@   F   At"j  j+   j+ °9   Aj!   @   F   At"j  j+   j+ °9   Aj!    (0! ( !A ! @   F   At"j  j+   j+ °9   Aj!   è# A∞k"$ @ ( "  F ("  FrE@    D        ˘ A 6 B 7  A 6  B 7@   D        ˘   ˙ $  	   A∞j$ ”  (  ( (  (#A¡j˚   (  (È@@ (@ (  ("E  ( A  AtÕ ( AF@  (   ( D      ?D        ¸ (AF@  (   ( D      ?D        ˝    D      ?D        ˛    A ˇO# Ak"$ @  G@ Aj"      É@ Ñ $  Aj	   Aj$  Ø# A0k"$ @@ ( "AK   (G       É Ñ A‘ : /  ( 6(  (6$ BÄÄÄÄÄÄÄ¯?7 A6 B 7 A/j A(j" A$j Aj (    Aj" Aj   Ö A0j$ Ø# A0k"$ @@ ( "AK   (G       à Ñ AŒ : /  ( 6(  (6$ BÄÄÄÄÄÄÄ¯?7 A6 B 7 A/j A(j" A$j Aj (    Aj" Aj   Ö A0j$ ı# A0k"$ @@ ( "AK   (G   ( "G   (G       â  ä AŒ : / AŒ : .   ( "6(   (6$  ("6  BÄÄÄÄÄÄÄ¯?7  6  6 B 7 A/j A.j A(j" A$j A j Aj (  Aj (  Aj Aj  (  ã A0j$ ß@   F  (! ( !A  /" /"F A AF AFq  AF AFq! /! (!@ E   /AK  (! AF AKr  AFqrE   ç   ;   6   6   6   6    ( 6  A ; B 7  AF6  AF6  A j   “ E r AKr A 6  AF6  AF6  A jA 6 (# Ak"$  A¯ :    AjA« Aj$ ‰| ( !@@@@@ ( Ak    +  + ¢9  + ! +!   + + "¢ +" +¢†9    ¢  ¢†9  +! + ! +!	 +(!
 +! + !   +@ +"¢ +0 + "¢ +" +8¢††9   
 ¢  ¢  ¢††9    ¢  ¢  	¢††9  +! +!	 + !
 +! +8! +0! + ! +(! +X! +P! +@! +H!   +x +"¢ +p +"¢ +` + "¢ +" +h¢†††9    ¢  ¢  ¢  ¢†††9    ¢  ¢  ¢  ¢†††9    ¢ 	 ¢ 
 ¢  ¢†††9  @  (A N@  ( A Nú             	 
AÜx# Ak" $ AT!  A: @  #A≤j!  A: @  á  A : #6#7X  $   - !    Aq: 	   $   - @ V	  ‰| ( !@@@@@ ( Ak    +  + ¢9  + ! +!   + + "¢ +" +¢†9    ¢  ¢†9  +0! + ! +!	 +8!
 +! + !   +@ +"¢ + + "¢ +" +(¢††9   
 ¢  ¢  ¢††9    ¢  ¢  	¢††9  +`! +@!	 + !
 + ! +h! +H! +! +(! +p! +P! +! +0!   +x +"¢ +X +"¢ + + "¢ +" +8¢†††9    ¢  ¢  ¢  ¢†††9    ¢  ¢  ¢  ¢†††9    ¢ 	 ¢ 
 ¢  ¢†††9 ¢ @@@@@ ( Ak   (   ( Alj  (  ( Alj  à  (   ( Atj  (  ( Atj  à  (   ( Atj  (  ( Atj  à  (   (   à4 @@ (A H  ( A H   (A H   ( A Nú #            	 
  AAå     /" AF  AFÈ©|# A‡k"$  ( "( ! +! A∞j (Ù!@@   G@     è A 6 B 7  A 6  B 7@     è   ˙ $  	  $  	    A‡j$ Ÿ  (  ( (  (#A¡jê   ( (È@@ (@ (  ("E  ( A  AtÕ (AF@  (   (  D        ë (AF@  (   (  D        ë  F@    D        í     D        ìO# Ak"$ @   G@ Aj"      É@ Ñ $  Aj	   Aj$  ß# A0k"$ @@ ( "AK   (G       î Ñ A‘ : /  ( 6(  (6$  9 A6 B 7 A/j A(j" A$j Aj (    Aj" Aj   Ö A0j$ ≈# A0k"$ @@ ( "AG@ (AG     ï (A0M@     ñ A’ : / A‘ : .   (6(  6$  9 B 7  6 A/j A.j A(j" A$j Aj (  Aj Aj  (  ó  ò A0j$ Î# A0k"$ @@ ( "AK   (G   ( "G   (G       ù  ä A‘ : / AŒ : .   ( 6(   (6$  ( "6   9  6  6 B 7 A/j A.j A(j" A$j A j Aj (  Aj (  Aj Aj  (  ã A0j$ Ç| ( !@@@@@ ( Ak    +  + ¢ ¢9  + ! +!   + + "¢ +" +¢† ¢9    ¢  ¢† ¢9  +! + !	 +!
 +(! +! + !   +@ +"¢ +0 + "¢ +" +8¢†† ¢9    ¢  ¢  ¢†† ¢9    ¢ 	 ¢  
¢†† ¢9  +!	 +!
 + ! +! +8! +0! + ! +(! +X! +P! +@! +H!   +x +"¢ +p +"¢ +` + "¢ +" +h¢††† ¢9    ¢  ¢  ¢  ¢††† ¢9    ¢  ¢  ¢  ¢††† ¢9   	 ¢ 
 ¢  ¢  ¢††† ¢9 …| ( !@ ("AG@  ( !  ( !	@ 
" F  ( " At"j!   ( " lAtj!  j+ ! Aj"
! !@  OE@  At"j+ !   lAtj   At"j+ ¢ ¢"9    lAtj  ¢ ¢"9   j 9   j 9  Aj! Aj!  O  	  lAtj j   At"j+ ¢ ¢"9  	  lAtj j 9    (   ô!  (   ¢9 œ| ( "A~q! ( ! (!@  G@    I!   lAtj" At"j!  ( " Atj!   ( " lAtj! !@  F@ Aj!   lAtj!A!A !	D        !D        !@  OE@  At"
j+   
j+ ¢ †!  	At"
j+   
j+ ¢ †! Aj! 	Aj!	   lAtj   G| +   j+ ¢ † † ¢"9   Atj 9  Aj!              	AAöæ|  ( !  ( !A ! @   G@   At"j!    lAtj!  Aj"!@  Aj"  OE@    lAtj+ !  Atj   lAtj+ 9    Atj 9  Aj! !   M  Atj   lAtj j+ 9 ö|  A M@A!@   ME@  At"j+   j+ ¢ †!  At"j+   j+ ¢ †! Aj! Aj!     A~q"G|  At" j+    j+ ¢ † †    õ9|# Ak"$    6 A6 Aj  Aj"    ú Aj$ ¢ @@@@@ ( Ak   (   ( Alj  (  ( Alj  î  (   ( Atj  (  ( Atj  î  (   ( Atj  (  ( Atj  î  (   (   îV|# A∞k"$ #!@@   •!   (AG Aæj¶ $   	   ( +    A∞j$    (   (ÆAsL# A∞k"$ @@@  Ø!   ∞"   ± $  	   A∞j$  ]|@ Aq@@   F   Atj+ ô†! Aj!  @   F   Atj+ ô†! Aj!   f|@ Aq@@   F  Atj+ " ¢ †! Aj!  @   F  Atj+ " ¢ †! Aj!   ü'   B 7   A 6   B 7  A 6   ß  X# A∞k"$  ( "AK#A¶j®@@  ( ©!    A ™ $  	   A∞j$ '   B 7   A 6   B 7  A 6   ¨  ö| (! ( !@@@  A !   A G È E  ( ! @  F   Atj (  (  lAtj ´9  Aj!      A GÈ E  E ( "  ( "FrE@   AtÖ ( ! ( !A! @   F    lAtj!A !@  F@  Aj!   At"j+ "	  j"+ d@  	9  Aj!   ö| A~q!D      ˇ!A!D      ˇ!@  ME@   Atj+ "   c!   Atj+ "   c! Aj! Aj!  G@   Atj+ "   c!    dó# A¿k"$  ( "AK#AÃj®  ( "6∞@   ( G@   A∞j ≠ A 6 B 7  A 6  B 7@  A∞j ≠   ˙ $  	   A¿j$ ≠|   ( ( "( "A A (" È@ ( ( "(E@  ("E  ( A  AtÕ  ( !A !  E@A !@D        !D        !	A!  F@  OE@ Aj!  (   Atj"+ ô†! 	 +ô†!	  Aj!   AkK@  (   Atj+ ô†!  Aj!   Atj 	 †9  Aj!  @   F@A  AM! !A!@A !   F@   F@ Aj!   Atj" +  (  Atj+ ô†9   Aj!  Aj!      At"j (  j+ ô9   Aj!   £|A!@@  K@  + ô"D      d D      crE  +ô"D      d D      crE Aj!  Aj! @ Ak O   + ô"D      d D      cr A A! f   ( 6    (6 (!  A 6    6  B 7  Ñ@  ( " ( "F  ("E    AtÖ  ˙|# Aêk"$ @ (E@  çA! ü  Ñ A‡jAA A∞j"≤!@@@ AA ≤! AŒ : Ø  ( "6®  ("6§  6†  ( 6ú  ( 6ò A 6î@      J"≥  At"6∞ A∞j ¥@ A  (AÄI  B 7 B 7  A6¨ AØj A®j A§j (  A†j  (  (  Aúj (  Aòj  A¨j (¿ Aîjµ (î + "	ôD      ‡Ac@ 	™AÄÄÄÄx" Al    J" Al"  Jj"  H"6¨  6   ∂@ AØj A®j A§j (  A†j  (  (  Aúj (  Aòj ( A¨j (¿ Aîjµ $  ∑	   $  A∞j∏	   $  	   $  	 A  (î ∑E! A∞j∏   Aêj$  /  /AM@  ç  ("@  ( A  AtÕ/   A 6    6   6   B 7    l6  Ñ  - @@@  /     AÈ    A È      AM  A j ∫6#            	 
   Aπ    AM  A j ≤6   ( AO@  ((     AAˇˇˇˇ⁄ß# Ak"$   @  6# Ak" $ AT! (!  A: @   !  A: @#3!  √" Aj6   A :  #4#5X  $   - !    Aq: 	   $   - @ V	   Aj$ q# !@ At"  ($j( "   A(j"¿  ($ j( "E@@   ¡! $  ¬	   ($ Atj 6  ¬  ’  ¨|A!  ( " ( !D      ˇ!  ("AF@ + ô! A~q!A ! @  OE@  Atj+ ô"   Atj+ ô"   c"  c! Aj!  Aj!   G|  Atj+ ô"   c    AA Ÿ¨|A!  ( " ( !D      !  ("AF@ + ô! A~q!A ! @  OE@  Atj+ ô"   Atj+ ô"   d"  d! Aj!  Aj!   G|  Atj+ ô"   d l  ( !  (!A∞A#ƒ"@  ( !  (!  BÄÄÄÄÄÄ¿7   6  6     l6    lAtjA  6  =   A 6   A ;   ;  A 6   6   6     l6  Ñ       «-@  G@   Atj" +  ¢9  Aj!È ( "(!@  ( "AqE@A !  ( " (( "rAqE@@   F   At"j  j+   j+ °9   Aj!   @   F   At"j  j+   j+ °9   Aj!    ( ! (( !A ! @   F   At"j  j+   j+ °9   Aj!   E# Ak"$    6# Ak" (" 6 (#1Aj6   #2Aj6  Aj$   (# Ak"$    6 (" á Aj$   D# Ak"$    6 (" B 7   B 7  B 7  A :   A À Aj$ 
   A¥ÿ$# Ak"$    6 (Ã Aj$ 
   AÿÿM@# j-  Aq@# j( !#"Aîj  j;!  jA:    j 6      ## Ak"$    6# j’ Aj$ X|# A¿k"$  A 6∞  6† A 6p  6`   6   A@k6Ä  6@ AÄjû A¿j$ e# Ak"$ @  E@A !    K#Aà
j≥ A 6 AjA A   t" AˇK  ¥E@ (" ’  Aj$   ˇ #¯ˇ % 	 }}}}    	  	  	          identity Mat::init(): requested size is not compatible with row vector layout Mat::init(): requested size is not compatible with column vector layout as_scalar(): expression must evaluate to exactly one element tinyformat: Not enough format arguments dot(): objects must have the same number of elements norm(): given matrix has non-finite elements class sys.calls _RcppEnsmallen_lin_reg_lbfgs names Cube::slice(): index out of bounds %.*s dataptr vector try-error simpleError C++Error evalq Rcpp stop fro condition addition subtraction matrix multiplication tinyformat: Cannot convert from argument type to integer for use as variable width or precision tinyformat: Not enough arguments to read variable precision dim call Rcpp:longjumpSentinel cppstack tinyformat: Not enough arguments to read variable width tryCatch tinyformat: Too many conversion specifiers in format string tinyformat: Not enough conversion specifiers in format string tinyformat: Conversion spec incorrectly terminated by end of string Mat::init(): mismatch between size of auxiliary memory and requested size Rcpp_precious_preserve Rcpp_precious_remove norm(): unsupported matrix norm type norm(): unsupported vector norm type exitRNGScope enterRNGScope line file demangle arma::memory::acquire(): requested size is too large message rcpp_set_stack_trace rcpp_get_stack_trace Rcpp_stack_trace tinyformat: the %a and %A conversion specs are not supported tinyformat: %n conversion spec not supported Assertion failed Mat::init(): size is fixed and hence cannot be changed integer overflow: matrix dimensions are too large for integer type used by BLAS and LAPACK Mat::init(): requested size is too large; suggest to enable ARMA_64BIT_WORD Cube::init(): requested size is too large; suggest to enable ARMA_64BIT_WORD max(): parameter 'dim' must be 0 or 1 sum(): parameter 'dim' must be 0 or 1 Not a matrix. Not compatible with requested type: [type=%s; target=%s]. c++ exception (unknown reason)  and  : incompatible matrix dimensions:  
warning:  N4Rcpp8internal20InterruptedExceptionE N4Rcpp17LongjumpExceptionE N4Rcpp9exceptionE N4Rcpp8RostreamILb1EEE N4Rcpp8RostreamILb0EEE N4Rcpp10RstreambufILb1EEE N4Rcpp10RstreambufILb0EEE N4Rcpp14not_compatibleE N4Rcpp12not_a_matrixE                          4      O          ï                     $       ò	          ‹ˇˇˇ‹ˇˇˇò	          D	  |	  ê	  X	  $                   ‹ˇˇˇ‹ˇˇˇ                a      $       
          ‹ˇˇˇ‹ˇˇˇ
          ∞	  Ë	  ¸	  ƒ	  $                   ‹ˇˇˇ‹ˇˇˇ                x          P
                                                              è          ú
                                                              ©          √          ®
                  	                  €          ‹
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           @target_features+mutable-globals+sign-ext+exception-handling